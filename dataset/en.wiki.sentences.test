The 1950 s to 1970 s represented the golden age of antibiotic discovery, where countless new classes of antibiotics were discovered to treat previously incurable diseases such as tuberculosis and syphilis.
However, since that time the discovery of new classes of antibiotics has been almost nonexistent, and represents a situation that is especially problematic considering the resiliency of bacteria shown over time and the continued misuse and overuse of antibiotics in treatment.
Without the creation of new and stronger antibiotics an era where common infections and minor injuries can kill, and where complex procedures such as surgery and chemotherapy become too risky, is a very real possibility.
Antimicrobial resistance threatens the world as we know it, and can lead to epidemics of enormous proportions if preventive actions are not taken.
In this day and age current antimicrobial resistance leads to longer hospital stays, higher medical costs, and increased mortality.
Since the mid-1980 s pharmaceutical companies have invested in medications for cancer or chronic disease that have greater potential to make money and have "de-emphasized or dropped development of antibiotics".
On January 20, 2016 at the World Economic Forum in Davos, Switzerland, more than "80 pharmaceutical and diagnostic companies" from around the world called for "transformational commercial models" at a global level to spur research and development on antibiotics and on the "enhanced use of diagnostic tests that can rapidly identify the infecting organism".
Some global health scholars have argued that a global, legal framework is needed to prevent and control antimicrobial resistance.
For instance, binding global policies could be used to create antimicrobial use standards, regulate antibiotic marketing, and strengthen global surveillance systems.
Ensuring compliance of involved parties is a challenge.
Global antimicrobial resistance policies could take lessons from the environmental sector by adopting strategies that have made international environmental agreements successful in the past such as: sanctions for non-compliance, assistance for implementation, majority vote decision-making rules, an independent scientific panel, and specific commitments.
For the United States 2016 budget, U.S. president Barack Obama proposed to nearly double the amount of federal funding to "combat and prevent" antibiotic resistance to more than $ 1.2 billion.
Many international funding agencies like USAID, DFID, SIDA and Bill & Melinda Gates Foundation have pledged money for developing strategies to counter antimicrobial resistance.
On March 27, 2015, the White House released a comprehensive plan to address the increasing need for agencies to combat the rise of antibiotic-resistant bacteria.
The Task Force for Combating Antibiotic-Resistant Bacteria developed "The National Action Plan for Combating Antibiotic-Resistant Bacteria" with the intent of providing a roadmap to guide the US in the antibiotic resistance challenge and with hopes of saving many lives.
This plan outlines steps taken by the Federal government over the next five years needed in order to prevent and contain outbreaks of antibiotic-resistant infections; maintain the efficacy of antibiotics already on the market; and to help to develop future diagnostics, antibiotics, and vaccines.
The Action Plan was developed around five goals with focuses on strengthening health care, public health veterinary medicine, agriculture, food safety and research, and manufacturing.
These goals, as listed by the White House, are as follows: The following are goals set to meet by 2020: According to World Health Organization, policymakers can help tackle resistance by strengthening resistance-tracking and laboratory capacity and by regulating and promoting the appropriate use of medicines.
Policymakers and industry can help tackle resistance by: fostering innovation and research and development of new tools; and promoting cooperation and information sharing among all stakeholders.
It is unclear if rapid viral testing affects antibiotic use in children.
Microorganisms do not develop resistance to vaccines because a vaccine enhances the body's immune system, whereas an antibiotic operates separately from the body's normal defenses.
Furthermore, if the use of vaccines increases, there is evidence that antibiotic resistant strains of pathogens will decrease; the need for antibiotics will naturally decrease as vaccines prevent infection before it occurs.
However, new strains that escape immunity induced by vaccines may evolve; for example, an updated influenza vaccine is needed each year.
While theoretically promising, antistaphylococcal vaccines have shown limited efficacy, because of immunological variation between "Staphylococcus" species, and the limited duration of effectiveness of the antibodies produced.
Development and testing of more effective vaccines is underway.
Alternating therapy is a proposed method in which two or three antibiotics are taken in a rotation versus taking just one antibiotic such that bacteria resistant to one antibiotic are killed when the next antibiotic is taken.
Studies have found that this method reduces the rate at which antibiotic resistant bacteria emerge in vitro relative to a single drug for the entire duration.
Studies have found that bacteria that evolve antibiotic resistance towards one group of antibiotic may become more sensitive to others.
This phenomenon can be utilized to select against resistant bacteria using an approach termed collateral sensitivity cycling, which has recently been found to be relevant in developing treatment strategies for chronic infections caused by "Pseudomonas aeruginosa".
Since the discovery of antibiotics, research and development (R&D) efforts have provided new drugs in time to treat bacteria that became resistant to older antibiotics, but in the 2000 s there has been concern that development has slowed enough that seriously ill people may run out of treatment options.
Another concern is that doctors may become reluctant to perform routine surgeries because of the increased risk of harmful infection.
Backup treatments can have serious side-effects; for example, treatment of multi-drug-resistant tuberculosis can cause deafness or psychological disability.
The potential crisis at hand is the result of a marked decrease in industry R&D.
Poor financial investment in antibiotic research has exacerbated the situation.
The pharmaceutical industry has little incentive to invest in antibiotics because of the high risk and because the potential financial returns are less likely to cover the cost of development than for other pharmaceuticals.
In 2011, Pfizer, one of the last major pharmaceutical companies developing new antibiotics, shut down its primary research effort, citing poor shareholder returns relative to drugs for chronic illnesses.
However, small and medium-sized pharmaceutical companies are still active in antibiotic drug research.
In the United States, drug companies and the administration of President Barack Obama had been proposing changing the standards by which the FDA approves antibiotics targeted at resistant organisms.
On 18 September 2014 Obama signed an executive order to implement the recommendations proposed in a report by the President's Council of Advisors on Science and Technology (PCAST) which outlines strategies to stream-line clinical trials and speed up the R&D of new antibiotics.
Among the proposals: Similar to the situation in malaria therapy, where successful treatments based on ancient recipes have been found, there has already been some success in finding and testing ancient drugs and other treatments that are effective against AMR bacteria.
Distinguishing infections requiring antibiotics from self-limiting ones is clinically challenging.
In order to guid appropriate use of antibiotics and prevent the development and spread of antimicrobial resistance, diagnostic tests that provide clinicians with timely, actionable results are needed.
Acute febrile illness is a common reason for seeking medical care worldwide and a major cause of morbidity and mortality.
In areas with decreasing malaria incidence, many febrile patients are inappropriately treated for malaria, and in the absence of a simple diagnostic test to identify alternative causes of fever, clinicians presume that a non-malarial febrile illness is most likely a bacterial infection, leading to inappropriate use of antibiotics.
Multiple studies have shown that the use of malaria rapid diagnostic tests without reliable tools to distinguish other fever causes has resulted in increased antibiotic use.
Antimicrobial susceptibility testing (AST) can help practitioners avoid prescribing unnecessary antibiotics in the style of precision medicine, and help them prescribe effective antibiotics, but with the traditional approach it could take 12 to 48 hours.
Rapid testing, possible from molecular diagnostics innovations, is defined as "being feasible within an 8-h working shift".
Progress has been slow due to a range of reasons including cost and regulation.
Phage therapy is the therapeutic use of bacteriophages to treat pathogenic bacterial infections.
Phage therapy has many potential applications in human medicine as well as dentistry, veterinary science, and agriculture.
Phage therapy relies on the use of naturally-occurring bacteriophages to infect and lyse bacteria at the site of infection in a host.
Due to current advances in genetics and biotechnology these bacteriophages can possibly be manufactured to treat specific infections.
Phages can be bioengineered to target multidrug-resistant bacterial infections, and their use involves the added benefit of preventing the elimination of beneficial bacteria in the human body.
Phages destroy bacterial cell walls and membrane through the use of lytic proteins which kill bacteria by making many holes from the inside out.
Bacteriophages can even possess the ability to digest the biofilm that many bacteria develop that protect them from antibiotics in order to effectively infect and kill bacteria.
Bioengineering can play a role in creating successful bacteriophages.
Understanding the mutual interactions and evolutions of bacterial and phage populations in the environment of a human or animal body is essential for rational phage therapy.
Bacteriophagics are used against antibiotic resistant bacteria in Georgia (George Eliava Institute) and in one institute in Wrocław, Poland.
Bacteriophage cocktails are common drugs sold over the counter in pharmacies in eastern countries.
In immunology, antigens (Ag) are structures (aka substances) specifically bound by antibodies (Ab) or a cell surface version of Ab ~ B cell antigen receptor (BCR).
The term antigen originally described a structural molecule that binds specifically to an antibody only in the form of native antigen.
It was expanded later to refer to any molecule or a linear molecular fragment after processing the native antigen that can be recognized by T-cell receptor (TCR).
BCR and TCR are both highly variable antigen receptors diversified by somatic V (D) J recombination.
Both T cells and B cells are cellular components of adaptive immunity.
The Ag abbreviation stands for an "antibody generator".
Antigens are "targeted" by antibodies.
Each antibody is specifically produced by the immune system to match an antigen after cells in the immune system come into "contact" with it; this allows a precise identification or matching of the antigen and the initiation of a tailored response.
The antibody is said to "match" the antigen in the sense that it can bind to it due to an adaptation in a region of the antibody; because of this, many different antibodies are produced, each able to bind a different antigen while sharing the same basic structure.
In most cases, an adapted antibody can only react to and bind one specific antigen; in some instances, however, antibodies may cross-react and bind more than one antigen.
Also, an antigen is a molecule that binds to Ag-specific receptors, but cannot necessarily induce an immune response in the body by itself.
Antigens are usually proteins, peptides (amino acid chains) and polysaccharides (chains of monosaccharides/simple sugars) but lipids and nucleic acids become antigens only when combined with proteins and polysaccharides.
In general, saccharides and lipids (as opposed to peptides) qualify as antigens but not as immunogens since they cannot elicit an immune response on their own.
Furthermore, for a peptide to induce an immune response (activation of T-cells by antigen-presenting cells) it must be a large enough size, since peptides too small will also not elicit an immune response.
The antigen may originate from within the body ("self-antigen") or from the external environment ("non-self").
The immune system is supposed to identify and attack "non-self" invaders from the outside world or modified/harmful substances present in the body and usually does not react to self-antigens under normal homeostatic conditions due to negative selection of T cells in the thymus.
Vaccines are examples of antigens in an immunogenic form, which are intentionally administered to a recipient to induce the memory function of adaptive immune system toward the antigens of the pathogen invading that recipient.
Paul Ehrlich coined the term antibody (in German "Antikörper") in his side-chain theory at the end of the 19th century.
In 1899, Ladislas Deutsch (Laszlo Detre) (1874 – 1939) named the hypothetical substances halfway between bacterial constituents and antibodies "substances immunogenes ou antigenes" (antigenic or immunogenic substances).
He originally believed those substances to be precursors of antibodies, just as zymogen is a precursor of an enzyme.
But, by 1903, he understood that an antigen induces the production of immune bodies (antibodies) and wrote that the word "antigen" is a contraction of antisomatogen ("Immunkörperbildner").
The "Oxford English Dictionary" indicates that the logical construction should be "anti (body) - gen".
Antigen presenting cells present antigens in the form of peptides on histocompatibility molecules.
The T cell selectively recognize the antigens; depending on the antigen and the type of the histocompatibility molecule, different types of T cells will be activated.
For T Cell Receptor (TCR) recognition, the peptide must be processed into small fragments inside the cell and presented by a major histocompatibility complex (MHC).
The antigen cannot elicit the immune response without the help of an immunologic adjuvant.
Similarly, the adjuvant component of vaccines plays an essential role in the activation of the innate immune system.
An immunogen is an antigen substance (or adduct) that is able to trigger a humoral (innate) or cell-mediated immune response.
It first initiates an innate immune response, which then causes the activation of the adaptive immune response.
An antigen binds the highly variable immunoreceptor products (B cell receptor or T cell receptor) once these have been generated.
Immunogens are those antigens, termed immunogenic, capable of inducing an immune response.
At the molecular level, an antigen can be characterized by its ability to bind to an antibody's variable Fab region.
Different antibodies have the potential to discriminate among specific epitopes present on the antigen surface.
A hapten is a small molecule that changes the structure of an antigenic epitope.
In order to induce an immune response, it needs to be attached to a large carrier molecule such as a protein (a complex of peptides).
Antigens are usually carried by proteins and polysaccharides, and less frequently, lipids.
This includes parts (coats, capsules, cell walls, flagella, fimbriae, and toxins) of bacteria, viruses, and other microorganisms.
Lipids and nucleic acids are antigenic only when combined with proteins and polysaccharides.
Non-microbial non-self antigens can include pollen, egg white and proteins from transplanted tissues and organs or on the surface of transfused blood cells.
Antigens can be classified according to their source.
Exogenous antigens are antigens that have entered the body from the outside, for example, by inhalation, ingestion or injection.
The immune system's response to exogenous antigens is often subclinical.
By endocytosis or phagocytosis, exogenous antigens are taken into the antigen-presenting cells (APCs) and processed into fragments.
APCs then present the fragments to T helper cells (CD4) by the use of class II histocompatibility molecules on their surface.
Some T cells are specific for the peptide: MHC complex.
They become activated and start to secrete cytokines, substances that activate cytotoxic T lymphocytes (CTL), antibody-secreting B cells, macrophages and other particles.
Some antigens start out as exogenous, and later become endogenous (for example, intracellular viruses).
Intracellular antigens can be returned to circulation upon the destruction of the infected cell.
Endogenous antigens are generated within normal cells as a result of normal cell metabolism, or because of viral or intracellular bacterial infection.
The fragments are then presented on the cell surface in the complex with MHC class I molecules.
If activated cytotoxic CD8 T cells recognize them, the T cells secrete various toxins that cause the lysis or apoptosis of the infected cell.
In order to keep the cytotoxic cells from killing cells just for presenting self-proteins, the cytotoxic cells (self-reactive T cells) are deleted as a result of tolerance (negative selection).
Endogenous antigens include xenogenic (heterologous), autologous and idiotypic or allogenic (homologous) antigens.
Sometimes antigens are part of the host itself in an autoimmune disease.
An autoantigen is usually a normal protein or protein complex (and sometimes DNA or RNA) that is recognized by the immune system of patients suffering from a specific autoimmune disease.
Under normal conditions, these antigens should not be the target of the immune system, but in autoimmune diseases, their associated T cells are not deleted and instead attack.
Neoantigens are those that are entirely absent from the normal human genome.
As compared with nonmutated self-antigens, neoantigens are of relevance to tumor control, as the quality of the T cell pool that is available for these antigens is not affected by central T cell tolerance.
Technology to systematically analyze T cell reactivity against neoantigens became available only recently.
For virus-associated tumors, such as cervical cancer and a subset of head and neck cancers, epitopes derived from viral open reading frames contribute to the pool of neoantigens.
"Tumor antigens" are those antigens that are presented by MHC class I or MHC class II molecules on the surface of tumor cells.
Antigens found only on such cells are called tumor-specific antigens (TSAs) and generally result from a tumor-specific mutation.
More common are antigens that are presented by tumor cells and normal cells, called tumor-associated antigens (TAAs).
Cytotoxic T lymphocytes that recognize these antigens may be able to destroy tumor cells.
Tumor antigens can appear on the surface of the tumor in the form of, for example, a mutated receptor, in which case they are recognized by B cells.
For human tumors without a viral etiology, novel peptides (neo-epitopes) are created by tumor-specific DNA alterations.
A large fraction of human tumor mutations are effectively patient-specific.
Therefore, neoantigens may also be based on individual tumor genomes.
Deep-sequencing technologies can identify mutations within the protein-coding part of the genome (the exome) and predict potential neoantigens.
In mice models, for all novel protein sequences, potential MHC-binding peptides were predicted.
The resulting set of potential neoantigens was used to assess T cell reactivity.
Exome–based analyses were exploited in a clinical setting, to assess reactivity in patients treated by either tumor-infiltrating lymphocyte (TIL) cell therapy or checkpoint blockade.
Neoantigen identification was successful for multiple experimental model systems and human malignancies.
The false-negative rate of cancer exome sequencing is low—i.
e.
: the majority of neoantigens occur within exonic sequence with sufficient coverage.
However, the vast majority of mutations within expressed genes do not produce neoantigens that are recognized by autologous T cells.
As of 2015 mass spectrometry resolution is insufficient to exclude many false positives from the pool of peptides that may be presented by MHC molecules.
Instead, algorithms are used to identify the most likely candidates.
These algorithms consider factors such as the likelihood of proteasomal processing, transport into the endoplasmic reticulum, affinity for the relevant MHC class I alleles and gene expression or protein translation levels.
The majority of human neoantigens identified in unbiased screens display a high predicted MHC binding affinity.
Minor histocompatibility antigens, a conceptually similar antigen class are also correctly identified by MHC binding algorithms.
Another potential filter examines whether the mutation is expected to improve MHC binding.
The nature of the central TCR-exposed residues of MHC-bound peptides is associated with peptide immunogenicity.
A native antigen is an antigen that is not yet processed by an APC to smaller parts.
T cells cannot bind native antigens, but require that they be processed by APCs, whereas B cells can be activated by native ones.
Antigenic specificity is the ability of the host cells to recognize an antigen specifically as a unique molecular entity and distinguish it from another with exquisite precision.
Antigen specificity is due primarily to the side-chain conformations of the antigen.
It is measurable and need not be linear or of a rate-limited step or equation.
An autosome is a chromosome that is not an allosome (a sex chromosome).
The members of an autosome pair in a diploid cell have the same morphology, unlike those in allosome pairs which may have different structures.
The DNA in autosomes is collectively known as atDNA or auDNA.
For example, humans have a diploid genome that usually contains 22 pairs of autosomes and one allosome pair (46 chromosomes total).
The autosome pairs are labeled with numbers (1 – 22 in humans) roughly in order of their sizes in base pairs, while allosomes are labelled with their letters.
By contrast, the allosome pair consists of two X chromosomes in females or one X and one Y chromosome in males.
Unusual combinations of XYY, XXY, XXX, XXXX, XXXXX or XXYY, among other allosome combinations, are known to occur and usually cause developmental abnormalities.
Autosomes still contain sexual determination genes even though they are not sex chromosomes.
For example, the SRY gene on the Y chromosome encodes the transcription factor TDF and is vital for male sex determination during development.
TDF functions by activating the SOX9 gene on chromosome 17, so mutations of the SOX9 gene can cause humans with an ordinary Y chromosome to develop as females.
All human autosomes have been identified and mapped by extracting the chromosomes from a cell arrested in metaphase or prometaphase and then staining them with a type of dye (most commonly, Giemsa).
These chromosomes are typically viewed as karyograms for easy comparison.
Clinical geneticists can compare the karyogram of an individual to a reference karyogram to discover the cytogenetic basis of certain phenotypes.
For example, the karyogram of someone with Patau Syndrome would show that they possess three copies of chromosome 13.
Karyograms and staining techniques can only detect large-scale disruptions to chromosomes—chromosomal aberrations smaller than a few million base pairs generally cannot be seen on a karyogram.
Autosomal genetic disorders can arise due to a number of causes, some of the most common being nondisjunction in parental germ cells or Mendelian inheritance of deleterious alleles from parents.
Autosomal genetic disorders which exhibit Mendelian inheritance can be inherited either in an autosomal dominant or recessive fashion.
These disorders manifest in and are passed on by either sex with equal frequency.
Autosomal dominant disorders are often present in both parent and child, as the child needs to inherit only one copy of the deleterious allele to manifest the disease.
Autosomal recessive diseases, however, require two copies of the deleterious allele for the disease to manifest.
Because it is possible to possess one copy of a deleterious allele without presenting a disease phenotype, two phenotypically normal parents can have a child with the disease if both parents are carriers (also known as heterozygotes) for the condition.
Autosomal aneuploidy can also result in disease conditions.
Aneuploidy of autosomes is not well tolerated and usually results in miscarriage of the developing fetus.
Fetuses with aneuploidy of gene-rich chromosomes—such as chromosome 1—never survive to term, and fetuses with aneuploidy of gene-poor chromosomes—such as chromosome 21 — are still miscarried over 23 % of the time.
Possessing a single copy of an autosome (known as a monosomy) is nearly always incompatible with life, though very rarely some monosomies can survive past birth.
Having three copies of an autosome (known as a trisomy) is far more compatible with life, however.
A common example is Down syndrome, which is caused by possessing three copies of chromosome 21 instead of the usual two.
Partial aneuploidy can also occur as a result of unbalanced translocations during meiosis.
Deletions of part of a chromosome cause partial monosomies, while duplications can cause partial trisomies.
If the duplication or deletion is large enough, it can be discovered by analyzing a karyogram of the individual.
Autosomal translocations can be responsible for a number of diseases, ranging from cancer to schizophrenia.
Unlike single gene disorders, diseases caused by aneuploidy are the result of improper gene dosage, not nonfunctional gene product.
Al-Qaeda (; ',, translation: "The Base", "The Foundation" or "The Database", alternatively spelled al-Qaida and al-Qa ' ida) is a militant Sunni Islamist multi-national organization founded in 1988 by Osama bin Laden, Abdullah Azzam, and several other Arab volunteers during the Soviet–Afghan War.
Al-Qaeda operates as a network of Islamic extremists and Salafist jihadists.
The organization has been designated as a terrorist group by the United Nations Security Council, the North Atlantic Treaty Organization (NATO), the European Union, the United States, the United Kingdom, Russia, India, and various other countries (see below).
Al-Qaeda has mounted attacks on non-military and military targets in various countries, including the 1998 United States embassy bombings, the September 11 attacks, and the 2002 Bali bombings.
The United States government responded to the September 11 attacks by launching the "War on Terror", which sought to undermine al-Qaeda and its allies.
The deaths of key leaders, including that of Osama bin Laden, have led al-Qaeda's operations to shift from the organization and planning of attacks, to the planning of attacks which are carried out by associated groups and "lone-wolf" operators.
Al-Qaeda characteristically employs attacks which include suicide attacks and the simultaneous bombing of several targets.
Activities which are ascribed to al-Qaeda involve the actions of those who have made a pledge of loyalty to bin Laden, or to the actions of "al-Qaeda-linked" individuals who have undergone training in one of its camps in Afghanistan, Pakistan, Iraq or Sudan.
Al-Qaeda ideologues envision the removal of all foreign influences in Muslim countries, and the creation of a new caliphate ruling over the entire Muslim world.
Al-Qaeda members believe in a that a Christian–Jewish alliance is conspiring to destroy Islam.
As Salafist jihadists, members of al-Qaeda believe that the killing of non-combatants is religiously sanctioned.
This belief ignores the aspects of religious scripture which forbid the murder of non-combatants and internecine fighting.
Al-Qaeda also opposes what it regards as man-made laws, and wants to replace them with a strict form of sharia law.
Al-Qaeda has carried out many attacks on targets which it considers "kafir".
Al-Qaeda is also responsible for instigating sectarian violence among Muslims.
Al-Qaeda's leaders regard liberal Muslims, Shias, Sufis and other sects as heretical and its members and sympathizers have attacked their mosques and gatherings.
Examples of sectarian attacks include the Yazidi community bombings, the Sadr City bombings, the Ashoura massacre and the April 2007 Baghdad bombings.
Following the death of bin Laden in 2011, the group has been led by Egyptian Ayman al-Zawahiri.
Al-Qaeda's philosophy calls for the centralization of decision making, while allowing for the decentralization of execution.
However, after the War on Terror, al-Qaeda's leadership has become isolated.
As a result, the leadership has become decentralized, and the organization has become regionalized into several al-Qaeda groups.
Many terrorism experts do not believe that the global jihadist movement is driven at every level by al-Qaeda's leadership.
However, bin Laden held considerable ideological sway over some Muslim extremists before his death.
Experts argue that al-Qaeda has fragmented into a number of disparate regional movements, and that these groups bear little connection with one another.
This view mirrors the account given by Osama bin Laden in his October 2001 interview with Tayseer Allouni: Bruce Hoffman, however, sees al-Qaeda as a cohesive network that is strongly led from the Pakistani tribal areas.
Al-Qaeda has the following direct affiliates: The following are presently believed to be indirect affiliates of al-Qaeda: Al-Qaeda's former affiliates include the following: Osama bin Laden served as the emir of al-Qaeda from the organization's founding in 1988 until his assassination by US forces on May 1, 2011.
Atiyah Abd al-Rahman was alleged to be second in command prior to his death on August 22, 2011.
Bin Laden was advised by a Shura Council, which consists of senior al-Qaeda members.
The group was estimated to consist of 20 – 30 people.
Ayman al-Zawahiri had been al-Qaeda's Deputy Emir and assumed the role of emir following bin Laden's death.
Al-Zawahiri replaced Saif al-Adel, who had served as interim commander.
On June 5, 2012, Pakistani intelligence officials announced that al-Rahman's alleged successor, Abu Yahya al-Libi, had been killed in Pakistan.
Nasir al-Wuhayshi was said to have become second in command in 2013.
He was the leader of al-Qaeda in the Arabian Peninsula (AQAP), until he was killed by a US airstrike in Yemen in June 2015.
Abu Khayr al-Masri, Wuhayshi's alleged successor as the deputy to Ayman al-Zawahiri, was killed by a US airstrike in Syria in February 2017.
Al-Qaeda's network was built from scratch as a conspiratorial network which drew upon the leadership of a number of regional nodes.
The organization divided itself into several committees, which include: Al-Qaeda is not operationally managed by Ayman al-Zawahiri.
Several operational groups exist, which consult with the leadership in situations where attacks are in preparation.
Al-Qaeda is a way of working ...
but this has the hallmark of that approach ...
al-Qaeda clearly has the ability to provide training ...
to provide expertise ...
On August 13, 2005, "The Independent" newspaper, reported that the July 7 bombers had acted independently of an al-Qaeda mastermind.
Nasser al-Bahri, who was Osama bin Laden's bodyguard for four years in the run-up to 9/11 wrote in his memoir a highly detailed description of how the group functioned at that time.
Al-Bahri described al-Qaeda's formal administrative structure and vast arsenal.
However, author Adam Curtis argued that the idea of al-Qaeda as a formal organization is primarily an American invention.
Curtis contended the name "al-Qaeda" was first brought to the attention of the public in the 2001 trial of bin Laden and the four men accused of the 1998 US embassy bombings in East Africa.
Curtis wrote: During the 2001 trial, the US Department of Justice needed to show that bin Laden was the leader of a criminal organization in order to charge him "in absentia" under the Racketeer Influenced and Corrupt Organizations Act.
The name of the organization and details of its structure were provided in the testimony of Jamal al-Fadl, who said he was a founding member of the group and a former employee of bin Laden.
Questions about the reliability of al-Fadl's testimony have been raised by a number of sources because of his history of dishonesty, and because he was delivering it as part of a plea bargain agreement after being convicted of conspiring to attack US military establishments.
Sam Schmidt, a defense attorney who defended al-Fadl said: The number of individuals in the group who have undergone proper military training, and are capable of commanding insurgent forces, is largely unknown.
Documents captured in the raid on bin Laden's compound in 2011 show that the core al-Qaeda membership in 2002 was 170.
In 2006, it was estimated that al-Qaeda had several thousand commanders embedded in 40 different countries.
, it was believed that no more than 200 – 300 members were still active commanders.
According to the 2004 BBC documentary "The Power of Nightmares", al-Qaeda was so weakly linked together that it was hard to say it existed apart from bin Laden and a small clique of close associates.
The lack of any significant numbers of convicted al-Qaeda members, despite a large number of arrests on terrorism charges, was cited by the documentary as a reason to doubt whether a widespread entity that met the description of al-Qaeda existed.
According to author Robert Cassidy, al-Qaeda maintains two separate forces which are deployed alongside insurgents in Iraq and Pakistan.
The first, numbering in the tens of thousands, was "organized, trained, and equipped as insurgent combat forces" in the Soviet–Afghan war.
The force was composed primarily of foreign "mujahideen" from Saudi Arabia and Yemen.
Many of these fighters went on to fight in Bosnia and Somalia for global "jihad".
Another group, which numbered 10,000 in 2006, live in the West and have received rudimentary combat training.
Other analysts have described al-Qaeda's rank and file as being "predominantly Arab" in its first years of operation, but that the organization also includes "other peoples".
It has been estimated that 62 % of al-Qaeda members have university education.
In the 1990 s, financing for al-Qaeda came partly from the personal wealth of Osama bin Laden.
Other sources of income included the heroin trade and donations from supporters in Kuwait, Saudi Arabia and other Islamic Gulf states.
A WikiLeaks-released 2009 internal US government cable stated that "terrorist funding emanating from Saudi Arabia remains a serious concern".
Among the first pieces of evidence regarding Saudi Arabia's support for al-Qaeda was the so-called "Golden Chain", a list of early al-Qaeda funders seized during a 2002 raid in Sarajevo by Bosnian police.
The hand-written list was validated by al-Qaeda defector Jamal al-Fadl, and included the names of both donors and beneficiaries.
Osama bin-Laden's name appeared seven times among the beneficiaries, while 20 Saudi and Gulf-based businessmen and politicians were listed among the donors.
Notable donors included Adel Batterjee, and Wael Hamza Julaidan.
Batterjee was designated as a terror financier by the US Department of the Treasury in 2004, and Julaidan is recognized as one of al-Qaeda's founders.
Documents seized during the 2002 Bosnia raid showed that al-Qaeda widely exploited charities to channel financial and material support to its operatives across the globe.
Notably, this activity exploited the International Islamic Relief Organization (IIRO) and the Muslim World League (MWL).
The IIRO had ties with al-Qaeda associates worldwide, including al-Qaeda's deputy Ayman al Zawahiri.
Zawahiri's brother worked for the IIRO in Albania and had actively recruited on behalf of al-Qaeda.
The MWL was openly identified by al-Qaeda's leader as one of the three charities al-Qaeda primarily relied upon for funding sources.
Several Qatari citizens have been accused of funding al-Qaeda.
This includes Abd Al-Rahman al-Nuaimi, a Qatari citizen and a human-rights activist who founded the Swiss-based non-governmental organization (NGO) Alkarama.
On December 18, 2013, the US Treasury designated Nuaimi as a terrorist for his activities supporting al-Qaeda.
The US Treasury has stated that Nuaimi "has facilitated significant financial support to al-Qaeda in Iraq, and served as an interlocutor between al-Qaeda in Iraq and Qatar-based donors".
Nuaimi was accused of overseeing a $ 2 million monthly transfer to al-Qaeda in Iraq as part of his role as mediator between Iraq-based al-Qaeda senior officers and Qatari citizens.
Nuaimi allegedly entertained relationships with Abu-Khalid al-Suri, al-Qaeda's top envoy in Syria, who processed a $ 600,000 transfer to al-Qaeda in 2013.
Nuaimi is also known to be associated with Abd al-Wahhab Muhammad ' Abd al-Rahman al-Humayqani, a Yemeni politician and founding member of Alkarama, who was listed as a Specially Designated Global Terrorist (SDGT) by the US Treasury in 2013.
The US authorities claimed that Humayqani exploited his role in Alkarama to fundraise on behalf of al-Qaeda in the Arabian Peninsula (AQAP).
A prominent figure in AQAP, Nuaimi was also reported to have facilitated the flow of funding to AQAP affiliates based in Yemen.
Nuaimi was also accused of investing funds in the charity directed by Humayqani to ultimately fund AQAP.
About ten months after being sanctioned by the US Treasury, Nuaimi was also restrained from doing business in the UK.
Another Qatari citizen, Kalifa Mohammed Turki Subayi, was sanctioned by the US Treasury on June 5, 2008, for his activities as a "Gulf-based al-Qaeda financier".
Subayi's name was added to the UN Security Council's Sanctions List in 2008 on charges of providing financial and material support to al-Qaeda senior leadership.
Subayi allegedly moved al-Qaeda recruits to South Asia-based training camps.
He also financially supported Khalid Sheikh Mohammed, a Pakistani national and senior al-Qaeda officer who is believed to be the mastermind behind the September 11 attack according to the September 11 Commission report.
Qataris provided support to al-Qaeda through the country's largest NGO, the Qatar Charity.
Al-Qaeda defector al-Fadl, who was a former member of Qatar Charity, testified in court that Abdullah Mohammed Yusef, who served as Qatar Charity's director, was affiliated to al-Qaeda and simultaneously to the National Islamic Front, a political group that gave al-Qaeda leader Osama Bin Laden harbor in Sudan in the early 1990 s.
Legal proceedings from the trial "United States vs. Enaam M. Arnaout" revealed that Qatar Charity was cited by Bin Laden in 1993 as one of the charities used to channel financial support to al-Qaeda operatives overseas.
The same documents also report Bin Laden's complaint that the failed assassination attempt of Egyptian President Hosni Mubarak had compromised the ability of al-Qaeda to exploit charities to support its operatives to the extent that it was capable of before 1995.
It is alleged that the Qatar Charity gave financial support to members of al-Qaeda in Chechnya.
This accusation was publicly denied by Hamad bin Nasser al-Thani.
Qatar Charity is among the NGOs allegedly channelling funds to Ansar Dine in North Mali, according to French military intelligence reports from France's intervention in the country in early 2013.
Qatar finances al-Qaeda's enterprises through al-Qaeda's affiliate in Syria, Jabhat al-Nusra.
The funding is primarily channeled through kidnapping for ransom.
The Consortium Against Terrorist Finance (CATF) reported that the Gulf country has funded al-Nusra since 2013.
Al-Awsat estimated that Qatar disbursed $ 25 million in support of al-Nusra through kidnapping for ransom.
In addition, Qatar has launched fundraising campaigns on behalf of al-Nusra.
Al-Nusra acknowledged a Qatar-sponsored campaign "as one of the preferred conduits for donations intended for the group".
In the disagreement over whether Al-Qaeda's objectives are religious or political, Mark Sedgwick describes Al-Qaeda's strategy as political in the immediate term but with ultimate aims that are religious.
On March 11, 2005, "Al-Quds Al-Arabi" published extracts from Saif al-Adel's document "Al Qaeda's Strategy to the Year 2020".
Abdel Bari Atwan summarizes this strategy as comprising five stages to rid the Ummah from all forms of oppression: Atwan noted that, while the plan is unrealistic, "it is sobering to consider that this virtually describes the downfall of the Soviet Union."
According to Fouad Hussein, a Jordanian journalist and author who has spent time in prison with Al-Zarqawi, Al Qaeda's strategy consists of seven phases and is similar to the plan described in Al Qaeda's Strategy to the year 2020.
These phases include: According to the seven-phase strategy, the war is projected to last less than two years.
According to Charles Lister of the Middle East Institute and Katherine Zimmerman of the American Enterprise Institute, the new model of al-Qaeda is to "socialize communities" and build a broad territorial base of operations with the support of local communities, also gaining income independent of the funding of sheiks.
The initial "al -" is the Arabic definite article "the", hence "the base".
However, since two of the Arabic consonants in the name are not phones found in the English language, the common naturalized English pronunciations include, and.
Al-Qaeda's name can also be transliterated as "al-Qaida", "al-Qa ' ida", or "el-Qaida".
Bin Laden explained the origin of the term in a videotaped interview with Al Jazeera journalist Tayseer Alouni in October 2001: It has been argued that two documents seized from the Sarajevo office of the Benevolence International Foundation prove that the name was not simply adopted by the "mujahideen" movement and that a group called al-Qaeda was established in August 1988.
Both of these documents contain minutes of meetings held to establish a new military group, and contain the term "al-Qaeda".
Former British Foreign Secretary Robin Cook wrote that the word al-Qaeda should be translated as "the database", because it originally referred to the computer file of the thousands of "mujahideen" militants who were recruited and trained with CIA help to defeat the Russians.
In April 2002, the group assumed the name "Qa'idat al-Jihad" (""), which means "the base of Jihad".
According to Diaa Rashwan, this was "apparently as a result of the merger of the overseas branch of Egypt's al-Jihad, which was led by Ayman al-Zawahiri, with the groups Bin Laden brought under his control after his return to Afghanistan in the mid-1990 s."
The radical Islamist movement developed during the Islamic revival and the rise of the Islamist movement after the Iranian revolution.
Some have argued that the writings of Islamic author and thinker Sayyid Qutb, inspired the al-Qaeda organization.
In the 1950 s and 1960 s, Qutb preached that because of the lack of "sharia" law, the Muslim world was no longer Muslim, and had reverted to the pre-Islamic ignorance known as "jahiliyyah".
To restore Islam, Qutb argued that a vanguard of righteous Muslims was needed in order to establish "true Islamic states", implement "sharia", and rid the Muslim world of any non-Muslim influences.
In Qutb's view, the enemies of Islam included "world Jewry", which "plotted conspiracies" and opposed Islam.
In the words of Mohammed Jamal Khalifa, a close college friend of bin Laden: Qutb also influenced bin Laden's mentor, Ayman al-Zawahiri.
Zawahiri's uncle and maternal family patriarch, Mafouz Azzam, was Qutb's student, protégé, personal lawyer, and an executor of his estate.
Azzam was one of the last people to see Qutb alive before his execution.
Zawahiri paid homage to Qutb in his work "Knights under the Prophet's Banner."
Qutb's argued that many Muslims were not true Muslims.
Some Muslims, Qutb argued, were apostates.
These alleged apostates included leaders of Muslim countries, since they failed to enforce "sharia" law.
The Afghan jihad against the pro-Soviet government further developed the Salafist Jihadist movement which inspired Al-Qaeda.
Abdel Bari Atwan wrote that: Following its 9/11 attack and in response to its condemnation by Islamic scholars, Al-Qaeda provided a justification for the killing of non-combatants/civilians, entitled, "A Statement from Qaidat al-Jihad Regarding the Mandates of the Heroes and the Legality of the Operations in New York and Washington".
According to a couple of critics, Quintan Wiktorowicz and John Kaltner, its provides "ample theological justification for killing civilians in almost any imaginable situation."
Among these justifications are that America is leading the west in waging a War on Islam so that attacks on America are a defense of Islam and any treaties and agreements between Muslim majority states and Western countries that would be violated by attacks are null and void.
According to the tract, several conditions allow for the killing of civilians including: "The Guardian" in 2009 described five distinct phases in the development of al-Qaeda: its beginnings in the late 1980 s, a "wilderness" period in 1990 – 1996, its "heyday" in 1996 – 2001, a network period from 2001 to 2005, and a period of fragmentation from 2005 to 2009.
The origins of al-Qaeda can be traced to the Soviet War in Afghanistan (December 1979 – February 1989).
The United States viewed the conflict in Afghanistan in terms of the Cold War, with Marxists on one side and the native Afghan "mujahideen" on the other.
This view led to a CIA program called Operation Cyclone, which channeled funds through Pakistan's Inter-Services Intelligence agency to the Afghan Mujahideen.
The US government provided substantial financial support to the Afghan Islamic militants.
Aid to Gulbuddin Hekmatyar, an Afghan "mujahideen" leader and founder of the Hezb-e Islami, amounted to more than $ 600 million.
In addition to American aid, Hekmatyar was the recipient of Saudi aid.
In the early 1990 s, after the US had withdrawn support, Hekmatyar "worked closely" with bin Laden.
At the same time, a growing number of Arab "mujahideen" joined the "jihad" against the Afghan Marxist regime, which was facilitated by international Muslim organizations, particularly the Maktab al-Khidamat (MAK).
In 1984, MAK was established in Peshawar, Pakistan, by bin Laden and Abdullah Yusuf Azzam, a Palestinian Islamic scholar and member of the Muslim Brotherhood.
MAK organized guest houses in Peshawar, near the Afghan border, and gathered supplies for the construction of paramilitary training camps to prepare foreign recruits for the Afghan war front.
MAK was funded by the Saudi government as well as by individual Muslims including Saudi businessmen.
Bin Laden also became a major financier of the "mujahideen", spending his own money and using his connections to influence public opinion about the war.
From 1986, MAK began to set up a network of recruiting offices in the US, the hub of which was the Al Kifah Refugee Center at the Farouq Mosque on Brooklyn's Atlantic Avenue.
Among notable figures at the Brooklyn center were "double agent" Ali Mohamed, whom FBI special agent Jack Cloonan called "bin Laden's first trainer", and "Blind Sheikh" Omar Abdel-Rahman, a leading recruiter of "mujahideen" for Afghanistan.
Azzam and bin Laden began to establish camps in Afghanistan in 1987.
MAK and foreign "mujahideen" volunteers, or "Afghan Arabs", did not play a major role in the war.
While over 250,000 Afghan "mujahideen" fought the Soviets and the communist Afghan government, it is estimated that were never more than 2,000 foreign "mujahideen" on the field at any one time.
Nonetheless, foreign "mujahideen" volunteers came from 43 countries, and the total number that participated in the Afghan movement between 1982 and 1992 is reported to have been 35,000.
Bin Laden played a central role in organizing training camps for the foreign Muslim volunteers.
The Soviet Union withdrew from Afghanistan in 1989.
Mohammad Najibullah's Communist Afghan government lasted for three more years, before it was overrun by elements of the "mujahideen".
Toward the end of the Soviet military mission in Afghanistan, some foreign "mujahideen" wanted to expand their operations to include Islamist struggles in other parts of the world, such as Palestine and Kashmir.
A number of overlapping and interrelated organizations were formed, to further those aspirations.
One of these was the organization that would eventually be called al-Qaeda.
Research suggests that al-Qaeda was formed on August 11, 1988, when a meeting between leaders of Egyptian Islamic Jihad, Abdullah Azzam, and bin Laden took place.
An agreement was reached to link bin Laden's money with the expertise of the Islamic Jihad organization and take up the jihadist cause elsewhere after the Soviets withdrew from Afghanistan.
Notes indicate al-Qaeda was a formal group by August 20, 1988.
A list of requirements for membership itemized the following: listening ability, good manners, obedience, and making a pledge ("bayat") to follow one's superiors.
In his memoir, bin Laden's former bodyguard, Nasser al-Bahri, gives the only publicly available description of the ritual of giving "bayat" when he swore his allegiance to the al-Qaeda chief.
According to Wright, the group's real name was not used in public pronouncements because "its existence was still a closely held secret."
After Azzam was assassinated in 1989 and MAK broke up, significant numbers of MAK followers joined bin Laden's new organization.
In November 1989, Ali Mohamed, a former special forces sergeant stationed at Fort Bragg, North Carolina, left military service and moved to California.
He traveled to Afghanistan and Pakistan and became "deeply involved with bin Laden's plans."
In 1991, Ali Mohammed is said to have helped orchestrate bin Laden's relocation to Sudan.
Following the Soviet Union's withdrawal from Afghanistan in February 1989, bin Laden returned to Saudi Arabia.
The Iraqi invasion of Kuwait in August 1990 had put the Kingdom and its ruling House of Saud at risk.
The world's most valuable oil fields were within striking distance of Iraqi forces in Kuwait, and Saddam's call to pan-Arab/Islamism could potentially rally internal dissent.
In the face of a seemingly massive Iraqi military presence, Saudi Arabia's own forces were outnumbered.
Bin Laden offered the services of his "mujahideen" to King Fahd to protect Saudi Arabia from the Iraqi army.
The Saudi monarch refused bin Laden's offer, opting instead to allow US and allied forces to deploy troops into Saudi territory.
The deployment angered bin Laden, as he believed the presence of foreign troops in the "land of the two mosques" (Mecca and Medina) profaned sacred soil.
After speaking publicly against the Saudi government for harboring American troops, he was banished and forced to live in exile in Sudan.
From around 1992 to 1996, al-Qaeda and bin Laden based themselves in Sudan at the invitation of Islamist theoretician Hassan al-Turabi.
The move followed an Islamist coup d'état in Sudan, led by Colonel Omar al-Bashir, who professed a commitment to reordering Muslim political values.
During this time, bin Laden assisted the Sudanese government, bought or set up various business enterprises, and established training camps.
A key turning point for bin Laden occurred in 1993 when Saudi Arabia gave support for the Oslo Accords, which set a path for peace between Israel and Palestinians.
Due to bin Laden's continuous verbal assault on King Fahd of Saudi Arabia, Fahd sent an emissary to Sudan on March 5, 1994 demanding bin Laden's passport.
Bin Laden's Saudi citizenship was also revoked.
His family was persuaded to cut off his stipend, $ 7 million a year, and his Saudi assets were frozen.
His family publicly disowned him.
There is controversy as to what extent bin Laden continued to garner support from members afterwards.
In 1993, a young schoolgirl was killed in an unsuccessful attempt on the life of the Egyptian prime minister, Atef Sedki.
Egyptian public opinion turned against Islamist bombings, and the police arrested 280 of al-Jihad's members and executed 6.
In June 1995, an attempt to assassinate Egyptian president Mubarak led to the expulsion of Egyptian Islamic Jihad (EIJ), and in May 1996, of bin Laden from Sudan.
According to Pakistani-American businessman Mansoor Ijaz, the Sudanese government offered the Clinton Administration numerous opportunities to arrest bin Laden.
Ijaz's claims appeared in numerous op-ed pieces, including one in the "Los Angeles Times" and one in "The Washington Post" co-written with former Ambassador to Sudan Timothy M. Carney.
Similar allegations have been made by "Vanity Fair" contributing editor David Rose, and Richard Miniter, author of "Losing bin Laden", in a November 2003 interview with "World".
Several sources dispute Ijaz's claim, including the 9/11 Commission, which concluded in part: After the fall of the Afghan communist regime in 1992, Afghanistan was effectively ungoverned for four years and plagued by constant infighting between various "mujahideen" groups.
This situation allowed the Taliban to organize.
The Taliban also garnered support from graduates of Islamic schools, which are called "madrassa".
According to Ahmed Rashid, five leaders of the Taliban were graduates of Darul Uloom Haqqania, a madrassa in the small town of Akora Khattak.
The town is situated near Peshawar in Pakistan, but the school is largely attended by Afghan refugees.
This institution reflected Salafi beliefs in its teachings, and much of its funding came from private donations from wealthy Arabs.
Four of the Taliban's leaders attended a similarly funded and influenced madrassa in Kandahar.
Bin Laden's contacts were laundering donations to these schools, and Islamic banks were used to transfer money to an "array" of charities which served as front groups for al-Qaeda.
Many of the "mujahideen" who later joined the Taliban fought alongside Afghan warlord Mohammad Nabi Mohammadi's Harkat i Inqilabi group at the time of the Russian invasion.
This group also enjoyed the loyalty of most Afghan Arab fighters.
The continuing lawlessness enabled the growing and well-disciplined Taliban to expand their control over territory in Afghanistan, and it came to establish an enclave which it called the Islamic Emirate of Afghanistan.
In 1994, it captured the regional center of Kandahar, and after making rapid territorial gains thereafter, the Taliban captured the capital city Kabul in September 1996.
In 1996, Taliban-controlled Afghanistan provided a perfect staging ground for al-Qaeda.
While not officially working together, Al-Qaeda enjoyed the Taliban's protection and supported the regime in such a strong symbiotic relationship that many Western observers dubbed the Taliban's Islamic Emirate of Afghanistan as, "the world's first terrorist-sponsored state."
However, at this time, only Pakistan, Saudi Arabia, and the United Arab Emirates recognized the Taliban as the legitimate government of Afghanistan.
While in Afghanistan, the Taliban government tasked al-Qaeda with the training of Brigade 055, an elite element of the Taliban's army.
The Brigade mostly consisted of foreign fighters, veterans from the Soviet Invasion, and adherents to the ideology of the mujahideen.
In November 2001, as Operation Enduring Freedom had toppled the Taliban government, many Brigade 055 fighters were captured or killed, and those that survived were thought to have escaped into Pakistan along with bin Laden.
By the end of 2008, some sources reported that the Taliban had severed any remaining ties with al-Qaeda, however, there is reason to doubt this.
According to senior US military intelligence officials, there were fewer than 100 members of al-Qaeda remaining in Afghanistan in 2009.
Al Qaeda chief, Asim Omar was killed in Afghanistan's Musa Qala district after a joint U.S. - Afghanistan commando airstrike on September 23, Afghan's National Directorate of Security (NDS) confirmed in October 2019.
In 1994, the Salafi groups waging Salafi jihadism in Bosnia entered into decline, and groups such as the Egyptian Islamic Jihad began to drift away from the Salafi cause in Europe.
Al-Qaeda stepped in and assumed control of around 80 % of non-state armed cells in Bosnia in late 1995.
At the same time, al-Qaeda ideologues instructed the network's recruiters to look for "Jihadi international" Muslims who believed that extremist - "jihad" must be fought on a global level.
Al-Qaeda also sought to open the "offensive phase" of the global Salafi "jihad".
Bosnian Islamists in 2006 called for "solidarity with Islamic causes around the world", supporting the insurgents in Kashmir and Iraq as well as the groups fighting for a Palestinian state.
In 1996, al-Qaeda announced its "jihad" to expel foreign troops and interests from what they considered Islamic lands.
Bin Laden issued a "fatwa", which amounted to a public declaration of war against the US and its allies, and began to refocus al-Qaeda's resources on large-scale, propagandist strikes.
On February 23, 1998, bin Laden and Ayman al-Zawahiri, a leader of Egyptian Islamic Jihad, along with three other Islamist leaders, co-signed and issued a "fatwa" calling on Muslims to kill Americans and their allies.
Under the banner of the World Islamic Front for Combat Against the Jews and Crusaders, they declared: Neither bin Laden nor al-Zawahiri possessed the traditional Islamic scholarly qualifications to issue a "fatwa".
However, they rejected the authority of the contemporary "ulema" (which they saw as the paid servants of "jahiliyya" rulers), and took it upon themselves.
Al-Qaeda has launched attacks against the Iraqi Shia majority in an attempt to incite sectarian violence.
Al-Zarqawi purportedly declared an all-out war on Shiites while claiming responsibility for Shiite mosque bombings.
The same month, a statement claiming to be from Al-Qaeda in Iraq was rejected as a "fake".
In a December 2007 video, al-Zawahiri defended the Islamic State in Iraq, but distanced himself from the attacks against civilians, which he deemed to be perpetrated by "hypocrites and traitors existing among the ranks".
US and Iraqi officials accused Al-Qaeda in Iraq of trying to slide Iraq into a full-scale civil war between Iraq's Shiite population and Sunni Arabs.
This was done through an orchestrated campaign of civilian massacres and a number of provocative attacks against high-profile religious targets.
With attacks including the 2003 Imam Ali Mosque bombing, the 2004 Day of Ashura and Karbala and Najaf bombings, the 2006 first al-Askari Mosque bombing in Samarra, the deadly single-day series of bombings in which at least 215 people were killed in Baghdad's Shiite district of Sadr City, and the second al-Askari bombing in 2007, Al-Qaeda in Iraq provoked Shiite militias to unleash a wave of retaliatory attacks, resulting in death squad-style killings and further sectarian violence which escalated in 2006.
In 2008, sectarian bombings blamed on al-Qaeda in Iraq killed at least 42 people at the Imam Husayn Shrine in Karbala in March, and at least 51 people at a bus stop in Baghdad in June.
In February 2014, after a prolonged dispute with al-Qaeda in Iraq's successor organisation, the Islamic State of Iraq and the Levant (ISIS), al-Qaeda publicly announced it was cutting all ties with the group, reportedly for its brutality and "notorious intractability".
In Somalia, al-Qaeda agents had been collaborating closely with its Somali wing, which was created from the al-Shabaab group.
In February 2012, al-Shabaab officially joined al-Qaeda, declaring loyalty in a video.
Somalian al-Qaeda recruited children for suicide-bomber training, recruited young people to participate in militant actions against Americans.
The percentage of attacks in the First World originating from the Afghanistan–Pakistan (AfPak) border declined starting in 2007, as al-Qaeda shifted to Somalia and Yemen.
While al-Qaeda leaders were hiding in the tribal areas along the AfPak border, middle-tier leaders heightened activity in Somalia and Yemen.
In January 2009, al-Qaeda's division in Saudi Arabia merged with its Yemeni wing to form al-Qaeda in the Arabian Peninsula (AQAP).
Centered in Yemen, the group takes advantage of the country's poor economy, demography and domestic security.
In August 2009, the group made an assassination attempt against a member of the Saudi royal family.
President Obama asked Ali Abdullah Saleh to ensure closer cooperation with the US in the struggle against the growing activity of al-Qaeda in Yemen, and promised to send additional aid.
The wars in Iraq and Afghanistan, drew US attention from Somalia and Yemen.
In December 2011, US Secretary of Defense Leon Panetta said that the US operations against al-Qaeda "are now concentrating on key groups in Yemen, Somalia and North Africa."
Al-Qaeda in the Arabian Peninsula claimed responsibility for the 2009 bombing attack on Northwest Airlines Flight 253 by Umar Farouk Abdulmutallab.
The AQAP declared the Al-Qaeda Emirate in Yemen on March 31, 2011, after capturing the most of the Abyan Governorate.
As the Saudi-led military intervention in Yemen escalated in July 2015, 50 civilians were killed, and 20 million were in need of aid.
In February 2016, al-Qaeda forces and Saudi Arabian-led coalition forces were both seen fighting Houthi rebels in the same battle.
In December 1998, the Director of the CIA Counterterrorism Center reported to President Bill Clinton that al-Qaeda was preparing to launch attacks in the United States, and that the group was training personnel to hijack aircraft.
On September 11, 2001, al-Qaeda attacked the United States, hijacking four airliners within the country and deliberately crashing two into the twin towers of the World Trade Center in New York City.
The third plane crashed into the western side of the Pentagon in Arlington County, Virginia.
The fourth plane was crashed into a field in Shanksville, Pennsylvania.
In total, the attackers killed 2,977 victims and injured more than 6,000 others.
US officials noted that Anwar al-Awlaki had considerable reach within the US.
A former FBI agent identified Awlaki as a known "senior recruiter for al-Qaeda", and a spiritual motivator.
Awlaki's sermons in the US were attended by three of the 9/11 hijackers, and accused Fort Hood shooter Nidal Malik Hasan.
US intelligence intercepted emails from Hasan to Awlaki between December 2008 and early 2009.
On his website, Awlaki has praised Hasan's actions in the Fort Hood shooting.
An unnamed official claimed there was good reason to believe Awlaki "has been involved in very serious terrorist activities since leaving the US [in 2002], including plotting attacks against America and our allies."
US President Barack Obama approved the targeted killing of al-Awlaki by April 2010, making al-Awlaki the first US citizen ever placed on the CIA target list.
That required the consent of the US National Security Council, and officials argued that the attack was appropriate because the individual posed an imminent danger to national security.
In May 2010, Faisal Shahzad, who pleaded guilty to the 2010 Times Square car bombing attempt, told interrogators he was "inspired by" al-Awlaki, and sources said Shahzad had made contact with al-Awlaki over the Internet.
Representative Jane Harman called him "terrorist number one", and "Investor's Business Daily" called him "the world's most dangerous man".
In July 2010, the US Treasury Department added him to its list of Specially Designated Global Terrorists, and the UN added him to its list of individuals associated with al-Qaeda.
In August 2010, al-Awlaki's father initiated a lawsuit against the US government with the American Civil Liberties Union, challenging its order to kill al-Awlaki.
In October 2010, US and UK officials linked al-Awlaki to the 2010 cargo plane bomb plot.
In September 2011, al-Awlaki was killed in a targeted killing drone attack in Yemen.
On March 16, 2012, it was reported that Osama bin Laden plotted to kill US President Barack Obama.
On May 1, 2011, US President Barack Obama announced that Osama bin Laden had been killed by "a small team of Americans" acting under direct orders, in a covert operation in Abbottabad, Pakistan.
The action took place north of Islamabad.
According to US officials, a team of 20 – 25 US Navy SEALs under the command of the Joint Special Operations Command stormed bin Laden's compound with two helicopters.
Bin Laden and those with him were killed during a firefight in which US forces experienced no casualties.
According to one US official the attack was carried out without the knowledge or consent of the Pakistani authorities.
In Pakistan some people were reported to be shocked at the unauthorized incursion by US armed forces.
The site is a few miles from the Pakistan Military Academy in Kakul.
In his broadcast announcement President Obama said that US forces "took care to avoid civilian casualties."
Details soon emerged that three men and a woman were killed along with bin Laden, the woman being killed when she was "used as a shield by a male combatant".
DNA from bin Laden's body, compared with DNA samples on record from his dead sister, confirmed bin Laden's identity.
The body was recovered by the US military and was in its custody until, according to one US official, his body was buried at sea according to Islamic traditions.
One US official stated that "finding a country willing to accept the remains of the world's most wanted terrorist would have been difficult."
US State Department issued a "Worldwide caution" for Americans following bin Laden's death and US diplomatic facilities everywhere were placed on high alert, a senior US official said.
Crowds gathered outside the White House and in New York City's Times Square to celebrate bin Laden's death.
In 2003, President Bashar al-Assad revealed in an interview with a Kuwaiti newspaper that he doubted that al-Qaeda even existed.
Was it in Afghanistan?
Following the mass protests that took place in 2011, which demanded the resignation of al-Assad, al-Qaeda affiliated groups and Sunni sympathizers soon began to constitute an effective fighting force against al-Assad.
Before the Syrian Civil War, al-Qaeda's presence in Syria was negligible, but its growth thereafter was rapid.
Groups such as the al-Nusra Front and the Islamic State of Iraq and the Levant have recruited many foreign Mujahideen to train and fight in what has gradually become a highly sectarian war.
Ideologically, the Syrian Civil War has served the interests of al-Qaeda as it pits a mainly Sunni opposition against a Shia government.
Al-Qaeda and other fundamentalist Sunni militant groups have invested heavily in the civil conflict, actively backing and supporting the Syrian Opposition.
On February 2, 2014, al-Qaeda distanced itself from ISIS and its actions in Syria, however during 2014 – 15, ISIS and the al-Qaeda-linked al-Nusra Front were still able to occasionally cooperate in their fight against the Syrian government.
Al-Nusra (backed by Saudi Arabia and Turkey as part of the Army of Conquest during 2015 – 2017) launched many attacks and bombings, mostly against targets affiliated with or supportive of the Syrian government.
From October 2015, Russian air strikes targeted positions held by al-Nusra Front, as well as other Islamist and non-Islamist rebels, while the US also targeted al-Nusra with airstrikes.
In early 2016, a leading ISIL ideologue described al-Qaeda as the "Jews of jihad".
In September 2014 al-Zawahiri announced al-Qaeda was establishing a front in India to "wage jihad against its enemies, to liberate its land, to restore its sovereignty, and to revive its Caliphate."
Al-Zawahiri nominated India as a beachhead for regional jihad taking in neighboring countries such as Myanmar and Bangladesh.
The motivation for the video was questioned, as it appeared the militant group was struggling to remain relevant in light of the emerging prominence of ISIS.
The new wing was to be known as "Qaedat al-Jihad fi'shibhi al-qarrat al-Hindiya" or al-Qaida in the Indian Subcontinent (AQIS).
Leaders of several Indian Muslim organizations rejected al-Zawahiri's pronouncement, saying they could see no good coming from it, and viewed it as a threat to Muslim youth in the country.
In 2014 "Zee News" reported that Bruce Riede (a former CIA analyst and National Security Council official for South Asia) accused the Pakistan military intelligence—Inter-Services Intelligence (ISI) — of organising and assisting Al-Qaeda to organise in India, that Pakistan ought to be warned that it will be placed on the list of State Sponsors of Terrorism, and wrote that "Zawahiri made the tape in his hideout in Pakistan, no doubt, and many Indians suspect the ISI is helping to protect him".
Al-Qaeda has carried out a total of six major attacks, four of them in its jihad against America.
In each case the leadership planned the attack years in advance, arranging for the shipment of weapons and explosives and using its businesses to provide operatives with safehouses and false identities.
Al-Qaeda usually does not disburse funds for attacks, and very rarely makes wire transfers.
On December 29, 1992, al-Qaeda's launched its first attack, the 1992 Yemen hotel bombings.
Two bombs were detonated in Aden, Yemen.
The first target was the Movenpick Hotel and the second was the parking lot of the Goldmohur Hotel.
The bombings were an attempt to eliminate American soldiers on their way to Somalia to take part in the international famine relief effort, Operation Restore Hope.
Internally, al-Qaeda considered the bombing a victory that frightened the Americans away, but in the US, the attack was barely noticed.
No American soldiers were killed because no soldiers were staying in the hotel which was bombed.
However, an Australian tourist and a Yemeni hotel worker were killed in the bombing.
Seven others, mostly Yemenis, were severely injured.
Two fatwas are said to have been appointed by al-Qaeda's members, Mamdouh Mahmud Salim, to justify the killings according to Islamic law.
Salim referred to a famous fatwa appointed by Ibn Taymiyyah, a 13th - century scholar much admired by Wahhabis, which sanctioned resistance by any means during the Mongol invasions.
In 1996, bin Laden personally engineered a plot to assassinate United States President Bill Clinton while the president was in Manila for the Asia-Pacific Economic Cooperation.
However, intelligence agents intercepted a message before the motorcade was to leave, and alerted the US Secret Service.
Agents later discovered a bomb planted under a bridge.
On August 7, 1998, al-Qaeda bombed the US embassies in East Africa, killing 224 people, including 12 Americans.
In retaliation, a barrage of cruise missiles launched by the US military devastated an al-Qaeda base in Khost, Afghanistan.
The network's capacity was unharmed.
In late 1999 and 2000, Al-Qaeda planned attacks to coincide with the millennium, masterminded by Abu Zubaydah and involving Abu Qatada, which would include the bombing of Christian holy sites in Jordan, the bombing of Los Angeles International Airport by Ahmed Ressam, and the bombing of the.
On October 12, 2000, al-Qaeda militants in Yemen bombed the missile destroyer "USS Cole" in a suicide attack, killing 17 US servicemen and damaging the vessel while it lay offshore.
Inspired by the success of such a brazen attack, al-Qaeda's command core began to prepare for an attack on the US itself.
The September 11 attacks on America by al-Qaeda killed 2,977 people — 2,507 civilians, 343 firefighters, 72 law enforcement officers, and 55 military personnel.
Two commercial airliners were deliberately flown into the twin towers of the World Trade Center, a third into the Pentagon, and a fourth, originally intended to target either the United States Capitol or the White House, crashed in a field in Stonycreek Township near Shanksville, Pennsylvania.
It was also the deadliest foreign attack on American soil since the Japanese attack on Pearl Harbor on December 7, 1941.
The attacks were conducted by al-Qaeda, acting in accord with the 1998 "fatwa" issued against the US and its allies by persons under the command of bin Laden, al-Zawahiri, and others.
Evidence points to suicide squads led by al-Qaeda military commander Mohamed Atta as the culprits of the attacks, with bin Laden, Ayman al-Zawahiri, Khalid Sheikh Mohammed, and Hambali as the key planners and part of the political and military command.
Messages issued by bin Laden after September 11, 2001, praised the attacks, and explained their motivation while denying any involvement.
Bin Laden legitimized the attacks by identifying grievances felt by both mainstream and Islamist Muslims, such as the general perception that the US was actively oppressing Muslims.
Bin Laden asserted that America was massacring Muslims in "Palestine, Chechnya, Kashmir and Iraq" and that Muslims should retain the "right to attack in reprisal."
He also claimed the 9/11 attacks were not targeted at people, but "America's icons of military and economic power," despite the fact he planned to attack in the morning when most of the people in the intended targets were present and thus generating the maximum number of human casualties.
Evidence has since come to light that the original targets for the attack may have been nuclear power stations on the US East Coast.
The targets were later altered by al-Qaeda, as it was feared that such an attack "might get out of hand".
Al-Qaeda is deemed a designated terrorist group by the following countries and international organizations: In the immediate aftermath of the 9/11 attacks, the US government responded, and began to prepare its armed forces to overthrow the Taliban, which it believed was harboring al-Qaeda.
The US offered Taliban leader Mullah Omar a chance to surrender bin Laden and his top associates.
The first forces to be inserted into Afghanistan were paramilitary officers from the CIA's elite Special Activities Division (SAD).
The Taliban offered to turn over bin Laden to a neutral country for trial if the US would provide evidence of bin Laden's complicity in the attacks.
Soon thereafter the US and its allies invaded Afghanistan, and together with the Afghan Northern Alliance removed the Taliban government as part of the war in Afghanistan.
As a result of the US special forces and air support for the Northern Alliance ground forces, a number of Taliban and al-Qaeda training camps were destroyed, and much of the operating structure of al-Qaeda is believed to have been disrupted.
After being driven from their key positions in the Tora Bora area of Afghanistan, many al-Qaeda fighters tried to regroup in the rugged Gardez region of the nation.
By early 2002, al-Qaeda had been dealt a serious blow to its operational capacity, and the Afghan invasion appeared to be a success.
Nevertheless, a significant Taliban insurgency remained in Afghanistan.
Debate continued regarding the nature of al-Qaeda's role in the 9/11 attacks.
The US State Department released a videotape showing bin Laden speaking with a small group of associates somewhere in Afghanistan shortly before the Taliban was removed from power.
Although its authenticity has been questioned by a couple of people, the tape definitively implicates bin Laden and al-Qaeda in the September 11 attacks.
The tape was aired on many television channels, with an accompanying English translation provided by the US Defense Department.
In September 2004, the 9/11 Commission officially concluded that the attacks were conceived and implemented by al-Qaeda operatives.
In October 2004, bin Laden appeared to claim responsibility for the attacks in a videotape released through Al Jazeera, saying he was inspired by Israeli attacks on high-rises in the 1982 invasion of Lebanon: "As I looked at those demolished towers in Lebanon, it entered my mind that we should punish the oppressor in kind and that we should destroy towers in America in order that they taste some of what we tasted and so that they be deterred from killing our women and children."
By the end of 2004, the US government proclaimed that two-thirds of the most senior al-Qaeda figures from 2001 had been captured and interrogated by the CIA: Abu Zubaydah, Ramzi bin al-Shibh and Abd al-Rahim al-Nashiri in 2002; Khalid Sheikh Mohammed in 2003; and Saif al Islam el Masry in 2004.
Mohammed Atef and several others were killed.
The West was criticized for not being able to handle Al-Qaida despite a decade of the war.
Al-Qaeda involvement in Africa has included a number of bombing attacks in North Africa, while supporting parties in civil wars in Eritrea and Somalia.
From 1991 to 1996, bin Laden and other al-Qaeda leaders were based in Sudan.
Islamist rebels in the Sahara calling themselves al-Qaeda in the Islamic Maghreb have stepped up their violence in recent years.
French officials say the rebels have no real links to the al-Qaeda leadership, but this has been disputed.
It seems likely that bin Laden approved the group's name in late 2006, and the rebels "took on the al Qaeda franchise label", almost a year before the violence began to escalate.
In Mali, the Ansar Dine faction was also reported as an ally of al-Qaeda in 2013.
The Ansar al Dine faction aligned themselves with the AQIM.
Following the Libyan Civil War, the removal of Gaddafi and the ensuing period of post-civil war violence in Libya, various Islamist militant groups affiliated with al-Qaeda were able to expand their operations in the region.
The 2012 Benghazi attack, which resulted in the death of US Ambassador J. Christopher Stevens and three other Americans, is suspected of having been carried out by various Jihadist networks, such as Al-Qaeda in the Islamic Maghreb, Ansar al-Sharia and several other Al-Qaeda affiliated groups.
The capture of Nazih Abdul-Hamed al-Ruqai, a senior al-Qaeda operative wanted by the United States for his involvement in the 1998 United States embassy bombings, on October 5, 2013, by US Navy Seals, FBI and CIA agents illustrates the importance the US and other Western allies have placed on North Africa.
Prior to the September 11 attacks, al-Qaeda was present in Bosnia and Herzegovina, and its members were mostly veterans of the El Mudžahid detachment of the Bosnian Muslim Army of the Republic of Bosnia and Herzegovina.
Three al-Qaeda operatives carried out the Mostar car bombing in 1997.
The operatives were closely linked to and financed by the Saudi High Commission for Relief of Bosnia and Herzegovina founded by then-prince King Salman of Saudi Arabia.
Before the 9/11 attacks and the US invasion of Afghanistan, westerners who had been recruits at al-Qaeda training camps were sought after by al-Qaeda's military wing.
Language skills and knowledge of Western culture were generally found among recruits from Europe, such was the case with Mohamed Atta, an Egyptian national studying in Germany at the time of his training, and other members of the Hamburg Cell.
Osama bin Laden and Mohammed Atef would later designate Atta as the ringleader of the 9/11 hijackers.
Following the attacks, Western intelligence agencies determined that al-Qaeda cells operating in Europe had aided the hijackers with financing and communications with the central leadership based in Afghanistan.
In 2003, Islamists carried out a series of bombings in Istanbul killing fifty-seven people and injuring seven hundred.
Seventy-four people were charged by the Turkish authorities.
Some had previously met bin Laden, and though they specifically declined to pledge allegiance to al-Qaeda they asked for its blessing and help.
In 2009, three Londoners, Tanvir Hussain, Assad Sarwar and Ahmed Abdullah Ali, were convicted of conspiring to detonate bombs disguised as soft drinks on seven airplanes bound for Canada and the US The MI5 investigation regarding the plot involved more than a year of surveillance work conducted by over two hundred officers.
British and US officials said the plot – unlike many similar homegrown European Islamic militant plots – was directly linked to al-Qaeda and guided by senior al-Qaeda members in Pakistan.
In 2012, Russian Intelligence indicated that al-Qaeda had given a call for "forest jihad" and has been starting massive forest fires as part of a strategy of "thousand cuts".
Following Yemeni unification in 1990, Wahhabi networks began moving missionaries into the country.
Although it is unlikely that bin Laden or Saudi al-Qaeda were directly involved, the personal connections they made would be established over the next decade and used in the USS "Cole" bombing.
Concerns grew over Al Qaeda's group in Yemen.
In Iraq, al-Qaeda forces loosely associated with the leadership were embedded in the Jama'at al-Tawhid wal-Jihad group commanded by Abu Musab al-Zarqawi.
Specializing in suicide operations, they have been a "key driver" of the Sunni insurgency.
Although they played a small part in the overall insurgency, between 30 % and 42 % of all suicide bombings which took place in the early years were claimed by Zarqawi's group.
Reports have indicated that oversights such as the failure to control access to the Qa'qaa munitions factory in Yusufiyah have allowed large quantities of munitions to fall into the hands of al-Qaida.
In November 2010, the militant group Islamic State of Iraq, which is linked to al-Qaeda in Iraq, threatened to "exterminate all Iraqi Christians".
Al-Qaeda did not begin training Palestinians until the late 1990 s.
Large groups such as Hamas and Palestinian Islamic Jihad have rejected an alliance with al-Qaeda, fearing that al-Qaeda will co-opt their cells.
This may have changed recently.
The Israeli security and intelligence services believe that al-Qaeda has managed to infiltrate operatives from the Occupied Territories into Israel, and is waiting for an opportunity to attack.
, Saudi Arabia, Qatar and Turkey are openly supporting the Army of Conquest, an umbrella rebel group fighting in the Syrian Civil War against the Syrian government that reportedly includes an al-Qaeda linked al-Nusra Front and another Salafi coalition known as Ahrar al-Sham.
Bin Laden and Ayman al-Zawahiri consider India to be a part of an alleged Crusader-Zionist-Hindu conspiracy against the Islamic world.
According to a 2005 report by the Congressional Research Service, bin Laden was involved in training militants for Jihad in Kashmir while living in Sudan in the early 1990 s.
By 2001, Kashmiri militant group Harkat-ul-Mujahideen had become a part of the al-Qaeda coalition.
According to the United Nations High Commissioner for Refugees (UNHCR), al-Qaeda was thought to have established bases in Pakistan administered Kashmir (in Azad Kashmir, and to some extent in Gilgit–Baltistan) during the 1999 Kargil War and continued to operate there with tacit approval of Pakistan's Intelligence services.
Many of the militants active in Kashmir were trained in the same madrasahs as Taliban and al-Qaeda.
Fazlur Rehman Khalil of Kashmiri militant group Harkat-ul-Mujahideen was a signatory of al-Qaeda's 1998 declaration of Jihad against America and its allies.
In a ' Letter to American People ' (2002), bin Laden wrote that one of the reasons he was fighting America was because of its support to India on the Kashmir issue.
In November 2001, Kathmandu airport went on high alert after threats that bin Laden planned to hijack a plane and crash it into a target in New Delhi.
In 2002, US Secretary of Defense Donald Rumsfeld, on a trip to Delhi, suggested that al-Qaeda was active in Kashmir though he did not have any evidence.
Rumsfeld proposed hi-tech ground sensors along the Line of Control to prevent militants from infiltrating into Indian-administered Kashmir.
An investigation in 2002 found evidence that al-Qaeda and its affiliates were prospering in Pakistan-administered Kashmir with tacit approval of Pakistan's Inter-Services Intelligence.
In 2002, a special team of Special Air Service and Delta Force was sent into Indian-Administered Kashmir to hunt for bin Laden after receiving reports that he was being sheltered by Kashmiri militant group Harkat-ul-Mujahideen, which had been responsible for kidnapping western tourists in Kashmir in 1995.
Britain's highest-ranking al-Qaeda operative Rangzieb Ahmed had previously fought in Kashmir with the group Harkat-ul-Mujahideen and spent time in Indian prison after being captured in Kashmir.
US officials believe that al-Qaeda was helping organize attacks in Kashmir in order to provoke conflict between India and Pakistan.
Their strategy was to force Pakistan to move its troops to the border with India, thereby relieving pressure on al-Qaeda elements hiding in northwestern Pakistan.
In 2006 al-Qaeda claimed they had established a wing in Kashmir.
However Indian Army General H.S. Panag argued that the army had ruled out the presence of al-Qaeda in Indian-administered Jammu and Kashmir.
Panag also stated that al-Qaeda had strong ties with Kashmiri militant groups Lashkar-e-Taiba and Jaish-e-Mohammed based in Pakistan.
It has been noted that Waziristan has become a battlefield for Kashmiri militants fighting NATO in support of al-Qaeda and Taliban.
Dhiren Barot, who wrote the "Army of Madinah in Kashmir" and was an al-Qaeda operative convicted for involvement in the 2004 financial buildings plot, had received training in weapons and explosives at a militant training camp in Kashmir.
Maulana Masood Azhar, the founder of Kashmiri group Jaish-e-Mohammed, is believed to have met bin Laden several times and received funding from him.
In 2002, Jaish-e-Mohammed organized the kidnapping and murder of Daniel Pearl in an operation run in conjunction with al-Qaeda and funded by bin Laden.
According to American counter-terrorism expert Bruce Riedel, al-Qaeda and Taliban were closely involved in the 1999 hijacking of Indian Airlines Flight 814 to Kandahar which led to the release of Maulana Masood Azhar and Ahmed Omar Saeed Sheikh from an Indian prison.
This hijacking, Riedel stated, was rightly described by then Indian Foreign Minister Jaswant Singh as a ' dress rehearsal ' for September 11 attacks.
Bin Laden personally welcomed Azhar and threw a lavish party in his honor after his release.
Ahmed Omar Saeed Sheikh, who had been in prison for his role in the 1994 kidnappings of Western tourists in India, went on to murder Daniel Pearl and was sentenced to death in Pakistan.
Al-Qaeda operative Rashid Rauf, who was one of the accused in 2006 transatlantic aircraft plot, was related to Maulana Masood Azhar by marriage.
Lashkar-e-Taiba, a Kashmiri militant group which is thought to be behind 2008 Mumbai attacks, is also known to have strong ties to senior al-Qaeda leaders living in Pakistan.
In late 2002, top al-Qaeda operative Abu Zubaydah was arrested while being sheltered by Lashkar-e-Taiba in a safe house in Faisalabad.
The FBI believes that al-Qaeda and Lashkar have been ' intertwined ' for a long time while the CIA has said that al-Qaeda funds Lashkar-e-Taiba.
In a video released in 2008, American-born senior al-Qaeda operative Adam Yahiye Gadahn stated that "victory in Kashmir has been delayed for years; it is the liberation of the jihad there from this interference which, Allah willing, will be the first step towards victory over the Hindu occupiers of that Islam land."
In September 2009, a US drone strike reportedly killed Ilyas Kashmiri who was the chief of Harkat-ul-Jihad al-Islami, a Kashmiri militant group associated with al-Qaeda.
Kashmiri was described by Bruce Riedel as a ' prominent ' al-Qaeda member while others have described him as head of military operations for al-Qaeda.
Kashmiri was also charged by the US in a plot against Jyllands-Posten, the Danish newspaper which was at the center of Jyllands-Posten Muhammad cartoons controversy.
US officials also believe that Kashmiri was involved in the Camp Chapman attack against the CIA.
In January 2010, Indian authorities notified Britain of an al-Qaeda plot to hijack an Indian airlines or Air India plane and crash it into a British city.
This information was uncovered from interrogation of Amjad Khwaja, an operative of Harkat-ul-Jihad al-Islami, who had been arrested in India.
In January 2010, US Defense secretary Robert Gates, while on a visit to Pakistan, stated that al-Qaeda was seeking to destabilize the region and planning to provoke a nuclear war between India and Pakistan.
Al-Qaeda and its successors have migrated online to escape detection in an atmosphere of increased international vigilance.
The group's use of the Internet has grown more sophisticated, with online activities that include financing, recruitment, networking, mobilization, publicity, and information dissemination, gathering and sharing.
Abu Ayyub al-Masri's al-Qaeda movement in Iraq regularly releases short videos glorifying the activity of jihadist suicide bombers.
In addition, both before and after the death of Abu Musab al-Zarqawi (the former leader of al-Qaeda in Iraq), the umbrella organization to which al-Qaeda in Iraq belongs, the Mujahideen Shura Council, has a regular presence on the Web.
The range of multimedia content includes guerrilla training clips, stills of victims about to be murdered, testimonials of suicide bombers, and videos that show participation in jihad through stylized portraits of mosques and musical scores.
A website associated with al-Qaeda posted a video of captured American entrepreneur Nick Berg being decapitated in Iraq.
Other decapitation videos and pictures, including those of Paul Johnson, Kim Sun-il, and Daniel Pearl, were first posted on jihadist websites.
In December 2004 an audio message claiming to be from bin Laden was posted directly to a website, rather than sending a copy to al Jazeera as he had done in the past.
Al-Qaeda turned to the Internet for release of its videos in order to be certain they would be available unedited, rather than risk the possibility of al Jazeera editing out anything critical of the Saudi royal family.
Alneda.
com and Jehad.
net were perhaps the most significant al-Qaeda websites.
Alneda was initially taken down by American Jon Messner, but the operators resisted by shifting the site to various servers and strategically shifting content.
The US government charged a British information technology specialist, Babar Ahmad, with terrorist offences related to his operating a network of English-language al-Qaeda websites, such as Azzam.
com.
He was convicted and sentenced to 12-and - a-half years in prison.
In 2007, al-Qaeda released "Mujahedeen Secrets", encryption software used for online and cellular communications.
A later version, "Mujahideen Secrets 2", was released in 2008.
Al-Qaeda is believed to be operating a clandestine aviation network including "several Boeing 727 aircraft", turboprops and executive jets, according to a 2010 Reuters story.
Based on a US Department of Homeland Security report, the story said that al-Qaeda is possibly using aircraft to transport drugs and weapons from South America to various unstable countries in West Africa.
A Boeing 727 can carry up to 10 tons of cargo.
The drugs eventually are smuggled to Europe for distribution and sale, and the weapons are used in conflicts in Africa and possibly elsewhere.
Gunmen with links to al-Qaeda have been increasingly kidnapping Europeans for ransom.
The profits from the drug and weapon sales, and kidnappings can, in turn, fund more militant activities.
The following is a list of military conflicts in which Al-Qaeda and its direct affiliates have taken part militarily.
Somali Civil War Africa Somalia Al-Shabaab Civil war in Afghanistan (1992 – 1996) Asia Islamic State of Afghanistan Al-Qaeda Central Al-Qaeda insurgency in Yemen Asia Yemen Al-Qaeda in the Arabian Peninsula Civil war in Afghanistan (1996 – 2001) Asia Islamic Emirate of Afghanistan Al-Qaeda Central War in Afghanistan (2001–present) Asia Afghanistan Al-Qaeda Central Insurgency in the Maghreb (2002–present) Africa AlgeriaChadMaliMauritaniaMoroccoNigerTunisia Al-Qaeda in the Islamic Maghreb Iraq War Asia Iraq Al-Qaeda in Iraq Islamic State of Iraq War in North-West Pakistan Asia Pakistan Al-Qaeda Central Insurgency in the North Caucasus Asia Russia Caucasus Emirate Syrian Civil War Asia Syria al-Nusra Front Saudi Arabian-led intervention in Yemen Asia Yemen Al-Qaeda in the Arabian Peninsula Experts debate the notion al-Qaeda attacks were an indirect result from the American CIA's Operation Cyclone program to help the Afghan mujahideen.
Robin Cook, British Foreign Secretary from 1997 to 2001, has written that al-Qaeda and bin Laden were "a product of a monumental miscalculation by western security agencies", and that "Al-Qaida, literally ' the database ', was originally the computer file of the thousands of mujahideen who were recruited and trained with help from the CIA to defeat the Russians."
Munir Akram, Permanent Representative of Pakistan to the United Nations from 2002 to 2008, wrote in a letter published in "The New York Times" on January 19, 2008: A variety of sources, including CNN journalist Peter Bergen, Pakistani ISI Brigadier Mohammad Yousaf, and CIA operatives involved in the Afghan program, such as Vincent Cannistraro, deny that the CIA or other American officials had contact with the foreign mujahideen or bin Laden, let alone armed, trained, coached or indoctrinated them.
Bergen and others argue that there was no need to recruit foreigners unfamiliar with the local language, customs or lay of the land since there were a quarter of a million local Afghans willing to fight.
Bergen further argues that foreign mujahideen had no need for American funds since they received several million dollars per year from internal sources.
Lastly, he argues that Americans could not have trained the mujahideen because Pakistani officials would not allow more than a handful of them to operate in Pakistan and none in Afghanistan, and that the Afghan Arabs were almost invariably militant Islamists reflexively hostile to Westerners whether or not the Westerners were helping the Muslim Afghans.
[is] a folk myth. There's no evidence of this ...
Bin Laden had his own money, he was anti-American and he was operating secretly and independently ...
Jason Burke also wrote: CNN report has revealed that Saudi Arabia and the United Arab Emirates (UAE) have been handing out sophisticated American-made weapons to al-Qaeda-linked fighters in Yemen.
In October 2014, US Vice President Joe Biden stated that Turkey, Saudi Arabia and the United Arab Emirates had "poured hundreds of millions of dollars and tens of thousands of tons of weapons into anyone who would fight against Al-Assad, except that the people who were being supplied were al-Nusra, and al Qaeda, and the extremist elements of jihadis coming from other parts of the world."
Anders Behring Breivik, the perpetrator of the 2011 Norway attacks, was inspired by Al-Qaeda, calling it "the most successful revolutionary movement in the world."
While admitting different aims, he sought to "create a European version of Al-Qaida."
Islamic extremism dates back to the Kharijites of the 7th century.
From their essentially political position, the Kharijites developed extreme doctrines that set them apart from both mainstream Sunni and Shiʿa Muslims.
The Kharijites were particularly noted for adopting a radical approach to Takfir, whereby they declared other Muslims to be unbelievers and therefore deemed them worthy of death.
According to a number of sources, a "wave of revulsion" has been expressed against al-Qaeda and its affiliates by "religious scholars, former fighters and militants" who are alarmed by al-Qaeda's takfir and its killing of Muslims in Muslim countries, especially in Iraq.
Noman Benotman, a former Afghan Arab and a militant member of the Libyan Islamic Fighting Group (LIFG), went public with an open letter of criticism to Ayman al-Zawahiri in November 2007, after persuading the imprisoned senior leaders of his former group to enter into peace negotiations with the Libyan regime.
While Ayman al-Zawahiri announced the affiliation of the group with al-Qaeda in November 2007, the Libyan government released 90 members of the group from prison several months after "they were said to have renounced violence."
In 2007, on the anniversary of the September 11 attacks, the Saudi sheikh Salman al-Ouda delivered a personal rebuke to bin Laden.
Al-Ouda, a religious scholar and one of the fathers of the Sahwa, the fundamentalist awakening movement that swept through Saudi Arabia in the 1980 s, is a widely respected critic of jihadism.
Al-Ouda addressed al-Qaeda's leader on television asking him: According to Pew polls, support for al-Qaeda had dropped in the Muslim world in the years before 2008.
Support of suicide bombings in Indonesia, Lebanon, and Bangladesh, dropped by half or more in the last five years.
In Saudi Arabia, only 10 percent had a favorable view of al-Qaeda, according to a December 2017 poll by Terror Free Tomorrow, a Washington-based think tank.
Although once associated with al-Qaeda, in September 2009 LIFG completed a new "code" for jihad, a 417-page religious document entitled "Corrective Studies".
Given its credibility and the fact that several other prominent Jihadists in the Middle East have turned against al-Qaeda, the LIFG's reversal may be an important step toward staunching al-Qaeda's recruitment.
Bilal Abdul Kareem, an American journalist based in Syria created a documentary about al-Shabab, al-Qaeda's affiliate in Somalia.
The documentary included interviews with former members of the group who stated their reasons for leaving al-Shabab.
The members made accusations of segregation, lack of religious awareness and internal corruption and favoritism.
In response to Kareem, the Global Islamic Media Front condemned Kareem, called him a liar, and denied the accusations from the former fighters.
In mid-2014 after the Islamic State of Iraq and the Levant declared that they had restored the Caliphate, an audio statement was released by the then-spokesman of the group Abu Muhammad al-Adnani claiming that "the legality of all emirates, groups, states, and organizations, becomes null by the expansion of the Caliphate's authority".
The speech included a religious refutation of Al-Qaeda for being too lenient regarding Shiites and their refusal to recognize the authority Abu Bakr al-Baghdadi, al-Adnani specifically noting: "It is not suitable for a state to give allegiance to an organization".
He also recalled a past instance in which Osama bin Laden called on al-Qaeda members and supporters to give allegiance to Abu Omar al-Baghdadi when the group was still solely operating in Iraq, as the Islamic State of Iraq, and condemned Ayman al-Zawahiri for not making this same claim for Abu Bakr al-Baghdadi, and that Zawahiri was encouraging factionalism and division between former allies of ISIL such as the al-Nusra Front.
Publications:
Alessandro Giuseppe Antonio Anastasio Volta (; 18 February 1745 – 5 March 1827) was an Italian physicist, chemist, and pioneer of electricity and power who is credited as the inventor of the electric battery and the discoverer of methane.
He invented the Voltaic pile in 1799, and reported the results of his experiments in 1800 in a two-part letter to the President of the Royal Society.
With this invention Volta proved that electricity could be generated chemically and debunked the prevalent theory that electricity was generated solely by living beings.
Volta's invention sparked a great amount of scientific excitement and led others to conduct similar experiments which eventually led to the development of the field of electrochemistry.
Volta also drew admiration from Napoleon Bonaparte for his invention, and was invited to the Institute of France to demonstrate his invention to the members of the Institute.
Volta enjoyed a certain amount of closeness with the emperor throughout his life and he was conferred numerous honours by him.
Volta held the chair of experimental physics at the University of Pavia for nearly 40 years and was widely idolised by his students.
Despite his professional success, Volta tended to be a person inclined towards domestic life and this was more apparent in his later years.
At this time he tended to live secluded from public life and more for the sake of his family until his eventual death in 1827 from a series of illnesses which began in 1823.
The SI unit of electric potential is named in his honour as the volt.
Volta was born in Como, a town in present-day northern Italy, on 18 February 1745.
In 1794, Volta married an aristocratic lady also from Como, Teresa Peregrini, with whom he raised three sons: Zanino, Flaminio, and Luigi.
His father, Filippo Volta, was of noble lineage.
His mother, Donna Maddalena, came from the family of the Inzaghis.
In 1774, he became a professor of physics at the Royal School in Como.
A year later, he improved and popularised the electrophorus, a device that produced static electricity.
His promotion of it was so extensive that he is often credited with its invention, even though a machine operating on the same principle was described in 1762 by the Swedish experimenter Johan Wilcke.
In 1777, he travelled through Switzerland.
There he befriended H. B. de Saussure.
In the years between 1776 and 1778, Volta studied the chemistry of gases.
He researched and discovered methane after reading a paper by Benjamin Franklin of the United States on "flammable air".
In November 1776, he found methane at Lake Maggiore, and by 1778 he managed to isolate methane.
He devised experiments such as the ignition of methane by an electric spark in a closed vessel.
Volta also studied what we now call electrical capacitance, developing separate means to study both electrical potential ("V") and charge ("Q"), and discovering that for a given object, they are proportional.
This is called Volta's Law of Capacitance, and for this work the unit of electrical potential has been named the volt.
In 1779 he became a professor of experimental physics at the University of Pavia, a chair that he occupied for almost 40 years.
Luigi Galvani, an Italian physicist, discovered something he named, "animal electricity" when two different metals were connected in series with a frog's leg and to one another.
Volta realised that the frog's leg served as both a conductor of electricity (what we would now call an electrolyte) and as a detector of electricity.
He also understood that the frog's legs were irrelevant to the electric current, which was caused by the two differing metals.
He replaced the frog's leg with brine-soaked paper, and detected the flow of electricity by other means familiar to him from his previous studies.
In this way he discovered the electrochemical series, and the law that the electromotive force (emf) of a galvanic cell, consisting of a pair of metal electrodes separated by electrolyte, is the difference between their two electrode potentials (thus, two identical electrodes and a common electrolyte give zero net emf).
This may be called Volta's Law of the electrochemical series.
In 1800, as the result of a professional disagreement over the galvanic response advocated by Galvani, Volta invented the voltaic pile, an early electric battery, which produced a steady electric current.
Volta had determined that the most effective pair of dissimilar metals to produce electricity was zinc and copper.
Initially he experimented with individual cells in series, each cell being a wine goblet filled with brine into which the two dissimilar electrodes were dipped.
The voltaic pile replaced the goblets with cardboard soaked in brine.
In announcing his discovery of the voltaic pile, Volta paid tribute to the influences of William Nicholson, Tiberius Cavallo, and Abraham Bennet.
The battery made by Volta is credited as one of the first electrochemical cells.
It consists of two electrodes: one made of zinc, the other of copper.
The electrolyte is either sulfuric acid mixed with water or a form of saltwater brine.
The electrolyte exists in the form 2H and SO.
The zinc, which is higher in the electrochemical series than both copper and hydrogen, reacts with the negatively charged sulfate (SO).
The positively charged hydrogen ions (protons) capture electrons from the copper, forming bubbles of hydrogen gas, H. This makes the zinc rod the negative electrode and the copper rod the positive electrode.
Thus, there are two terminals, and an electric current will flow if they are connected.
The chemical reactions in this voltaic cell are as follows: The copper does not react, but rather it functions as an electrode for the electric current.
However, this cell also has some disadvantages.
It is unsafe to handle, since sulfuric acid, even if diluted, can be hazardous.
Also, the power of the cell diminishes over time because the hydrogen gas is not released.
Instead, it accumulates on the surface of the copper electrode and forms a barrier between the metal and the electrolyte solution.
In 1809 Volta became associated member of the Royal Institute of the Netherlands.
In honour of his work, Volta was made a count by Napoleon Bonaparte in 1810.
Volta retired in 1819 to his estate in Camnago, a frazione of Como, Italy, now named "Camnago Volta" in his honour.
He died there on 5 March 1827, just after his 82nd birthday.
Volta's remains were buried in Camnago Volta.
Volta's legacy is celebrated by the Tempio Voltiano memorial located in the public gardens by the lake.
There is also a museum which has been built in his honour, which exhibits some of the equipment that Volta used to conduct experiments.
Nearby stands the Villa Olmo, which houses the Voltian Foundation, an organization promoting scientific activities.
Volta carried out his experimental studies and produced his first inventions near Como.
His image was depicted on the Italian 10,000 lire note (1990 – 1997) along with a sketch of his voltaic pile.
In late 2017, Nvidia announced a new workstation-focused microarchitecture called Volta, succeeding Pascal and preceding Turing.
The first graphics cards featuring Volta were released in December 2017, with two more cards releasing over the course of 2018.
Volta was raised as a Catholic and for all of his life continued to maintain his belief.
Because he was not ordained a clergyman as his family expected, he was sometimes accused of being irreligious and some people have speculated about his possible unbelief, stressing that "he did not join the Church", or that he virtually "ignored the church's call".
Nevertheless, he cast out doubts in a declaration of faith in which he said: I do not understand how anyone can doubt the sincerity and constancy of my attachment to the religion which I profess, the Roman, Catholic and Apostolic religion in which I was born and brought up, and of which I have always made confession, externally and internally.
I have, indeed, and only too often, failed in the performance of those good works which are the mark of a Catholic Christian, and I have been guilty of many sins: but through the special mercy of God I have never, as far as I know, wavered in my faith ...
In this faith I recognise a pure gift of God, a supernatural grace; but I have not neglected those human means which confirm belief, and overthrow the doubts which at times arise.
I studied attentively the grounds and basis of religion, the works of apologists and assailants, the reasons for and against, and I can say that the result of such study is to clothe religion with such a degree of probability, even for the merely natural reason, that every spirit unperverted by sin and passion, every naturally noble spirit must love and accept it.
May this confession which has been asked from me and which I willingly give, written and subscribed by my own hand, with authority to show it to whomsoever you will, for I am not ashamed of the Gospel, may it produce some good fruit!
Argo Navis (the Ship Argo), or simply Argo, was a large constellation in the southern sky that has since been divided into the three constellations of Carina, Puppis and Vela.
The genitive was "Argus Navis", abbreviated "Arg".
Flamsteed and other early modern astronomers called the constellation just Navis (the Ship), genitive "Navis", abbreviated "Nav".
It was identified in Greek mythology with the "Argo", the ship used by Jason and the Argonauts that sailed to Colchis in search of the Golden Fleece.
The original constellation is presently found near the southern horizon of the Mediterranean sky, becoming visible in springtime and sailed westward, skimming along the "river of the Milky Way."
Due to precession of the equinoxes, many of the stars of Argo have been shifted farther south since Classical times, and far fewer of its stars are visible today from the latitudes of the Mediterranean.
This includes its brightest 1st - magnitude star, Canopus or α Carinae.
All the stars of Argo Navis are easily visible south of the equator, and pass near zenith from southern temperate latitudes.
Argo Navis was long-known to Greek observers, who are believed to have derived it from Egypt around 1000 BCE.
For example, Plutarch identified Argo with the Egyptian constellation called the "Boat of Osiris."
Although some academics theorized a Sumerian origin related to the Epic of Gilgamesh, this hypothesis has been rejected as there is no evidence that the Sumerians or other Mesopotamian culture considered these stars, or any portion of them, to form a boat.
Over time, the constellation became identified specifically with ancient Greek myth of Jason and the Argonauts.
In his Almagest, Claudius Ptolemy described Argo Navis as occupying the portion of the Milky Way between Canis Major and Centaurus, and identified stars comprising such details as the "little shield", the "steering-oar", the "mast-holder", and the "stern-ornament", which continued to be reflected in cartographic representations in celestial atlases into the nineteenth century (see below).
Another interesting feature of the constellation is that it appeared to be moving backwards against the backdrop of the night sky.
Aratus, the Greek poet/historian living in the third century BCE, noted this backward progression writing, "Argo by the" Great Dog's "[Canis Major's] tail is drawn; for hers is not a usual course, but backward turned she comes ...".
In modern times, Argo Navis was considered unwieldy due to its enormous size (28 % larger than Hydra, the largest modern constellation).
In his 1763 star atlas, Nicolas Louis de Lacaille explained that there were more than a hundred and sixty stars clearly visible to the naked eye in Navis, and so he used the set of lowercase and uppercase Latin letters three times on portions of the constellation referred to as "" Argûs in carina "" (Carina, the keel or hull), "" Argûs in puppi "" (Puppis, the poop deck or stern), and "" Argûs in velis "" (Vela, the sails).
Lacaille replaced Bayer's designations with new ones that followed stellar magnitudes more closely, but used only a single Greek-letter sequence and described the constellation for those stars as "Argûs".
Similarly, faint unlettered stars were listed only as in "Argûs".
The final breakup and abolition of Argo Navis was proposed by Sir John Herschel in 1841 and again in 1844.
Despite this, the constellation remained in use in parallel with its constituent parts into the 20th century.
In 1922, along with the other constellations, it received a three-letter abbreviation: "Arg".
The breakup and relegation to a former constellation occurred in 1930 when the IAU defined the 88 modern constellations, formally instituting "Carina", "Puppis", and "Vela", and declaring "Argo" obsolete.
Lacaille's designations were kept in the three separate constellations, so "Carina" has α, β, and ε; "Vela" has γ and δ; "Puppis" has ζ; and so on.
As a result of this breakup, Argo Navis is the only one of the 48 constellations listed by Ptolemy in his "Almagest" that is no longer officially recognized as a single constellation.
In addition, the constellation "Pyxis" (the mariner's compass) occupies an area near that which in antiquity was considered part of Argo's mast.
Some recent authors state that modern Pyxis was part of the ancient Greek conception of Argo Navis, but magnetic compasses were unknown in ancient Greek times, nor does it appear that the stars now in Pyxis were included in the original conception of Argo Navis.
Lacaille considered it a separate constellation representing a modern scientific instrument (like "Microscopium" and "Telescopium"), that he created for maps of the stars of the southern hemisphere.
Pyxis was listed among his 14 new constellations, separate from Argo.
In 1844, John Herschel suggested formalizing the mast as a new constellation, "Malus", to replace Lacaille's "Pyxis", but the idea did not catch on.
Similarly, an effort by Edmond Halley to detach the "cloud of mist" at the prow of Argo Navis to form a new constellation named "Robur Carolinum" (Charles' Oak) in honor of King Charles II, his patron, was unsuccessful.
The Māori had several names for what was the constellation "Argo", including "Te Waka-o-Tamarereti" (the canoe of Tamarereti), "Te Kohi-a-Autahi" (an expression meaning "cold of autumn settling down on land and water"), and "Te Kohi".
In Vedic astronomy, Indian observers also saw Argo Navis as "the Boat".
In Greek mythology, Andromeda (; Greek: Ἀνδρομέδα, "Androméda" or Ἀνδρομέδη, "Andromédē") is the daughter of the Aethiopian king Cepheus and his wife Cassiopeia.
When Cassiopeia's hubris leads her to boast that Andromeda is more beautiful than the Nereids, Poseidon sends the sea monster Cetus to ravage Andromeda as divine punishment.
Andromeda is chained to a rock as a sacrifice to sate the monster, but is saved from death by Perseus.
Her name is the Latinized form of the Greek ("Androméda") or ("Andromédē"): "ruler of men", from ("anēr, andrós") "man", and ("medō") "I protect, rule over".
As a subject, Andromeda has been popular in art since classical times; it is one of several Greek myths of a Greek hero's rescue of the intended victim of an archaic "hieros gamos" (sacred marriage), giving rise to the "princess and dragon" motif.
From the Renaissance, interest revived in the original story, typically as derived from Ovid's account.
In Greek mythology, Andromeda was the daughter of Cepheus and Cassiopeia, king and queen of the African kingdom of Aethiopia.
Her mother Cassiopeia boasted that she was more beautiful than the Nereids, the nymph-daughters of the sea god Nereus and often seen accompanying Poseidon.
To punish the queen for her arrogance, Poseidon, brother to Zeus and god of the sea, sent a sea monster named Cetus to ravage the coast of Aethiopia including the kingdom of the vain queen.
The desperate king consulted the Oracle of Apollo, who announced that no respite would be found until the king sacrificed his daughter, Andromeda, to the monster.
She was then chained to a rock on the coast.
Perseus was returning from having slain the Gorgon, Medusa.
Seeing Andromeda bound to the rock awaiting death, Perseus fell in love with her.
After he happened upon the chained Andromeda, he held up the head of Medusa to the sea monster, turning it into a giant sandstone statue, which dissolved into the waves.
He set Andromeda free, and married her in spite of her having been previously promised to her uncle Phineus.
At the wedding a quarrel took place between the rivals, and Phineus was turned to stone by the sight of the Gorgon's head.
Andromeda followed her husband, first to his native island of Serifos, where he rescued his mother Danaë, and then to Tiryns in Argos.
They remained in Tiryns, where Perseus became a king.
Together, they became the ancestors of the family of the "Perseidae" through the line of their son Perses.
Perseus and Andromeda had seven sons: Perses, Alcaeus, Heleus, Mestor, Sthenelus, Electryon, and Cynurus as well as two daughters, Autochthe and Gorgophone.
Their descendants ruled Mycenae from Electryon down to Eurystheus, after whom Atreus attained the kingdom, and would also include the great hero Heracles.
According to this mythology, Perseus is the ancestor of the Persians.
At the port city of Jaffa (today part of Tel Aviv) an outcrop of rocks near the harbor has been associated with the place of Andromeda's chaining and rescue by the traveler Pausanias, the geographer Strabo and the historian of the Jews Josephus.
After Andromeda's death, as Euripides had promised Athena at the end of his "Andromeda", produced in 412 BC, the goddess placed her among the constellations in the northern sky, near Perseus and Cassiopeia; the constellation Andromeda, so known since antiquity, is named after her.
Andromeda was the daughter of the king and queen of Aethiopia (Αἰθιοπία), which is not to be confused with modern-day Ethiopia, which was called Abyssinia during the time period of the story.
The term Aethiopia, as a generic or ethnic designation, comprises the people who dwelt above the equator, between the Atlantic Ocean and the Indian Ocean; the term Aethiopian refer to all the “ sun-burnt ” races, so designated from their being of a slightly darker hue than their immediate Hellenic neighbours.
The etymology of the word Aithiop details a ‘ sunburnt ’ complexion as the word ' Aithiops' is derived from the two Greek words, from "αἴθω" + "ὤψ" ("aitho" “ I burn ” + "ops" “ face ”); translating as "Burnt-face" in noun form and "red-brown" in adjectival form, as a reference to the natural light-to-dark red-brown skin tones of the North Africans, Middle Easterners and Indians.
Hecataeus of Miletus stated that Aethiopia was located to the east of the Nile, as far as the Red Sea and the Indian Ocean.
Ancient Aethiopia was seen as a region that “ many ancient writers liken to ancient India. ”
Homer places Aethiopia at the world's edge, somewhere vaguely in Asia.
In her 1992 article "The Black Andromeda," Prof.
Elizabeth McGrath discusses the idea of Andromeda being black based on Ovid's writings.
Likewise, Henry Louis Gates Jr. wrote about the black Andromeda in a 2014 article for "The Root" magazine.
In his article Gates points out the so-called ‘ inaccuracies ’ seen in the 1981 film "Clash of the Titans".
In his book "100 Amazing Facts About the Negro" Gates has at No 68: What was the original colour of the mythical beauty Andromeda - and why does it matter?
The book is his homage to Joel Augustus Rogers "100 Amazing Facts About The Negro With Complete Proof".
In his works, Ovid described Andromeda as having been of the colour black.
In his first work, the "Heroides" or "Epistulae Heroidum" (Epistles of the Heroines), Ovid uses the Latin word "" fuscae "" to describe Andromeda, with “ fusca ” being used to describe the colour black or brown.
In his "Ars Amatoria" (The Art of Love), Ovid mentions that Perseus found Andromeda among "the black Indians."
However, in his "Metamorphoses", Ovid makes mention of Perseus having initially mistaken Andromeda as a statue of marble, which indicates that Ovid acknowledged stories that portray Andromeda as being pale of skin, as the Ancient Greco-Romans used white marble for their statues.
it is worth noting that aside from Philodemus, who (in Greek Anthology) also stated that Andromeda was an Indian, Ovid was the only ancient author to have outright described Andromeda as being dark skinned.
In his Histories, Herodotus described Andromeda as being a Persian Princess, indicating that she was Iranian in origin as she and her husband Perseus were seen as the progenitors of the Persians.
Isidore mentions in "The Etymologies of Isidore of Seville" that the story of Andromeda was said to have taken place in the prehistoric city of Joppa, now Jaffa in modern Israel.
He reports a rock displayed there which still retains traces of the chains of Andromeda, in the shape of a sea-monster larger than an elephant.
Here, Isidore refers to Andromeda as being a Palestinian (at the time meaning Philistine) Princess.
In Heliodorus ’ tale, the "Aethiopica", set in the kingdom Meroë (modern Sudan), Queen Persinna gives birth to her daughter, Chariclea who, despite having black parents, was born with white skin.
In a letter to Chariclea, Persinna attributes her daughter's anomalous colour to the fact that when Persinna became pregnant with her, she was gazing up at a picture of the white-skinned Andromeda.
I knew the reason, that it was because, while my husband had to do with me, I was looking at the picture of Andromeda brought down by Perseus naked from the rock, and so by mishap engendered presently a thing like to her. ”
In his "Imagines", Philostratus describes that Andromeda, though Aethiopian, was white; making a clear contrast to all the other natives who assembled to cheer Perseus.
Within this text, Philostratus describes Andromeda as delightful or charming in her white beauty.
Manilius in his Poetica Astronomica describes Andromeda as ‘ nivea cervice ’ (white-throated); indicating that she was of a more Greco-Roman ethnicity.
Overall, Andromeda had no clear ethnicity in mythology as her appearance and her place of origin depended upon the author or artist depicting her, meaning that there is no ethnic designation for Andromeda.
Ancient artwork portrayals of Andromeda portray her as either a pale woman of Greco-Roman ethnicity or of Asian ethnicity, the usually understood locale of the story before its later transfer in the Greco-Roman imagination to modern Ethiopia.
Andromeda is represented in the northern sky by the constellation Andromeda, which contains the Andromeda Galaxy.
The advancement of science and technology allowed the emergence of astrophotography which allowed more concrete observation of the Andromeda constellation and led to the discovery that the galaxy lies within the Andromeda constellation.
Four constellations are associated with the myth. Viewing the fainter stars visible to the naked eye, the constellations are rendered as: Other constellations related to the story are: Sophocles and Euripides (and in more modern times, Corneille) made the story the subject of tragedies, and its incidents were represented in numerous ancient works of art, including Greek vases.
Jean-Baptiste Lully's opera, "Persée", also dramatizes the myth. Andromeda has been the subject of numerous ancient and modern works of art, which typically show the moment of rescue, with Andromeda usually still chained, and often naked or nearly so.
Examples include: one of Titian's "poesies" (Wallace Collection), and compositions by Joachim Wtewael (Louvre), Veronese (Rennes), many versions by Rubens, Ingres, and Gustave Moreau.
From the Renaissance onward the chained nude figure of Andromeda typically was the centre of interest.
Rembrandt's "Andromeda Chained to the Rocks" is unusual in showing her alone, fearfully awaiting the monster.
Attribution
Antlia (; from Ancient Greek "ἀντλία") is a constellation in the Southern Celestial Hemisphere.
Its name means "pump" in Latin; it represents an air pump.
Originally Antlia Pneumatica, the constellation was established by Nicolas-Louis de Lacaille in the 18th century, though its name was later abbreviated by John Herschel.
Located close to the stars forming the old constellation of the ship Argo Navis, Antlia is completely visible from latitudes south of 49 degrees north.
Antlia is a faint constellation; its brightest star is Alpha Antliae, an orange giant that is a suspected variable star, ranging between apparent magnitudes 4.22 and 4.29.
S Antliae is an eclipsing binary star system, changing in brightness as one star passes in front of the other.
Sharing a common envelope, the stars are so close they will one day merge to form a single star.
Two star systems with known exoplanets, HD 93083 and WASP-66, lie within Antlia, as do NGC 2997, a spiral galaxy, and the Antlia Dwarf Galaxy.
The French astronomer Nicolas-Louis de Lacaille first described the constellation in French as "la Machine Pneumatique" (the Pneumatic Machine) in 1751 – 52, commemorating the air pump invented by the French physicist Denis Papin.
De Lacaille had observed and catalogued almost 10,000 southern stars during a two-year stay at the Cape of Good Hope, devising fourteen new constellations in uncharted regions of the Southern Celestial Hemisphere not visible from Europe.
He named all but one in honour of instruments that symbolised the Age of Enlightenment.
Lacaille depicted Antlia as a single-cylinder vacuum pump used in Papin's initial experiments, while German astronomer Johann Bode chose the more advanced double-cylinder version.
Lacaille Latinised the name to "Antlia pneumatica" on his 1763 chart.
English astronomer John Herschel proposed shrinking the name to one word in 1844, noting that Lacaille himself had abbreviated his constellations thus on occasion.
This was universally adopted.
The International Astronomical Union adopted it as one of the 88 modern constellations in 1922.
Although visible to the Ancient Greeks, Antlia's stars were too faint to have been included in any ancient constellations.
The stars that now comprise Antlia lay within an area of the sky covered by the ancient constellation Argo Navis, the Ship of the Argonauts, which due to its immense size was split into several smaller constellations by Lacaille in 1763.
Ridpath reports that due to their faintness, the stars of Antlia did not make up part of the classical depiction of Argo Navis.
Chinese astronomers were able to view what is modern Antlia from their latitudes, and incorporated its stars into two different constellations.
Several stars in the southern part of Antlia were a portion of "" Dong'ou "", which represented an area in southern China.
Furthermore, Epsilon, Eta, and Theta Antliae were incorporated into the celestial temple, which also contained stars from modern Pyxis.
Covering 238.9 square degrees and hence 0.579 % of the sky, Antlia ranks 62nd of the 88 modern constellations by area.
Its position in the Southern Celestial Hemisphere means that the whole constellation is visible to observers south of 49 ° N. Hydra the sea snake runs along the length of its northern border, while Pyxis the compass, Vela the sails, and Centaurus the centaur line it to the west, south and east respectively.
The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union, is Ant. The official constellation boundaries, as set by Belgian astronomer Eugène Delporte in 1930, are defined by a polygon with an east side, south side and ten other sides (facing the two other cardinal compass points) ("illustrated in infobox at top-right").
In the equatorial coordinate system, the right ascension coordinates of these borders lie between and, while the declination coordinates are between − 24.54 ° and − 40.42 °.
Lacaille gave nine stars Bayer designations, labelling them Alpha through to Theta, combining two stars next to each other as Zeta.
Gould later added a tenth, Iota Antliae.
Beta and Gamma Antliae (now HR 4339 and HD 90156) ended up in the neighbouring constellation Hydra once the constellation boundaries were delineated in 1930.
Within the constellation's borders, there are 42 stars brighter than or equal to apparent magnitude 6.5.
The constellation's two brightest stars—Alpha and Epsilon Antliae—shine with a reddish tinge.
Alpha is an orange giant of spectral type K4III that is a suspected variable star, ranging between apparent magnitudes 4.22 and 4.29.
It is located 320 ± 10 light-years away from Earth.
Estimated to be shining with around 480 to 555 times the luminosity of the Sun, it is most likely an ageing star that is brightening and on its way to becoming a Mira variable star, having converted all its core fuel into carbon.
Located 590 ± 30 light-years from Earth, Epsilon Antliae is an evolved orange giant star of spectral type K3 IIIa, that has swollen to have a diameter about 69 times that of the Sun, and a luminosity of around 1279 Suns.
It is slightly variable.
At the other end of Antlia, Iota Antliae is likewise an orange giant of spectral type K1 III.
It is 202 ± 2 light-years distant.
Located near Alpha is Delta Antliae, a binary star, 450 ± 10 light-years distant from Earth.
The primary is a blue-white main sequence star of spectral type B9.
5 V and magnitude 5.6, and the secondary is a yellow-white main sequence star of spectral type F9Ve and magnitude 9.6.
Zeta Antliae is a wide optical double star.
The brighter star—Zeta Antliae—is 410 ± 40 light-years distant and has a magnitude of 5.74, though it is a true binary star system composed of two white main sequence stars of magnitudes 6.20 and 7.01 that are separated by 8.042 arcseconds.
The fainter star—Zeta Antliae—is 386 ± 5 light-years distant and of magnitude 5.9.
Eta Antliae is another double composed of a yellow white star of spectral type F1V and magnitude 5.31, with a companion of magnitude 11.3.
Theta Antliae is likewise double, most likely composed of an A-type main sequence star and a yellow giant.
S Antliae is an eclipsing binary star system that varies in apparent magnitude from 6.27 to 6.83 over a period of 15.6 hours.
The system is classed as a W Ursae Majoris variable—the primary is hotter than the secondary and the drop in magnitude is caused by the latter passing in front of the former.
Calculating the properties of the component stars from the orbital period indicates that the primary star has a mass 1.94 times and a diameter 2.026 times that of the Sun, and the secondary has a mass 0.76 times and a diameter 1.322 times that of the Sun.
The two stars have similar luminosity and spectral type as they have a common envelope and share stellar material.
The system is thought to be around 5 – 6 billion years old.
The two stars will eventually merge to form a single fast-spinning star.
T Antliae is a yellow-white supergiant of spectral type F6Iab and Classical Cepheid variable ranging between magnitude 8.88 and 9.82 over 5.9 days.
U Antliae is a red C-type carbon star and is an irregular variable that ranges between magnitudes 5.27 and 6.04.
At 910 ± 50 light-years distant, it is around 5819 times as luminous as the Sun.
BF Antliae is a Delta Scuti variable that varies by 0.01 of a magnitude.
HR 4049, also known as AG Antliae, is an unusual hot variable ageing star of spectral type B9.
5Ib - II.
It is undergoing intense loss of mass and is a unique variable that does not belong to any class of known variable star, ranging between magnitudes 5.29 and 5.83 with a period of 429 days.
It is around 6000 light-years away from Earth.
UX Antliae is an R Coronae Borealis variable with a baseline apparent magnitude of around 11.85, with irregular dimmings down to below magnitude 18.0.
A luminous and remote star, it is a supergiant with a spectrum resembling that of a yellow-white F-type star but it has almost no hydrogen.
HD 93083 is an orange dwarf star of spectral type K3V that is smaller and cooler than the Sun.
It has a planet that was discovered by the radial velocity method with the HARPS spectrograph in 2005.
About as massive as Saturn, the planet orbits its star with a period of 143 days at a mean distance of 0.477 AU.
WASP-66 is a sunlike star of spectral type F4V.
A planet with 2.3 times the mass of Jupiter orbits it every 4 days, discovered by the transit method in 2012.
DEN 1048 - 3956 is a brown dwarf of spectral type M8 located around 13 light-years distant from Earth.
At magnitude 17 it is much too faint to be seen with the unaided eye.
It has a surface temperature of about 2500 K. Two powerful flares lasting 4 – 5 minutes each were detected in 2002.
2MASS 0939 - 2448 is a system of two cool and faint brown dwarfs, probably with effective temperatures of about 500 and 700 K and masses of about 25 and 40 times that of Jupiter, though it is also possible that both objects have temperatures of 600 K and 30 Jupiter masses.
Antlia contains many faint galaxies, the brightest of which is NGC 2997 at magnitude 10.6.
It is a loosely wound face-on spiral galaxy of type Sc. Though nondescript in most amateur telescopes, it presents bright clusters of young stars and many dark dust lanes in photographs.
Discovered in 1997, the Antlia Dwarf is a 14.8 dwarf spheroidal galaxy that belongs to the Local Group of galaxies.
In 2018 the discovery was announced of a very low surface brightness galaxy near Epsilon Antliae, Antlia 2, which is a satellite galaxy of the Milky Way.
The Antlia Cluster, also known as Abell S0636, is a cluster of galaxies located in the Hydra-Centaurus Supercluster.
It is the third nearest to the Local Group after the Virgo Cluster and the Fornax Cluster.
The cluster's distance from earth is to Located in the southeastern corner of the constellation, it boasts the giant elliptical galaxies NGC 3268 and NGC 3258 as the main members of a southern and northern subgroup respectively, and contains around 234 galaxies in total.
Ara (Latin: "The Altar") is a southern constellation situated between Scorpius and Triangulum Australe.
Ara (Greek: Βωμός) was one of the 48 Greek constellations described by the 2nd century astronomer Ptolemy, and it remains one of the 88 modern constellations defined by the International Astronomical Union.
The orange supergiant Beta Arae is the brightest star in the constellation, with an apparent magnitude of 2.85 — marginally brighter than the blue-white Alpha Arae.
Seven star systems are known to host planets.
The sunlike star Mu Arae hosts four known planets, while Gliese 676 is a binary red dwarf system with four known planets.
The Milky Way crosses the northwestern part of Ara.
In ancient Greek mythology, Ara was identified as the altar where the gods first made offerings and formed an alliance before defeating the Titans.
One of the southernmost constellations depicted by Ptolemy, it had been recorded by Aratus in 270 BC as lying close to the horizon, and the Almagest portrays stars as far south as Gamma Arae.
Professor of astronomy Bradley Schaefer has proposed that ancient observers must have been able to see as far south as Zeta Arae to define a pattern that looked like an altar.
In illustrations, Ara is usually depicted as compact classical altar with its smoke ' rising ' southward.
However, depictions often vary.
In the early days of printing, a 1482 woodcut of Gaius Julius Hyginus's classic "Poeticon Astronomicon" depicts the altar as surrounded by demons.
Johann Bayer in 1603 depicted Ara as an altar with burning incense.
Hyginus depicted the same though his featured devils on either side of the flames.
Willem Blaeu, a Dutch uranographer active in the 16th and 17th centuries, drew Ara as an altar designed for sacrifice, with a burning animal offering unusually whose smoke rises northward, represented by Alpha Arae.
"The Castle of Knowledge" by Robert Record of 1556 lists the constellation stating that "Under the Scorpions tayle, standeth the Altar."
; a decade later a translation of a fairly recent mainly astrological work by Marcellus Palingenius of 1565, by Barnabe Googe states "Here mayst thou both the Altar, and the myghty Cup beholde."
In Chinese astronomy, the stars of the constellation Ara lie within "The Azure Dragon of the East" (東方青龍, "Dōng Fāng Qīng Lóng").
Five stars of Ara formed Guī (龜), a tortoise, while another three formed Chǔ (杵), a pestle.
The Wardaman people of the Northern Territory in Australia saw the stars of Ara and the neighbouring constellation Pavo as flying foxes.
Covering 237.1 square degrees and hence 0.575 % of the sky, Ara ranks 63rd of the 88 modern constellations by area.
Its position in the Southern Celestial Hemisphere means that the whole constellation is visible to observers south of 22 ° N. Scorpius runs along the length of its northern border, while Norma and Triangulum Australe border it to the west, Apus to the south, and Pavo and Telescopium to the east respectively.
The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union, is Ara.
The official constellation boundaries, as set by Belgian astronomer Eugène Delporte in 1930, are defined by a polygon of twelve segments.
In the equatorial coordinate system, the right ascension coordinates of these borders lie between and, while the declination coordinates are between − 45.49 ° and − 67.69 °.
Bayer gave eight stars Bayer designations, labelling them Alpha through to Theta, though he had never seen the constellation directly as it never rises above the horizon in Germany.
After charting the southern constellations, French astronomer Nicolas-Louis de Lacaille recharted the stars of Ara from Alpha though to Sigma, including three pairs of stars next to each other as Epsilon, Kappa and Nu.
Ara contains part of the Milky Way to the south of Scorpius and thus has rich star fields.
Within the constellation's borders, there are 71 stars brighter than or equal to apparent magnitude 6.5.
Just shading Alpha Arae, Beta Arae is the brightest star in the constellation.
It is an orange-hued star of spectral type K3Ib - IIa that has been classified as a supergiant or bright giant, that is around 650 light-years from Earth.
It is around 8.21 times as massive and 5,636 times as luminous as the Sun.
At apparent magnitude 2.85, this difference in brightness between the two is undetectable by the unaided eye.
Close to Beta Arae is Gamma Arae, a blue-hued supergiant of spectral type B1Ib.
Of apparent magnitude 3.3, it is 1110 ± 60 light-years from Earth.
It has been estimated to be between 12.5 and 25 times as massive as the Sun, and have around 120,000 times its luminosity.
Alpha Arae is a blue-white main sequence star of magnitude 2.95, that is 270 ± 20 light-years from Earth.
This star is around 9.6 times as massive as the Sun, and has an average of 4.5 times its radius.
It is 5,800 times as luminous as the Sun, its energy emitted from its outer envelope at an effective temperature of 18,044 K. A Be star, Alpha Arae is surrounded by a dense equatorial disk of material in Keplerian (rather than uniform) rotation.
The star is losing mass by a polar stellar wind with a terminal velocity of approximately 1,000 km/s.
The third brightest star in Ara at magnitude 3.13 is Zeta Arae, an orange giant of spectral type K3III that is located 490 ± 10 light-years from Earth.
Around 7 – 8 times as massive as the Sun, it has swollen to a diameter around 114 times that of the Sun and is 3800 times as luminous.
Were it not dimmer by intervening interstellar dust, it would be significantly brighter at magnitude 2.11.
Delta Arae is a blue-white main sequence star of spectral type B8Vn and magnitude 3.6, 198 ± 4 light-years from Earth.
It is around 3.56 times as massive as the Sun.
Epsilon Arae is an orange giant of apparent magnitude 4.1, 360 ± 10 light-years distant from Earth.
It is around 74 % more massive than the Sun.
At an age of about 1.7 billion years, the outer envelope of the star has expanded to almost 34 times the Sun's radius.
Eta Arae is an orange giant of apparent magnitude 3.76, located 299 ± 5 light-years distant from Earth.
Estimated to be around five billion years old, it has reached the giant star stage of its evolution.
With 1.12 times the mass of the Sun, it has an outer envelope that has expanded to 40 times the Sun's radius.
The star is now spinning so slowly that it takes more than eleven years to complete a single rotation.
GX 339 - 4 (V821 Arae) is a moderately strong variable galactic low-mass X-ray binary (LMXB) source and black-hole candidate that flares from time to time.
From spectroscopic measurements, the mass of the black-hole was found to be at least of 5.8 solar masses.
Exoplanets have been discovered in seven star systems in the constellation.
Mu Arae (Cervantes) is a sunlike star that hosts four planets.
HD 152079 is a sunlike star with a planet.
HD 154672 is an ageing sunlike star with a Hot Jupiter.
HD 154857 is a sunlike star with one confirmed and one suspected planet.
HD 156411 is a star hotter and larger than the sun with a gas giant planet in orbit.
Gliese 674 is a nearby red dwarf star with a planet.
Gliese 676 is a binary star system composed of two red dwarves with four planets.
The northwest corner of Ara is crossed by the galactic plane of the Milky Way and contains several open clusters (notably NGC 6200) and diffuse nebulae (including the bright cluster/nebula pair NGC 6188 and NGC 6193).
The brightest of the globular clusters, sixth magnitude NGC 6397, lies at a distance of just, making it one of the closest globular clusters to the Solar System.
Ara also contains Westerlund 1, a super star cluster that contains the red hypergiant Westerlund 1 - 26, which is possibly the largest star known with an estimate varying between and.
Although Ara lies close to the heart of the Milky Way, two spiral galaxies (NGC 6215 and NGC 6221) are visible near star Eta Arae.
Online sources
Its name is from the Osage language, of Siouan derivation; it denoted their related kin, the Quapaw people.
The state's diverse geography ranges from the mountainous regions of the Ozark and the Ouachita Mountains, which make up the U.S. Interior Highlands, to the densely forested land in the south known as the Arkansas Timberlands, to the eastern lowlands along the Mississippi River and the Arkansas Delta.
Arkansas is the 29th largest by area and the 33rd most populous of the 50 United States.
The capital and most populous city is Little Rock, located in the central portion of the state, a hub for transportation, business, culture, and government.
The northwestern corner of the state, such as the Fayetteville–Springdale–Rogers Metropolitan Area and Fort Smith metropolitan area, is a population, education, and economic center.
The largest city in the state's eastern part is Jonesboro.
The largest city in the state's southeastern part is Pine Bluff.
The Territory of Arkansas was admitted to the Union as the 25th state on June 15, 1836.
Much of the Delta had been developed for cotton plantations, and the state landowners largely depended on enslaved African Americans as workers.
In 1861, Arkansas seceded from the United States and joined the Confederate States of America during the Civil War.
On returning to the Union in 1868, the state continued to suffer due to its reliance on the large-scale plantation economy.
Cotton continued as the leading commodity crop, although the cotton market declined.
Because farmers and businessmen did not diversify and there was little industrial investment, the state fell behind in terms of its economy and opportunities for residents.
White rural interests dominated the state's politics by disenfranchisement of African Americans and by refusal to reapportion the legislature.
It was not until after the civil rights movement and passage of federal legislation that more African Americans were able to vote.
The Supreme Court overturned rural domination in the South and other states that had refused to reapportion their state legislatures, or retained rules based on geographic districts.
In "one man, one vote", it ruled that states had to organize both houses of their legislatures by districts that held approximately equal populations, and that these had to be redefined as necessary after each decade's census.
Following World War II, Arkansas began to diversity its economy.
In the 21st century, its economy is based on service industries, aircraft, poultry, steel, and tourism, along with important commodity crops of cotton, soybeans and rice.
The culture of Arkansas is observable in museums, theaters, novels, television shows, restaurants, and athletic venues across the state.
Notable people from the state include politician and educational advocate William Fulbright; former president Bill Clinton, who also served as the 40th and 42nd governor of Arkansas; general Wesley Clark, former NATO Supreme Allied Commander; Walmart founder and magnate Sam Walton; singer-songwriters Johnny Cash, Charlie Rich, Jimmy Driftwood, and Glen Campbell; actor-filmmaker, Billy Bob Thornton; poet C. D. Wright; and physicist William L. McMillan, who was a pioneer in superconductor research.
The name "Arkansas" was initially applied to the Arkansas River.
It derives from a French term, "Arcansas", their plural term for their transliteration of "akansa", an Algonquian term for the Quapaw people.
These were a Dhegiha Siouan-speaking people who settled in Arkansas around the 13th century.
"akansa" is likely also the root term for Kansas.
The name has been pronounced and spelled in a variety of fashions.
In 1881, the state legislature defined the official pronunciation of Arkansas as having the final "s" be silent (as it would be in French).
A dispute had arisen between the state's two senators over the pronunciation issue.
One favored pronunciation as while the other favored.
In 2007, the state legislature passed a non-binding resolution declaring that the possessive form of the state's name is "Arkansas's", which has been followed increasingly by the state government.
Arkansas borders Louisiana to the south, Texas to the southwest, Oklahoma to the west, Missouri to the north, and Tennessee and Mississippi to the east.
The United States Census Bureau classifies Arkansas as a southern state, sub-categorized among the West South Central States.
The Mississippi River forms most of Arkansas's eastern border, except in Clay and Greene, counties where the St. Francis River forms the western boundary of the Missouri Bootheel, and in many places where the channel of the Mississippi has meandered (or been straightened by man) from its original 1836 course.
Arkansas can generally be split into two halves, the highlands in the northwest half and the lowlands of the southeastern half.
The highlands are part of the Southern Interior Highlands, including The Ozarks and the Ouachita Mountains.
The southern lowlands include the Gulf Coastal Plain and the Arkansas Delta.
This dual split can yield to general regions named northwest, southwest, northeast, southeast, or central Arkansas.
These directionally named regions are broad and not defined along county lines.
Arkansas has seven distinct natural regions: the Ozark Mountains, Ouachita Mountains, Arkansas River Valley, Gulf Coastal Plain, Crowley's Ridge, and the Arkansas Delta, with Central Arkansas sometimes included as a blend of multiple regions.
The southeastern part of Arkansas along the Mississippi Alluvial Plain is sometimes called the Arkansas Delta.
This region is a flat landscape of rich alluvial soils formed by repeated flooding of the adjacent Mississippi.
Farther away from the river, in the southeast portion of the state, the Grand Prairie consists of a more undulating landscape.
Both are fertile agricultural areas.
The Delta region is bisected by a geological formation known as Crowley's Ridge.
A narrow band of rolling hills, Crowley's Ridge rises from above the surrounding alluvial plain and underlies many of the major towns of eastern Arkansas.
Northwest Arkansas is part of the Ozark Plateau including the Ozark Mountains, to the south are the Ouachita Mountains, and these regions are divided by the Arkansas River; the southern and eastern parts of Arkansas are called the Lowlands.
These mountain ranges are part of the U.S. Interior Highlands region, the only major mountainous region between the Rocky Mountains and the Appalachian Mountains.
The highest point in the state is Mount Magazine in the Ouachita Mountains, which rises to above sea level.
Arkansas has many rivers, lakes, and reservoirs within or along its borders.
Major tributaries of the Mississippi River include the Arkansas River, the White River, and the St. Francis River.
The Arkansas is fed by the Mulberry River and the Fourche LaFave River in the Arkansas River Valley, which is also home to Lake Dardanelle.
The Buffalo River, Little Red River, Black River and Cache River all serve as tributaries to the White River, which also empties into the Mississippi.
The Saline River, Little Missouri River, Bayou Bartholomew, and the Caddo River all serve as tributaries to the Ouachita River in south Arkansas, which eventually empties into the Mississippi in Louisiana.
The Red River briefly serves as the state's boundary with Texas.
Arkansas has few natural lakes and many reservoirs, such as Bull Shoals Lake, Lake Ouachita, Greers Ferry Lake, Millwood Lake, Beaver Lake, Norfork Lake, DeGray Lake, and Lake Conway.
Arkansas is home to many caves, such as Blanchard Springs Caverns.
More than 43,000 Native American living, hunting and tool making sites, many of them Pre-Columbian burial mounds and rock shelters, have been cataloged by the State Archeologist.
Crater of Diamonds State Park near Murfreesboro is the world's only diamond-bearing site accessible to the public for digging.
Arkansas is home to a dozen Wilderness Areas totaling.
These areas are set aside for outdoor recreation and are open to hunting, fishing, hiking, and primitive camping.
No mechanized vehicles nor developed campgrounds are allowed in these areas.
Arkansas is divided into three broad ecoregions, the "Ozark, Ouachita-Appalachian Forests", "Mississippi Alluvial and Southeast USA Coastal Plains", and the "Southeastern USA Plains" and two biomes, the subtropical coniferous forest and the temperate deciduous forest.
The state is further divided into seven subregions: the Arkansas Valley, Boston Mountains, Mississippi Alluvial Plain, Mississippi Valley Loess Plain, Ozark Highlands, Ouachita Mountains, and the South Central Plains.
A 2010 United States Forest Service survey determined of Arkansas's land is forestland, or 56 % of the state's total area.
Dominant species in Arkansas's forests include "Quercus" (oak), "Carya" (hickory), "Pinus echinata" (shortleaf pine) and "Pinus taeda" (loblolly pine).
Arkansas's plant life varies with its climate and elevation.
The pine belt stretching from the Arkansas delta to Texas consists of dense oak-hickory-pine growth.
Lumbering and paper milling activity is active throughout the region.
In eastern Arkansas, one can find "Taxodium" (cypress), "Quercus nigra" (water oaks), and hickories with their roots submerged in the Mississippi Valley bayous indicative of the deep south.
Nearby Crowley's Ridge is only home of the tulip tree in the state, and generally hosts more northeastern plant life such as the beech tree.
The northwestern highlands are covered in an oak-hickory mixture, with Ozark white cedars, "cornus" (dogwoods), and "Cercis canadensis" (redbuds) also present.
The higher peaks in the Arkansas River Valley play host to scores of ferns, including the "Woodsia scopulina" and "Adiantum" (maidenhair fern) on Mount Magazine.
Arkansas generally has a humid subtropical climate.
While not bordering the Gulf of Mexico, Arkansas is still close enough to this warm, large body of water for it to influence the weather in the state.
Generally, Arkansas has hot, humid summers and slightly drier, mild to cool winters.
In Little Rock, the daily high temperatures average around with lows around in July.
In January highs average around and lows around.
In Siloam Springs in the northwest part of the state, the average high and low temperatures in July are and in January the average high and lows are.
Annual precipitation throughout the state averages between about; somewhat wetter in the south and drier in the northern part of the state.
Snowfall is infrequent but most common in the northern half of the state.
The half of the state south of Little Rock is more apt to see ice storms.
Arkansas's all-time record high is at Ozark on August 10, 1936; the all-time record low is at Gravette, on February 13, 1905.
Arkansas is known for extreme weather and frequent storms.
A typical year brings thunderstorms, tornadoes, hail, snow and ice storms.
Between both the Great Plains and the Gulf States, Arkansas receives around 60 days of thunderstorms.
Arkansas is located in Tornado Alley, and as a result, a few of the most destructive tornadoes in U.S. history have struck the state.
While sufficiently far from the coast to avoid a direct hit from a hurricane, Arkansas can often get the remnants of a tropical system, which dumps tremendous amounts of rain in a short time and often spawns smaller tornadoes.
Before European settlement of North America, Arkansas was inhabited by indigenous peoples for thousands of years.
The Caddo, Osage, and Quapaw peoples encountered European explorers.
The first of these Europeans was Spanish explorer Hernando de Soto in 1541, who crossed the Mississippi and marched across central Arkansas and the Ozark Mountains.
After finding nothing he considered of value and encountering native resistance the entire way, he and his men returned to the Mississippi River where de Soto fell ill.
From his deathbed he ordered his men to massacre all of the men of the nearby village of Anilco, who he feared had been plotting with a powerful polity down the Mississippi River, "Quigualtam".
His men obeyed and did not stop with the men, but were said to have massacred women and children as well.
He died the following day in what is believed to be the vicinity of modern-day McArthur, Arkansas in May 1542.
His body was weighted down with sand and he was consigned to a watery grave in the Mississippi River under cover of darkness by his men.
De Soto had attempted to deceive the native population into thinking he was an immortal deity, sun of the sun, in order to forestall attack by outraged Native Americans on his by then weakened and bedraggled army.
In order to keep the ruse up, his men informed the locals that de Soto had ascended into the sky.
His will at the time of his death listed: "four Indian slaves, three horses and 700 hogs."
which were auctioned off to his men.
His starving men, who had been living off maize stolen from Native Americans and who had not been allowed to eat the enormous herd of hogs but had had to care for them, immediately started to butcher them.
Later on his remaining men, now commanded by his aide de camp Moscoso, attempted an overland return to Mexico.
They made it as far as Texas before running into territory too dry for maize farming and too thinly populated to sustain themselves by stealing food from the locals.
The expedition promptly backtracked to Arkansas.
After building a small fleet of boats they then headed down the Mississippi River and eventually on to Mexico by water.
Later explorers included the French Jacques Marquette and Louis Jolliet in 1673, and Frenchmen Robert La Salle and Henri de Tonti in 1681.
Tonti established Arkansas Post at a Quapaw village in 1686, making it the first European settlement in the territory.
The early Spanish or French explorers of the state gave it its name, which is probably a phonetic spelling of the Illinois tribe's name for the Quapaw people, who lived downriver from them.
The name Arkansas has been pronounced and spelled in a variety of fashions.
The region was organized as the Territory of Arkansaw on July 4, 1819, with the territory admitted to the United States as the state of Arkansas on June 15, 1836.
The name was historically,, and several other variants.
Historically and modernly, the people of Arkansas call themselves either "Arkansans" or "Arkansawyers".
In 1881, the Arkansas General Assembly passed Arkansas Code 1 - 4 - 105 (official text): Whereas, confusion of practice has arisen in the pronunciation of the name of our state and it is deemed important that the true pronunciation should be determined for use in oral official proceedings.
And, whereas, the matter has been thoroughly investigated by the State Historical Society and the Eclectic Society of Little Rock, which have agreed upon the correct pronunciation as derived from history, and the early usage of the American immigrants.
Be it therefore resolved by both houses of the General Assembly, that the only true pronunciation of the name of the state, in the opinion of this body, is that received by the French from the native Indians and committed to writing in the French word representing the sound.
It should be pronounced in three (3) syllables, with the final "s" silent, the "a" in each syllable with the Italian sound, and the accent on the first and last syllables.
The pronunciation with the accent on the second syllable with the sound of "a" in "man" and the sounding of the terminal "s" is an innovation to be discouraged.
Citizens of the state of Kansas often pronounce the Arkansas River as, in a manner similar to the common pronunciation of the name of their state.
Settlers, such as fur trappers, moved to Arkansas in the early 18th century.
These people used Arkansas Post as a home base and entrepôt.
During the colonial period, Arkansas changed hands between France and Spain following the Seven Years' War, although neither showed interest in the remote settlement of Arkansas Post.
In April 1783, Arkansas saw its only battle of the American Revolutionary War, a brief siege of the post by British Captain James Colbert with the assistance of the Choctaw and Chickasaw.
Napoleon Bonaparte sold French Louisiana to the United States in 1803, including all of Arkansas, in a transaction known today as the Louisiana Purchase.
French soldiers remained as a garrison at Arkansas Post.
Following the purchase, the balanced give-and-take relationship between settlers and Native Americans began to change all along the frontier, including in Arkansas.
Following a controversy over allowing slavery in the territory, the Territory of Arkansas was organized on July 4, 1819.
Gradual emancipation in Arkansas was struck down by one vote, the Speaker of the House Henry Clay, allowing Arkansas to organize as a slave territory.
Slavery became a wedge issue in Arkansas, forming a geographic divide that remained for decades.
Owners and operators of the cotton plantation economy in southeast Arkansas firmly supported slavery, as they perceived slave labor as the best or "only" economically viable method of harvesting their commodity crops.
The "hill country" of northwest Arkansas was unable to grow cotton and relied on a cash-scarce, subsistence farming economy.
As European Americans settled throughout the East Coast and into the Midwest, in the 1830 s the United States government forced the removal of many Native American tribes to Arkansas and Indian Territory west of the Mississippi River.
Additional Native American removals began in earnest during the territorial period, with final Quapaw removal complete by 1833 as they were pushed into Indian Territory.
The capital was relocated from Arkansas Post to Little Rock in 1821, during the territorial period.
When Arkansas applied for statehood, the slavery issue was again raised in Washington, D.C..
Congress eventually approved the Arkansas Constitution after a 25-hour session, admitting Arkansas on June 15, 1836, as the 25th state and the 13th slave state, having a population of about 60,000.
Arkansas struggled with taxation to support its new state government, a problem made worse by a state banking scandal and worse yet by the Panic of 1837.
In early antebellum Arkansas, the southeast Arkansas slave-based economy developed rapidly.
On the eve of the Civil War in 1860, enslaved African Americans numbered 111,115 people, just over 25 % of the state's population.
Plantation agriculture set the state and region behind the nation for decades.
The wealth developed among planters of southeast Arkansas caused a political rift to form between the northwest and southeast.
Many politicians were elected to office from the Family, the Southern rights political force in antebellum Arkansas.
Residents generally wanted to avoid a civil war.
When the Gulf states seceded in early 1861, Arkansas voted to remain in the Union.
Arkansas did not secede until Abraham Lincoln demanded Arkansas troops be sent to Fort Sumter to quell the rebellion there.
On May 6, a state convention voted to terminate Arkansas's membership in the Union and join the Confederate States of America.
Arkansas held a very important position for the Rebels, maintaining control of the Mississippi River and surrounding Southern states.
The bloody Battle of Wilson's Creek just across the border in Missouri shocked many Arkansans who thought the war would be a quick and decisive Southern victory.
Battles early in the war took place in northwest Arkansas, including the Battle of Cane Hill, Battle of Pea Ridge, and Battle of Prairie Grove.
Union general Samuel Curtis swept across the state to Helena in the Delta in 1862.
Little Rock was captured the following year.
The government shifted the state Confederate capital to Hot Springs, and then again to Washington from 1863 to 1865, for the remainder of the war.
Throughout the state, guerrilla warfare ravaged the countryside and destroyed cities.
Passion for the Confederate cause waned after implementation of programs such as the draft, high taxes, and martial law.
Under the Military Reconstruction Act, Congress declared Arkansas restored to the Union in June 1868, after the Legislature accepted the 14th Amendment.
The Republican-controlled reconstruction legislature established universal male suffrage (though temporarily disfranchising former Confederate Army officers, who were all Democrats), a public education system for blacks and whites, and passed general issues to improve the state and help more of the population.
The State soon came under control of the Radical Republicans and Unionists, and led by Governor Powell Clayton, they presided over a time of great upheaval as Confederate sympathizers and the Ku Klux Klan fought the new developments, particularly voting rights for African Americans.
In 1874, the Brooks-Baxter War, a political struggle between factions of the Republican Party shook Little Rock and the state governorship.
It was settled only when President Ulysses S. Grant ordered Joseph Brooks to disperse his militant supporters.
Following the Brooks-Baxter War, a new state constitution was ratified, re-enfranchising former Confederates.
In 1881, the Arkansas state legislature enacted a bill that adopted an official pronunciation of the state's name, to combat a controversy then simmering.
(See Law and Government below.)
After Reconstruction, the state began to receive more immigrants and migrants.
Chinese, Italian, and Syrian men were recruited for farm labor in the developing Delta region.
None of these nationalities stayed long at farm labor; the Chinese especially quickly became small merchants in towns around the Delta.
Many Chinese became such successful merchants in small towns that they were able to educate their children at college.
Some early 20th - century immigration included people from eastern Europe.
Together, these immigrants made the Delta more diverse than the rest of the state.
In the same years, some black migrants moved into the area because of opportunities to develop the bottomlands and own their own property.
Construction of railroads enabled more farmers to get their products to market.
It also brought new development into different parts of the state, including the Ozarks, where some areas were developed as resorts.
In a few years at the end of the 19th century, for instance, Eureka Springs in Carroll County grew to 10,000 people, rapidly becoming a tourist destination and the fourth-largest city of the state.
It featured newly constructed, elegant resort hotels and spas planned around its natural springs, considered to have healthful properties.
The town's attractions included horse racing and other entertainment.
It appealed to a wide variety of classes, becoming almost as popular as Hot Springs.
In the late 1880 s, the worsening agricultural depression catalyzed Populist and third party movements, leading to interracial coalitions.
Struggling to stay in power, in the 1890 s the Democrats in Arkansas followed other Southern states in passing legislation and constitutional amendments that disfranchised blacks and poor whites.
Democrats wanted to prevent their alliance.
In 1891 state legislators passed a requirement for a literacy test, knowing that it would exclude many blacks and whites.
At the time, more than 25 % of the population could neither read nor write.
In 1892, they amended the state constitution to require a poll tax and more complex residency requirements, both of which adversely affected poor people and sharecroppers, forcing most blacks and many poor whites from voter rolls.
By 1900 the Democratic Party expanded use of the white primary in county and state elections, further denying blacks a part in the political process.
Only in the primary was there any competition among candidates, as Democrats held all the power.
The state was a Democratic one-party state for decades, until after passage of the federal Civil Rights Act of 1964 and Voting Rights Act of 1965 to enforce constitutional rights.
Between 1905 and 1911, Arkansas began to receive a small immigration of German, Slovak, and Scots-Irish from Europe.
The German and Slovak peoples settled in the eastern part of the state known as the Prairie, and the Irish founded small communities in the southeast part of the state.
The Germans were mostly Lutheran and the Slovaks were primarily Catholic.
The Irish were mostly Protestant from Ulster, of Scots and Northern Borders descent.
Based on the order of President Franklin D. Roosevelt given shortly after Imperial Japan's attack on Pearl Harbor, nearly 16,000 Japanese Americans were forcibly removed from the West Coast of the United States and incarcerated in two internment camp located in the Arkansas Delta.
The Rohwer Camp in Desha County operated from September 1942 to November 1945 and at its peak interned 8,475 prisoners.
The Jerome War Relocation Center in Drew County operated from October 1942 to June 1944 and held c.
8,000 prisoners.
After the Supreme Court's decision in "Brown" v.
"Board of Education of Topeka, Kansas" in 1954 that segregation in public schools was unconstitutional, some students worked to integrate schools in the state.
The Little Rock Nine brought Arkansas to national attention in 1957 when the Federal government had to intervene to protect African-American students trying to integrate a high school in the Arkansas capital.
Governor Orval Faubus had ordered the Arkansas National Guard to aid segregationists in preventing nine African-American students from enrolling at Little Rock's Central High School.
After attempting three times to contact Faubus, President Dwight D. Eisenhower sent 1000 troops from the active-duty 101st Airborne Division to escort and protect the African-American students as they entered school on September 25, 1957.
In defiance of federal court orders to integrate, the governor and city of Little Rock decided to close the high schools for the remainder of the school year.
By the fall of 1959, the Little Rock high schools were completely integrated.
Bill Clinton, the 42nd president of the United States, was born in Hope.
Before his presidency, Clinton served as the 40th and 42nd governor of Arkansas, a total of nearly 12 years.
Little Rock has been Arkansas's capital city since 1821 when it replaced Arkansas Post as the capital of the Territory of Arkansas.
The state capitol was moved to Hot Springs and later Washington during the Civil War when the Union armies threatened the city in 1862, and state government did not return to Little Rock until after the war ended.
Today, the Little Rock–North Little Rock–Conway metropolitan area is the largest in the state, with a population of 724,385 in 2013.
The Fayetteville–Springdale–Rogers Metropolitan Area is the second-largest metropolitan area in Arkansas, growing at the fastest rate due to the influx of businesses and the growth of the University of Arkansas and Walmart.
The state has eight cities with populations above 50,000 (based on 2010 census).
In descending order of size, they are: Little Rock, Fort Smith, Fayetteville, Springdale, Jonesboro, North Little Rock, Conway, and Rogers.
Of these, only Fort Smith and Jonesboro are outside the two largest metropolitan areas.
Other cities are located in Arkansas such as Pine Bluff, Crossett, Bryant, Lake Village, Hot Springs, Bentonville, Texarkana, Sherwood, Jacksonville, Russellville, Bella Vista, West Memphis, Paragould, Cabot, Searcy, Van Buren, El Dorado, Blytheville, Harrison, Dumas, Rison, Warren, and Mountain Home.
The United States Census Bureau estimates that the population of Arkansas was 3,013,825 on July 1, 2018, a 3.36 % increase since the 2010 United States Census.
As of 2018, Arkansas has an estimated population of 3,013,825.
From fewer than 15,000 in 1820, Arkansas's population grew to 52,240 during a special census in 1835, far exceeding the 40,000 required to apply for statehood.
Following statehood in 1836, the population doubled each decade until the 1870 Census conducted following the Civil War.
The state recorded growth in each successive decade, although it gradually slowed in the 20th century.
It recorded population losses in the 1950 and 1960 Censuses.
This outmigration was a result of multiple factors, including farm mechanization, decreasing labor demand, and young educated people leaving the state due to a lack of non-farming industry in the state.
Arkansas again began to grow, recording positive growth rates ever since and exceeding the 2 million mark during the 1980 Census.
Arkansas's rate of change, age distributions, and gender distributions mirror national averages.
Minority group data also approximates national averages.
There are fewer people in Arkansas of Hispanic or Latino origin than the national average.
The center of population of Arkansas for 2000 was located in Perry County, near Nogal.
In terms of race and ethnicity, the state was 80.1 % white (74.2 % non-Hispanic white), 15.6 % black or African American, 0.9 % American Indian and Alaska Native, 1.3 % Asian, and 1.8 % from two or more races.
Hispanics or Latinos of any race made up 6.6 % of the population.
As of 2011, 39.0 % of Arkansas's population younger than age 1 were minorities.
+ Arkansas Racial Breakdown of Population European Americans have a strong presence in the northwestern Ozarks and the central part of the state.
African Americans live mainly in the southern and eastern parts of the state.
Arkansans of Irish, English and German ancestry are mostly found in the far northwestern Ozarks near the Missouri border.
Ancestors of the Irish in the Ozarks were chiefly Scots-Irish, Protestants from Northern Ireland, the Scottish lowlands and northern England part of the largest group of immigrants from Great Britain and Ireland before the American Revolution.
English and Scots-Irish immigrants settled throughout the backcountry of the South and in the more mountainous areas.
Americans of English stock are found throughout the state.
A 2010 survey of the principal ancestries of Arkansas's residents revealed the following: Most of the people identifying as American are of English descent and/or Scots-Irish descent.
Their families have been in the state so long, in many cases since before statehood, that they choose to identify simply as having American ancestry or do not in fact know their own ancestry.
Their ancestry primarily goes back to the original 13 colonies and for this reason many of them today simply claim American ancestry.
Many people who identify themselves as Irish descent are in fact of Scots-Irish descent.
According to the 2006 – 2008 American Community Survey, 93.8 % of Arkansas's population (over the age of five) spoke only English at home.
About 4.5 % of the state's population spoke Spanish at home.
About 0.7 % of the state's population spoke any other Indo-European languages.
About 0.8 % of the state's population spoke an Asian language, and 0.2 % spoke other languages.
Arkansas, like most other Southern states, is part of the Bible Belt and is predominantly Protestant.
The largest denominations by number of adherents in 2010 were the Southern Baptist Convention with 661,382; the United Methodist Church with 158,574; non-denominational Evangelical Protestants with 129,638; the Catholic Church with 122,662; and The Church of Jesus Christ of Latter-day Saints with 31,254.
There are some residents of the state who live by other religions such as Islam, Judaism, Wicca, Paganism, Hinduism, Buddhism or who claim no religious affiliation.
Once a state with a cashless society in the uplands and plantation agriculture in the lowlands, Arkansas's economy has evolved and diversified.
The state's gross domestic product (GDP) was $ 119 billion in 2015.
Six Fortune 500 companies are based in Arkansas, including the world's # 1 retailer, Walmart; Tyson Foods, J.B. Hunt, Dillard's, Murphy USA, and Windstream are also headquartered in the state.
The per capita personal income in 2015 was $ 39,107, ranking forty-fifth in the nation.
The median household income from 2011 to 2015 was $ 41,371, ranking forty-ninth in the nation.
The state's agriculture outputs are poultry and eggs, soybeans, sorghum, cattle, cotton, rice, hogs, and milk.
Its industrial outputs are food processing, electric equipment, fabricated metal products, machinery, and paper products.
Mines in Arkansas produce natural gas, oil, crushed stone, bromine, and vanadium.
According to CNBC, Arkansas ranks as the 20th best state for business, with the 2nd - lowest cost of doing business, 5th - lowest cost of living, 11th best workforce, 20th - best economic climate, 28th - best educated workforce, 31st - best infrastructure and the 32nd - friendliest regulatory environment.
Arkansas gained twelve spots in the best state for business rankings since 2011.
As of 2014, Arkansas was the most affordable U.S. state to live in.
As of November 2016, the state's unemployment rate is 4.0 % Arkansas's earliest industries were fur trading and agriculture, with development of cotton plantations in the areas near the Mississippi River.
They were dependent on slave labor through the American Civil War.
Today only approximately 3 % of the population is employed in the agricultural sector, it remains a major part of the state's economy, ranking 13th in the nation in the value of products sold.
The state is the U.S.'s largest producer of rice, broilers, and turkeys, and ranks in the top three for cotton, pullets, and aquaculture (catfish).
Forestry remains strong in the Arkansas Timberlands, and the state ranks fourth nationally and first in the South in softwood lumber production.
Automobile parts manufacturers have opened factories in eastern Arkansas to support auto plants in other states.
Bauxite was formerly a large part of the state's economy, mined mostly around Saline County.
Tourism is also very important to the Arkansas economy; the official state nickname "The Natural State" was created for state tourism advertising in the 1970 s, and is still used to this day.
The state maintains 52 state parks and the National Park Service maintains seven properties in Arkansas.
The completion of the William Jefferson Clinton Presidential Library in Little Rock has drawn many visitors to the city and revitalized the nearby River Market District.
Many cities also hold festivals, which draw tourists to Arkansas culture, such as The Bradley County Pink Tomato Festival in Warren, King Biscuit Blues Festival, Ozark Folk Festival, Toad Suck Daze, and Tontitown Grape Festival.
As of 2010 many Arkansas local newspapers are owned by WEHCO Media, Alabama-based Lancaster Management, Kentucky-based Paxton Media Group, Missouri-based Rust Communications, Nevada-based Stephens Media, and New York-based GateHouse Media.
The culture of Arkansas is available to all in various forms, whether it be architecture, literature, or fine and performing arts.
The state's culture also includes distinct cuisine, dialect, and traditional festivals.
Sports are also very important to the culture of Arkansas, ranging from football, baseball, and basketball to hunting and fishing.
Perhaps the best-known piece of Arkansas's culture is the stereotype of its citizens as shiftless hillbillies.
The reputation began when the state was characterized by early explorers as a savage wilderness full of outlaws and thieves.
The most enduring icon of Arkansas's hillbilly reputation is "The Arkansas Traveller", a painted depiction of a folk tale from the 1840 s.
Although intended to represent the divide between rich southeastern plantation Arkansas planters and the poor northwestern hill country, the meaning was twisted to represent a Northerner lost in the Ozarks on a white horse asking a backwoods Arkansan for directions.
The state also suffers from the racial stigma common to former Confederate states, with historical events such as the Little Rock Nine adding to Arkansas's enduring image.
Art and history museums display pieces of cultural value for Arkansans and tourists to enjoy.
Crystal Bridges Museum of American Art in Bentonville was visited by 604,000 people in 2012, its first year.
The museum includes walking trails and educational opportunities in addition to displaying over 450 works covering five centuries of American art.
Several historic town sites have been restored as Arkansas state parks, including Historic Washington State Park, Powhatan Historic State Park, and Davidsonville Historic State Park.
Arkansas features a variety of native music across the state, ranging from the blues heritage of West Memphis, Pine Bluff, Helena–West Helena to rockabilly, bluegrass, and folk music from the Ozarks.
Festivals such as the King Biscuit Blues Festival and Bikes, Blues, and BBQ pay homage to the history of blues in the state.
The Ozark Folk Festival in Mountain View is a celebration of Ozark culture and often features folk and bluegrass musicians.
Literature set in Arkansas such as "I Know Why the Caged Bird Sings" by Maya Angelou and "A Painted House" by John Grisham describe the culture at various time periods.
Sports have become an integral part of the culture of Arkansas, and her residents enjoy participating in and spectating various events throughout the year.
Team sports and especially collegiate football have been important to Arkansans.
College football in Arkansas began from humble beginnings.
The University of Arkansas first fielded a team in 1894 when football was a very dangerous game.
Recent studies of the damage to team members from the concussions common in football make it clear that the danger persists.
"Calling the Hogs" is a cheer that shows support for the Razorbacks, one of the two NCAA Division I Football Bowl Subdivision (FBS) teams in the state.
High school football also began to grow in Arkansas in the early 20th century.
Over the years, many Arkansans have looked to the Razorbacks football team as the public image of the state.
Although the University of Arkansas is based in Fayetteville, the Razorbacks have always played at least one game per season at War Memorial Stadium in Little Rock in an effort to keep fan support in central and south Arkansas.
Arkansas State University joined the University of Arkansas in FBS (then known as Division I-A) in 1992 after playing in lower divisions for nearly two decades.
The two schools have never played each other, due to the University of Arkansas's policy of not playing intrastate games.
Two other campuses of the University of Arkansas System are Division I members.
The University of Arkansas at Pine Bluff is a member of the Southwestern Athletic Conference, a league whose members all play football in the second-level Football Championship Subdivision (FCS).
The University of Arkansas at Little Rock is a member of the FBS Sun Belt Conference, but is one of two conference schools that has no football program.
The state's other Division I member is the University of Central Arkansas, which is a full member (including football) of the FCS Southland Conference.
Seven of Arkansas's smaller colleges play in NCAA Division II, with six in the Great American Conference and one in the Lone Star Conference.
Two other small Arkansas colleges compete in NCAA Division III, in which athletic scholarships are prohibited.
Baseball runs deep in Arkansas and has been popular before the state hosted Major League Baseball (MLB) spring training in Hot Springs from 1886 to the 1920 s.
Two minor league teams are based in the state.
The Arkansas Travelers play at Dickey–Stephens Park in North Little Rock, and the Northwest Arkansas Naturals play in Arvest Ballpark in Springdale.
Both teams compete in the Texas League.
Related to the state's frontier past, hunting continues in the state.
The state created the Arkansas Game and Fish Commission in 1915 to regulate hunting and enforce those regulations.
Today a significant portion of Arkansas's population participates in hunting duck in the Mississippi flyway and deer across the state.
Millions of acres of public land are available for both bow and modern gun hunters.
Fishing has always been popular in Arkansas, and the sport and the state have benefited from the creation of reservoirs across the state.
Following the completion of Norfork Dam, the Norfork Tailwater and the White River have become a destination for trout fishers.
Several smaller retirement communities such as Bull Shoals, Hot Springs Village, and Fairfield Bay have flourished due to their position on a fishing lake.
The Buffalo National River has been preserved in its natural state by the National Park Service and is frequented by fly fishers annually.
As of 2012, Arkansas, as with many Southern states, has a high incidence of premature death, infant mortality, cardiovascular deaths, and occupational fatalities compared to the rest of the United States.
The state is tied for 43rd with New York in percentage of adults who regularly exercise.
Arkansas is usually ranked as one of the least healthy states due to high obesity, smoking, and sedentary lifestyle rates.
However, a Gallup poll demonstrates that Arkansas made the most immediate progress in reducing its number of uninsured residents following the passage of the Affordable Care Act.
The percentage of uninsured in Arkansas dropped from 22.5 percent in 2013 to 12.4 percent in August 2014.
The Arkansas Clean Indoor Air Act went into effect in 2006, a statewide smoking ban excluding bars and some restaurants.
Healthcare in Arkansas is provided by a network of hospitals as members of the Arkansas Hospital Association.
Major institutions with multiple branches include Baptist Health, Community Health Systems, and HealthSouth.
The University of Arkansas for Medical Sciences (UAMS) in Little Rock operates the UAMS Medical Center, a teaching hospital ranked as high performing nationally in cancer and nephrology.
The pediatric division of UAMS Medical Center is known as Arkansas Children's Hospital, nationally ranked in pediatric cardiology and heart surgery.
Together, these two institutions are the state's only Level I trauma centers.
Arkansas has 1,064 state-funded kindergartens, elementary, junior - and senior high schools.
The state supports a network of public universities and colleges, including two major university systems: Arkansas State University System and University of Arkansas System.
The University of Arkansas, flagship campus of the University of Arkansas System in Fayetteville was ranked # 63 among public schools in the nation by "U.S. News & World Report".
Other public institutions include University of Arkansas at Pine Bluff, Arkansas Tech University, Henderson State University, Southern Arkansas University, and University of Central Arkansas across the state.
It is also home to 11 private colleges and universities including Hendrix College, one of the nation's top 100 liberal arts colleges, according to U.S. News & World Report.
In the 1920 s the state required all children to attend public schools.
The school year was set at 131 days, although some areas were unable to meet that requirement.
Although unusual in the West, school corporal punishment is not uncommon in Arkansas, with 20,083 public school students paddled at least one time, according to government data for the 2011 – 2012 school year.
The rate of corporal punishment in public schools is higher only in Mississippi.
Arkansas is one of the most under-educated states in the Union.
It ranks near the bottom in terms of percentage of the population with either a high school or college degree.
The state's educational system has a history of under-funding, low teachers' salaries and political meddling in the curriculum.
Educational statistics during these early days are fragmentary and unreliable.
Many counties did not submit full reports to the secretary of state who did double-duty as commissioner of common schools.
However, the percentage of Whites over twenty years of age who were illiterate was given as: In 2010 Arkansas students earned an average score of 20.3 on the ACT exam, just below the national average of 21.
These results were expected due to the large increase in the number of students taking the exam since the establishment of the Academic Challenge Scholarship.
Top high schools receiving recognition from the U.S. News & World Report are spread across the state, including Haas Hall Academy in Fayetteville, KIPP Delta Collegiate in Helena-West Helena, Bentonville, Rogers, Rogers Heritage, Valley Springs, Searcy, and McCrory.
A total of 81 Arkansas high schools were ranked by the U.S. News & World Report in 2012.
Arkansas ranks as the 32nd smartest state on the Morgan Quitno Smartest State Award, 44th in percentage of residents with at least a high school diploma, and 48th in percentage of bachelor's degree attainment.
Arkansas has been making strides in education reform.
"Education Week" has praised the state, ranking Arkansas in the top 10 of their Quality Counts Education Rankings every year since 2009 while scoring it in the top 5 during 2012 and 2013.
Arkansas specifically received an A in Transition and Policy Making for progress in this area consisting of early-childhood education, college readiness, and career readiness.
Governor Mike Beebe has made improving education a major issue through his attempts to spend more on education.
Through reforms, the state is a leader in requiring curricula designed to prepare students for postsecondary education, rewarding teachers for student achievement, and providing incentives for principals who work in lower-tier schools.
As an organized territory, and later in the early days of statehood, education was funded by the sales of federally controlled public lands.
This system was inadequate and prone to local graft.
In an 1854 message to the legislature, Governor Elias N. Conway said, "We have a common-school law intended as a system to establish common schools in all part of the state; but for the want of adequate means there are very few in operation under this law."
At this time, only about a quarter of children were enrolled in school.
In 1867, the state legislature was still controlled by ex-Confederates.
It passed a Common Schools Law that allowed public funded but limited schools to White children.
The 1868 legislature banned former Confederates and passed a more wide-ranging law detailing funding and administrative issues and allowing Black children to attend school.
In furtherance of this, the postwar 1868 state constitution was the first to permit a personal-property tax to fund the lands and buildings for public schools.
With the 1868 elections, the first county school commissioners took office.
In 2014, the state spent $ 9,616 per student, compared with a national average of about $ 11,000 putting Arkansas in nineteenth place.
1829 Territorial legislature permits townships to establish schools.
1868 State law required racial segregation of schools.
1871 University of Arkansas established.
1873 University of Arkansas at Pine Bluff established as a school to train Black teachers.
1877 Philander Smith College established as a school for Black students.
1890 Henderson State University established as a private school.
The state assumed responsibility for it in 1929 as Henderson State Teachers College.
1885 Arkansas School for the Deaf and Arkansas School for the Blind established.
1909 Arkansas Tech University, Southern Arkansas University, University of Arkansas at Monticello and Arkansas State University established as schools offering high school diplomas and vocational training.
"c."
1920 Schooling made compulsory.
1925 University of Central Arkansas established as Arkansas State Normal School established.
1948 University of Arkansas School of Law admits a Black student 1957 Governor Orval Faubus used National Guard troops to oppose racial integration of Little Rock Central High School.
1958 In Cooper v.
Aaron the United States Supreme Court ruled the state was bound to integrate school despite the opposition of the governor and legislature.
1983 The Arkansas State Supreme Court ruled the state's funding of education was Constitutionally deficient.
Transportation in Arkansas is overseen by the Arkansas Department of Transportation (ArDOT), headquartered in Little Rock.
Several main corridors pass through Little Rock, including Interstate 30 (I-30) and I-40 (the nation's 3rd - busiest trucking corridor).
In northeast Arkansas, I-55 travels north from Memphis to Missouri, with a new spur to Jonesboro (I-555).
Northwest Arkansas is served by the segment of I-49 from Fort Smith to the beginning of the Bella Vista Bypass.
This segment of I-49 currently follows mostly the same route as the former section of I-540 that extended north of I-40.
The state also has the 13th largest state highway system in the nation.
Arkansas is served by of railroad track divided among twenty-six railroad companies including three Class I railroads.
Freight railroads are concentrated in southeast Arkansas to serve the industries in the region.
The Texas Eagle, an Amtrak passenger train, serves five stations in the state Walnut Ridge, Little Rock, Malvern, Arkadelphia, and Texarkana.
Arkansas also benefits from the use of its rivers for commerce.
The Mississippi River and Arkansas River are both major rivers.
The United States Army Corps of Engineers maintains the McClellan-Kerr Arkansas River Navigation System, allowing barge traffic up the Arkansas River to the Port of Catoosa in Tulsa, Oklahoma.
There are four airports with commercial service: Clinton National Airport, Northwest Arkansas Regional Airport, Fort Smith Regional Airport, and Texarkana Regional Airport, with dozens of smaller airports in the state.
Public transit and community transport services for the elderly or those with developmental disabilities are provided by agencies such as the Central Arkansas Transit Authority and the Ozark Regional Transit, organizations that are part of the Arkansas Transit Association.
As with the federal government of the United States, political power in Arkansas is divided into three branches: executive, legislative, and judicial.
Each officer's term is four years long.
Office holders are term-limited to two full terms plus any partial terms before the first full term.
The governor of Arkansas is Asa Hutchinson, a Republican, who was inaugurated on January 13, 2015.
The six other elected executive positions in Arkansas are lieutenant governor, secretary of state, attorney general, treasurer, auditor, and land commissioner.
The governor also appoints qualified individuals to lead various state boards, committees, and departments.
Arkansas governors served two-year terms until a referendum lengthened the term to four years, effective with the 1986 general election.
In Arkansas, the lieutenant governor is elected separately from the governor and thus can be from a different political party.
The Arkansas General Assembly is the state's bicameral bodies of legislators, composed of the Senate and House of Representatives.
The Senate contains 35 members from districts of approximately equal population.
These districts are redrawn decennially with each US census, and in election years ending in "2", the entire body is put up for reelection.
Following the election, half of the seats are designated as two-year seats and are up for reelection again in two years, these "half-terms" do not count against a legislator's term limits.
The remaining half serve a full four-year term.
This staggers elections such that half the body is up for re-election every two years and allows for complete body turnover following redistricting.
Arkansas voters selected a 21 – 14 Republican majority in the Senate in 2012.
Arkansas House members can serve a maximum of three two-year terms.
House districts are redistricted by the Arkansas Board of Apportionment.
Following the 2012 elections, Republicans gained a 51 – 49 majority in the House of Representatives.
The Republican Party majority status in the Arkansas State House of Representatives following the 2012 elections is the party's first since 1874.
Arkansas was the last state of the old Confederacy to never have Republicans control either chamber of its house since the Civil War.
Following the term limits changes, studies have shown that lobbyists have become less influential in state politics.
Legislative staff, not subject to term limits, have acquired additional power and influence due to the high rate of elected official turnover.
Arkansas's judicial branch has five court systems: Arkansas Supreme Court, Arkansas Court of Appeals, Circuit Courts, District Courts and City Courts.
Most cases begin in district court, which is subdivided into state district court and local district court.
State district courts exercise district-wide jurisdiction over the districts created by the General Assembly, and local district courts are presided over by part-time judges who may privately practice law.
25 state district court judges preside over 15 districts, with more districts created in 2013 and 2017.
There are 28 judicial circuits of Circuit Court, with each contains five subdivisions: criminal, civil, probate, domestic relations, and juvenile court.
The jurisdiction of the Arkansas Court of Appeals is determined by the Arkansas Supreme Court, and there is no right of appeal from the Court of Appeals to the high court.
The Arkansas Supreme Court can review Court of Appeals cases upon application by either a party to the litigation, upon request by the Court of Appeals, or if the Arkansas Supreme Court feels the case should have been initially assigned to it.
The twelve judges of the Arkansas Court of Appeals are elected from judicial districts to renewable six-year terms.
The Arkansas Supreme Court is the court of last resort in the state, composed of seven justices elected to eight-year terms.
Established by the Arkansas Constitution in 1836, the court's decisions can be appealed to only the Supreme Court of the United States.
Both of Arkansas's U.S. senators, John Boozman and Tom Cotton, are Republicans.
The state has four seats in U.S. House of Representatives.
All four seats are held by Republicans: Rick Crawford (1st district), French Hill (2nd district), Steve Womack (3rd district), and Bruce Westerman (4th district).
Arkansas governor Bill Clinton brought national attention to the state with a long speech at the 1988 Democratic National Convention endorsing Michael Dukakis.
Some journalists suggested the speech was a threat to his ambitions; Clinton defined it "a comedy of error, just one of those fluky things".
Clinton won the Democratic nomination for president the following cycle.
Presenting himself as a "New Democrat" and using incumbent George H. W. Bush's against him, Clinton won the 1992 presidential election (43.0 % of the vote) against Republican Bush (37.4 % of the vote) and billionaire populist Ross Perot, who ran as an independent (18.9 % of the vote).
Most Republican strength traditionally lay mainly in the northwestern part of the state, particularly Fort Smith and Bentonville, as well as North Central Arkansas around the Mountain Home area.
In the latter area, Republicans have been known to get 90 percent or more of the vote, while the rest of the state was more Democratic.
After 2010, Republican strength expanded further to the Northeast and Southwest and into the Little Rock suburbs.
The Democrats are mostly concentrated to central Little Rock, the Mississippi Delta, the Pine Bluff area, and the areas around the southern border with Louisiana.
Arkansas has only elected three Republicans to the U.S. Senate since Reconstruction: Tim Hutchinson, who was defeated after one term by Mark Pryor; John Boozman, who defeated incumbent Blanche Lincoln; and Tom Cotton, who defeated Mark Pryor in the 2014 elections.
Before 2013, the General Assembly had not been controlled by the Republican Party since Reconstruction, with the GOP holding a 51-seat majority in the state House and a 21-seat (of 35) in the state Senate following victories in 2012.
Arkansas was one of just three states among the states of the former Confederacy that sent two Democrats to the U.S. Senate (the others being Florida and Virginia) for any period during the first decade of the 21st century.
In 2010, Republicans captured three of the state's four seats in the U.S. House of Representatives.
In 2012, Republicans won election for all four House seats.
Arkansas held the distinction of having a U.S. House delegation composed entirely of military veterans (Rick Crawford – Army; Tim Griffin – Army Reserve; Steve Womack – Army National Guard, Tom Cotton - Army).
In 2014, the last Democrat in Arkansas's congressional delegation, Mark Pryor, was defeated in his campaign to win a third term in the U.S. Senate, leaving the entire congressional delegation in GOP hands for the first time since Reconstruction.
Reflecting the state's large evangelical population, the state has a strong social conservative bent.
Arkansas is one of only four states in the U.S. to not have any legal protection against hate crimes (an anti-hate crimes measure passed the state Senate in 2001 but failed before a House panel, and a similar bill failed in 2017).
The forests of Arkansas and the Ozark mountain region have provided cover for clandestine hate groups.
White nationalist groups such as The Covenant, The Sword, and the Arm of the Lord (abbreviated CSA.
In the 1980 s this group had a compound in the Ozarks, later raided by the authorities) found cover in the Ozarks, as the overwhelmingly white towns are small and spread far and wide throughout the mountains.
The Knights of the KKK and the Kingdom Identity Ministries (a Christian identity organization) made their headquarters in the state at this time.
In the early 1990 s, a series of race riots occurred in Harrison (the largest town in Arkansas and home to the (K) KKK and KIM) led to most of that town's African-American population to flee.
In February 2018, prosecutors in Little Rock unsealed indictments against 54 members of the New Aryan Empire (a white supremacist group that began as a prison gang).
Most of the NEE members indicted in 2019 are from Russellville.
Its leader briefly escaped from a Pine Bluff jail in August of that year.
In May, another group of white supremacists protesters carrying the flag of Nazi Germany also disrupted a Holocaust remembrance event in Russellville.
Billboards have appeared in thr state displaying white supremacist slogans (e.g. "anti-racist is a code word for anti-white") or promoting white pride websites.
In 2018, the Southern Poverty Law Center (an organization which tracks hate groups) identified 14 distinct hate groups in the state.
In 2019, Republican Governor Asa Hutchinson (who as federal prosecutor in the 1980 s was involved in negotiations with the CSA) and Democratic Senator Joyce Elliott have called on lawmakers in the state to approve harsher penalties for hate crimes.
The Strategic Air Command facility of Little Rock Air Force Base was one of eighteen silos in the command of the 308th Strategic Missile Wing (308th SMW), specifically one of the nine silos within its 374th Strategic Missile Squadron (374th SMS).
The squadron was responsible for Launch Complex 374 - 7, site of the 1980 explosion of a Titan II Intercontinental Ballistic Missile (ICBM) in Damascus, Arkansas.
Arkansas is home to many areas protected by the National Park System.
These include:
An atmosphere is a gas layer around a celestial body.
Atmosphere may also refer to:
Apus is a small constellation in the southern sky.
It represents a bird-of-paradise, and its name means "without feet" in Greek because the bird-of-paradise was once wrongly believed to lack feet.
First depicted on a celestial globe by Petrus Plancius in 1598, it was charted on a star atlas by Johann Bayer in his 1603 "Uranometria".
The French explorer and astronomer Nicolas Louis de Lacaille charted and gave the brighter stars their Bayer designations in 1756.
The five brightest stars are all reddish in hue.
Shading the others at apparent magnitude 3.8 is Alpha Apodis, an orange giant that has around 48 times the diameter and 928 times the luminosity of the Sun.
Marginally fainter is Gamma Apodis, another ageing giant star.
Delta Apodis is a double star, the two components of which are 103 arcseconds apart and visible with the naked eye.
Two star systems have been found to have planets.
Apus was one of twelve constellations published by Petrus Plancius from the observations of Pieter Dirkszoon Keyser and Frederick de Houtman who had sailed on the first Dutch trading expedition, known as the "Eerste Schipvaart", to the East Indies.
It first appeared on a 35-cm (14 in) diameter celestial globe published in 1598 in Amsterdam by Plancius with Jodocus Hondius.
De Houtman included it in his southern star catalogue in 1603 under the Dutch name "De Paradijs Voghel", "The Bird of Paradise", and Plancius called the constellation "Paradysvogel Apis Indica"; the first word is Dutch for "bird of paradise".
"Apis" (Latin for "bee") is assumed to have been a typographical error for "avis" ("bird").
After its introduction on Plancius's globe, the constellation's first known appearance in a celestial atlas was in German cartographer Johann Bayer's "Uranometria" of 1603.
Bayer called it "Apis Indica" while fellow astronomers Johannes Kepler and his son-in-law Jakob Bartsch called it "Apus" or "Avis Indica".
The name "Apus" is derived from the Greek "apous", meaning "without feet".
This referred to the Western misconception that the bird-of-paradise had no feet, which arose because the only specimens available in the West had their feet and wings removed.
Such specimens began to arrive in Europe in 1522, when the survivors of Ferdinand Magellan's expedition brought them home.
The constellation later lost some of its tail when Nicolas-Louis de Lacaille used those stars to establish Octans in the 1750 s.
Covering 206.3 square degrees and hence 0.5002 % of the sky, Apus ranks 67th of the 88 modern constellations by area.
Its position in the Southern Celestial Hemisphere means that the whole constellation is visible to observers south of 7 ° N. It is bordered by Ara, Triangulum Australe and Circinus to the north, Musca and Chamaeleon to the west, Octans to the south, and Pavo to the east.
The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is' Aps'.
The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of six segments ("illustrated in infobox").
In the equatorial coordinate system, the right ascension coordinates of these borders lie between and, while the declination coordinates are between − 67.48 ° and − 83.12 °.
Lacaille gave twelve stars Bayer designations, labelling them Alpha through to Kappa, including two stars next to each other as Delta and another two stars near each other as Kappa.
Within the constellation's borders, there are 39 stars brighter than or equal to apparent magnitude 6.5.
Beta, Gamma and Delta Apodis form a narrow triangle, with Alpha Apodis lying to the east.
The five brightest stars are all red-tinged, which is unusual among constellations.
Alpha Apodis is an orange giant of spectral type K3III located 430 ± 20 light-years away from Earth, with an apparent magnitude of 3.8.
It spent much of its life as a blue-white (B-type) main sequence star before expanding, cooling and brightening as it used up its core hydrogen.
It has swollen to 48 times the Sun's diameter, and shines with a luminosity approximately 928 times that of the Sun, with a surface temperature of 4312 K. Beta Apodis is an orange giant 149 ± 2 light-years away, with a magnitude of 4.2.
It is around 1.84 times as massive as the Sun, with a surface temperature of 4677 K. Gamma Apodis is a yellow giant of spectral type G8III located 150 ± 4 light-years away, with a magnitude of 3.87.
It is approximately 63 times as luminous the Sun, with a surface temperature of 5279 K. Delta Apodis is a double star, the two components of which are 103 arcseconds apart and visible through binoculars.
Delta is a red giant star of spectral type M4III located 630 ± 30 light-years away.
It is a semiregular variable that varies from magnitude + 4.66 to + 4.87, with pulsations of multiple periods of 68.0, 94.9 and 101.7 days.
Delta is an orange giant star of spectral type K3III, located 550 ± 10 light-years away, with a magnitude of 5.3.
The separate components can be resolved with the naked eye.
The fifth-brightest star is Zeta Apodis at magnitude 4.8, a star that has swollen and cooled to become an orange giant of spectral type K1III, with a surface temperature of 4649 K and a luminosity 133 times that of the Sun.
It is 300 ± 4 light-years distant.
Near Zeta is Iota Apodis, a binary star system 1,040 ± 60 light-years distant, that is composed of two blue-white main sequence stars that orbit each other every 59.32 years.
Of spectral types B9V and B9.
5 V, they are both over three times as massive as the Sun.
Eta Apodis is a white main sequence star located 140.8 ± 0.9 light-years distant.
Of apparent magnitude 4.89, it is 1.77 times as massive, 15.5 times as luminous as the Sun and has 2.13 times its radius.
Aged 250 ± 200 million years old, this star is emitting an excess of 24 μm infrared radiation, which may be caused by a debris disk of dust orbiting at a distance of more than 31 astronomical units from it.
Theta Apodis is a cool red giant of spectral type M7 III located 350 ± 30 light-years distant.
It shines with a luminosity approximately 3879 times that of the Sun and has a surface temperature of 3151 K. A semiregular variable, it varies by 0.56 magnitudes with a period of 119 days—or approximately 4 months.
It is losing mass at the rate of times the mass of the Sun per year through its stellar wind.
Dusty material ejected from this star is interacting with the surrounding interstellar medium, forming a bow shock as the star moves through the galaxy.
NO Apodis is a red giant of spectral type M3III that varies between magnitudes 5.71 and 5.95.
Located 780 ± 20 light-years distant, it shines with a luminosity estimated at 2059 times that of the Sun and has a surface temperature of 3568 K. S Apodis is a rare R Coronae Borealis variable, an extremely hydrogen-deficient supergiant thought to have arisen as the result of the merger of two white dwarfs; fewer than 100 have been discovered as of 2012.
It has a baseline magnitude of 9.7.
R Apodis is a star that was given a variable star designation, yet has turned out not to be variable.
Of magnitude 5.3, it is another orange giant.
Two star systems have had exoplanets discovered by doppler spectroscopy, and the substellar companion of a third star system—the sunlike star HD 131664—has since been found to be a brown dwarf with a calculated mass of the companion to 23 times that of Jupiter (minimum of 18 and maximum of 49 Jovian masses).
HD 134606 is a yellow sunlike star of spectral type G6IV that has begun expanding and cooling off the main sequence.
Three planets orbit it with periods of 12, 59.5 and 459 days, successively larger as they are further away from the star.
HD 137388 is another star—of spectral type K2IV — that is cooler than the Sun and has begun cooling off the main sequence.
Around 47 % as luminous and 88 % as massive as the Sun, with 85 % of its diameter, it is thought to be around 7.4 ± 3.9 billion years old.
It has a planet that is 79 times as massive as the Earth and orbits its sun every 330 days at an average distance of 0.89 astronomical units (AU).
The Milky Way covers much of the constellation's area.
Of the deep-sky objects in Apus, there are two prominent globular clusters—NGC 6101 and IC 4499—and a large faint nebula that covers several degrees east of Beta and Gamma Apodis.
NGC 6101 is a globular cluster of apparent magnitude 9.2 located around 50,000 light-years distant from Earth, which is around 160 light-years across.
Around 13 billion years old, it contains a high concentration of massive bright stars known as blue stragglers, thought to be the result of two stars merging.
IC 4499 is a loose globular cluster in the medium-far galactic halo; its apparent magnitude is 10.6.
The galaxies in the constellation are faint.
IC 4633 is a very faint spiral galaxy surrounded by a vast amount of Milky Way line-of-sight integrated flux nebulae—large faint clouds thought to be lit by large numbers of stars.
Abadan ("Ābādān",) is a city and capital of Abadan County, Khuzestan Province which is located in the southwest of Iran.
It lies on Abadan Island (long, 3 – 19 km or 2 – 12 miles wide), the island is bounded in the west by the Arvand waterway and to the east by the Bahmanshir outlet of the Karun River (the Arvand Rood), from the Persian Gulf, near the Iran–Iraq border.
Abadan is 140 km from the capital city of ahvaz.
The earliest mention of the island of Abadan, if not the port itself is found in works of the geographer Marcian, who renders the name "Apphadana".
Earlier, the classical geographer, Ptolemy notes "Apphana" as an island off the mouth of the Tigris (which is, where the modern Island of Abadan is located).
An etymology for this name is presented by B. Farahvashi to be derived from the Persian word "ab" (water) and the root "pā" (guard, watch) thus "coastguard station").
In the Islamic times, a pseudo-etymology was produced by the historian Ahmad ibn Yahya al-Baladhuri (d.
892) quoting a folk story that the town was presumably founded by one "" Abbad bin Hosayn "from the Arabian Tribe of Banu Tamim", who established a garrison there during the governorship of "Hajjaj" in the Ummayad period.
In the subsequent centuries, the Persian version of the name had begun to come into general use before it was adopted by official decree in 1935.
+ Population The civilian population of the city dropped close to zero during the eight years of the Iran–Iraq War (1980 – 1988).
The 1986 census recorded only 6 people.
In 1991, 84,774 had returned to live in the city.
By 2001, the population had jumped to 206,073, and it was 217,988, in 48,061 families, according to 2006 census.
Abadan Refinery is one of the largest in the world.
The population today has reached almost 350,000 people.
Only 9 % of managers (of the oil company) were from Khuzestan.
The proportion of natives of Tehran, the Caspian, Azarbaijan and Kurdistan rose from 4 % of blue collar workers to 22 % of white collar workers to 45 % of managers, thus Arabic-speakers were concentrated on the lower rungs of the work force, managers tended to be brought in from some distance.
There is also a single Armenian church in the centre of the city.
Abadan is thought to have been further developed into a major port city under the Abbasids' rule.
In this time period, it was a commercial source of salt and woven mats.
The siltation of the river delta forced the town further away from water; In the 14th century, however, Ibn Battutah described Abadan just as a small port in a flat salty plain.
Politically, Abadan was often the subject of dispute between the nearby states; in 1847, Persia acquired it from the Ottoman Empire, in which state Abadan has remained since.
From the 17th century onward, the island of Abadan was part of the lands of the Arab "Ka'ab" (Bani Kaab) tribe.
One section of this tribe, "Mohaysen", had its headquarters at "Mohammara" (present-day Khorramshahr), until the removal of Shaikh Khaz'al Khan in 1924.
It was not until the 20th century that rich oil fields were discovered in the area.
On 16 July 1909, after secret negotiation with the British consul, Percy Cox, assisted by Arnold Wilson, Sheik Khaz'al agreed to a rental agreement for the island including Abadan.
The Sheik continued to administer the island until 1924.
The Anglo-Persian Oil Company built their first pipeline terminus oil refinery in Abadan, starting in 1909 and completing it in 1912, with oil flowing by August 1912 (see Abadan Refinery).
Refinery throughput numbers rose from 33,000 tons in 1912 – 1913 to 4,338,000 tons in 1931.
By 1938, it was the largest in the world.
During World War II, Abadan was the site of brief combat between Iranian forces and British and Indian troops during the Anglo-Soviet invasion of Iran.
Later, Abadan was a major logistics centre for Lend-Lease aircraft being sent to the Soviet Union by the United States.
In 1951, Iran nationalized all oil properties and refining ground to a stop on the island.
Rioting broke out in Abadan, after the government had decided to nationalize the oil facilities, and three British workers were killed.
It was not until 1954, that a settlement was reached, which allowed a consortium of international oil companies to manage the production and refining on the island.
This continued until 1973, when the NIOC took over all facilities.
After total nationalization, Iran focused on supplying oil domestically and built a pipeline from Abadan to Tehran.
Whereas Abadan was not a major cultural or religious centre, it did play an important role in the Islamic Revolution.
On 19 August 1978 the anniversary of the US backed coup d'état which overthrew the nationalist and popular Iranian prime minister, Dr. Mohammed Mossadegh – the Cinema Rex, a movie theatre in Abadan, Iran, was set ablaze.
The Cinema Rex Fire caused 430 deaths, but more importantly, it was another event that kept the Islamic Revolution moving ahead.
At the time there was much confusion and misinformation about the perpetrators of the incident.
The public largely put the blame on the local police chief and also the Shah and SAVAK.
The reformist "Sobhe Emrooz" newspaper in one of its editorials revealed that the Cinema Rex was burned down by the radical Islamists.
The newspaper was shut down immediately after.
Over time, the true culprits, radical Islamists, were apprehended and the logic behind this act was revealed, as they were trying both to foment the general public to distrust the government even more, and also as they perceived cinema as a link to the Americans.
This fire was one of four during a short period in August, with other fires in Mashhad, Rizaiya, and Shiraz.
In September 1980, Abadan was almost overrun during a surprise attack on Khuzestan by Iraq, marking the beginning of the Iran–Iraq War.
For 12 months Abadan was besieged, but never captured, by Iraqi forces, and in September 1981, the Iranians broke the siege of Abadan.
Much of the city, including the oil refinery which was the world's largest refinery with capacity of 628,000 barrels per day, was badly damaged or destroyed by the siege and by bombing.
Previous to the war, the city's civilian population was about 300,000, but before it was over, almost the entire populace had sought refuge elsewhere in Iran.
After the war, the biggest concern was the rebuilding of Abadan's oil refinery, as it was operating at 10 % of capacity due to damage.
In 1993, the refinery began limited operation and the port reopened.
By 1997, the refinery reached the same rate of production as before the war.
Recently, Abadan has been the site of major labour activity as workers at the oil refineries in the city have staged walkouts and strikes to protest non-payment of wages and the political situation in the country.
To honour the 100th anniversary of the refining of oil in Abadan, city officials are planning an oil museum.
The Abadan oil refinery was featured on the reverse side of Iran's 100-rial banknotes printed in 1965 and from 1971 to 1973.
Abadan today has been declared as a free zone city.
The healthy relationship between Iran and Iraq has become one of the transit cities connecting both countries through a 40-minute drive.
The climate in Abadan is arid (Köppen climate classification "BWh") and similar to Baghdad's, but slightly hotter due to Abadan's lower latitude.
Summers are dry and extremely hot, with temperatures above almost daily and temperatures above can be almost common.
Abadan is notably one of the few hottest populated places on earth and experiences a few sand and dust storms per year.
Winters are mildly wet and spring-like, though subject to cold spells.
Winter temperatures are around.
The world's highest unconfirmed temperature was a temperature flare up during a heat burst in June 1967, with a temperature of.
The lowest recorded temperature in the city range is.
which was recorded on January 20, 1964 and February 3, 1967 while the highest is, recorded on July 11, 1951 and August 9, 1981.
The Abadan Institute of Technology was established in Abadan in 1939.
The school specialized in engineering and petroleum chemistry, and was designed to train staff for the refinery in town.
The school's name has since changed several times, but since 1989 has been considered a branch campus of the Petroleum University of Technology, centred in Tehran.
There is an international airport in Abadan.
It is represented by the IATA airport code ABD. There is a large amount of external investment from East Asian countries that are building oil refineries and developing a lot of real estate.
Rangoonis Mosque The city is served by Abadan-Ayatollah Jami International Airport with flights on various commercial airlines.
Sir Alexander Fleming (6 August 1881 – 11 March 1955) was a Scottish biologist, physician, microbiologist, and pharmacologist.
His best-known discoveries are the enzyme lysozyme in 1923 and the world's first antibiotic substance benzylpenicillin (Penicillin G) from the mould "Penicillium notatum" in 1928, for which he shared the Nobel Prize in Physiology or Medicine in 1945 with Howard Florey and Ernst Boris Chain.
He wrote many articles on bacteriology, immunology, and chemotherapy.
Fleming was knighted for his scientific achievements in 1944.
In 1999, he was named in "Time" magazine's list of the.
In 2002, he was chosen in the BBC's television poll for determining the 100 Greatest Britons, and in 2009, he was also voted third "greatest Scot" in an opinion poll conducted by STV, behind only Robert Burns and William Wallace.
Born on 6 August 1881 at Lochfield farm near Darvel, in Ayrshire, Scotland, Alexander was the third of four children of farmer Hugh Fleming (1816 – 1888) from his second marriage to Grace Stirling Morton (1848 – 1928), the daughter of a neighbouring farmer.
Hugh Fleming had four surviving children from his first marriage.
He was 59 at the time of his second marriage, and died when Alexander was seven.
Fleming went to Loudoun Moor School and Darvel School, and earned a two-year scholarship to Kilmarnock Academy before moving to London, where he attended the Royal Polytechnic Institution.
After working in a shipping office for four years, the twenty-year-old Alexander Fleming inherited some money from an uncle, John Fleming.
His elder brother, Tom, was already a physician and suggested to him that he should follow the same career, and so in 1903, the younger Alexander enrolled at St Mary's Hospital Medical School in Paddington; he qualified with an MBBS degree from the school with distinction in 1906.
Fleming had been a private in the London Scottish Regiment of the Volunteer Force since 1900, and had been a member of the rifle club at the medical school.
The captain of the club, wishing to retain Fleming in the team, suggested that he join the research department at St Mary's, where he became assistant bacteriologist to Sir Almroth Wright, a pioneer in vaccine therapy and immunology.
In 1908, he gained a BSc degree with Gold Medal in Bacteriology, and became a lecturer at St Mary's until 1914.
Fleming served throughout World War I as a captain in the Royal Army Medical Corps, and was Mentioned in Dispatches.
He and many of his colleagues worked in battlefield hospitals at the Western Front in France.
In 1918 he returned to St Mary's Hospital, where he was elected Professor of Bacteriology of the University of London in 1928.
In 1951 he was elected the Rector of the University of Edinburgh for a term of three years.
During World War I, Fleming witnessed the death of many soldiers from sepsis resulting from infected wounds.
Antiseptics, which were used at the time to treat infected wounds, often worsened the injuries.
In an article he submitted for the medical journal "The Lancet" during World War I, Fleming described an ingenious experiment, which he was able to conduct as a result of his own glass blowing skills, in which he explained why antiseptics were killing more soldiers than infection itself during World War I. Antiseptics worked well on the surface, but deep wounds tended to shelter anaerobic bacteria from the antiseptic agent, and antiseptics seemed to remove beneficial agents produced that protected the patients in these cases at least as well as they removed bacteria, and did nothing to remove the bacteria that were out of reach.
Sir Almroth Wright strongly supported Fleming's findings, but despite this, most army physicians over the course of the war continued to use antiseptics even in cases where this worsened the condition of the patients.
At St Mary's Hospital Fleming continued his investigations into antibacterial substances.
Testing the nasal secretions from a patient with a heavy cold, he found that nasal mucus had an inhibitory effect on bacterial growth.
This was the first recorded discovery of lysozyme, an enzyme present in many secretions including tears, saliva, skin, hair and nails as well as mucus.
Although he was able to obtain larger amounts of lysozyme from egg whites, the enzyme was only effective against small counts of harmless bacteria, and therefore had little therapeutic potential.
By 1927, Fleming had been investigating the properties of staphylococci.
He was already well known from his earlier work, and had developed a reputation as a brilliant researcher, but his laboratory was often untidy.
On 3 September 1928, Fleming returned to his laboratory having spent August on holiday with his family.
Before leaving, he had stacked all his cultures of staphylococci on a bench in a corner of his laboratory.
On returning, Fleming noticed that one culture was contaminated with a fungus, and that the colonies of staphylococci immediately surrounding the fungus had been destroyed, whereas other staphylococci colonies farther away were normal, famously remarking "That's funny".
Fleming showed the contaminated culture to his former assistant Merlin Pryce, who reminded him, "That's how you discovered lysozyme."
Fleming grew the mould in a pure culture and found that it produced a substance that killed a number of disease-causing bacteria.
He identified the mould as being from the genus "Penicillium", and, after some months of calling it "mould juice", named the substance it released "penicillin" on 7 March 1929.
The laboratory in which Fleming discovered and tested penicillin is preserved as the Alexander Fleming Laboratory Museum in St. Mary's Hospital, Paddington.
He investigated its positive anti-bacterial effect on many organisms, and noticed that it affected bacteria such as staphylococci and many other Gram-positive pathogens that cause scarlet fever, pneumonia, meningitis and diphtheria, but not typhoid fever or paratyphoid fever, which are caused by Gram-negative bacteria, for which he was seeking a cure at the time.
It also affected "Neisseria gonorrhoeae," which causes gonorrhoea, although this bacterium is Gram-negative.
Fleming published his discovery in 1929, in the "British Journal of Experimental Pathology," but little attention was paid to his article.
Fleming continued his investigations, but found that cultivating "Penicillium" was quite difficult, and that after having grown the mould, it was even more difficult to isolate the antibiotic agent.
Fleming's impression was that because of the problem of producing it in quantity, and because its action appeared to be rather slow, penicillin would not be important in treating infection.
Fleming also became convinced that penicillin would not last long enough in the human body ("in vivo") to kill bacteria effectively.
Many clinical tests were inconclusive, probably because it had been used as a surface antiseptic.
In the 1930 s, Fleming's trials occasionally showed more promise, but Fleming largely abandoned penicillin work, leaving Howard Florey and Ernst Boris Chain at the Radcliffe Infirmary in Oxford to take up research to mass-produce it, with funds from the U.S. and British governments.
They started mass production after the bombing of Pearl Harbor.
By D-Day in 1944, enough penicillin had been produced to treat all the wounded in the Allied forces.
In Oxford, Ernst Boris Chain and Edward Abraham were studying the molecular structure of the antibiotic.
Abraham was the first to propose the correct structure of penicillin.
Shortly after the team published its first results in 1940, Fleming telephoned Howard Florey, Chain's head of department, to say that he would be visiting within the next few days.
Norman Heatley suggested transferring the active ingredient of penicillin back into water by changing its acidity.
This produced enough of the drug to begin testing on animals.
There were many more people involved in the Oxford team, and at one point the entire Dunn School was involved in its production.
After the team had developed a method of purifying penicillin to an effective first stable form in 1940, several clinical trials ensued, and their amazing success inspired the team to develop methods for mass production and mass distribution in 1945.
Fleming was modest about his part in the development of penicillin, describing his fame as the "Fleming Myth" and he praised Florey and Chain for transforming the laboratory curiosity into a practical drug.
Fleming was the first to discover the properties of the active substance, giving him the privilege of naming it: penicillin.
He also kept, grew, and distributed the original mould for twelve years, and continued until 1940 to try to get help from any chemist who had enough skill to make penicillin.
But Sir Henry Harris said in 1998: "Without Fleming, no Chain; without Chain, no Florey; without Florey, no Heatley; without Heatley, no penicillin."
Fleming's accidental discovery and isolation of penicillin in September 1928 marks the start of modern antibiotics.
Before that, several scientists had published or pointed out that mould or "Penicillium sp." were able to inhibit bacterial growth, and even to cure bacterial infections in animals.
Ernest Duchesne in 1897 in his thesis "Contribution to the study of vital competition in micro-organisms: antagonism between moulds and microbes", or also Clodomiro Picado Twight whose work at the Institut Pasteur in 1923 on the inhibiting action of fungi of the "Penicillin sp." genre in the growth of staphylococci drew little interest from the directors of the Institut at the time.
Fleming was the first to push these studies further by isolating the penicillin, and by being motivated enough to promote his discovery at a larger scale.
Fleming also discovered very early that bacteria developed antibiotic resistance whenever too little penicillin was used or when it was used for too short a period.
Almroth Wright had predicted antibiotic resistance even before it was noticed during experiments.
Fleming cautioned about the use of penicillin in his many speeches around the world.
In such cases the thoughtless person playing with penicillin is morally responsible for the death of the man who finally succumbs to infection with the penicillin-resistant organism.
He cautioned not to use penicillin unless there was a properly diagnosed reason for it to be used, and that if it were used, never to use too little, or for too short a period, since these are the circumstances under which bacterial resistance to antibiotics develops.
The popular story of Winston Churchill's father paying for Fleming's education after Fleming's father saved young Winston from death is false.
According to the biography, "Penicillin Man: Alexander Fleming and the Antibiotic Revolution" by Kevin Brown, Alexander Fleming, in a letter to his friend and colleague Andre Gratia, described this as "A wondrous fable."
Nor did he save Winston Churchill himself during World War II.
Churchill was saved by Lord Moran, using sulphonamides, since he had no experience with penicillin, when Churchill fell ill in Carthage in Tunisia in 1943.
"The Daily Telegraph" and "The Morning Post" on 21 December 1943 wrote that he had been saved by penicillin.
He was saved by the new sulphonamide drug Sulphapyridine, known at the time under the research code M&B 693, discovered and produced by May & Baker Ltd, Dagenham, Essex – a subsidiary of the French group Rhône-Poulenc.
In a subsequent radio broadcast, Churchill referred to the new drug as "This admirable M&B".
It is highly probable that the correct information about the sulphonamide did not reach the newspapers because, since the original sulphonamide antibacterial, Prontosil, had been a discovery by the German laboratory Bayer, and as Britain was at war with Germany at the time, it was thought better to raise British morale by associating Churchill's cure with a British discovery, penicillin.
Fleming's discovery of penicillin changed the world of modern medicine by introducing the age of useful antibiotics; penicillin has saved, and is still saving, millions of people around the world.
The laboratory at St Mary's Hospital where Fleming discovered penicillin is home to the Fleming Museum, a popular London attraction.
His alma mater, St Mary's Hospital Medical School, merged with Imperial College London in 1988.
The "Sir Alexander Fleming Building" on the South Kensington campus was opened in 1998, where his son Robert and his great granddaughter Claire were presented to the Queen; it is now one of the main preclinical teaching sites of the Imperial College School of Medicine.
His other alma mater, the Royal Polytechnic Institution (now the University of Westminster) has named one of its student halls of residence "Alexander Fleming House", which is near to Old Street.
On 24 December 1915, Fleming married a trained nurse, Sarah Marion McElroy of Killala, County Mayo, Ireland.
Their only child, Robert Fleming (1924 – 2015), became a general medical practitioner.
After his first wife's death in 1949, Fleming married Dr. Amalia Koutsouri-Vourekas, a Greek colleague at St. Mary's, on 9 April 1953; she died in 1986.
Fleming was a Roman Catholic.
From 1921 until his death in 1955, Fleming owned a country home in Barton Mills, Suffolk.
On 11 March 1955, Fleming died at his home in London of a heart attack.
His ashes are buried in St Paul's Cathedral.
Andrew Carnegie (November 25, 1835August 11, 1919) was a Scottish-American industrialist, business magnate, and philanthropist.
Carnegie led the expansion of the American steel industry in the late 19th century and became one of the richest Americans in history.
He became a leading philanthropist in the United States and in the British Empire.
During the last 18 years of his life, he gave away $ 350 million (conservatively $ 65 billion in 2019 dollars, based on percentage of GDP) to charities, foundations, and universities – almost 90 percent of his fortune.
His 1889 article proclaiming "The Gospel of Wealth" called on the rich to use their wealth to improve society, and stimulated a wave of philanthropy.
Carnegie was born in Dunfermline, Scotland, and immigrated to the United States with his parents in 1848 at age 12.
Carnegie started work as a telegrapher, and by the 1860 s had investments in railroads, railroad sleeping cars, bridges, and oil derricks.
He accumulated further wealth as a bond salesman, raising money for American enterprise in Europe.
He built Pittsburgh's Carnegie Steel Company, which he sold to J. P. Morgan in 1901 for $ 303,450,000.
It became the U.S. Steel Corporation.
After selling Carnegie Steel, he surpassed John D. Rockefeller as the richest American for the next several years.
Carnegie devoted the remainder of his life to large-scale philanthropy, with special emphasis on local libraries, world peace, education, and scientific research.
With the fortune he made from business, he built Carnegie Hall in New York, NY, and the Peace Palace and founded the Carnegie Corporation of New York, Carnegie Endowment for International Peace, Carnegie Institution for Science, Carnegie Trust for the Universities of Scotland, Carnegie Hero Fund, Carnegie Mellon University, and the Carnegie Museums of Pittsburgh, among others.
Andrew Carnegie was born to Margaret Morrison Carnegie and William Carnegie in Dunfermline, Scotland, in a typical weaver's cottage with only one main room, consisting of half the ground floor, which was shared with the neighboring weaver's family.
The main room served as a living room, dining room and bedroom.
He was named after his legal grandfather.
In 1836, the family moved to a larger house in Edgar Street (opposite Reid's Park), following the demand for more heavy damask, from which his father benefited.
He was educated at the Free School in Dunfermline, which had been a gift to the town by the philanthropist Adam Rolland of Gask.
Carnegie's uncle, George Lauder, Sr., a Scottish political leader, deeply influenced him as a boy by introducing him to the writings of Robert Burns and historical Scottish heroes such as Robert the Bruce, William Wallace, and Rob Roy.
Lauder's son, also named George Lauder, grew up with Carnegie and would become his business partner.
When Carnegie was thirteen, his father had fallen on very hard times as a handloom weaver; making matters worse, the country was in starvation.
His mother helped support the family by assisting her brother (a cobbler), and by selling potted meats at her "sweetie shop", leaving her as the primary breadwinner.
Struggling to make ends meet, the Carnegies then decided to borrow money from George Lauder, Sr. and move to Allegheny, Pennsylvania, in the United States in 1848 for the prospect of a better life.
Carnegie's migration to America would be his second journey outside Dunfermline – the first being an outing to Edinburgh to see Queen Victoria.
In September 1848, Carnegie arrived with his family at their new prosperous home.
Allegheny was rapidly populating in the 1840 s, growing from around 10,000 to 21,262 residents.
The city was very industrial and produced many products including wool and cotton cloth.
The "Made in Allegheny" label used on these and other diversified products was becoming more and more popular.
For his father, the promising circumstances still did not provide him any good fortune.
Dealers were not interested in selling his product, and he himself struggled to sell it on his own.
Eventually, the father and son both received job offers at the same Scottish-owned cotton mill, Anchor Cotton Mills.
Carnegie's first job in 1848 was as a bobbin boy, changing spools of thread in a cotton mill 12 hours a day, 6 days a week in a Pittsburgh cotton factory.
His starting wage was $ 1.20 per week ($ by 2018 inflation).
His father quit his position at the cotton mill soon after, returning to his loom and removing him as breadwinner once again.
But Carnegie attracted the attention of John Hay, a Scottish manufacturer of bobbins, who offered him a job for $ 2.00 per week ($ by 2018 inflation).
In his autobiography, Carnegie speaks of his past hardships he had to endure with this new job.
In 1849, Carnegie became a telegraph messenger boy in the Pittsburgh Office of the Ohio Telegraph Company, at $ 2.50 per week ($ by 2018 inflation) following the recommendation of his uncle.
He was a hard worker and would memorize all of the locations of Pittsburgh's businesses and the faces of important men.
He made many connections this way.
He also paid close attention to his work, and quickly learned to distinguish the differing sounds the incoming telegraph signals produced.
He developed the ability to translate signals by ear, without using the paper slip, and within a year was promoted to operator.
Carnegie's education and passion for reading was given a boost by Colonel James Anderson, who opened his personal library of 400 volumes to working boys each Saturday night.
Carnegie was a consistent borrower and a "self-made man" in both his economic development and his intellectual and cultural development.
He was so grateful to Colonel Anderson for the use of his library that he "resolved, if ever wealth came to me, [to see to it] that other poor boys might receive opportunities similar to those for which we were indebted to the noble man".
His capacity, his willingness for hard work, his perseverance and his alertness soon brought him opportunities.
Starting in 1853, when Carnegie was around 18 years old, Thomas A. Scott of the Pennsylvania Railroad Company employed him as a secretary/telegraph operator at a salary of $ 4.00 per week ($ by 2018 inflation).
Carnegie accepted the job with the railroad as he saw more prospects for career growth and experience there than with the telegraph company.
At age 24, Scott asked Carnegie if he could handle being superintendent of the Western Division of the Pennsylvania Railroad.
On December 1, 1859, Carnegie officially became superintendent of the Western Division.
Carnegie then hired his sixteen-year-old brother, Tom, to be his personal secretary and telegraph operator.
Not only did Carnegie hire his brother, but he also hired his cousin, Maria Hogan, who became the first female telegraph operator in the country.
As superintendent Carnegie made a salary of fifteen hundred dollars a year ($ by 2018 inflation).
His employment by the Pennsylvania Railroad Company would be vital to his later success.
The railroads were the first big businesses in America, and the Pennsylvania was one of the largest of them all.
Carnegie learned much about management and cost control during these years, and from Scott in particular.
Scott also helped him with his first investments.
Many of these were part of the corruption indulged in by Scott and the Pennsylvania's president, John Edgar Thomson, which consisted of inside trading in companies that the railroad did business with, or payoffs made by contracting parties "as part of a quid pro quo".
In 1855, Scott made it possible for Carnegie to invest $ 500 in the Adams Express, which contracted with the Pennsylvania to carry its messengers.
The money was secured by his mother's placing of a $ 600 mortgage on the family's $ 700 home, but the opportunity was available only because of Carnegie's close relationship with Scott.
A few years later, he received a few shares in Theodore Tuttle Woodruff's sleeping car company, as a reward for holding shares that Woodruff had given to Scott and Thomson, as a payoff.
Reinvesting his returns in such inside investments in railroad-related industries: (iron, bridges, and rails), Carnegie slowly accumulated capital, the basis for his later success.
Throughout his later career, he made use of his close connections to Thomson and Scott, as he established businesses that supplied rails and bridges to the railroad, offering the two men a stake in his enterprises.
Before the Civil War, Carnegie arranged a merger between Woodruff's company and that of George Pullman, the inventor of a sleeping car for first class travel, which facilitated business travel at distances over.
The investment proved a success and a source of profit for Woodruff and Carnegie.
The young Carnegie continued to work for the Pennsylvania's Tom Scott, and introduced several improvements in the service.
In spring 1861, Carnegie was appointed by Scott, who was now Assistant Secretary of War in charge of military transportation, as Superintendent of the Military Railways and the Union Government's telegraph lines in the East.
Carnegie helped open the rail lines into Washington D.C. that the rebels had cut; he rode the locomotive pulling the first brigade of Union troops to reach Washington D.C. Following the defeat of Union forces at Bull Run, he personally supervised the transportation of the defeated forces.
Under his organization, the telegraph service rendered efficient service to the Union cause and significantly assisted in the eventual victory.
Carnegie later joked that he was "the first casualty of the war" when he gained a scar on his cheek from freeing a trapped telegraph wire.
Defeat of the Confederacy required vast supplies of munitions, as well as railroads (and telegraph lines) to deliver the goods.
The war demonstrated how integral the industries were to American success.
In 1864, Carnegie was one of the early investors in the Columbia Oil Company in Venango County, Pennsylvania.
In one year, the farm yielded over $ 1,000,000 in cash dividends, and petroleum from oil wells on the property sold profitably.
The demand for iron products, such as armor for gunboats, cannons, and shells, as well as a hundred other industrial products, made Pittsburgh a center of wartime production.
Carnegie worked with others in establishing a steel rolling mill, and steel production and control of industry became the source of his fortune.
Carnegie had some investments in the iron industry before the war.
After the war, Carnegie left the railroads to devote his energies to the ironworks trade.
Carnegie worked to develop several ironworks, eventually forming the Keystone Bridge Works and the Union Ironworks, in Pittsburgh.
Although he had left the Pennsylvania Railroad Company, he remained connected to its management, namely Thomas A. Scott and J. Edgar Thomson.
He used his connection to the two men to acquire contracts for his Keystone Bridge Company and the rails produced by his ironworks.
He also gave stock to Scott and Thomson in his businesses, and the Pennsylvania was his best customer.
When he built his first steel plant, he made a point of naming it after Thomson.
As well as having good business sense, Carnegie possessed charm and literary knowledge.
He was invited to many important social functions, which Carnegie exploited to his advantage.
Carnegie believed in using his fortune for others and doing more than making money.
He wrote: Carnegie did not want to marry during his mother's lifetime, instead choosing to take care of her in her illness towards the end of her life.
After she died in 1886, the 51-year - old Carnegie married Louise Whitfield, who was 21 years his junior.
In 1897, the couple had their only child, a daughter, whom they named after Carnegie's mother, Margaret.
Carnegie made his fortune in the steel industry, controlling the most extensive integrated iron and steel operations ever owned by an individual in the United States.
One of his two great innovations was in the cheap and efficient mass production of steel by adopting and adapting the Bessemer process, which allowed the high carbon content of pig iron to be burnt away in a controlled and rapid way during steel production.
Steel prices dropped as a result, and Bessemer steel was rapidly adopted for rails; however, it was not suitable for buildings and bridges.
The second was in his vertical integration of all suppliers of raw materials.
In the late 1880 s, Carnegie Steel was the largest manufacturer of pig iron, steel rails, and coke in the world, with a capacity to produce approximately 2,000 tons of pig metal per day.
In 1883, Carnegie bought the rival Homestead Steel Works, which included an extensive plant served by tributary coal and iron fields, a long railway, and a line of lake steamships.
Carnegie combined his assets and those of his associates in 1892 with the launching of the Carnegie Steel Company.
By 1889, the U.S. output of steel exceeded that of the UK, and Carnegie owned a large part of it.
Carnegie's empire grew to include the J. Edgar Thomson Steel Works in Braddock, (named for John Edgar Thomson, Carnegie's former boss and president of the Pennsylvania Railroad), Pittsburgh Bessemer Steel Works, the Lucy Furnaces, the Union Iron Mills, the Union Mill (Wilson, Walker & County), the Keystone Bridge Works, the Hartman Steel Works, the Frick Coke Company, and the Scotia ore mines.
Carnegie, through Keystone, supplied the steel for and owned shares in the landmark Eads Bridge project across the Mississippi River at St. Louis, Missouri (completed 1874).
This project was an important proof-of-concept for steel technology, which marked the opening of a new steel market.
In 1901, Carnegie was 66 years of age and considering retirement.
He reformed his enterprises into conventional joint stock corporations as preparation for this.
John Pierpont Morgan was a banker and America's most important financial deal maker.
He had observed how efficiently Carnegie produced profits.
He envisioned an integrated steel industry that would cut costs, lower prices to consumers, produce in greater quantities and raise wages to workers.
To this end, he needed to buy out Carnegie and several other major producers and integrate them into one company, thereby eliminating duplication and waste.
He concluded negotiations on March 2, 1901, and formed the United States Steel Corporation.
It was the first corporation in the world with a market capitalization over $ 1 billion.
The buyout, secretly negotiated by Charles M. Schwab (no relation to Charles R. Schwab), was the largest such industrial takeover in United States history to date.
The holdings were incorporated in the United States Steel Corporation, a trust organized by Morgan, and Carnegie retired from business.
His steel enterprises were bought out for $ 303,450,000.
Carnegie's share of this amounted to $ 225.64 million (in, $), which was paid to Carnegie in the form of 5 %, 50-year gold bonds.
The letter agreeing to sell his share was signed on February 26, 1901.
On March 2, the circular formally filing the organization and capitalization (at $ 1.4 billion – 4 percent of the U.S. gross domestic product (GDP) at the time) of the United States Steel Corporation actually completed the contract.
The bonds were to be delivered within two weeks to the Hudson Trust Company of Hoboken, New Jersey, in trust to Robert A. Franks, Carnegie's business secretary.
There, a special vault was built to house the physical bulk of nearly $ 230 million worth of bonds.
Carnegie continued his business career; some of his literary intentions were fulfilled.
He befriended the English poet Matthew Arnold, the English philosopher Herbert Spencer, and the American humorist Mark Twain, as well as being in correspondence and acquaintance with most of the U.S. Presidents, statesmen, and notable writers.
Carnegie constructed commodious swimming-baths for the people of his hometown in Dunfermline in 1879.
In the following year, Carnegie gave £ 8,000 for the establishment of a Dunfermline Carnegie Library in Scotland.
In 1884, he gave $ 50,000 to Bellevue Hospital Medical College (now part of New York University Medical Center) to found a histological laboratory, now called the Carnegie Laboratory.
In 1881, Carnegie took his family, including his 70-year - old mother, on a trip to the United Kingdom.
They toured Scotland by coach, and enjoyed several receptions en route.
The highlight was a return to Dunfermline, where Carnegie's mother laid the foundation stone of a Carnegie library which he funded.
Carnegie's criticism of British society did not mean dislike; on the contrary, one of Carnegie's ambitions was to act as a catalyst for a close association between English-speaking peoples.
To this end, in the early 1880 s in partnership with Samuel Storey, he purchased numerous newspapers in England, all of which were to advocate the abolition of the monarchy and the establishment of "the British Republic".
Carnegie's charm, aided by his wealth, afforded him many British friends, including Prime Minister William Ewart Gladstone.
In 1886, Carnegie's younger brother Thomas died at age 43.
While owning steel works, Carnegie had purchased at low cost the most valuable of the iron ore fields around Lake Superior.
The same year Carnegie became a figure of controversy.
Following his tour of the UK, he wrote about his experiences in a book entitled "An American Four-in-hand in Britain".
Although actively involved in running his many businesses, Carnegie had become a regular contributor to numerous magazines, most notably "The Nineteenth Century", under the editorship of James Knowles, and the influential "North American Review", led by editor Lloyd Bryce.
In 1886, Carnegie wrote his most radical work to date, entitled "Triumphant Democracy".
Liberal in its use of statistics to make its arguments, the book argued his view that the American republican system of government was superior to the British monarchical system.
It gave a highly favorable and idealized view of American progress and criticized the British royal family.
The cover depicted an upended royal crown and a broken scepter.
The book created considerable controversy in the UK.
The book made many Americans appreciate their country's economic progress and sold over 40,000 copies, mostly in the US.
In 1889, Carnegie published "Wealth" in the June issue of the "North American Review".
After reading it, Gladstone requested its publication in England, where it appeared as "The Gospel of Wealth" in the "Pall Mall Gazette".
Carnegie argued that the life of a wealthy industrialist should comprise two parts.
The first part was the gathering and the accumulation of wealth.
The second part was for the subsequent distribution of this wealth to benevolent causes.
Philanthropy was key to making life worthwhile.
Carnegie was a well-regarded writer.
He published three books on travel.
While Carnegie did not comment on British imperialism, he strongly opposed the idea of American colonies.
He opposed the annexation of the Philippines almost to the point of supporting William Jennings Bryan against McKinley in 1900.
In 1898, Carnegie tried to arrange for independence for the Philippines.
As the end of the Spanish–American War neared, the United States bought the Philippines from Spain for $ 20 million.
To counter what he perceived as imperialism on the part of the United States, Carnegie personally offered $ 20 million to the Philippines so that the Filipino people could buy their independence from the United States.
However, nothing came of the offer.
In 1898 Carnegie joined the American Anti-Imperialist League, in opposition to the U.S. annexation of the Philippines.
Its membership included former presidents of the United States Grover Cleveland and Benjamin Harrison and literary figures like Mark Twain.
Carnegie spent his last years as a philanthropist.
From 1901 forward, public attention was turned from the shrewd business acumen which had enabled Carnegie to accumulate such a fortune, to the public-spirited way in which he devoted himself to utilizing it on philanthropic projects.
He had written about his views on social subjects and the responsibilities of great wealth in "Triumphant Democracy" (1886) and "Gospel of Wealth" (1889).
Carnegie bought Skibo Castle in Scotland, and made his home partly there and partly in his New York mansion located at 2 East 91st Street at Fifth Avenue.
The building was completed in late 1902, and he lived there until his death in 1919.
His wife Louise continued to live there until her death in 1946.
The building is now the Cooper-Hewitt, Smithsonian Design Museum, part of the Smithsonian Institution.
The surrounding neighborhood on Manhattan's Upper East Side has come to be called Carnegie Hill.
The mansion was named a National Historic Landmark in 1966.
He then devoted his life to providing the capital for purposes of public interest and social and educational advancement, saving letters of appreciation from those he helped in a desk drawer labeled "Gratitude and Sweet Words."
He was a powerful supporter of the movement for spelling reform, as a means of promoting the spread of the English language.
His organisation, the Simplified Spelling Board, created the "Handbook of Simplified Spelling", which was written wholly in reformed spelling.
Among his many philanthropic efforts, the establishment of public libraries throughout the United States, Britain, Canada and other English-speaking countries was especially prominent.
In this special driving interest and project of his, he was inspired by meetings with philanthropist Enoch Pratt (1808 – 1896).
The Enoch Pratt Free Library (1886) impressed Carnegie deeply; he said, "Pratt was my guide and inspiration."
Carnegie turned over management of the library project by 1908 to his staff, led by James Bertram (1874 – 1934).
The first Carnegie library opened in 1883 in Dunfermline.
His method was to build and equip, but only on condition that the local authority matched that by providing the land and a budget for operation and maintenance.
To secure local interest, in 1885, he gave $ 500,000 to Pittsburgh for a public library, and in 1886, he gave $ 250,000 to Allegheny City for a music hall and library; and $ 250,000 to Edinburgh for a free library.
In total, Carnegie funded some 3,000 libraries, located in 47 US states, and also in Canada, Britain, Ireland, Australia, New Zealand, South Africa, the West Indies, and Fiji.
He also donated £ 50,000 to help set up the University of Birmingham in 1899.
As Van Slyck (1991) showed, the last years of the 19th century saw acceptance of the idea that free libraries should be available to the American public.
But the design of the idealized free library was the subject of prolonged and heated debate.
On one hand, the library profession called for designs that supported efficiency in administration and operation; on the other, wealthy philanthropists favored buildings that reinforced the paternalistic metaphor and enhanced civic pride.
Between 1886 and 1917, Carnegie reformed both library philanthropy and library design, encouraging a closer correspondence between the two.
In 1900, Carnegie gave $ 2 million to start the Carnegie Institute of Technology (CIT) at Pittsburgh and the same amount in 1902 to found the Carnegie Institution at Washington, D.C. He later contributed more to these and other schools.
CIT is now known as Carnegie Mellon University after it merged with the Mellon Institute of Industrial Research.
Carnegie also served on the Boards of Cornell University and Stevens Institute of Technology.
The telescope saw first light on November 2, 1917, with Carnegie still alive.
In 1901, in Scotland, he gave $ 10 million to establish the Carnegie Trust for the Universities of Scotland.
It was created by a deed which he signed on June 7, 1901, and it was incorporated by Royal Charter on August 21, 1902.
The establishing gift of $ 10 million was then an unprecedented sum: at the time, total government assistance to all four Scottish universities was about £ 50,000 a year.
The aim of the Trust was to improve and extend the opportunities for scientific research in the Scottish universities and to enable the deserving and qualified youth of Scotland to attend a university.
He was subsequently elected Lord Rector of University of St. Andrews in December 1901, and formally installed as such in October 1902, serving until 1907.
He also donated large sums of money to Dunfermline, the place of his birth.
In addition to a library, Carnegie also bought the private estate which became Pittencrieff Park and opened it to all members of the public, establishing the Carnegie Dunfermline Trust to benefit the people of Dunfermline.
A statue of him stands there today.
He gave a further $ 10 million in 1913 to endow the Carnegie United Kingdom Trust, a grant-making foundation.
He transferred to the trust the charge of all his existing and future benefactions, other than university benefactions in the United Kingdom.
He gave the trustees a wide discretion, and they inaugurated a policy of financing rural library schemes rather than erecting library buildings, and of assisting the musical education of the people rather than granting organs to churches.
In 1901, Carnegie also established large pension funds for his former employees at Homestead and, in 1905, for American college professors.
The latter fund evolved into TIAA-CREF.
One critical requirement was that church-related schools had to sever their religious connections to get his money.
His interest in music led him to fund construction of 7,000 church organs.
He built and owned Carnegie Hall in New York City.
Carnegie was a large benefactor of the Tuskegee Institute for African-American education under Booker T. Washington.
He helped Washington create the National Negro Business League.
In 1904, he founded the Carnegie Hero Fund for the United States and Canada (a few years later also established in the United Kingdom, Switzerland, Norway, Sweden, France, Italy, the Netherlands, Belgium, Denmark, and Germany) for the recognition of deeds of heroism.
Carnegie contributed $ 1,500,000 in 1903 for the erection of the Peace Palace at The Hague; and he donated $ 150,000 for a Pan-American Palace in Washington as a home for the International Bureau of American Republics.
Carnegie was honored for his philanthropy and support of the arts by initiation as an honorary member of Phi Mu Alpha Sinfonia Fraternity on October 14, 1917, at the New England Conservatory of Music in Boston, Massachusetts.
The fraternity's mission reflects Carnegie's values by developing young men to share their talents to create harmony in the world.
By the standards of 19th century tycoons, Carnegie was not a particularly ruthless man but a humanitarian with enough acquisitiveness to go in the ruthless pursuit of money.
"Maybe with the giving away of his money," commented biographer Joseph Wall, "he would justify what he had done to get that money."
To some, Carnegie represents the idea of the American dream.
He was an immigrant from Scotland who came to America and became successful.
He is not only known for his successes but his enormous amounts of philanthropist works, not only to charities but also to promote democracy and independence to colonized countries.
Carnegie died on August 11, 1919, in Lenox, Massachusetts, at his Shadow Brook estate, of bronchial pneumonia.
He had already given away $ 350,695,653 (approximately $ 76.9 billion, adjusted to 2015 share of GDP figures) of his wealth.
After his death, his last $ 30,000,000 was given to foundations, charities, and to pensioners.
He was buried at Sleepy Hollow Cemetery in Sleepy Hollow, New York.
The grave site is located on the Arcadia Hebron plot of land at the corner of Summit Avenue and Dingle Road.
Carnegie is buried only a few yards away from union organizer Samuel Gompers, another important figure of industry in the Gilded Age.
Carnegie was one of more than 50 members of the South Fork Fishing and Hunting Club, which has been blamed for the Johnstown Flood that killed 2,209 people in 1889.
At the suggestion of his friend Benjamin Ruff, Carnegie's partner Henry Clay Frick had formed the exclusive South Fork Fishing and Hunting Club high above Johnstown, Pennsylvania.
The sixty-odd club members were the leading business tycoons of Western Pennsylvania and included among their number Frick's best friend, Andrew Mellon, his attorneys Philander Knox and James Hay Reed, as well as Frick's business partner, Carnegie.
High above the city, near the small town of South Fork, the South Fork Dam was originally built between 1838 and 1853 by the Commonwealth of Pennsylvania as part of a canal system to be used as a reservoir for a canal basin in Johnstown.
With the coming-of-age of railroads superseding canal barge transport, the lake was abandoned by the Commonwealth, sold to the Pennsylvania Railroad, and sold again to private interests and eventually came to be owned by the South Fork Fishing and Hunting Club in 1881.
Prior to the flood, speculators had purchased the abandoned reservoir, made less than well-engineered repairs to the old dam, raised the lake level, built cottages and a clubhouse, and created the South Fork Fishing and Hunting Club.
Less than downstream from the dam sat the city of Johnstown.
The dam was high and long.
Between 1881 when the club was opened, and 1889, the dam frequently sprang leaks and was patched, mostly with mud and straw.
Additionally, a previous owner removed and sold for scrap the 3 cast iron discharge pipes that previously allowed a controlled release of water.
There had been some speculation as to the dam's integrity, and concerns had been raised by the head of the Cambria Iron Works downstream in Johnstown.
Such repair work, a reduction in height, and unusually high snowmelt and heavy spring rains combined to cause the dam to give way on May 31, 1889 resulting in twenty million tons of water sweeping down the valley as the Johnstown Flood.
When word of the dam's failure was telegraphed to Pittsburgh, Frick and other members of the South Fork Fishing and Hunting Club gathered to form the Pittsburgh Relief Committee for assistance to the flood victims as well as determining never to speak publicly about the club or the flood.
This strategy was a success, and Knox and Reed were able to fend off all lawsuits that would have placed blame upon the club's members.
Although Cambria Iron and Steel's facilities were heavily damaged by the flood, they returned to full production within a year.
After the flood, Carnegie built Johnstown a new library to replace the one built by Cambria's chief legal counsel Cyrus Elder, which was destroyed in the flood.
The Carnegie-donated library is now owned by the Johnstown Area Heritage Association, and houses the Flood Museum.
The Homestead Strike was a bloody labor confrontation lasting 143 days in 1892, one of the most serious in U.S. history.
The conflict was centered on Carnegie Steel's main plant in Homestead, Pennsylvania, and grew out of a labor dispute between the Amalgamated Association of Iron and Steel Workers (AA) and the Carnegie Steel Company.
Carnegie left on a trip to Scotland before the unrest peaked.
In doing so, Carnegie left mediation of the dispute in the hands of his associate and partner Henry Clay Frick.
Frick was well known in industrial circles for maintaining staunch anti-union sentiment.
With the collective bargaining agreement between the union and company expiring at the end of June, Frick and the leaders of the local AA union entered into negotiations in February.
With the steel industry doing well and prices higher, the AA asked for a wage increase; the AA represented about 800 of the 3,800 workers at the plant.
Frick immediately countered with an average 22 % wage decrease that would affect nearly half the union's membership and remove a number of positions from the bargaining unit.
The union and company failed to come to an agreement, and management locked the union out.
Workers considered the stoppage a "lockout" by management and not a "strike" by workers.
As such, the workers would have been well within their rights to protest, and subsequent government action would have been a set of criminal procedures designed to crush what was seen as a pivotal demonstration of the growing labor rights movement, strongly opposed by management.
Frick brought in thousands of strikebreakers to work the steel mills and Pinkerton agents to safeguard them.
On July 6, the arrival of a force of 300 Pinkerton agents from New York City and Chicago resulted in a fight in which 10 men — seven strikers and three Pinkertons — were killed and hundreds were injured.
Pennsylvania Governor Robert Pattison ordered two brigades of state militia to the strike site.
Then allegedly in response to the fight between the striking workers and the Pinkertons, anarchist Alexander Berkman shot at Frick in an attempted assassination, wounding him.
While not directly connected to the strike, Berkman was tied in for the assassination attempt.
Afterwards, the company successfully resumed operations with non-union immigrant employees in place of the Homestead plant workers, and Carnegie returned to the United States.
However, Carnegie's reputation was permanently damaged by the Homestead events.
Carnegie gave "formal allegiance" to the Republican Party, though he was said to be "a violent opponent of some of the most sacred doctrines" of the party.
In his final days, Carnegie suffered from pneumonia.
Before his death on August 11, 1919, Carnegie had donated $ 350,695,654 for various causes.
The "Andrew Carnegie Dictum" was: Carnegie was involved in philanthropic causes, but he kept himself away from religious circles.
He wanted to be identified by the world as a "positivist".
He was highly influenced in public life by John Bright.
As early as 1868, at age 33, he drafted a memo to himself.
The amassing of wealth is one of the worse species of idolatry.
However, he did not begin his philanthropic work in all earnest until 1881, with the gift of a library to his hometown of Dunfermline, Scotland.
Carnegie wrote "The Gospel of Wealth", an article in which he stated his belief that the rich should use their wealth to help enrich society.
In that article, Carnegie also expressed sympathy for the ideas of progressive taxation and an estate tax.
The following is taken from one of Carnegie's memos to himself: Carnegie claimed to be a champion of evolutionary thought particularly the work of Herbert Spencer, even declaring Spencer his teacher.
Although Carnegie claims to be a disciple of Spencer many of his actions went against the ideas espoused by Spencer.
Spencerian evolution was for individual rights and against government interference.
Furthermore, Spencerian evolution held that those unfit to sustain themselves must be allowed to perish.
Spencer believed that just as there were many varieties of beetles, respectively modified to existence in a particular place in nature, so too had human society "spontaneously fallen into division of labour".
Individuals who survived to this, the latest and highest stage of evolutionary progress would be "those in whom the power of self-preservation is the greatest—are the select of their generation."
Moreover, Spencer perceived governmental authority as borrowed from the people to perform the transitory aims of establishing social cohesion, insurance of rights, and security.
Spencerian ' survival of the fittest ' firmly credits any provisions made to assist the weak, unskilled, poor and distressed to be an imprudent disservice to evolution.
Spencer insisted people should resist for the benefit of collective humanity, as severe fate singles out the weak, debauched, and disabled.
Andrew Carnegie's political and economic focus during the late nineteenth and early twentieth century was the defense of laissez faire economics.
Carnegie emphatically resisted government intrusion in commerce, as well as government-sponsored charities.
Carnegie believed the concentration of capital was essential for societal progress and should be encouraged.
Carnegie was an ardent supporter of commercial "survival of the fittest" and sought to attain immunity from business challenges by dominating all phases of the steel manufacturing procedure.
Carnegie's determination to lower costs included cutting labor expenses as well.
In a notably Spencerian manner, Carnegie argued that unions impeded the natural reduction of prices by pushing up costs, which blocked evolutionary progress.
Carnegie felt that unions represented the narrow interest of the few while his actions benefited the entire community.
On the surface, Andrew Carnegie appears to be a strict laissez-faire capitalist and follower of Herbert Spencer, often referring to himself as a disciple of Spencer.
Conversely, Carnegie, a titan of industry, seems to embody all of the qualities of Spencerian survival of the fittest.
The two men enjoyed a mutual respect for one another and maintained correspondence until Spencer's death in 1903.
There are however, some major discrepancies between Spencer's capitalist evolutionary conceptions and Andrew Carnegie's capitalist practices.
Spencer wrote that in production the advantages of the superior individual are comparatively minor, and thus acceptable, yet the benefit that dominance provides those who control a large segment of production might be hazardous to competition.
Spencer feared that an absence of "sympathetic self-restraint" of those with too much power could lead to the ruin of their competitors.
He did not think free market competition necessitated competitive warfare.
Furthermore, Spencer argued that individuals with superior resources who deliberately used investment schemes to put competitors out of business were committing acts of "commercial murder".
Carnegie built his wealth in the steel industry by maintaining an extensively integrated operating system.
Carnegie also bought out some regional competitors, and merged with others, usually maintaining the majority shares in the companies.
Over the course of twenty years, Carnegie's steel properties grew to include the Edgar Thomson Steel Works, the Lucy Furnace Works, the Union Iron Mills, the Homestead Works, the Keystone Bridge Works, the Hartman Steel Works, the Frick Coke Company, and the Scotia ore mines among many other industry related assets.
Furthermore, Carnegie's success was due to his convenient relationship with the railroad industries, which not only relied on steel for track, but were also making money from steel transport.
The steel and railroad barons worked closely to negotiate prices instead of free market competition determinations.
Besides Carnegie's market manipulation, United States trade tariffs were also working in favor of the steel industry.
Carnegie spent energy and resources lobbying congress for a continuation of favorable tariffs from which he earned millions of dollars a year.
Carnegie tried to keep this information concealed, but legal documents released in 1900, during proceedings with the ex-chairman of Carnegie Steel, Henry Clay Frick, revealed how favorable the tariffs had been.
Herbert Spencer absolutely was against government interference in business in the form of regulatory limitation, taxes, and tariffs as well.
Spencer saw tariffs as a form of taxation that levied against the majority in service to "the benefit of a small minority of manufacturers and artisans".
Despite Carnegie's personal dedication to Herbert Spencer as a friend, his adherence to Spencer's political and economic ideas is more contentious.
In particular, it appears Carnegie either misunderstood or intentionally misrepresented some of Spencer's principal arguments.
Spencer remarked upon his first visit to Carnegie's steel mills in Pittsburgh, which Carnegie saw as the manifestation of Spencer's philosophy, "Six months' residence here would justify suicide."
On the subject of charity Andrew Carnegie's actions diverged in the most significant and complex manner from Herbert Spencer's philosophies.
In his 1854 essay "Manners and Fashion", Spencer referred to public education as "Old schemes".
He went on to declare that public schools and colleges fill the heads of students with inept, useless knowledge and exclude useful knowledge.
Spencer stated that he trusted no organization of any kind, "political, religious, literary, philanthropic", and believed that as they expanded in influence so too did their regulations expand.
In addition, Spencer thought that as all institutions grow they become evermore corrupted by the influence of power and money.
The institution eventually loses its "original spirit, and sinks into a lifeless mechanism".
Spencer insisted that all forms of philanthropy that uplift the poor and downtrodden were reckless and incompetent.
Spencer thought any attempt to prevent "the really salutary sufferings" of the less fortunate "bequeath to posterity a continually increasing curse".
Carnegie, a self-proclaimed devotee of Spencer, testified to Congress on February 5, 1915: "My business is to do as much good in the world as I can; I have retired from all other business."
Carnegie held that societal progress relied on individuals who maintained moral obligations to themselves and to society.
Furthermore, he believed that charity supplied the means for those who wish to improve themselves to achieve their goals.
Carnegie urged other wealthy people to contribute to society in the form of parks, works of art, libraries and other endeavors that improve the community and contribute to the "lasting good".
Carnegie also held a strong opinion against inherited wealth.
Carnegie believed that the sons of prosperous businesspersons were rarely as talented as their fathers.
By leaving large sums of money to their children, wealthy business leaders were wasting resources that could be used to benefit society.
Most notably, Carnegie believed that the future leaders of society would rise from the ranks of the poor.
Carnegie strongly believed in this because he had risen from the bottom.
He believed the poor possessed an advantage over the wealthy because they receive greater attention from their parents and are taught better work ethics.
Carnegie and his family belonged to the Presbyterian Church in the United States of America, also known informally as the Northern Presbyterian Church.
In his early life Carnegie was skeptical of Calvinism, and religion as a whole, but reconciled with it later in his life.
In his autobiography, Carnegie describes his family as moderate Presbyterian believers, writing that "there was not one orthodox Presbyterian" in his family; various members of his family having somewhat distanced themselves from Calvinism, some of them leaning more towards Swedenborgianism.
Although, being a child, his family led vigorous theological and political disputes.
His mother avoided the topic of religion.
His father left the Presbyterian church after a sermon on infant damnation, while, according to Carnegie, still remaining very religious on his own.
Witnessing sectarianism and strife in 19th century Scotland regarding religion and philosophy, Carnegie kept his distance from organized religion and theism.
Carnegie instead preferred to see things through naturalistic and scientific terms stating, "Not only had I got rid of the theology and the supernatural, but I had found the truth of evolution."
Later in life, Carnegie's firm opposition to religion softened.
For many years he was a member of Madison Avenue Presbyterian Church, pastored from 1905 to 1926 by Social Gospel exponent Henry Sloane Coffin, while his wife and daughter belonged to the Brick Presbyterian Church.
He also prepared (but did not deliver) an address in which he professed a belief in "an Infinite and Eternal Energy from which all things proceed".
Records exist of a short period of correspondence around 1912 – 1913 between Carnegie and ' Abdu'l - Bahá, the eldest son of Bahá'u ' lláh, founder of the Bahá'í Faith.
In these letters, one of which was published in the "New York Times" in full text, Carnegie is extolled as a "lover of the world of humanity and one of the founders of Universal Peace".
Influenced by his "favorite living hero in public life" John Bright, Carnegie started his efforts in pursuit of world peace at a young age, and supported causes that opposed military intervention.
His motto, "All is well since all grows better", served not only as a good rationalization of his successful business career, but also his view of international relations.
Despite his efforts towards international peace, Carnegie faced many dilemmas on his quest.
These dilemmas are often regarded as conflicts between his view on international relations and his other loyalties.
Throughout the 1880 s and 1890 s, for example, Carnegie allowed his steel works to fill large orders of armor plate for the building of an enlarged and modernized United States Navy, but he opposed American oversea expansion.
Despite that, Carnegie served as a major donor for the newly-established International Court of Arbitration's Peace Palace – brainchild of Russian Tsar Nicolas II.
His largest and in the long run most influential peace organization was the Carnegie Endowment for International Peace, formed in 1910 with a $ 10 million endowment.
In 1913, at the dedication of the Peace Palace in The Hague, Carnegie predicted that the end of war was "as certain to come, and come soon, as day follows night."
In 1914, on the eve of the First World War, Carnegie founded the Church Peace Union (CPU), a group of leaders in religion, academia, and politics.
Through the CPU, Carnegie hoped to mobilize the world's churches, religious organizations, and other spiritual and moral resources to join in promoting moral leadership to put an end to war forever.
For its inaugural international event, the CPU sponsored a conference to be held on August 1, 1914, on the shores of Lake Constance in southern Germany.
As the delegates made their way to the conference by train, Germany was invading Belgium.
Despite its inauspicious beginning, the CPU thrived.
Today its focus is on ethics and it is known as the Carnegie Council for Ethics in International Affairs, an independent, nonpartisan, nonprofit organization, whose mission is to be the voice for ethics in international affairs.
The outbreak of the First World War was clearly a shock to Carnegie and his optimistic view on world peace.
Although his promotion of anti-imperialism and world peace had all failed, and the Carnegie Endowment had not fulfilled his expectations, his beliefs and ideas on international relations had helped build the foundation of the League of Nations after his death, which took world peace to another level.
On the matter of American colonial expansion, Carnegie had always thought it is an unwise gesture for the United States.
He did not oppose the annexation of the Hawaiian islands or Puerto Rico, but he opposed the annexation of the Philippines.
Carnegie believed that it involved a denial of the fundamental democratic principle, and he also urged William McKinley to withdraw American troops and allow the Filipinos to live with their independence.
This act strongly impressed the other American anti-imperialists, who soon elected him vice-president of the Anti-Imperialist League.
After he sold his steel company in 1901, Carnegie was able to get fully involved in the peace cause, both financially and personally.
He gave away much of his fortunes to various peace-keeping agencies in order to keep them growing.
When his friend, the British writer William T. Stead, asked him to create a new organization for the goal of a peace and arbitration society, his reply was: Carnegie believed that it is the effort and will of the people, that maintains the peace in international relations.
Money is just a push for the act.
If world peace depended solely on financial support, it would not seem a goal, but more like an act of pity.
Like Stead, he believed that the United States and the British Empire would merge into one nation, telling him "We are heading straight to the Re-United States".
Carnegie believed that the combined country's power would maintain world peace and disarmament.
The creation of the Carnegie Endowment for International Peace in 1910 was regarded as a milestone on the road to the ultimate goal of abolition of war.
Beyond a gift of $ 10 million for peace promotion, Carnegie also encouraged the "scientific" investigation of the various causes of war, and the adoption of judicial methods that should eventually eliminate them.
He believed that the Endowment exists to promote information on the nations' rights and responsibilities under existing international law and to encourage other conferences to codify this law.
Carnegie was a frequent contributor to periodicals on labor issues.
In addition to "Triumphant Democracy" (1886) and "The Gospel of Wealth" (1889), he also wrote "Our Coaching Trip, Brighton to Inverness" (1882), "An American Four-in-hand in Britain" (1883), "Round the World" (1884), "The Empire of Business" (1902), "The Secret of Business is the Management of Men" (1903), "James Watt" (1905) in the Famous Scots Series, "Problems of Today" (1907), and his posthumously published "Autobiography of Andrew Carnegie" (1920).
Carnegie received the honorary Doctor of Laws (DLL) from the University of Glasgow in June 1901, and received the Freedom of the City of Glasgow "" in recognition of his munificence "" later the same year.
In July 1902 he received the Freedom of the city of St Andrews, "" in testimony of his great zeal for the welfare of his fellow-men on both sides of the Atlantic "," and in October 1902 the Freedom of the City of Perth "" in testimony of his high personal worth and beneficial influence, and in recognition of widespread benefactions bestowed on this and other lands, and especially in gratitude for the endowment granted by him for the promotion of University education in Scotland "" and the Freedom of the City of Dundee.
In 1910, he received the Freedom of the City of Belfast.
Carnegie received 1 July 1914 a honorary doctorate from the University of Groningen the Netherlands.
According to biographer Burton J. Hendrick: Hendrick argues that: Carnegie's personal papers are at the Library of Congress Manuscript Division.
The Carnegie Collections of the Columbia University Rare Book and Manuscript Library consist of the archives of the following organizations founded by Carnegie: The Carnegie Corporation of New York (CCNY); The Carnegie Endowment for International Peace (CEIP); the Carnegie Foundation for the Advancement of Teaching (CFAT); The Carnegie Council on Ethics and International Affairs (CCEIA).
These collections deal primarily with Carnegie philanthropy and have very little personal material related to Carnegie.
Carnegie Mellon University and the Carnegie Library of Pittsburgh jointly administer the Andrew Carnegie Collection of digitized archives on Carnegie's life.
Collections
Approximants are speech sounds that involve the articulators approaching each other but not narrowly enough nor with enough articulatory precision to create turbulent airflow.
Therefore, approximants fall between fricatives, which do produce a turbulent airstream, and vowels, which produce no turbulence.
This class is composed of sounds like (as in "rest") and semivowels like and (as in "yes" and "west", respectively), as well as lateral approximants like (as in "less").
Before Peter Ladefoged coined the term "approximant" in the 1960 s, the term "frictionless continuant" referred to non-lateral approximants.
In phonology, "approximant" is also a distinctive feature that encompasses all sonorants except nasals, including vowels, taps and trills.
Some approximants resemble vowels in acoustic and articulatory properties and the terms "semivowel" and "glide" are often used for these non-syllabic vowel-like segments.
The correlation between semivowels and vowels is strong enough that cross-language differences between semivowels correspond with the differences between their related vowels.
Vowels and their corresponding semivowels alternate in many languages depending on the phonological environment, or for grammatical reasons, as is the case with Indo-European ablaut.
Similarly, languages often avoid configurations where a semivowel precedes its corresponding vowel.
A number of phoneticians distinguish between semivowels and approximants by their location in a syllable.
Although he uses the terms interchangeably, remarks that, for example, the final glides of English "par" and "buy" differ from French "par" (' through ') and "baille" (' tub ') in that, in the latter pair, the approximants appear in the syllable coda, whereas, in the former, they appear in the syllable nucleus.
This means that opaque (if not minimal) contrasts can occur in languages like Italian (with the i-like sound of "piede" ' foot ', appearing in the nucleus:, and that of "piano" ' slow ', appearing in the syllable onset:) and Spanish (with a near minimal pair being "abyecto" ' abject ' and "abierto" ' opened ').
+ Approximant-vowel correspondences In articulation and often diachronically, palatal approximants correspond to front vowels, velar approximants to back vowels, and labialized approximants to rounded vowels.
In American English, the rhotic approximant corresponds to the rhotic vowel.
This can create alternations (as shown in the above table).
In addition to alternations, glides can be inserted to the left or the right of their corresponding vowels when they occur next to a hiatus.
For example, in Ukrainian, medial triggers the formation of an inserted that acts as a syllable onset so that when the affix is added to футбол (' football ') to make футболіст ' football player ', it is pronounced, but маоїст (' Maoist '), with the same affix, is pronounced with a glide.
Dutch for many speakers has a similar process that extends to mid vowels: Similarly, vowels can be inserted next to their corresponding glide in certain phonetic environments.
Sievers' law describes this behaviour for Germanic.
Non-high semivowels also occur.
In colloquial Nepali speech, a process of glide-formation occurs, where one of two adjacent vowels becomes non-syllabic; the process includes mid vowels so that (' cause to wish ') features a non-syllabic mid vowel.
Spanish features a similar process and even nonsyllabic can occur so that "ahorita" (' right away ') is pronounced.
It is not often clear, however, whether such sequences involve a semivowel (a consonant) or a diphthong (a vowel), and in many cases, it may not be a meaningful distinction.
Although many languages have central vowels, which lie between back/velar and front/palatal, there are few cases of a corresponding approximant.
One is in the Korean diphthong or though it is more frequently analyzed as velar (as in the table above), and Mapudungun may be another, with three high vowel sounds,,, and three corresponding consonants,, and, and a third one is often described as a voiced unrounded velar fricative; some texts note a correspondence between this approximant and that is parallel to – and –.
An example is "liq" (?)
(' white ').
In addition to less turbulence, approximants also differ from fricatives in the precision required to produce them.
When emphasized, approximants may be slightly fricated (that is, the airstream may become slightly turbulent), which is reminiscent of fricatives.
For example, the Spanish word "ayuda" (' help ') features a palatal approximant that is pronounced as a fricative in emphatic speech.
Spanish can be analyzed as having a meaningful distinction between fricative, approximant, and intermediate.
However, such frication is generally slight and intermittent, unlike the strong turbulence of fricative consonants.
Because voicelessness has comparatively reduced resistance to air flow from the lungs, the increased air flow creates more turbulence, making acoustic distinctions between voiceless approximants (which are extremely rare cross-linguistically) and voiceless fricatives difficult.
This is why, for example, no language is known to contrast the voiceless labialized velar approximant (also transcribed with the special letter) with a voiceless labialized velar fricative.
Similarly, Standard Tibetan has a voiceless lateral approximant,, and Welsh has a voiceless lateral fricative, but the distinction is not always clear from descriptions of these languages.
Again, no language is known to contrast the two.
Iaai is reported to have an unusually large number of voiceless approximants, with.
For places of articulation further back in the mouth, languages do not contrast voiced fricatives and approximants.
Therefore, the IPA allows the symbols for the voiced fricatives to double for the approximants, with or without a lowering diacritic.
Occasionally, the glottal "fricatives" are called approximants, since typically has no more frication than voiceless approximants, but they are often phonations of the glottis without any accompanying manner or place of articulation.
In lateral approximants, the center of tongue makes solid contact with the roof of the mouth.
However, the defining location is the side of the tongue, which only approaches the teeth.
Voiceless approximants are rarely distinguished from voiceless fricatives.
Iaai has an unusually large number of them, with contrasting with (as well as a large number of voiceless nasals).
Attested voiceless approximants are: Examples are: In Portuguese, the nasal glides and historically became and in some words.
In Edo, the nasalized allophones of the approximants and are nasal occlusives, and.
What are transcribed as nasal approximants may include non-syllabic elements of nasal vowels or diphthongs.
Astronomer Royal is a senior post in the Royal Households of the United Kingdom.
There are two officers, the senior being the Astronomer Royal dating from 22 June 1675; the second is the Astronomer Royal for Scotland dating from 1834.
The post was created by King Charles II in 1675, at the same time as he founded the Royal Observatory Greenwich.
He appointed John Flamsteed, instructing him "."
The Astronomer Royal was director of the Royal Observatory Greenwich from the establishment of the post in 1675 until 1972.
The Astronomer Royal became an honorary title in 1972 without executive responsibilities and a separate post of Director of the Royal Greenwich Observatory was created to manage the institution.
The Astronomer Royal today receives a stipend of 100 GBP per year and is a member of the Royal Household, under the general authority of the Lord Chamberlain.
After the separation of the two offices, the position of Astronomer Royal has been largely honorary, though he remains available to advise the Sovereign on astronomical and related scientific matters, and the office is of great prestige.
There was also formerly a Royal Astronomer of Ireland.
The Astronomer Royal is referenced in HG Wells' The War of the Worlds.
The word aeon, also spelled eon (in American English), originally meant "life", "vital force" or "being", "generation" or "a period of time", though it tended to be translated as "age" in the sense of "ages", "forever", "timeless" or "for eternity".
It is a Latin transliteration from the koine Greek word ("ho aion"), from the archaic ("aiwon").
In Homer it typically refers to life or lifespan.
Its latest meaning is more or less similar to the Sanskrit word "kalpa" and Hebrew word "olam".
A cognate Latin word "aevum" or "aeuum" (cf.) for "age" is present in words such as "longevity" and "mediaeval".
Although the term aeon may be used in reference to a period of a billion years (especially in geology, cosmology or astronomy), its more common usage is for any long, indefinite period.
Aeon can also refer to the four aeons on the Geologic Time Scale that make up the Earth's history, the Hadean, Archean, Proterozoic, and the current aeon Phanerozoic.
In astronomy an aeon is defined as a billion years (10 years, abbreviated AE).
Roger Penrose uses the word "aeon" to describe the period between successive and cyclic Big Bangs within the context of conformal cyclic cosmology.
The Bible translation is a treatment of the Hebrew word "olam" and the Greek word "aion".
These words have similar meaning, and Young's Literal Translation renders them and their derivatives as "age" or "age-during".
Other English versions most often translate them to indicate eternity, being translated as eternal, everlasting, forever, etc.
Rendering "aion" to indicate eternality in this verse would result in the contradictory phrase "end of eternity", so the question arises whether it should ever be so.
Proponents of universal reconciliation point out that this has significant implications for the problem of hell.
Contrast in well-known English translations with its rendering in Young's Literal Translation: < poem > And these shall go away to punishment age-during, but the righteous to life age-during.
(YLT) Then they will go away to eternal punishment, but the righteous to eternal life.
(NIV) These will go away into eternal punishment, but the righteous into eternal life.
(NASB) And these shall go away into everlasting punishment, but the righteous into eternal life.
(KJV) And these will depart into everlasting cutting-off, but the righteous ones into everlasting life.
(NWT) </ poem > Plato used the word "aeon" to denote the eternal world of ideas, which he conceived was "behind" the perceived world, as demonstrated in his famous allegory of the cave.
Christianity's idea of "eternal life" comes from the word for life, "zoe", and a form of "aeon", which could mean life in the next aeon, the Kingdom of God, or Heaven, just as much as immortality, as in.
According to the Christian doctrine of universal reconciliation, the Greek New Testament scriptures use the word "aeon" to mean a long period (perhaps 1000 years) and the word "aeonian" to mean "during a long period"; Thus there was a time before the aeons, and the aeonian period is finite.
After each man's mortal life ends, he is judged worthy of aeonian life or aeonian punishment.
This contrasts with the conventional Christian belief in eternal life and eternal punishment.
Occultists of the Thelema and O.T.O. traditions sometimes speak of a "magical Aeon" that may last for far less time, perhaps as little as 2,000 years.
Evolution itself is taken to result from a certain specific process – and this process can be described, or explained [or're - presented '] via a bifurcation of time.
That is, evolution is an expression of how the cosmos changes over or through or because of, ' time ' – this' time ' having two components.
An aeon is a manifestation, in the causal, of a particular type of acausal energy.
This energy re-orders, or changes, the causal.
These changes have certain limits – in both causal space and causal time.
That is, they have a specific beginning and a specific end.
A civilization (or rather, a higher or aeonic-civilization) is how this energy becomes ordered or manifests itself in the causal: how this energy is revealed.
A civilization represents the practical changes which this energy causes in the causal - in terms of the effect such energy has on individuals and this planet.
A civilization is tied to, is born from, a particular aeon.
By the nature of this energy, a civilization is an evolution of life – a move toward a more complex, and thus more conscious existence ...
In many Gnostic systems, the various emanations of God, who is also known by such names as the One, the Monad, "Aion teleos" ("The Broadest Aeon"), Bythos ("depth or profundity", Greek), "Proarkhe" ("before the beginning", Greek), the "Arkhe" ("the beginning", Greek), "Sophia" (wisdom), Christos (the Anointed One) are called "Aeons".
In the different systems these emanations are differently named, classified, and described, but the emanation theory itself is common to all forms of Gnosticism.
In the Basilidian Gnosis they are called sonships (υἱότητες "huiotetes"; sing.
Similarly, in the Greek Magical Papyri, the term "Aion" is often used to denote the All, or the supreme aspect of God.
An airline is a company that provides air transport services for traveling passengers and freight.
Airlines utilize aircraft to supply these services, and may form partnerships or alliances with other airlines for codeshare agreements.
Generally, airline companies are recognized with an air operating certificate or license issued by a governmental aviation body.
Airlines vary in size, from small domestic airlines to full-service international airlines with double decker airplanes.
Airline services can be categorized as being intercontinental, domestic, regional, or international, and may be operated as scheduled services or charters.
The largest airline currently is American Airlines Group.
DELAG, "Deutsche Luftschiffahrts-Aktiengesellschaft I" was the world's first airline.
It was founded on November 16, 1909, with government assistance, and operated airships manufactured by The Zeppelin Corporation.
Its headquarters were in Frankfurt.
The first fixed wing scheduled airline was started on January 1, 1914, from St. Petersburg, Florida, to Tampa, Florida, operated by the St. Petersburg and Tampa Airboat Line.
The four oldest non-dirigible airlines that still exist are Netherlands' KLM (1919), Colombia's Avianca (1919), Australia's Qantas (1921), and the Czech Republic's Czech Airlines (1923).
The earliest fixed wing airline in Europe was Aircraft Transport and Travel, formed by George Holt Thomas in 1916; via a series of takeovers and mergers, this company is an ancestor of modern-day British Airways.
Using a fleet of former military Airco DH.
4A biplanes that had been modified to carry two passengers in the fuselage, it operated relief flights between Folkestone and Ghent.
On 15 July 1919, the company flew a proving flight across the English Channel, despite a lack of support from the British government.
Flown by Lt. H Shaw in an Airco DH.
9 between RAF Hendon and Paris – Le Bourget Airport, the flight took 2 hours and 30 minutes at £ 21 per passenger.
On 25 August 1919, the company used DH.
16 s to pioneer a regular service from Hounslow Heath Aerodrome to Le Bourget, the first regular international service in the world.
The airline soon gained a reputation for reliability, despite problems with bad weather, and began to attract European competition.
In November 1919, it won the first British civil airmail contract.
Six Royal Air Force Airco DH.
9A aircraft were lent to the company, to operate the airmail service between Hawkinge and Cologne.
In 1920, they were returned to the Royal Air Force.
Other British competitors were quick to follow – Handley Page Transport was established in 1919 and used the company's converted wartime Type O/400 bombers with a capacity for 12 passengers, to run a London-Paris passenger service.
The first French airline was Société des lignes Latécoère, later known as Aéropostale, which started its first service in late 1918 to Spain.
The Société Générale des Transports Aériens was created in late 1919, by the Farman brothers and the Farman F. 60 Goliath plane flew scheduled services from Toussus-le-Noble to Kenley, near Croydon, England.
Another early French airline was the Compagnie des Messageries Aériennes, established in 1919 by Louis-Charles Breguet, offering a mail and freight service between Le Bourget Airport, Paris and Lesquin Airport, Lille.
The first German airline to use heavier than air aircraft was Deutsche Luft-Reederei established in 1917 which started operating in February 1919.
In its first year, the D.L.R. operated regularly scheduled flights on routes with a combined length of nearly 1000 miles.
By 1921 the D.L.R. network was more than 3000 km (1865 miles) long, and included destinations in the Netherlands, Scandinavia and the Baltic Republics.
Another important German airline was Junkers Luftverkehr, which began operations in 1921.
It was a division of the aircraft manufacturer Junkers, which became a separate company in 1924.
It operated joint-venture airlines in Austria, Denmark, Estonia, Finland, Hungary, Latvia, Norway, Poland, Sweden and Switzerland.
The Dutch airline KLM made its first flight in 1920, and is the oldest continuously operating airline in the world.
Established by aviator Albert Plesman, it was immediately awarded a "Royal" predicate from Queen Wilhelmina.
Its first flight was from Croydon Airport, London to Amsterdam, using a leased Aircraft Transport and Travel DH-16, and carrying two British journalists and a number of newspapers.
In 1921, KLM started scheduled services.
In Finland, the charter establishing Aero O/Y (now Finnair) was signed in the city of Helsinki on September 12, 1923.
Junkers F. 13 D-335 became the first aircraft of the company, when Aero took delivery of it on March 14, 1924.
The first flight was between Helsinki and Tallinn, capital of Estonia, and it took place on March 20, 1924, one week later.
In the Soviet Union, the Chief Administration of the Civil Air Fleet was established in 1921.
One of its first acts was to help found Deutsch-Russische Luftverkehrs A.G. (Deruluft), a German-Russian joint venture to provide air transport from Russia to the West. Domestic air service began around the same time, when Dobrolyot started operations on 15 July 1923 between Moscow and Nizhni Novgorod.
Since 1932 all operations had been carried under the name Aeroflot.
Early European airlines tended to favor comfort – the passenger cabins were often spacious with luxurious interiors – over speed and efficiency.
The relatively basic navigational capabilities of pilots at the time also meant that delays due to the weather were commonplace.
By the early 1920 s, small airlines were struggling to compete, and there was a movement towards increased rationalization and consolidation.
In 1924, Imperial Airways was formed from the merger of Instone Air Line Company, British Marine Air Navigation, Daimler Airway and Handley Page Transport Co Ltd., to allow British airlines to compete with stiff competition from French and German airlines that were enjoying heavy government subsidies.
The airline was a pioneer in surveying and opening up air routes across the world to serve far-flung parts of the British Empire and to enhance trade and integration.
The first new airliner ordered by Imperial Airways, was the Handley Page W8f "City of Washington", delivered on 3 November 1924.
In the first year of operation the company carried 11,395 passengers and 212,380 letters.
In April 1925, the film "The Lost World" became the first film to be screened for passengers on a scheduled airliner flight when it was shown on the London-Paris route.
Two French airlines also merged to form Air Union on 1 January 1923.
This later merged with four other French airlines to become Air France, the country's flagship carrier to this day, on 7 October 1933.
Germany's Deutsche Luft Hansa was created in 1926 by merger of two airlines, one of them Junkers Luftverkehr.
Luft Hansa, due to the Junkers heritage and unlike most other airlines at the time, became a major investor in airlines outside of Europe, providing capital to Varig and Avianca.
German airliners built by Junkers, Dornier, and Fokker were among the most advanced in the world at the time.
In 1926, Alan Cobham surveyed a flight route from the UK to Cape Town, South Africa, following this up with another proving flight to Melbourne, Australia.
Other routes to British India and the Far East were also charted and demonstrated at this time.
Regular services to Cairo and Basra began in 1927 and were extended to Karachi in 1929.
The London-Australia service was inaugurated in 1932 with the Handley Page HP 42 airliners.
Further services were opened up to Calcutta, Rangoon, Singapore, Brisbane and Hong Kong passengers departed London on 14 March 1936 following the establishment of a branch from Penang to Hong Kong.
Like Imperial Airways, Air France and KLM's early growth depended heavily on the needs to service links with far-flung colonial possessions (North Africa and Indochina for the French and the East Indies for the Dutch).
France began an air mail service to Morocco in 1919 that was bought out in 1927, renamed Aéropostale, and injected with capital to become a major international carrier.
In 1933, Aéropostale went bankrupt, was nationalized and merged into Air France.
Although Germany lacked colonies, it also began expanding its services globally.
In 1931, the airship Graf Zeppelin began offering regular scheduled passenger service between Germany and South America, usually every two weeks, which continued until 1937.
In 1936, the airship Hindenburg entered passenger service and successfully crossed the Atlantic 36 times before crashing at Lakehurst, New Jersey, on May 6, 1937.
In 1938, a weekly air service from Berlin to Kabul, Afghanistan, started operating.
From February 1934 until World War II began in 1939 Deutsche Lufthansa operated an airmail service from Stuttgart, Germany via Spain, the Canary Islands and West Africa to Natal in Brazil.
This was the first time an airline flew across an ocean.
By the end of the 1930 s Aeroflot had become the world's largest airline, employing more than 4,000 pilots and 60,000 other service personnel and operating around 3,000 aircraft (of which 75 % were considered obsolete by its own standards).
During the Soviet era Aeroflot was synonymous with Russian civil aviation, as it was the only air carrier.
It became the first airline in the world to operate sustained regular jet services on 15 September 1956 with the Tupolev Tu-104.
Deregulation of the European Union airspace in the early 1990 s has had substantial effect on the structure of the industry there.
The shift towards' budget ' airlines on shorter routes has been significant.
Airlines such as EasyJet and Ryanair have often grown at the expense of the traditional national airlines.
There has also been a trend for these national airlines themselves to be privatized such as has occurred for Aer Lingus and British Airways.
Other national airlines, including Italy's Alitalia, have suffered – particularly with the rapid increase of oil prices in early 2008.
Tony Jannus conducted the United States' first scheduled commercial airline flight on 1 January 1914 for the St. Petersburg-Tampa Airboat Line.
The 23-minute flight traveled between St. Petersburg, Florida and Tampa, Florida, passing some above Tampa Bay in Jannus' Benoist XIV wood and muslin biplane flying boat.
His passenger was a former mayor of St. Petersburg, who paid $ 400 for the privilege of sitting on a wooden bench in the open cockpit.
The Airboat line operated for about four months, carrying more than 1,200 passengers who paid $ 5 each.
Chalk's International Airlines began service between Miami and Bimini in the Bahamas in February 1919.
Based in Ft. Lauderdale, Chalk's claimed to be the oldest continuously operating airline in the United States until its closure in 2008.
Following World War I, the United States found itself swamped with aviators.
Many decided to take their war-surplus aircraft on barnstorming campaigns, performing aerobatic maneuvers to woo crowds.
In 1918, the United States Postal Service won the financial backing of Congress to begin experimenting with air mail service, initially using Curtiss Jenny aircraft that had been procured by the United States Army Air Service.
Private operators were the first to fly the mail but due to numerous accidents the US Army was tasked with mail delivery.
During the Army's involvement they proved to be too unreliable and lost their air mail duties.
By the mid-1920 s, the Postal Service had developed its own air mail network, based on a transcontinental backbone between New York City and San Francisco.
To supplement this service, they offered twelve contracts for spur routes to independent bidders.
Some of the carriers that won these routes would, through time and mergers, evolve into Pan Am, Delta Air Lines, Braniff Airways, American Airlines, United Airlines (originally a division of Boeing), Trans World Airlines, Northwest Airlines, and Eastern Air Lines.
Service during the early 1920 s was sporadic: most airlines at the time were focused on carrying bags of mail.
In 1925, however, the Ford Motor Company bought out the Stout Aircraft Company and began construction of the all-metal Ford Trimotor, which became the first successful American airliner.
With a 12-passenger capacity, the Trimotor made passenger service potentially profitable.
Air service was seen as a supplement to rail service in the American transportation network.
At the same time, Juan Trippe began a crusade to create an air network that would link America to the world, and he achieved this goal through his airline, Pan American World Airways, with a fleet of flying boats that linked Los Angeles to Shanghai and Boston to London.
Pan Am and Northwest Airways (which began flights to Canada in the 1920 s) were the only U.S. airlines to go international before the 1940 s.
With the introduction of the Boeing 247 and Douglas DC-3 in the 1930 s, the U.S. airline industry was generally profitable, even during the Great Depression.
This trend continued until the beginning of World War II.
World War II, like World War I, brought new life to the airline industry.
Many airlines in the Allied countries were flush from lease contracts to the military, and foresaw a future explosive demand for civil air transport, for both passengers and cargo.
They were eager to invest in the newly emerging flagships of air travel such as the Boeing Stratocruiser, Lockheed Constellation, and Douglas DC-6.
Most of these new aircraft were based on American bombers such as the B-29, which had spearheaded research into new technologies such as pressurization.
Most offered increased efficiency from both added speed and greater payload.
In the 1950 s, the De Havilland Comet, Boeing 707, Douglas DC-8, and Sud Aviation Caravelle became the first flagships of the Jet Age in the West, while the Eastern bloc had Tupolev Tu-104 and Tupolev Tu-124 in the fleets of state-owned carriers such as Czechoslovak ČSA, Soviet Aeroflot and East-German Interflug.
The Vickers Viscount and Lockheed L-188 Electra inaugurated turboprop transport.
On 4 October 1958, BOAC started transatlantic flights between London Heathrow and New York Idlewild with a Comet 4, and Pan Am followed on 26 October with a B707 service between New York and Paris.
The next big boost for the airlines would come in the 1970 s, when the Boeing 747, McDonnell Douglas DC-10, and Lockheed L-1011 inaugurated widebody ("jumbo jet") service, which is still the standard in international travel.
The Tupolev Tu-144 and its Western counterpart, Concorde, made supersonic travel a reality.
Concorde first flew in 1969 and operated through 2003.
In 1972, Airbus began producing Europe's most commercially successful line of airliners to date.
The added efficiencies for these aircraft were often not in speed, but in passenger capacity, payload, and range.
Airbus also features modern electronic cockpits that were common across their aircraft to enable pilots to fly multiple models with minimal cross-training.
The 1978 U.S. airline industry deregulation lowered federally controlled barriers for new airlines just as a downturn in the nation's economy occurred.
New start-ups entered during the downturn, during which time they found aircraft and funding, contracted hangar and maintenance services, trained new employees, and recruited laid-off staff from other airlines.
Major airlines dominated their routes through aggressive pricing and additional capacity offerings, often swamping new start-ups.
In the place of high barriers to entry imposed by regulation, the major airlines implemented an equally high barrier called loss leader pricing.
In this strategy an already established and dominant airline stomps out its competition by lowering airfares on specific routes, below the cost of operating on it, choking out any chance a start-up airline may have.
The industry side effect is an overall drop in revenue and service quality.
Since deregulation in 1978 the average domestic ticket price has dropped by 40 %.
So has airline employee pay.
By incurring massive losses, the airlines of the USA now rely upon a scourge of cyclical Chapter 11 bankruptcy proceedings to continue doing business.
America West Airlines (which has since merged with US Airways) remained a significant survivor from this new entrant era, as dozens, even hundreds, have gone under.
In many ways, the biggest winner in the deregulated environment was the air passenger.
Although not exclusively attributable to deregulation, indeed the U.S. witnessed an explosive growth in demand for air travel.
Many millions who had never or rarely flown before became regular fliers, even joining frequent flyer loyalty programs and receiving free flights and other benefits from their flying.
New services and higher frequencies meant that business fliers could fly to another city, do business, and return the same day, from almost any point in the country.
Air travel's advantages put long distance intercity railroad travel and bus lines under pressure, with most of the latter having withered away, whilst the former is still protected under nationalization through the continuing existence of Amtrak.
By the 1980 s, almost half of the total flying in the world took place in the U.S., and today the domestic industry operates over 10,000 daily departures nationwide.
Toward the end of the century, a new style of low cost airline emerged, offering a no-frills product at a lower price.
Southwest Airlines, JetBlue, AirTran Airways, Skybus Airlines and other low-cost carriers began to represent a serious challenge to the so-called "legacy airlines", as did their low-cost counterparts in many other countries.
Their commercial viability represented a serious competitive threat to the legacy carriers.
However, of these, ATA and Skybus have since ceased operations.
Increasingly since 1978, US airlines have been reincorporated and spun off by newly created and internally led management companies, and thus becoming nothing more than operating units and subsidiaries with limited financially decisive control.
Among some of these holding companies and parent companies which are relatively well known, are the UAL Corporation, along with the AMR Corporation, among a long list of airline holding companies sometime recognized worldwide.
Less recognized are the private equity firms which often seize managerial, financial, and board of directors control of distressed airline companies by temporarily investing large sums of capital in air carriers, to rescheme an airlines assets into a profitable organization or liquidating an air carrier of their profitable and worthwhile routes and business operations.
Thus the last 50 years of the airline industry have varied from reasonably profitable, to devastatingly depressed.
As the first major market to deregulate the industry in 1978, U.S. airlines have experienced more turbulence than almost any other country or region.
In fact, no U.S. legacy carrier survived bankruptcy-free.
Among the outspoken critics of deregulation, former CEO of American Airlines, Robert Crandall has publicly stated: "Chapter 11 bankruptcy protection filing shows airline industry deregulation was a mistake."
Congress passed the Air Transportation Safety and System Stabilization Act (P.L. 107 - 42) in response to a severe liquidity crisis facing the already-troubled airline industry in the aftermath of the September 11th terrorist attacks.
Through the ATSB Congress sought to provide cash infusions to carriers for both the cost of the four-day federal shutdown of the airlines and the incremental losses incurred through December 31, 2001, as a result of the terrorist attacks.
This resulted in the first government bailout of the 21st century.
Between 2000 and 2005 US airlines lost $ 30 billion with wage cuts of over $ 15 billion and 100,000 employees laid off.
In recognition of the essential national economic role of a healthy aviation system, Congress authorized partial compensation of up to $ 5 billion in cash subject to review by the U.S. Department of Transportation and up to $ 10 billion in loan guarantees subject to review by a newly created Air Transportation Stabilization Board (ATSB).
The applications to DOT for reimbursements were subjected to rigorous multi-year reviews not only by DOT program personnel but also by the Government Accountability Office and the DOT Inspector General.
Ultimately, the federal government provided $ 4.6 billion in one-time, subject-to-income-tax cash payments to 427 U.S. air carriers, with no provision for repayment, essentially a gift from the taxpayers.
(Passenger carriers operating scheduled service received approximately $ 4 billion, subject to tax.)
In addition, the ATSB approved loan guarantees to six airlines totaling approximately $ 1.6 billion.
Data from the U.S. Treasury Department show that the government recouped the $ 1.6 billion and a profit of $ 339 million from the fees, interest and purchase of discounted airline stock associated with loan guarantees.
The three largest major carriers and Southwest Airlines control 70 % of the U.S. passenger market.
Although Philippine Airlines (PAL) was officially founded on February 26, 1941, its license to operate as an airliner was derived from merged Philippine Aerial Taxi Company (PATCO) established by mining magnate Emmanuel N. Bachrach on December 3, 1930, making it Asia's oldest scheduled carrier still in operation.
Commercial air service commenced three weeks later from Manila to Baguio, making it Asia's first airline route.
Bachrach's death in 1937 paved the way for its eventual merger with Philippine Airlines in March 1941 and made it Asia's oldest airline.
It is also the oldest airline in Asia still operating under its current name.
Bachrach's majority share in PATCO was bought by beer magnate Andres R. Soriano in 1939 upon the advice of General Douglas MacArthur and later merged with newly formed Philippine Airlines with PAL as the surviving entity.
Soriano has controlling interest in both airlines before the merger.
PAL restarted service on March 15, 1941, with a single Beech Model 18 NPC-54 aircraft, which started its daily services between Manila (from Nielson Field) and Baguio, later to expand with larger aircraft such as the DC-3 and Vickers Viscount.
Korean Air was one of the first airlines to be launched among the other Asian countries in 1946 along with Asiana Airlines, which later joined in 1988.
The license to operate as an airliner was granted by the federal government body after reviewing the necessity at the national assembly.
The Hanjin occupies the largest ownership of Korean Air as well as few low-budget airlines as of now.
The Korean Air is among the founders of SkyTeam, which was established in 2000.
Asiana Airlines joined Star Alliance in 2003.
Korean Air and Asiana Airlines comprise one of the largest combined airline miles and number of passenger served at the regional market of Asian airline industry India was also one of the first countries to embrace civil aviation.
One of the first Asian airline companies was Air India, which was founded as Tata Airlines in 1932, a division of Tata Sons Ltd. (now Tata Group).
The airline was founded by India's leading industrialist, JRD Tata.
On October 15, 1932, J. R. D. Tata himself flew a single engined De Havilland Puss Moth carrying air mail (postal mail of Imperial Airways) from Karachi to Bombay via Ahmedabad.
The aircraft continued to Madras via Bellary piloted by Royal Air Force pilot Nevill Vintcent.
Tata Airlines was also one of the world's first major airlines which began its operations without any support from the Government.
With the outbreak of World War II, the airline presence in Asia came to a relative halt, with many new flag carriers donating their aircraft for military aid and other uses.
Following the end of the war in 1945, regular commercial service was restored in India and Tata Airlines became a public limited company on July 29, 1946, under the name Air India.
After the independence of India, 49 % of the airline was acquired by the Government of India.
In return, the airline was granted status to operate international services from India as the designated flag carrier under the name Air India International.
On July 31, 1946, a chartered Philippine Airlines (PAL) DC-4 ferried 40 American servicemen to Oakland, California, from Nielson Airport in Makati City with stops in Guam, Wake Island, Johnston Atoll and Honolulu, Hawaii, making PAL the first Asian airline to cross the Pacific Ocean.
A regular service between Manila and San Francisco was started in December.
It was during this year that the airline was designated as the flag carrier of Philippines.
During the era of decolonization, newly born Asian countries started to embrace air transport.
Among the first Asian carriers during the era were Cathay Pacific of Hong Kong (founded in September 1946), Orient Airways (later Pakistan International Airlines; founded in October 1946), Air Ceylon (later SriLankan Airlines; founded in 1947), Malayan Airways Limited in 1947 (later Singapore and Malaysia Airlines), El Al in Israel in 1948, Garuda Indonesia in 1949, Japan Airlines in 1951, Thai Airways International in 1960, and Korean National Airlines in 1947.
Among the first countries to have regular airlines in Latin America and the Caribbean were Bolivia with Lloyd Aéreo Boliviano, Cuba with Cubana de Aviación, Colombia with Avianca (the first airline established in the Americas), Argentina with Aerolineas Argentinas, Chile with LAN Chile (today LATAM Airlines), Brazil with Varig, Dominican Republic with Dominicana de Aviación, Mexico with Mexicana de Aviación, Trinidad and Tobago with BWIA West Indies Airways (today Caribbean Airlines), Venezuela with Aeropostal, Puerto Rico with Puertorriquena; and TACA based in El Salvador and representing several airlines of Central America (Costa Rica, Guatemala, Honduras and Nicaragua).
All the previous airlines started regular operations well before World War II.
Puerto Rican commercial airlines such as Prinair, Oceanair, Fina Air and Vieques Air Link came much after the second world war, as did several others from other countries like Mexico's Interjet and Volaris, Venezuela's Aserca Airlines and others.
The air travel market has evolved rapidly over recent years in Latin America.
Some industry estimates indicate that over 2,000 new aircraft will begin service over the next five years in this region.
These airlines serve domestic flights within their countries, as well as connections within Latin America and also overseas flights to North America, Europe, Australia, and Asia.
Only two airlines - Avianca and LATAM Airlines - have international subsidiaries and cover many destinations within the Americas as well as major hubs in other continents.
LATAM with Chile as the central operation along with Peru, Ecuador, Colombia, Brazil and Argentina and formerly with some operations in the Dominican Republic.
The Avianca group has its main operation in Colombia based around the hub in Bogotá, Colombia, as well as subsidiaries in various latin american countries with hubs in San Salvador, El Salvador, as well as Lima, Peru, with a smaller operation in Ecuador.
Many countries have national airlines that the government owns and operates.
Fully private airlines are subject to a great deal of government regulation for economic, political, and safety concerns.
For instance, governments often intervene to halt airline labor actions to protect the free flow of people, communications, and goods between different regions without compromising safety.
The United States, Australia, and to a lesser extent Brazil, Mexico, India, the United Kingdom, and Japan have "deregulated" their airlines.
In the past, these governments dictated airfares, route networks, and other operational requirements for each airline.
Since deregulation, airlines have been largely free to negotiate their own operating arrangements with different airports, enter and exit routes easily, and to levy airfares and supply flights according to market demand.
The entry barriers for new airlines are lower in a deregulated market, and so the U.S. has seen hundreds of airlines start up (sometimes for only a brief operating period).
This has produced far greater competition than before deregulation in most markets.
The added competition, together with pricing freedom, means that new entrants often take market share with highly reduced rates that, to a limited degree, full service airlines must match.
This is a major constraint on profitability for established carriers, which tend to have a higher cost base.
As a result, profitability in a deregulated market is uneven for most airlines.
These forces have caused some major airlines to go out of business, in addition to most of the poorly established new entrants.
In the United States, the airline industry is dominated by four large firms.
Because of industry consolidation, after fuel prices dropped considerably in 2015, very little of the savings were passed on to consumers.
Groups such as the International Civil Aviation Organization establish worldwide standards for safety and other vital concerns.
Most international air traffic is regulated by bilateral agreements between countries, which designate specific carriers to operate on specific routes.
The model of such an agreement was the Bermuda Agreement between the US and UK following World War II, which designated airports to be used for transatlantic flights and gave each government the authority to nominate carriers to operate routes.
Bilateral agreements are based on the "freedoms of the air", a group of generalized traffic rights ranging from the freedom to overfly a country to the freedom to provide domestic flights within a country (a very rarely granted right known as cabotage).
Most agreements permit airlines to fly from their home country to designated airports in the other country: some also extend the freedom to provide continuing service to a third country, or to another destination in the other country while carrying passengers from overseas.
In the 1990 s, "open skies" agreements became more common.
These agreements take many of these regulatory powers from state governments and open up international routes to further competition.
Open skies agreements have met some criticism, particularly within the European Union, whose airlines would be at a comparative disadvantage with the United States' because of cabotage restrictions.
In 2017, 4.1 billion passengers have been carried by airlines in 41.9 million commercial scheduled flights (an average payload of 4100/41.9 round0 passengers), for 7.75 trillion passenger kilometres (an average trip of 7750/4.100 round0 km) over 45,091 airline routes served globally.
In 2016, air transport generated $ 704.4 billion of revenue in 2016, employed 10.2 million workers, supported 65.5 million jobs and $ 2.7 trillion of economic activity: 3.6 % of the global GDP.
In July 2016, the total weekly airline capacity was 181.1 billion Available Seat Kilometers (+ 6.9 % compared to July 2015): 57.6 bn in Asia-Pacific, 47.7 bn in Europe, 46.2 bn in North America, 12.2 bn in Middle East, 12.0 bn in Latin America and 5.4 bn in Africa.
+ Top 150 airline groups Historically, air travel has survived largely through state support, whether in the form of equity or subsidies.
The airline industry as a whole has made a cumulative loss during its 100-year history.
One argument is that positive externalities, such as higher growth due to global mobility, outweigh the microeconomic losses and justify continuing government intervention.
A historically high level of government intervention in the airline industry can be seen as part of a wider political consensus on strategic forms of transport, such as highways and railways, both of which receive public funding in most parts of the world.
Although many countries continue to operate state-owned or parastatal airlines, many large airlines today are privately owned and are therefore governed by microeconomic principles to maximize shareholder profit.
In December 1991, the collapse of Pan Am, an airline often credited for shaping the international airline industry, highlighted the financial complexities faced by major airline companies.
Following the 1978 deregulation, U.S. carriers did not manage to make an aggregate profit for 12 years in 31, including four years where combined losses amounted to $ 10 billion, but rebounded with eight consecutive years of profits since 2010, including its four with over $ 10 billion profits.
They drop loss-making routes, avoid fare wars and market share battles, limit capacity growth, add hub feed with regional jets to increase their profitability.
They change schedules to create more connections, buy used aircraft, reduce international frequencies and leverage partnerships to optimise capacities and benefit from overseas connectivity.
The world's largest airlines can be defined in several ways.
American Airlines Group is the largest by its fleet size, revenue, profit, passengers carried and revenue passenger mile.
Delta Air Lines is the largest by assets value and market capitalization.
Lufthansa Group is the largest by number of employees, FedEx Express by freight tonne-kilometers, Ryanair by number of international passengers carried and Turkish Airlines by number of countries served.
Airlines assign prices to their services in an attempt to maximize profitability.
The pricing of airline tickets has become increasingly complicated over the years and is now largely determined by computerized yield management systems.
Because of the complications in scheduling flights and maintaining profitability, airlines have many loopholes that can be used by the knowledgeable traveler.
Many of these airfare secrets are becoming more and more known to the general public, so airlines are forced to make constant adjustments.
Most airlines use differentiated pricing, a form of price discrimination, to sell air services at varying prices simultaneously to different segments.
Factors influencing the price include the days remaining until departure, the booked load factor, the forecast of total demand by price point, competitive pricing in force, and variations by day of week of departure and by time of day.
Carriers often accomplish this by dividing each cabin of the aircraft (first, business and economy) into a number of travel classes for pricing purposes.
A complicating factor is that of origin-destination control ("O&D control").
Someone purchasing a ticket from Melbourne to Sydney (as an example) for A $ 200 is competing with someone else who wants to fly Melbourne to Los Angeles through Sydney on the same flight, and who is willing to pay A $ 1400.
Should the airline prefer the $ 1400 passenger, or the $ 200 passenger plus a possible Sydney-Los Angeles passenger willing to pay $ 1300?
Airlines have to make hundreds of thousands of similar pricing decisions daily.
The advent of advanced computerized reservations systems in the late 1970 s, most notably Sabre, allowed airlines to easily perform cost-benefit analyses on different pricing structures, leading to almost perfect price discrimination in some cases (that is, filling each seat on an aircraft at the highest price that can be charged without driving the consumer elsewhere).
The intense nature of airfare pricing has led to the term "fare war" to describe efforts by airlines to undercut other airlines on competitive routes.
Through computers, new airfares can be published quickly and efficiently to the airlines' sales channels.
For this purpose the airlines use the Airline Tariff Publishing Company (ATPCO), who distribute latest fares for more than 500 airlines to Computer Reservation Systems across the world.
The extent of these pricing phenomena is strongest in "legacy" carriers.
In contrast, low fare carriers usually offer pre-announced and simplified price structure, and sometimes quote prices for each leg of a trip separately.
Computers also allow airlines to predict, with some accuracy, how many passengers will actually fly after making a reservation to fly.
This allows airlines to overbook their flights enough to fill the aircraft while accounting for "no-shows", but not enough (in most cases) to force paying passengers off the aircraft for lack of seats, stimulative pricing for low demand flights coupled with overbooking on high demand flights can help reduce this figure.
This is especially crucial during tough economic times as airlines undertake massive cuts to ticket prices to retain demand.
Over January/February 2018, the cheapest airline surveyed by price comparator rome2rio was Tigerair Australia with $ 0.06/km followed by AirAsia X with $ 0.07/km, while the most expensive was Charterlines, Inc.
with $ 1.26/km followed by Buddha Air with $ 1.18/km.
For the IATA, the global airline industry revenue was $ 754 billion in 2017 for a $ 38.4 billion collective profit, and should rise by 10.7 % to $ 834 billion in 2018 for a $ 33.8 billion profit forecast, down by 12 % due to rising jet fuel and labor costs.
The demand for air transport will be less elastic for longer flights than for shorter flights, and more elastic for leisure travel than for business travel.
Airlines have substantial fixed and operating costs to establish and maintain air services: labor, fuel, airplanes, engines, spares and parts, IT services and networks, airport equipment, airport handling services, booking commissions, advertising, catering, training, aviation insurance and other costs.
Thus all but a small percentage of the income from ticket sales is paid out to a wide variety of external providers or internal cost centers.
Moreover, the industry is structured so that airlines often act as tax collectors.
Airline fuel is untaxed because of a series of treaties existing between countries.
Ticket prices include a number of fees, taxes and surcharges beyond the control of airlines.
Airlines are also responsible for enforcing government regulations.
If airlines carry passengers without proper documentation on an international flight, they are responsible for returning them back to the original country.
Analysis of the 1992 – 1996 period shows that every player in the air transport chain is far more profitable than the airlines, who collect and pass through fees and revenues to them from ticket sales.
While airlines as a whole earned 6 % return on capital employed (2 – 3.5 % less than the cost of capital), airports earned 10 %, catering companies 10 – 13 %, handling companies 11 – 14 %, aircraft lessors 15 %, aircraft manufacturers 16 %, and global distribution companies more than 30 %.
(Source: Spinetta, 2000, quoted in Doganis, 2002) There has been continuing cost competition from low cost airlines.
Many companies emulate Southwest Airlines in various respects.
The lines between full-service and low-cost airlines have become blurred – e.g., with most "full service" airlines introducing baggage check fees despite Southwest not doing so.
Many airlines in the U.S. and elsewhere have experienced business difficulty.
U.S. airlines that have declared Chapter 11 bankruptcy since 1990 have included American Airlines, Continental Airlines (twice), Delta Air Lines, Northwest Airlines, Pan Am, United Airlines, and US Airways (twice).
Where an airline has established an engineering base at an airport, then there may be considerable economic advantages in using that same airport as a preferred focus (or "hub") for its scheduled flights.
Operating costs for US major airlines are primarily aircraft operating expense including jet fuel, aircraft maintenance, depreciation and aircrew for 44 %, servicing expense for 29 % (traffic 11 %, passenger 11 % and aircraft 7 %), 14 % for reservations and sales and 13 % for overheads (administration 6 % and advertising 2 %).
An average US major Boeing 757 - 200 flies stages 11.3 block hours per day and costs $ 2,550 per block hour: $ 923 of ownership, $ 590 of maintenance, $ 548 of fuel and $ 489 of crew; or $ 13.34 per 186 seats per block hour.
For a Boeing 737 - 500, a low-cost carrier like Southwest have lower operating costs at $ 1,526 than a full service one like United at $ 2,974, and higher productivity with 399,746 ASM per day against 264,284, resulting in a unit cost of 152600/399746round2 $ cts/ASM against 297400/264284round2 $ cts/ASM.
Airline financing is quite complex, since airlines are highly leveraged operations.
Not only must they purchase (or lease) new airliner bodies and engines regularly, they must make major long-term fleet decisions with the goal of meeting the demands of their markets while producing a fleet that is relatively economical to operate and maintain; comparably Southwest Airlines and their reliance on a single airplane type (the Boeing 737 and derivatives), with the now defunct Eastern Air Lines which operated 17 different aircraft types, each with varying pilot, engine, maintenance, and support needs.
A second financial issue is that of hedging oil and fuel purchases, which are usually second only to labor in its relative cost to the company.
However, with the current high fuel prices it has become the largest cost to an airline.
Legacy airlines, compared with new entrants, have been hit harder by rising fuel prices partly due to the running of older, less fuel efficient aircraft.
While hedging instruments can be expensive, they can easily pay for themselves many times over in periods of increasing fuel costs, such as in the 2000 – 2005 period.
In view of the congestion apparent at many international airports, the ownership of slots at certain airports (the right to take-off or land an aircraft at a particular time of day or night) has become a significant tradable asset for many airlines.
Clearly take-off slots at popular times of the day can be critical in attracting the more profitable business traveler to a given airline's flight and in establishing a competitive advantage against a competing airline.
If a particular city has two or more airports, market forces will tend to attract the less profitable routes, or those on which competition is weakest, to the less congested airport, where slots are likely to be more available and therefore cheaper.
For example, Reagan National Airport attracts profitable routes due partly to its congestion, leaving less-profitable routes to Baltimore-Washington International Airport and Dulles International Airport.
Other factors, such as surface transport facilities and onward connections, will also affect the relative appeal of different airports and some long distance flights may need to operate from the one with the longest runway.
For example, LaGuardia Airport is the preferred airport for most of Manhattan due to its proximity, while long-distance routes must use John F. Kennedy International Airport's longer runways.
Codesharing is the most common type of airline partnership; it involves one airline selling tickets for another airline's flights under its own airline code.
An early example of this was Japan Airlines' (JAL) codesharing partnership with Aeroflot in the 1960 s on Tokyo–Moscow flights; Aeroflot operated the flights using Aeroflot aircraft, but JAL sold tickets for the flights as if they were JAL flights.
This practice allows airlines to expand their operations, at least on paper, into parts of the world where they cannot afford to establish bases or purchase aircraft.
Another example was the Austrian–Sabena partnership on the Vienna–Brussels–New York/JFK route during the late ' 60 s, using a Sabena Boeing 707 with Austrian livery.
Since airline reservation requests are often made by city-pair (such as "show me flights from Chicago to Düsseldorf"), an airline that can codeshare with another airline for a variety of routes might be able to be listed as indeed offering a Chicago–Düsseldorf flight.
The passenger is advised however, that airline no. 1 operates the flight from say Chicago to Amsterdam, and airline no. 2 operates the continuing flight (on a different airplane, sometimes from another terminal) to Düsseldorf.
Thus the primary rationale for code sharing is to expand one's service offerings in city-pair terms to increase sales.
A more recent development is the airline alliance, which became prevalent in the late 1990 s.
These alliances can act as virtual mergers to get around government restrictions.
Alliances of airlines such as Star Alliance, Oneworld, and SkyTeam coordinate their passenger service programs (such as lounges and frequent-flyer programs), offer special interline tickets, and often engage in extensive codesharing (sometimes systemwide).
These are increasingly integrated business combinations—sometimes including cross-equity arrangements—in which products, service standards, schedules, and airport facilities are standardized and combined for higher efficiency.
One of the first airlines to start an alliance with another airline was KLM, who partnered with Northwest Airlines.
Both airlines later entered the SkyTeam alliance after the fusion of KLM and Air France in 2004.
Often the companies combine IT operations, or purchase fuel and aircraft as a bloc to achieve higher bargaining power.
However, the alliances have been most successful at purchasing invisible supplies and services, such as fuel.
Airlines usually prefer to purchase items visible to their passengers to differentiate themselves from local competitors.
If an airline's main domestic competitor flies Boeing airliners, then the airline may prefer to use Airbus aircraft regardless of what the rest of the alliance chooses.
Fuel hedging is a contractual tool used by transportation companies like airlines to reduce their exposure to volatile and potentially rising fuel costs.
Several low-cost carriers such as Southwest Airlines adopt this practice.
Southwest is credited with maintaining strong business profits between 1999 and the early 2000 s due to its fuel hedging policy.
Many other airlines are replicating Southwest's hedging policy to control their fuel costs.
Airlines often have a strong seasonality, with traffic low in Winter and peaking in Summer.
In Europe the most extreme market are the Greek islands with July/August having more than ten times the winter traffic, as Jet2 is the most seasonal among low-cost carriers with July having seven times the January traffic, whereas legacy carriers are much less with only 85/115 % variability.
Aircraft engines emit noise pollution, gases and particulate emissions, and contribute to global dimming.
Growth of the industry in recent years raised a number of ecological questions.
Domestic air transport grew in China at 15.5 percent annually from 2001 to 2006.
The rate of air travel globally increased at 3.7 percent per year over the same time.
In the EU greenhouse gas emissions from aviation increased by 87 % between 1990 and 2006.
However it must be compared with the flights increase, only in UK, between 1990 and 2006 terminal passengers increased from 100 000 thousands to 250 000 thousands., according to AEA reports every year, 750 million passengers travel by European airlines, which also share 40 % of merchandise value in and out of Europe.
Without even pressure from "green activists", targeting lower ticket prices, generally, airlines do what is possible to cut the fuel consumption (and gas emissions connected therewith).
Further, according to some reports, it can be concluded that the last piston-powered aircraft were as fuel-efficient as the average jet in 2005.
Despite continuing efficiency improvements from the major aircraft manufacturers, the expanding demand for global air travel has resulted in growing greenhouse gas (GHG) emissions.
Currently, the aviation sector, including US domestic and global international travel, make approximately 1.6 percent of global anthropogenic GHG emissions per annum.
North America accounts for nearly 40 percent of the world's GHG emissions from aviation fuel use.
CO2 emissions from the jet fuel burned per passenger on an average airline flight is about 353 kilograms (776 pounds).
Loss of natural habitat potential associated with the jet fuel burned per passenger on a airline flight is estimated to be 250 square meters (2700 square feet).
In the context of climate change and peak oil, there is a debate about possible taxation of air travel and the inclusion of aviation in an emissions trading scheme, with a view to ensuring that the total external costs of aviation are taken into account.
The airline industry is responsible for about 11 percent of greenhouse gases emitted by the U.S. transportation sector.
Boeing estimates that biofuels could reduce flight-related greenhouse-gas emissions by 60 to 80 percent.
The solution would be blending algae fuels with existing jet fuel: There are projects on electric aircraft, and some of them are fully operational as of 2013.
Each operator of a scheduled or charter flight uses an airline call sign when communicating with airports or air traffic control centres.
Most of these call-signs are derived from the airline's trade name, but for reasons of history, marketing, or the need to reduce ambiguity in spoken English (so that pilots do not mistakenly make navigational decisions based on instructions issued to a different aircraft), some airlines and air forces use call-signs less obviously connected with their trading name.
For example, British Airways uses a "Speedbird" call-sign, named after the logo of one of its predecessors, BOAC, while SkyEurope used "Relax".
The various types of airline personnel include: Airlines follow a corporate structure where each broad area of operations (such as maintenance, flight operations (including flight safety), and passenger service) is supervised by a vice president.
Larger airlines often appoint vice presidents to oversee each of the airline's hubs as well.
Airlines employ lawyers to deal with regulatory procedures and other administrative tasks.
The pattern of ownership has been privatized in the recent years, that is, the ownership has gradually changed from governments to private and individual sectors or organizations.
This occurs as regulators permit greater freedom and non-government ownership, in steps that are usually decades apart.
This pattern is not seen for all airlines in all regions.
Growth rates are not consistent in all regions, but countries with a de-regulated airline industry have more competition and greater pricing freedom.
This results in lower fares and sometimes dramatic spurts in traffic growth.
The U.S., Australia, Canada, Japan, Brazil, India and other markets exhibit this trend.
The industry has been observed to be cyclical in its financial performance.
Four or five years of poor earnings precede five or six years of improvement.
But profitability even in the good years is generally low, in the range of 2 – 3 % net profit after interest and tax.
In times of profit, airlines lease new generations of airplanes and upgrade services in response to higher demand.
Since 1980, the industry has not earned back the cost of capital during the best of times.
Conversely, in bad times losses can be dramatically worse.
As in many mature industries, consolidation is a trend.
Airline groupings may consist of limited bilateral partnerships, long-term, multi-faceted alliances between carriers, equity arrangements, mergers, or takeovers.
Since governments often restrict ownership and merger between companies in different countries, most consolidation takes place within a country.
In the U.S., over 200 airlines have merged, been taken over, or gone out of business since deregulation in 1978.
Many international airline managers are lobbying their governments to permit greater consolidation to achieve higher economy and efficiency.
The Australian Democrats is a centrist political party in Australia.
Founded in 1977 from a merger of the Australia Party and the New Liberal Movement, both of which were descended from Liberal Party splinter group, it was Australia's largest minor party from its formation in 1977 through to 2004 and frequently held the balance of power in the Senate during that time.
The party's inaugural leader was Don Chipp, a former Liberal cabinet minister, who famously promised to "keep the bastards honest".
At the 1977 federal election, the Democrats polled 11.1 percent of the Senate vote and secured two seats.
The party would retain a presence in the Senate for the next 30 years, at its peak (between 1999 and 2002) holding nine out of 76 seats, though never securing a seat in the lower house.
The party's share of the vote collapsed at the 2004 election and was further diminished in 2007 with the last senators leaving office in 2008.
Due to the party's numbers in the Senate, both Liberal and Labor governments required the assistance of the Democrats to pass contentious legislation, most notably in the case of the Howard Government's goods and services tax (GST).
Ideologically, the Democrats were usually regarded as centrists, occupying the political middle ground between the Liberal Party and the Labor Party.
The party was formally deregistered in 2016 for not having the required 500 members.
In 2018 the Australian Democrats merged with Country Minded, an Australian political party seeking accountable regional and agricultural representation.
On 7 April 2019 the merged entity regained registration of the name "Australian Democrats" with the Australian Electoral Commission.
The party unsuccessfully contested the lower-house seat of Adelaide and a total of six Senate seats (two in each state of New South Wales, Victoria and South Australia) at the 2019 federal election.
From the outset, members' participation was fiercely protected in national and divisional constitutions prescribing internal elections, regular meeting protocols, annual conferences—and monthly journals for open discussion and balloting.
Dispute resolution procedures were established, with final recourse to a party ombudsman and membership ballot.
Policies determined by the unique participatory method promoted environmental awareness and sustainability, opposition to the primacy of economic rationalism (Australian neoliberalism), preventative approaches to human health and welfare, animal rights, rejection of nuclear technology and weapons.
The Australian Democrats were the first representatives of green politics at the federal level in Australia.
They played a key role in the "cause célèbre" of the Franklin River Dam.
The party's centrist role made it subject to criticism from both the right and left of the political spectrum.
In particular, Chipp's former conservative affiliation was frequently recalled by opponents on the left.
This problem was to torment later leaders and strategists who, by 1991, were proclaiming "the electoral objective" as a higher priority than the rigorous participatory democracy espoused by the party's founders.
Because of their numbers on the cross benches during the Hawke and Keating governments, the Democrats were sometimes regarded as exercising a balance of power—which attracted electoral support from a significant sector of the electorate which had been alienated by both Labor and Coalition policies and practices.
Over three decades, the Australian Democrats achieved representation in the legislatures of the ACT, South Australia, New South Wales, Western Australia and Tasmania as well as Senate seats in all six states.
However, at the 2004 and 2007 federal elections, all seven of its Senate seats were lost.
The last remaining State parliamentarian, David Winderlich, left the party and was defeated as an independent in 2010.
The Australian Democrats were formed in May 1977 from an amalgamation of the Australia Party and the New Liberal Movement.
The two groups found a common basis for a new political movement in the widespread discontent with the two major parties.
In the former Liberal Government Minister, Don Chipp, the two groups found their leader.
The first Australian Democrat to sit in the federal parliamentarian was Senator Janine Haines who in 1977 was nominated by the South Australian Parliament to fill the casual vacancy caused by the resignation of Liberal Senator Steele Hall.
The party's broad aim was to achieve a balance of power in one or more parliaments and to exercise it responsibly in line with policies determined by membership.
In 1977, the Australian Democrats secured two seats in the Senate with the election of Colin Mason (NSW) and Don Chipp (VIC).
In 1980, this increased to five seats with the election of Michael Macklin (QLD) and John Siddons (VIC) and the re-election of Janine Haines (SA).
Thereafter they frequently held enough seats to give them the balance of power in the upper chamber.
At a Melbourne media conference on 19 September 1980, in the midst of the 1980 election campaign, Chipp described his party's aim as to "keep the bastards honest" — the "bastards" being the major parties and/or politicians in general.
This became a long-lived slogan for the Democrats.
In South Australia, the New Liberal Movement dissolved and merged with the Democrats, making its sole parliamentary representative, Robin Millhouse, the Democrats' first member of the South Australian parliament.
Millhouse held his seat (Mitcham) at the 1977 and 1979 state elections.
In 1982, Millhouse resigned to take up a senior judicial appointment, and Heather Southcott won the by-election for the Democrats, but lost the seat to the Liberals later that year at the 1982 state election.
Mitcham was the only single-member lower-house seat anywhere in Australia to be won by the Democrats.
Don Chipp resigned from the Senate on 18 August 1986, being succeeded as party leader by Janine Haines and replaced as a senator for Victoria by Janet Powell.
At the 1987 election following a double dissolution, the reduced quota of 7.7 % necessary to win a seat assisted the election of three new senators.
6-year terms were won by Paul McLean (NSW) and incumbents Janine Haines (South Australia) and Janet Powell (Victoria).
In South Australia, a second senator, John Coulter, was elected for a 3-year term, as were incumbent Michael Macklin (Queensland) and Jean Jenkins (Western Australia).
1990 saw the voluntary departure from the Senate of Janine Haines (a step with which not all Democrats agreed) and the failure of her strategic goal of winning the House of Representatives seat of Kingston.
The casual vacancy was filled by Meg Lees several months before the election of Cheryl Kernot in place of retired deputy leader Michael Macklin.
The ambitious Kernot immediately contested the party's national parliamentary deputy leadership.
Being unemployed at the time, she requested and obtained party funds to pay for her travel to address members in all seven divisions.
In the event, Victorian Janet Powell was elected as leader and John Coulter was chosen as deputy leader.
Despite the loss of Haines and the WA Senate seat (through an inconsistent national preference agreement with the ALP), the 1990 federal election heralded something of a rebirth for the party, with a dramatic rise in primary vote.
This was at the same time as an economic recession was building, and events such as the Gulf War in Kuwait were beginning to shepherd issues of globalisation and transnational trade on to national government agendas.
Election Results Senate – National ^ NSW, SA and VIC Only The Australian Democrats had a long-standing policy to oppose war and so opposed Australia's support of, and participation in, the Gulf War.
Whereas the House of Representatives was able to avoid any debate about the war and Australia's participation, the Democrats took full advantage of the opportunity to move for a debate in the Senate.
Because of the party's pacifist-based opposition to the Gulf War, there was mass-media antipathy and negative publicity which some construed as poor media performance by Janet Powell, the party's standing having stalled at about 10 %.
Before 12 months of her leadership had passed, the South Australian and Queensland divisions were circulating the party's first-ever petition to criticise and oust the parliamentary leader.
The explicit grounds related to Powell's alleged responsibility for poor AD ratings in Gallup and other media surveys of potential voting support.
When this charge was deemed insufficient, interested party officers and senators reinforced it with negative media ' leaks' concerning her openly established relationship with Sid Spindler and exposure of administrative failings resulting in excessive overtime to a staff member.
With National Executive blessing, the party room pre-empted the ballot by replacing the leader with deputy John Coulter.
In the process, severe internal divisions were generated.
One major collateral casualty was the party whip Paul McLean who resigned and quit the Senate in disgust at what he perceived as in-fighting between close friends.
The casual NSW vacancy created by his resignation was filled by Karin Sowada.
Powell duly left the party, along with many leading figures of the Victorian branch of the party, and unsuccessfully stood as an Independent candidate when her term expired.
In later years, she campaigned for the Australian Greens.
The party's parliamentary influence was weakened in 1996 after the Howard Government was elected, and a Labor senator, Mal Colston, resigned from the Labor Party.
Since the Democrats now shared the parliamentary balance of power with two Independent senators, the Coalition government was able on occasion to pass legislation by negotiating with Colston and Brian Harradine.
In October 1997, party leader Cheryl Kernot resigned, announcing that she would be joining the Australian Labor Party.
(Five years later it was revealed that she had been in a sexual relationship with Labor deputy leader Gareth Evans).
Kernot resigned from the Senate and was replaced by Andrew Bartlett, while deputy Meg Lees became the new party leader.
Under Lees' leadership, in the 1998 federal election, the Democrats' candidate John Schumann came within 2 per cent of taking Liberal Foreign Minister Alexander Downer's seat of Mayo in the Adelaide Hills under Australia's preferential voting system.
The party's representation increased to nine senators, and they regained the balance of power, holding it until the Coalition gained a Senate majority at the 2004 election.
Internal conflict and leadership tensions from 2000 to 2002, blamed on the party's support for the Government's Goods and Services Tax (GST), was damaging to the Democrats.
Opposed by the Labor Party, the Australian Greens and independent Senator Harradine, the GST required Democrat support to pass. In an election fought on tax, the Democrats publicly stated that they liked neither the Liberal (GST) tax package nor the Labor package, but pledged to work with whichever party was elected to make their tax package better.
They campaigned with the slogan "No GST on food".
In 1999, after negotiations with Prime Minister Howard, Meg Lees, Andrew Murray and the party room senators agreed to support the A New Tax System (ANTS) legislation with exemptions from GST for most food and some medicines, as well as many environmental and social concessions.
Five Australian Democrats senators voted in favour.
However, two dissident senators on the party's left Natasha Stott Despoja and Andrew Bartlett voted against the GST.
In 2001, a leadership spill saw Meg Lees replaced as leader by Natasha Stott Despoja after a very public and bitter leadership battle.
Despite criticism of Stott Despoja's youth and lack of experience, the 2001 election saw the Democrats receive similar media coverage to the previous election.
Despite the internal divisions, the Australian Democrats' election result in 2001 was quite good.
However, it was not enough to prevent the loss of Vicki Bourne's Senate seat in NSW.
The 2002 South Australian election was the last time an Australian Democrat would be elected to an Australian parliament.
Sandra Kanck was re-elected to a second eight-year term from an upper house primary vote of 7.3 percent.
Resulting tensions between Stott Despoja and Lees led to Meg Lees leaving the party in 2002, becoming an independent and forming the Australian Progressive Alliance.
Stott Despoja stood down from the leadership following a loss of confidence by her party room colleagues.
It led to a protracted leadership battle in 2002, which eventually led to the election of Senator Andrew Bartlett as leader.
While the public fighting stopped, the public support for the party remained at record lows.
On 6 December 2003, Bartlett stepped aside temporarily as leader of the party, after an incident in which he swore at Liberal Senator Jeannie Ferris on the floor of Parliament while intoxicated.
The party issued a statement stating that deputy leader Lyn Allison would serve as the acting leader of the party.
Bartlett apologised to the Democrats, Jeannie Ferris and the Australian public for his behaviour and assured all concerned that it would never happen again.
On 29 January 2004, after seeking medical treatment, Bartlett returned to the Australian Democrats leadership, vowing to abstain from alcohol.
Following internal conflict over GST (1998 – 2001) and resultant leadership changes, a dramatic decline occurred in the Democrats' membership and voting support in all states.
Simultaneously, an increase was recorded in support for the Australian Greens who, by 2004, were supplanting the Democrats as a substantial third party.
The trend was noted that year by political scientists Dean Jaensch et al.
Support for the Australian Democrats fell significantly at the 2004 federal election in which they achieved only 2.4 per cent of the national vote.
Nowhere was this more noticeable than in their key support base of suburban Adelaide in South Australia, where they received between 1 and 4 percent of the lower house vote; by comparison, they tallied between 7 and 31 per cent of the vote in 2001.
Three incumbent senators were defeated—Aden Ridgeway (NSW), Brian Greig (WA) and John Cherry (Qld).
Following the loss, the customary post-election leadership ballot installed Allison as leader, with Bartlett as her deputy.
From 1 July 2005 the Australian Democrats lost official parliamentary party status, being represented by only four senators while the governing Liberal-National Coalition gained a majority and potential control of the Senate—the first time this advantage had been enjoyed by any government since 1980.
On 28 August 2006, the founder of the Australian Democrats, Don Chipp, died.
In November 2006, the Australian Democrats fared very poorly in the Victorian state election, receiving a Legislative Council vote tally of only 0.83 %, less than half of the party's result in 2002 (1.79 per cent).
The Tasmanian division of the party was deregistered for having insufficient members in January 2006.
On 18 March 2006, at the 2006 South Australian election, the Australian Democrats were reduced to 1.7 per cent of the Legislative Council (upper house) vote.
Their sole councillor up for re-election, Kate Reynolds, was defeated.
In July 2006, Richard Pascoe, national and South Australian party president, resigned, citing slumping opinion polls and the poor result in the 2006 South Australian election as well as South Australian parliamentary leader Sandra Kanck's comments regarding the drug MDMA which he saw as damaging to the party.
In the New South Wales state election of March 2007, the Australian Democrats lost their last remaining NSW Upper House representative, Arthur Chesterfield-Evans.
The party fared poorly, gaining only 1.8 per cent of the Legislative Council vote.
On 13 September 2007, the ACT Democrats (Australian Capital Territory Division of the party) was deregistered by the ACT Electoral Commissioner, being unable to demonstrate a minimum membership of 100 electors.
The Democrats had no success at the 2007 federal election.
Two incumbent senators, Lyn Allison (Victoria) and Andrew Bartlett (Queensland), were defeated, their seats both reverting to major parties.
Their two remaining colleagues, Andrew Murray (WA) and Natasha Stott Despoja (SA), retired.
All four senators' terms expired on 30 June 2008—leaving the Australian Democrats with no federal representation for the first time since its founding in 1977.
Later, in 2009, Jaensch suggested it was possible the Democrats could make a political comeback at the 2010 South Australian election, but this did not occur.
The last of the party's state upper-house members, David Winderlich, resigned from the party in October 2009 and was defeated as an independent at the 2010 election.
On 16 April 2015, the Australian Electoral Commission deregistered the Australian Democrats as a political party for failure to demonstrate the requisite 500 members to maintain registration.
However, the party did run candidates and remain registered for a period of time thereafter in the New South Wales Democrats and Queensland Democrat divisions.
In November 2018 there was a report that CountryMinded, a de-registered microparty, would merge with the Australian Democrats in a new bid to seek membership growth, electoral re-registration and financial support.
In February 2019, application for registration was submitted to the AEC and was upheld on 7 April 2019, despite an objection from the party's incorporated former Queensland division.
colspan = 7Senate 1 Don Chipp VIC 9 May 1977 18 August 1986 1977, 1980, 1983, 1984 2 Janine Haines SA 18 August 1986 24 March 1990 1987, 1990 "Michael Macklin" QLD 24 March 1990 30 June 1990 0 years, none 3 Janet Powell VIC 1 July 1990 19 August 1991 none 4 John Coulter SA 19 August 1991 29 April 1993 1993 5 Cheryl Kernot QLD 29 April 1993 15 October 1997 1996 Meg Lees SA 15 October 1997 1998 7 Natasha Stott Despoja SA 21 August 2002 2001 "Brian Greig" WA 23 August 2002 5 October 2002 0 years, none 8 Andrew Bartlett QLD 5 October 2002 3 November 2004 2004 9 Lyn Allison VIC 3 November 2004 30 June 2008 2007 Janine Haines South Australia Don Chipp 1978 – 1986 Colin Mason 1978 – 1987 Michael Macklin John Siddons 1981 – 1983; 1985 – 1986 (1987) Jack Evans 1983 – 1985 David Vigor 1985 – 1987 Norm Sanders 1985 – 1990 Janet Powell 1986 – 1992 (1993) John Coulter South Australia 1987 – 1995 Paul McLean 1987 – 1991 Jean Jenkins 1987 – 1990 Vicki Bourne 1990 – 2002 Sid Spindler 1990 – 1996 Cheryl Kernot 1990 – 1997 Robert Bell 1990 – 1996 Karin Sowada 1991 – 1993 John Woodley 1993 – 2001 Meg Lees 1990 – 2002 (2005) Natasha Stott Despoja 1995 – 2008 Lyn Allison 1996 – 2008 Andrew Murray 1996 – 2008 Andrew Bartlett 1997 – 2008 Aden Ridgeway 1999 – 2005 Brian Greig 1999 – 2005 John Cherry 2001 – 2005
The Australian Capital Territory, formerly known as the Federal Capital Territory until 1938 and commonly referred to as the ACT, is a federal territory of Australia containing the Australian capital city of Canberra and some surrounding townships.
It is located in the south-east of the country and is an enclave within the state of New South Wales.
Founded after Federation as the seat of government for the new nation, all important institutions of the Australian federal government are centred in the territory.
On 1 January 1901, federation of the colonies of Australia was achieved.
Section 125 of the new Australian Constitution provided that land, situated in New South Wales and at least from Sydney, would be ceded to the new federal government.
Following discussion and exploration of various areas within New South Wales, the "Seat of Government Act 1908" was passed in 1908 which specified a capital in the Yass-Canberra region.
The territory was transferred to the Commonwealth by New South Wales in 1911, two years prior to the capital city being founded and formally named as Canberra in 1913.
While the overwhelming majority of the population reside in the city of Canberra in the ACT's north-east, the territory also includes some surrounding townships such as Williamsdale, Naas, Uriarra, Tharwa and Hall.
The ACT also includes the Namadgi National Park which comprises the majority of land area of the territory.
Despite a common misconception, the Jervis Bay Territory is not part of the ACT although the laws of the Australian Capital Territory apply as if Jervis Bay did form part of the ACT.
The territory has a relatively dry, continental climate experiencing warm to hot summers and cool to cold winters.
The Australian Capital Territory is home to many important institutions of the federal government, national monuments and museums.
This includes the Parliament of Australia, the High Court of Australia, the Australian Defence Force Academy and the Australian War Memorial.
It also hosts the majority of foreign embassies in Australia as well as regional headquarters of many international organisations, not-for-profit groups, lobbying groups and professional associations.
Several major universities also have campuses in the ACT including the Australian National University, the University of Canberra, the University of New South Wales, Charles Sturt University and the Australian Catholic University.
A locally elected legislative assembly has governed the territory since 1988.
However, the Commonwealth maintains authority over the territory and may overturn local laws.
It still maintains control over the area known as the Parliamentary Triangle through the National Capital Authority.
Residents of the territory elect three members to the House of Representatives and two Senators to the Australian Senate.
With 423,800 residents, the Australian Capital Territory is the second smallest mainland state or territory by population.
At the, the median weekly income for people in the territory aged over 15 was $ 998 and higher than the national average of $ 662.
The average level of degree qualification in the ACT is also higher than the national average.
Within the ACT, 37.1 % of the population hold a bachelor's degree level or above education compared to the national figure of 20 %.
Indigenous Australian peoples have long inhabited the area.
Evidence indicates habitation dating back at least 25,000 years.
It is possible that the area was inhabited for considerably longer, with evidence of an Aboriginal presence at Lake Mungo in south-western New South Wales dating back around 40,000 years.
The principal group occupying the region were the Ngunnawal people.
Following European settlement, the growth of the new colony of New South Wales led to an increasing demand for arable land.
Governor Lachlan Macquarie supported expeditions to open up new lands to the south of Sydney.
The 1820 s saw further exploration in the Canberra area associated with the construction of a road from Sydney to the Goulburn plains.
While working on the project, Charles Throsby learned of a nearby lake and river from the local Indigenous peoples and he accordingly sent Wild to lead a small party to investigate the site.
The search was unsuccessful, but they did discover the Yass River and it is surmised that they would have set foot on part of the future territory.
A second expedition was mounted shortly thereafter and they became the first Europeans to camp at the Molonglo (Ngambri) and Queanbeyan (Jullergung) Rivers.
However, they failed to find the Murrumbidgee River.
The issue of the Murrumbidgee was solved in 1821 when Throsby mounted a third expedition and successfully reached the watercourse, on the way providing the first detailed account of the land where Canberra now resides.
The last expedition in the region before settlement was undertaken by Allan Cunningham in 1824.
He reported that the region was suitable for grazing and the settlement of the Limestone Plains followed immediately thereafter.
The first land grant in the region was made to Joshua John Moore in 1823 and European settlement in the area began in 1824 with the construction of a homestead by his stockmen on what is now the Acton Peninsula.
Moore formally purchased the site in 1826 and named the property "Canberry" or "Canberra".
A significant influx of population and economic activity occurred around the 1850 s goldrushes.
The goldrushes prompted the establishment of communication between Sydney and the region by way of the Cobb & Co coaches, which transported mail and passengers.
The first post offices opened in Ginninderra in 1859 and at Lanyon in 1860.
During colonial times, the European communities of Ginninderra, Molonglo and Tuggeranong settled and farmed the surrounding land.
The region was also called the Queanbeyan-Yass district, after the two largest towns in the area.
The villages of Ginninderra and Tharwa developed to service the local agrarian communities.
During the first 20 years of settlement, there was only limited contact between the settlers and Aboriginal people.
Over the succeeding years, the Ngunnawal and other local indigenous people effectively ceased to exist as cohesive and independent communities adhering to their traditional ways of life.
Those who had not succumbed to disease and other predations either dispersed to the local settlements or were relocated to more distant Aboriginal reserves set up by the New South Wales government in the latter part of the 19th century.
In 1898, a referendum on a proposed Constitution was held in four of the colonies – New South Wales, Victoria, South Australia and Tasmania.
Although the referendum achieved a majority in all four colonies, the New South Wales referendum failed to gain the minimum number of votes needed for the bill to pass. Following this result, a meeting of the four Premiers in 1898 heard from George Reid, the Premier of New South Wales, who argued that locating the future capital in New South Wales would be sufficient to ensure the passage of the Bill.
The 1899 referendum on this revised bill was successful and passed with sufficient numbers.
Section 125 of the Australian Constitution thus provided that, following Federation in 1901, land would be ceded freely to the new Federal Government.
This, however, left open the question of where to locate the capital.
In 1906 and after significant deliberations, New South Wales agreed to cede sufficient land on the condition that it was in the Yass-Canberra region, this site being closer to Sydney.
Initially, Dalgety, New South Wales remained at the forefront, but Yass-Canberra prevailed after voting by federal representatives.
The "Seat of Government Act 1908" was passed in 1908, which repealed the 1904 Act and specified a capital in the Yass-Canberra region.
Government surveyor Charles Scrivener was deployed to the region in the same year to map out a specific site and, after an extensive search, settled upon the present location.
The territory was transferred to the Commonwealth by New South Wales in 1911, two years before the naming of Canberra as the national capital in 1913.
In 1911, an international competition to design the future capital was held, which was won by the Chicago architect Walter Burley Griffin in 1912.
The official naming of Canberra occurred on 12 March 1913 and construction began immediately.
After Griffin's departure following difficulty in implementing his project, the Federal Capital Advisory Committee was established in 1920 to advise the government of the construction efforts.
The Committee had limited success meeting its goals.
However, the chairman, John Sulman, was instrumental in applying the ideas of the garden city movement to Griffin's plan.
The Committee was replaced in 1925 by the Federal Capital Commission.
In 1930, the ACT Advisory Council was established to advise the minister for territories on the community's concerns.
In 1934, Supreme Court of the Australian Capital Territory was established.
From 1938 to 1957, the National Capital Planning and Development Committee continued to plan the further expansion of Canberra.
However, the National Capital Planning and Development Committee did not have executive power, and decisions were made on the development of Canberra without the Committee's consultation.
During this time, Prime Minister Robert Menzies regarded the state of the national capital as an embarrassment.
After World War II, there was a shortage of housing and office space in Canberra.
A Senate Select Committee hearing was held in 1954 to address its development requirements.
This Committee recommended the creation of a single planning body with executive power.
Consequently, the National Capital Planning and Development Committee was replaced by the National Capital Development Commission in 1957.
The National Capital Development Commission ended four decades of disputes over the shape and design of Lake Burley Griffin and construction was completed in 1964 after four years of work.
The completion of the centrepiece of Griffin's design finally the laid the platform for the development of Griffin's Parliamentary Triangle.
In 1988, the new minister for the Australian Capital Territory Gary Punch received a report recommending the abolition of the National Capital Development Commission and the formation of a locally elected government.
Punch recommended that the Hawke government accept the report's recommendations and subsequently Clyde Holding introduced legislation to grant self-government to the territory in October 1988.
The enactment on 6 December 1988 of the "Australian Capital Territory (Self-Government) Act 1988" established the framework for self-government.
The first election for the 17-member Australian Capital Territory Legislative Assembly was held on 4 March 1989.
The initial years of self-government were difficult and unstable.
A majority of ACT residents had opposed self-government and had it imposed upon them by the federal parliament.
At the first election, 4 of the 17 seats were won by anti-self-government single-issue parties due to a protest vote by disgruntled territorians and a total of 8 were won by minor parties and independents.
In 1992, Labor won eight seats and the minor parties and independents won only three.
Stability increased, and in 1995, Kate Carnell became the first elected Liberal chief minister.
In 1998, Carnell became the first chief minister to be re-elected.
The Australian Capital Territory is the smallest mainland territory (aside from the Jervis Bay Territory) and covers a total land area of.
It is bounded by the Goulburn-Cooma railway line in the east, the watershed of Naas Creek in the south, the watershed of the Cotter River in the west and the watershed of the Molonglo River in the north-east.
These boundaries were set to give the ACT an adequate water supply.
The ACT extends about North-South between 35.124 ° S and 35.921 ° S, and West-East between 148.763 ° E and 149.399 ° E. The city area of Canberra occupies the north-eastern corner of this area.
The Australian Capital Territory includes the city of Canberra and some other townships such as Williamsdale, Naas, Uriarra, Tharwa and Hall.
The Australian Capital Territory also contains agricultural land (sheep, dairy cattle, vineyards and small amounts of crops) and a large area of national park (Namadgi National Park), much of it mountainous and forested.
Tidbinbilla is a locality to the south-west of Canberra that features the Tidbinbilla Nature Reserve and the Canberra Deep Space Communication Complex, operated by the United States' National Aeronautics and Space Administration (NASA) as part of its Deep Space Network.
There are a large range of mountains, rivers and creeks throughout the territory and are largely contained within the Namadgi National Park.
These include the Naas and Murrumbidgee Rivers.
The territory has a relatively dry, continental climate experiencing warm to hot summers and cool to cold winters.
Under Köppen-Geiger classification, the territory has an oceanic climate ("Cfb").
January is the hottest month with an average high of.
July is the coldest month when the average high drops to.
The highest maximum temperature recorded in the territory was on 1 February 1968.
The lowest minimum temperature was on 11 July 1971.
Rainfall varies significantly across the territory.
Much higher rainfall occurs in the mountains to the west of Canberra compared to the east.
The mountains act as a barrier during winter with the city receiving less rainfall.
Average annual rainfall in the territory is and there is an average of 108 rain days annually.
The wettest month is October with an average rainfall of and the driest month is June with an average of.
Frost is common in the winter months.
Snow is rare in Canberra's city centre, but the surrounding areas get annual snowfall through winter and often the snow-capped mountains can be seen from the city.
The last significant snowfall in the city centre was in 1968.
The environments range from alpine area on the higher mountains, to sclerophyll forest and to woodland.
Much of the ACT has been cleared for grazing and is also burnt off by bushfires several times per century.
The kinds of plants can be grouped into vascular plants, that include gymnosperms, flowering plants, and ferns, as well as bryophytes, lichens, fungi and freshwater algae.
Four flowering plants are endemic to the ACT.
Several lichens are unique to the territory.
Most plants in the ACT are characteristic of the Flora of Australia and include well known plants such as Grevillea, Eucalyptus trees and kangaroo grass.
The native forest in the Canberra region was almost wholly eucalypt species and provided a resource for fuel and domestic purposes.
By the early 1960 s, logging had depleted the eucalypt, and concern about water quality led to the forests being closed.
Interest in forestry began in 1915 with trials of a number of species including "Pinus radiata" on the slopes of Mount Stromlo.
Since then, plantations have been expanded, with the benefit of reducing erosion in the Cotter catchment, and the forests are also popular recreation areas.
The fauna of the territory includes representatives from most major Australian animal groups.
This includes kangaroos, wallabies, koalas, platypus, echidna, emu, kookaburras and dragon lizards.
Notable geological formations in the Australian Capital Territory include the "Canberra Formation", the "Pittman Formation", "Black Mountain Sandstone" and "State Circle Shale".
In the 1840 s fossils of brachiopods and trilobites from the Silurian period were discovered at Woolshed Creek near Duntroon.
At the time, these were the oldest fossils discovered in Australia, though this record has now been far surpassed.
Other specific geological places of interest include the State Circle cutting and the Deakin anticline.
The oldest rocks in the ACT date from the Ordovician around 480 million years ago.
During this period the region along with most of Eastern Australia was part of the ocean floor; formations from this period include the "Black Mountain Sandstone" formation and the "Pittman Formation" consisting largely of quartz-rich sandstone, siltstone and shale.
These formations became exposed when the ocean floor was raised by a major volcanic activity in the Devonian forming much of the east coast of Australia.
The ACT has internal self-government, but Australia's Constitution does not afford a territory legislature the high degree of independence provided to that of a state.
Instead, each territory is governed under a Commonwealth statutefor the ACT, the Australian Capital Territory (Self-Government) Act 1988.
The chief minister performs many of the roles that a state governor normally holds in the context of a state; however, the Speaker of the Legislative Assembly gazettes the laws and summons meetings of the Assembly.
Laws are made in a 25-member Legislative Assembly that combines both state and local government functions (prior to 2016, the Assembly was made up of 17 members).
Members of the Legislative Assembly are elected via the Hare–Clark system.
The executive of the Australian Capital Territory, also known as the ACT Government, consists of the chief minister and such other ministers as are appointed by the chief minister.
The ACT chief minister (currently Andrew Barr, Labor) is elected by members of the Legislative Assembly.
The chief minister represents the ACT Government as a member of the Council of Australian Governments.
Unlike other self-governing Australian territories (for example, the Northern Territory), the ACT does not have an Administrator.
The Crown is represented in government of the ACT by the Australian Governor-General.
Until 4 December 2011, the decisions of the assembly could be overruled by the Governor-General (effectively by the national government) under section 35 of the Australian Capital Territory (Self-Government) Act 1988, although the federal parliament voted in 2011 to abolish this veto power, instead requiring a majority of both houses of the federal parliament to override an enactment of the ACT.
The court system of the territory consists of the Supreme Court of the Australian Capital Territory, the Magistrates Court of the Australian Capital Territory and the ACT Civil and Administrative Tribunal.
It is unique in that the territory does not have an intermediary court like other mainland states and territories; there is only the superior court and a court of summary jurisdiction.
the Chief Justice is Helen Murrell and the current Chief Magistrate is Lorraine Walker.
ACT Policing (part of the Australian Federal Police) is responsible for providing policing services to the ACT.
Canberra had the lowest rate of crime of any capital city in Australia.
In Australia's Federal Parliament, the ACT is represented by five federal members: three members of the House of Representatives represent the Division of Bean, the Division of Canberra and the Division of Fenner, and it is one of only two territories to be represented in the Senate, with two Senators (the other being the Northern Territory).
The Member for Bean and the ACT Senators also represent the constituents of Norfolk Island.
The Member for Fenner and the ACT Senators also represent the constituents of the Jervis Bay Territory.
In 1915, the "Jervis Bay Territory Acceptance Act 1915" created the Jervis Bay Territory as an annexe to the Federal Capital Territory.
While the Act's use of the language of "annexed" is sometimes interpreted as implying that the Jervis Bay Territory was to form part of the Federal Capital Territory, the accepted legal position is that it has been a legally distinct territory from its creation despite being subject to ACT law and, prior to ACT self-government in 1988, being administratively treated as part of the ACT.
In 1988, when the ACT gained self-government, Jervis Bay was formally pronounced as a separate territory administered by the Commonwealth known as the Jervis Bay Territory.
However, the laws of the ACT continue to apply to the Jervis Bay Territory.
Magistrates from the ACT regularly travel to the Jervis Bay Territory to conduct court.
Another occasional misconception is that the ACT retains a small area of territory on the coast on the Beecroft Peninsula, consisting of a strip of coastline around the northern headland of Jervis Bay.
While the land is owned by the Commonwealth Government, that area itself is still considered to be under the jurisdiction of New South Wales government, not a separate territory nor a part of the ACT.
The Australian Bureau of Statistics estimates that the population of the territory was 419,200 on 31 March 2019.
The population is projected to reach to approximately 700,000 by 2058.
The overwhelming majority of the population reside in the city of Canberra.
At the, the median weekly income for people in the territory aged over 15 was $ 998 while the national average was $ 662.
The average level of degree qualification in the ACT is higher than the national average.
Within the ACT, 37.1 % of the population hold a bachelor's degree level or above education compared to the national figure of 20 %.
The Australian Capital Territory consists of the city of Canberra and some surrounding townships including Williamsdale, Naas, Uriarra, Tharwa and Hall.
The urban areas of Canberra are organised into a hierarchy of districts, town centres, group centres, local suburbs as well as other industrial areas and villages.
There are seven districts (with an eighth currently under construction), each of which is divided into smaller suburbs, and most of which have a town centre which is the focus of commercial and social activities.
The districts were settled in the following chronological order: The North and South Canberra districts are substantially based on Walter Burley Griffin's designs.
In 1967, the then National Capital Development Commission adopted the "Y Plan" which laid out future urban development in Canberra around a series of central shopping and commercial area known as the ' town centres' linked by freeways, the layout of which roughly resembled the shape of the letter Y, with Tuggeranong at the base of the Y and Belconnen and Gungahlin located at the ends of the arms of the Y. At the 2016 census, the most commonly nominated ancestries were: The 2016 census showed that 32 % of the ACT's inhabitants were born overseas.
Of inhabitants born outside of Australia, the most prevalent countries of birth were England, China, India, New Zealand and the Philippines.
1.6 % of the population, or 6,476 people, identified as Indigenous Australians (Aboriginal Australians and Torres Strait Islanders) in 2016.
At the 2016 census, 72.7 % of people spoke only English at home.
The other languages most commonly spoken at home were Mandarin (3.1 %), Vietnamese (1.1 %), Cantonese (1 %), Hindi (0.9 %) and Spanish (0.8 %).
The most common responses in the for religion in the territory were No Religion (36.2 %), Catholic (22.3 %), Anglican (10.8 %), Not stated (9.2 %) and Hinduism (2.6 %).
In Australian Capital Territory, Christianity was the largest religious group reported overall (49.9 %).
Almost all educational institutions in the Australian Capital Territory are located within Canberra.
The ACT public education system schooling is normally split up into Pre-School, Primary School (K-6), High School (7 – 10) and College (11 – 12) followed by studies at university or CIT (Canberra Institute of Technology).
Many private high schools include years 11 and 12 and are referred to as colleges.
Children are required to attend school until they turn 17 under the ACT Government's "Learn or Earn" policy.
In February 2004 there were 140 public and non-governmental schools in ACT; 96 were operated by the Government and 44 are non-Government.
In 2005, there were 60,275 students in the ACT school system.
59.3 % of the students were enrolled in government schools with the remaining 40.7 % in non-government schools.
There were 30,995 students in primary school, 19,211 in high school, 9,429 in college and a further 340 in special schools.
As of May 2004, 30 % of people in the ACT aged 15 – 64 had a level of educational attainment equal to at least a bachelor's degree, significantly higher than the national average of 19 %.
The two main tertiary institutions are the Australian National University (ANU) in Acton and the University of Canberra (UC) in Bruce.
There are also two religious university campuses in Canberra: Signadou is a campus of the Australian Catholic University and St Mark's Theological College is a campus of Charles Sturt University.
Tertiary level vocational education is also available through the multi-campus Canberra Institute of Technology.
The Australian Defence Force Academy (ADFA) and the Royal Military College, Duntroon (RMC) are in the suburb of Campbell in Canberra's inner northeast.
ADFA teaches military undergraduates and postgraduates and is officially a campus of the University of New South Wales while Duntroon provides Australian Army Officer training.
The Academy of Interactive Entertainment (AIE) offers courses in computer game development and 3D animation.
The Australian Capital Territory is home to a number of major professional sports league franchise teams including the Canberra Raiders (rugby league), the Brumbies (rugby union), and the Canberra Capitals (basketball).
The Greater Western Sydney Giants (Australian rules football) play three regular season matches a year and one pre-season match in Canberra at Manuka Oval.
The Prime Minister's XI (cricket), started by Robert Menzies in the 1950 s and revived by Bob Hawke in 1984, has been played every year at Manuka Oval against an overseas touring team.
The territory is home to many national monuments and institutions such as the Australian War Memorial, the National Gallery of Australia, the National Portrait Gallery, the National Library, the National Archives, the Australian Academy of Science, the National Film and Sound Archive and the National Museum.
Many Commonwealth government buildings in Canberra are open to the public, including Parliament House, the High Court and the Royal Australian Mint.
Lake Burley Griffin is the site of the Captain James Cook Memorial and the National Carillon.
Other sites of interest include the Telstra Tower, the Australian National Botanic Gardens, the National Zoo and Aquarium, the National Dinosaur Museum and Questacon – the National Science and Technology Centre.
The Canberra Museum and Gallery in the city is a repository of local history and art, housing a permanent collection and visiting exhibitions.
Several historic homes are open to the public: Lanyon and Tuggeranong Homesteads in the Tuggeranong Valley, Mugga-Mugga in Symonston, and Blundells' Cottage in Parkes all display the lifestyle of the early European settlers.
Calthorpes' House in Red Hill is a well-preserved example of a 1920 s house from Canberra's very early days.
Canberra has many venues for live music and theatre: the Canberra Theatre and Playhouse which hosts many major concerts and productions; and Llewellyn Hall (within the ANU School of Music), a world-class concert hall are two of the most notable.
The Albert Hall was Canberra's first performing arts venue, opened in 1928.
It was the original performance venue for theatre groups such as the Canberra Repertory Society.
There are numerous bars and nightclubs which also offer live entertainment, particularly concentrated in the areas of Dickson, Kingston and the city.
Most town centres have facilities for a community theatre and a cinema, and they all have a library.
Popular cultural events include the National Folk Festival, the Royal Canberra Show, the Summernats car festival, Enlighten festival and the National Multicultural Festival in February.
Canberra and the territory have a daily newspaper, "The Canberra Times", which was established in 1926.
There are also several free weekly publications, including news magazines "CityNews" and "Canberra Weekly."
There are a number of AM and FM stations broadcasting throughout the ACT (AM/FM Listing).
The main commercial operators are the Capital Radio Network (2CA and 2CC), and Austereo/ARN (104.7 and Mix 106.3).
There are also several community operated stations as well as the local and national stations of the Australian Broadcasting Corporation.
A DAB + digital radio trial is also in operation, it simulcasts some of the AM/FM stations, and also provides several digital only stations (DAB + Trial Listing).
Five free-to-air television stations service the territory: Each station broadcasts a primary channel and several multichannels.
Pay television services are available from Foxtel (via satellite) and telecommunications company TransACT (via cable).
The Australian Capital Territory has two large public hospitals both located in Canberra: the approximately 600-bed Canberra Hospital in Garran and the 174-bed Calvary Public Hospital in Bruce.
Both are teaching institutions.
The largest private hospital is the Calvary John James Hospital in Deakin.
Calvary Private Hospital in Bruce and Healthscope's National Capital Private Hospital in Garran are also major healthcare providers.
Canberra has 10 aged care facilities.
Canberra's hospitals receive emergency cases from throughout southern New South Wales, and ACT Ambulance Service is one of four operational agencies of the ACT Emergency Services Authority.
NETS provides a dedicated ambulance service for inter-hospital transport of sick newborns within the ACT and into surrounding New South Wales.
The automobile is by far the dominant form of transport in Canberra and the territory.
The city is laid out so that arterial roads connecting inhabited clusters run through undeveloped areas of open land or forest, which results in a low population density; this also means that idle land is available for the development of future transport corridors if necessary without the need to build tunnels or acquire developed residential land.
In contrast, other capital cities in Australia have substantially less green space.
Canberra's districts are generally connected by parkways—limited access dual carriageway roads with speed limits generally set at a maximum of.
An example is the Tuggeranong Parkway which links Canberra's CBD and Tuggeranong, and bypasses Weston Creek.
In most districts, discrete residential suburbs are bounded by main arterial roads with only a few residential linking in, to deter non-local traffic from cutting through areas of housing.
ACTION, the government-operated bus service, provides public transport throughout Canberra.
Qcity Transit provides bus services between Canberra and nearby areas of New South Wales through their Transborder Express brand (Murrumbateman and Yass) and as Qcity Transit (Queanbeyan).
A light rail line that opened in April 2019 links the CBD with the northern district of Gungahlin.
At the 2016 census, 7.1 % of the journeys to work involved public transport while 4.5 % were on foot.
There are two local taxi companies.
Aerial Capital Group enjoyed monopoly status until the arrival of Cabxpress in 2007.
In October 2015, the ACT Government passed legislation to regulate ride sharing, allowing ride share services including Uber to operate legally in Canberra.
The ACT Government was the first jurisdiction in Australia to enact legislation to regulate the service.
An interstate NSW TrainLink railway service connects Canberra to Sydney.
Canberra's railway station is in the inner south suburb of Kingston.
Train services to Melbourne are provided by way of a NSW TrainLink bus service which connects with a rail service between Sydney and Melbourne in Yass, about a one-hour drive from Canberra.
Canberra is about three hours by road from Sydney on the Federal Highway (National Highway 23), which connects with the Hume Highway (National Highway 31) near Goulburn, and seven hours by road from Melbourne on the Barton Highway (National Highway 25), which joins the Hume Highway at Yass.
It is a two-hour drive on the Monaro Highway (National Highway 23) to the ski fields of the Snowy Mountains and the Kosciuszko National Park.
Batemans Bay, a popular holiday spot on the New South Wales coast, is also two hours away via the Kings Highway.
Canberra Airport provides direct domestic services to Sydney, Melbourne, Brisbane, Adelaide, Gold Coast and Perth, with connections to other domestic centres.
There are also direct flights to small regional towns: Dubbo and Newcastle in New South Wales.
Regular commercial international flights operate to Singapore and Wellington from the airport four times a week.
Canberra Airport is, as of September 2013, designated by the Australian Government Department of Infrastructure and Regional Development as a restricted use designated international airport.
Until 2003, the civilian airport shared runways with RAAF Base Fairbairn.
In June of that year, the Air Force base was decommissioned and from that time the airport was fully under civilian control.
The government-owned ACTEW Corporation manages the territory's water and sewerage infrastructure.
ActewAGL is a joint venture between ACTEW and AGL, and is the retail provider of Canberra's utility services including water, natural gas, electricity, and also some telecommunications services via a subsidiary TransACT.
Canberra's water is stored in four reservoirs, the Corin, Bendora and Cotter dams on the Cotter River and the Googong Dam on the Queanbeyan River.
Although the Googong Dam is located in New South Wales, it is managed by the ACT government.
ACTEW Corporation owns Canberra's two wastewater treatment plants, located at Fyshwick and on the lower reaches of the Molonglo River.
Electricity for Canberra mainly comes from the national power grid through substations at Holt and Fyshwick (via Queanbeyan).
Power was first supplied from a thermal plant built in 1913, near the Molonglo River, but this was finally closed in 1957.
The ACT has four solar farms, which were opened between 2014 and 2017: Royalla (rated output of 20 megawatts, 2014), Mount Majura (2.3 MW, 2016), Mugga Lane (13 MW, 2017) and Williamsdale (11 MW, 2017).
In addition numerous houses in Canberra have photovoltaic panels and/or solar hot water systems.
In 2015/16, rooftop solar systems supported by the ACT government's feed-in tariff had a capacity of 26.3 megawatts, producing 34,910 MWh.
In the same year, retailer-supported schemes had a capacity of 25.2 megawatts and exported 28,815 MWh to the grid (power consumed locally was not recorded).
The ACT has the highest rate with internet access at home (94 per cent of households in 2014 – 15).
The economic activity of the Australian Capital Territory is heavily concentrated around the city of Canberra.
A stable housing market, steady employment and rapid population growth in the 21st century have led to economic prosperity and, in 2011, CommSec ranked the ACT as the second best performing economic region in the country.
This trend continued into 2016, when the territory was ranked the third best performing out of all of Australia's states and territories.
In 2017 - 18, the ACT had the fastest rate of growth in the nation due to a rapid growth in population, a strongly performing higher education sector as well as a significant housing and infrastructure investment.
Higher education is the territory's largest export industry.
Canberra is home to a significant number of universities and higher education providers.
The other major services exports of the ACT in 2017 - 18 were government services and personal travel.
The major goods exports of the territory in 2017 - 18 were gold coin, legal tender coin, metal structures and fish, though these represent a small proportion of the economy compared to services exports.
The economy of the ACT is largely dependent on the public sector with 30 % of the jobs in the territory being in the public sector.
Decisions by the federal government regarding the public service can have a significant impact on the territory's economy.
The ACT's gross state product in 2017 - 18 was $ 39,792,000,000 and the territory's economy represented 2.2 % of the overall gross domestic product of Australia.
In 2017 - 18 the ACT economy grew by 4.0 per cent, the highest growth rate of any jurisdiction in Australia.
This brought real economic growth over the three years to June 2018 to 12 per cent.
Units of alcohol are used in the United Kingdom (UK) as a measure to quantify the actual alcoholic content within a given volume of an alcoholic beverage, in order to provide guidance on total alcohol consumption.
A number of other countries (including Australia, Canada, New Zealand, and the US) use the concept of a "standard drink", the definition of which varies from country to country, for the same purpose.
"Standard drinks" were referred to in the first UK guidelines (1984) that published "safe limits" for drinking, but these were replaced by references to "alcohol units" in the 1987 guidelines and the latter term has been used in all subsequent UK guidance.
One unit of alcohol (UK) is defined as 10 millilitres (8 grams) of pure alcohol.
Typical drinks (i.e., typical quantities or servings of common alcoholic beverages) may contain 1 – 3 units of alcohol.
Containers of alcoholic beverages sold directly to UK consumers are normally labelled to indicate the number of units of alcohol in a typical serving of the beverage (optional) and in the full container (can or bottle), as well as information about responsible drinking.
As an approximate guideline, a typical healthy adult can metabolise (break down) about one unit of alcohol per hour, although this may vary depending on sex, age, weight, health and many other factors.
The number of UK units of alcohol in a drink can be determined by multiplying the volume of the drink (in millilitres) by its percentage ABV, and dividing by 1000.
For example, one imperial pint (568 ml) of beer at 4 % alcohol by volume (ABV) contains: The formula uses.
This results in exactly one unit per percentage point per litre, of any alcoholic beverage.
The formula can be simplified for everyday use by expressing the serving size in centilitres and the alcohol content literally as a percentage: Thus, a 750 ml bottle of wine at 12 % ABV contains 75 cl × 12 % = 9 units.
Alternatively, the serving size in litres multiplied by the alcohol content as a number, the above example giving 0.75 × 12 = 9 units: Both pieces of input data are usually mentioned in this form on the bottle, so is easy to retrieve.
UK alcohol companies pledged in March 2011 to implement an innovative health labelling scheme to provide more information about responsible drinking on alcohol labels and containers.
This voluntary scheme is the first of its kind in Europe and has been developed in conjunction with the UK Department of Health.
The pledge stated: At the end of 2014, 101 companies had committed to the pledge labelling scheme.
There are five elements included within the overall labelling scheme, the first three being mandatory, and the last two optional: Drinks companies had pledged to display the three mandatory items on 80 % of drinks containers on shelves in the UK off-trade by the end of December 2013.
A report published in Nov 2014, confirmed that UK drinks producers had delivered on that pledge with a 79.3 % compliance with the pledge elements as measured by products on shelf.
Compared with labels from 2008 on a like-for-like basis, information on Unit alcohol content had increased by 46 %; 91 % of products displayed alcohol and pregnancy warnings (18 % in 2008); and 75 % showed the Chief Medical Officers ’ lower risk daily guidelines (6 % in 2008).
It is sometimes misleadingly stated that there is one unit per half-pint of beer, or small glass of wine, or single measure of spirits.
However, such statements do not take into account the various strengths and volumes supplied in practice.
For example, the ABV of beer typically varies from 3.5 % to 5.5 %.
A typical "medium" glass of wine with 175 ml at 12 % ABV has 2.1 units.
And spirits, although typically 35 – 40 % ABV, have single measures of 25 ml or 35 ml (so 1 or 1.4 units) depending on location.
The misleading nature of "one unit per half-pint of beer, or small glass of wine, or single measure of spirits" can lead to people underestimating their alcohol intake.
Most spirits sold in the United Kingdom have 40 % ABV or slightly less.
In England, a single pub measure (25 ml) of a spirit contains one unit.
However, a larger 35 ml measure is increasingly used (and in particular is standard in Northern Ireland), which contains 1.4 units of alcohol at 40 % ABV.
Sellers of spirits by the glass must state the capacity of their standard measure in ml.
On average, it takes about one hour for the body to metabolise (break down) one unit of alcohol.
However, this will vary with body weight, sex, age, personal metabolic rate, recent food intake, the type and strength of the alcohol, and medications taken.
Alcohol may be metabolised more slowly if liver function is impaired.
From 1992 to 1995, the UK government advised that men should drink no more than 21 units per week, and women no more than 14.
(The difference between the sexes was due to the typically lower weight and water-to-body-mass ratio of women).
"The Times" reported in October 2007 that these limits had been "plucked out of the air" and had no scientific basis.
This was changed after a government study showed that many people were in effect "saving up" their units and using them at the end of the week, a phenomenon referred to as binge drinking.
Since 1995 the advice was that regular consumption of 3 – 4 units a day for men, or 2 – 3 units a day for women, would not pose significant health risks, but that consistently drinking four or more units a day (men), or three or more units a day (women), is not advisable.
An international study of about 6,000 men and 11,000 women for a total of 75,000 person-years found that people who reported that they drank more than a threshold value of 2 units of alcohol a day had a higher risk of fractures than non-drinkers.
For example, those who drank over 3 units a day had nearly twice the risk of a hip fracture.
Aotus (the name is derived from the Ancient Greek words for "earless" in both cases: the monkey is missing external ears, and the pea is missing earlike bracteoles) may refer to:
Ally McBeal is an American legal comedy-drama television series, originally aired on Fox from September 8, 1997, to May 20, 2002.
Created by David E. Kelley, the series stars Calista Flockhart in the title role as a lawyer working in the fictional Boston law firm Cage and Fish, with other lawyers whose lives and loves were eccentric, humorous, and dramatic.
The series received critical acclaim in its early seasons, winning the Golden Globe Award for Best Television Series – Musical or Comedy in 1997 and 1998, and also winning the Emmy Award for Outstanding Comedy Series in 1999.
The series, set in the fictional Boston law firm Cage and Fish, begins with main character Allison Marie "Ally" McBeal joining the firm co-owned by her law school classmate Richard Fish (Greg Germann) after leaving her previous job due to sexual harassment.
On her first day, Ally is horrified to find that she will be working alongside her ex-boyfriend Billy Thomas (Gil Bellows) — whom she has never gotten over.
To make things worse, Billy is now married to fellow lawyer Georgia (Courtney Thorne-Smith), who later joins Cage and Fish.
The triangle among the three forms the basis for the main plot for the show's first three seasons.
Although ostensibly a legal drama, the main focus of the series was the romantic and personal lives of the main characters, often using legal proceedings as plot devices to contrast or reinforce a character's drama.
For example, bitter divorce litigation of a client might provide a backdrop for Ally's decision to break up with a boyfriend.
Legal arguments were also frequently used to explore multiple sides of various social issues.
Cage and Fish (which becomes Cage/Fish & McBeal or Cage, Fish, & Associates towards the end of the series), the fictional law firm where most of the characters work, is depicted as a highly sexualized environment symbolized by its unisex restroom.
Lawyers and secretaries in the firm routinely date, flirt with, or have a romantic history with each other and frequently run into former or potential romantic interests in the courtroom or on the street outside.
The series had many offbeat and frequently surreal running gags and themes, such as Ally's tendency to immediately fall over whenever she met somebody she found attractive, Richard Fish's wattle fetish and humorous mottos ("Fishisms" & "Bygones"), John's gymnastic dismounts out of the office's unisex bathroom stalls, or the dancing twins (played by Eric & Steve Cohen) at the bar, that ran through the series.
The show also used vivid, dramatic fantasy sequences for Ally's and other characters' wishful thinking; of particular note is the early internet sensation the dancing baby.
The series also featured regular visits to a local bar where singer Vonda Shepard regularly performed (though occasionally handing over the microphone to the characters).
Star contemporary singers also performed in the bar at the end of the shows, including acts such as Barry White and Anastacia.
The series also took place in the same continuity as David E. Kelley's legal drama "The Practice" (which aired on ABC), as the two shows crossed over with one another on occasion, a very rare occurrence for two shows that aired on different networks.
Ultimately, in the last installment of the fifth and final season, "Bygones", Ally decided to resign from Cage & Fish, leave Boston, and return to New York City.
Fox canceled "Ally McBeal" after five seasons.
In addition to being the lowest-rated season of "Ally McBeal" and the grounds for the show's cancelation, the fifth season was also the only season of the show that failed to win any Emmy or Golden Globe awards.
1 2 3 4 5 In Australia, "Ally McBeal" was aired by the Seven Network from 1997 to 2002.
In 2010, it was aired repeatedly by Network 10.
Seymore Walsh, a stern judge often exasperated by the eccentricities of the Cage & Fish lawyers and played by actor Albert Hall, was also a recurring character on "The Practice".
In addition, Judge Jennifer (Whipper) Cone appears on "The Practice" episode "Line of Duty" (S02 E15), while Judge Roberta Kittelson, a recurring character on "The Practice", has a featured guest role in the "Ally McBeal" episode "Do you Wanna Dance?"
Most of the primary "Practice" cast members guest starred in the "Ally McBeal" episode "The Inmates" (S01 E20), in a storyline that concluded with the "Practice" episode "Axe Murderer" (S02 E26), featuring Calista Flockhart and Gil Bellows reprising their "Ally" characters.
What is unusual about this continuing storyline is that "Ally McBeal" and "The Practice" aired on different networks.
Bobby Donnell, the main character of "The Practice" played by Dylan McDermott, was featured heavily in both this crossover and another "Ally McBeal" episode, "These are the Days".
Regular "Practice" cast members Lara Flynn Boyle and Michael Badalucco each had a cameo in "Ally McBeal" (Boyle as a woman who trades insults with Ally in the episode "Making Spirits Bright" and Badalucco as one of Ally's dates in the episode "I Know him by Heart") but it is unclear whether they were playing the same characters they play on "The Practice".
Upon premiering in 1997, the show was an instant hit, averaging around 11 million viewers per episode.
The show's second season saw an increase in ratings and soon became a top 20 show, averaging around 13 million viewers per episode.
The show's ratings began to decline in the third season, but stabilized in the fourth season after Robert Downey Jr. joined the regular cast as Ally's boyfriend Larry Paul, and a fresher aesthetic was created by new art director Matthew DeCoste.
However, Downey's character was written out after the end of the season due to the actor's troubles with drug addiction.
The first two seasons, as well as the fourth, remain the most critically acclaimed and saw the most awards success at the Emmys, SAG Awards and the Golden Globes.
In 2007, "Ally McBeal" placed # 48 on "Entertainment Weekly" 2007 "New TV Classics" list.
"Ally McBeal" received some criticism from TV critics and feminists who found the title character annoying and demeaning to women (specifically regarding professional women) because of her perceived flightiness, lack of demonstrated legal knowledge, short skirts, and emotional instability.
Perhaps the most notorious example of the debate sparked by the show was the June 29, 1998, cover story of "Time" magazine, which juxtaposed McBeal with three pioneering feminists (Susan B. Anthony, Betty Friedan, Gloria Steinem) and asked "Is Feminism Dead?"
In episode 12 of the second season of the show, Ally talks to her co-worker John Cage about a dream she had, saying "You know, I had a dream that they put my face on the cover of" Time "magazine as' the face of feminism '."
"Ally McBeal" was a heavily music-oriented show.
Vonda Shepard, a virtually unknown musician at the time, was featured continually on the show.
Her song "Searchin ' My Soul" became the show's theme song.
Many of the songs Shepard performed were established hits with lyrics that paralleled the events of the episode, including "Both Sides Now", "Hooked on a Feeling" and "Tell Him".
Besides recording background music for the show, Shepard frequently appeared at the ends of episodes as a musician performing at a local piano bar frequented by the main characters.
On rare occasions, her character would have conventional dialogue.
A portion of "Searchin ' My Soul" was played at the beginning of each episode, but the song was never played in its entirety.
Several of the characters had a musical leitmotif that played when they appeared.
John Cage's was "You're the First, the Last, My Everything", Ling Woo's was the Wicked Witch of the West theme from "The Wizard of Oz", and Ally McBeal herself picked "Tell Him", when told by a psychiatrist that she needed a theme.
Due to the popularity of the show and Shepard's music, a soundtrack titled "Songs from Ally McBeal" was released in 1998, as well as a successor soundtrack titled "" in 1999.
Two compilation albums from the show featuring Shepard were also released in 2000 and 2001.
A Christmas album was also released under the title "Ally McBeal: A Very Ally Christmas".
The album received positive reviews, and Shephard's version of Kay Starr's Christmas song "(Everybody's Waitin ' For) The Man with the Bag", received considerable airplay during the holiday season.
Other artists featured on the show include Michael Jackson, Barry White, Al Green, Tina Turner, Macy Gray, Gloria Gaynor, Chayanne, Barry Manilow, Anastacia, Elton John, Sting and Mariah Carey.
Josh Groban played the role of Malcolm Wyatt in the May 2001 season finale, performing "You're Still You".
The series creator, David E. Kelley, was impressed with Groban's performance at The Family Celebration event and based on the audience reaction to Groban's singing, Kelley created a character for him in that finale.
The background score for the show was composed by Danny Lux.
Due to music licensing issues, none of the seasons of "Ally McBeal" were available on DVD in the United States (only 6 random episodes could be found on the R1 edition) until 2009, though the show had been available in Italy, Belgium, the Netherlands, Japan, Hong Kong, Portugal, Spain, France, Germany, the United Kingdom, Mexico, Taiwan, Australia, Brazil, and the Czech Republic with all the show's music intact since 2005.
In the UK, Ireland, and Spain all seasons are available in a complete box set.
20th Century Fox released the complete first season on DVD in Region 1 on October 6, 2009.
They also released a special complete series edition on the same day.
Season 1 does not contain any special features, but the complete series set contains several bonus features, including featurettes, an all-new retrospective, the episode of "The Practice" in which Calista Flockhart guest-starred, and a bonus disc entitled "The Best of Ally McBeal Soundtrack."
In addition, both releases contain all of the original music.
Season 2 was released on April 6, 2010.
Seasons 3, 4, and 5 were all released on October 5, 2010.
In 1999, at the height of the show's popularity, a half-hour version entitled "Ally" began airing in parallel with the main program.
This version, designed in a sitcom format, used re-edited scenes from the main program, along with previously unseen footage.
The intention was to further develop the plots in the comedy-drama in a sitcom style.
It also focused only on Ally's personal life, cutting all the courtroom plots.
The repackaged show was cancelled partway through its initial run.
While 13 episodes of "Ally" were produced, only ten aired.
McBeal and 1990 s young affluent professional women were parodied in the song "Ally McBeal" (tune of "Like a Rolling Stone" by Bob Dylan) by a cappella group Da Vinci's Notebook on their album "The Life and Times of Mike Fanning", released in 2000.
In episode 2, season 3 of the British comedy "The Adam and Joe Show", the show was parodied as "Ally McSqueal" using soft toys.
Episode 2, season 2 of the show "Futurama", "When Aliens Attack", centers on an invasion of Earth by the Omicronians precipitated by a signal loss during the climax of an episode of "Single Female Lawyer", whose main character is Jenny McNeal.
Andreas Capellanus ("Capellanus" meaning "chaplain"), also known as Andrew the Chaplain, and occasionally by a French translation of his name, André le Chapelain, was the 12th - century author of a treatise commonly known as "De amore" ("About Love"), and often known in English, somewhat misleadingly, as "The Art of Courtly Love", though its realistic, somewhat cynical tone suggests that it is in some measure an antidote to courtly love.
Little is known of Andreas Capellanus's life, but he is presumed to have been a courtier of Marie de Champagne, and probably of French origin.
"De Amore" was written at the request of Marie de Champagne, daughter of King Louis VII of France and of Eleanor of Aquitaine.
In it, the author informs a young pupil, Walter, of the pitfalls of love.
A dismissive allusion in the text to the "wealth of Hungary" has suggested the hypothesis that it was written after 1184, at the time when Bela III of Hungary had sent to the French court a statement of his income and had proposed marriage to Marie's half-sister Marguerite of France, but before 1186, when his proposal was accepted.
"De Amore" is made up of three books.
The first book covers the etymology and definition of love and is written in the manner of an academic lecture.
The second book consists of sample dialogues between members of different social classes; it outlines how the romantic process between the classes should work.
This second work is largely considered to be a bit not good.
Book three is made of stories from actual courts of love presided over by noble women.
John Jay Parry, the editor of one modern edition of "De Amore", quotes critic Robert Bossuat as describing "De Amore" as "one of those capital works which reflect the thought of a great epoch, which explains the secret of a civilization".
It may be viewed as didactic, mocking, or merely descriptive; in any event it preserves the attitudes and practices that were the foundation of a long and significant tradition in Western literature.
The social system of "courtly love", as gradually elaborated by the Provençal troubadours from the mid twelfth century, soon spread.
One of the circles in which this poetry and its ethic were cultivated was the court of Eleanor of Aquitaine (herself the granddaughter of an early troubadour poet, William IX of Aquitaine).
It has been claimed that "De Amore" codifies the social and sexual life of Eleanor's court at Poitiers between 1170 and 1174, though it was evidently written at least ten years later and, apparently, at Troyes.
It deals with several specific themes that were the subject of poetical debate among late twelfth century troubadours and trobairitz.
The meaning of "De Amore" has been debated over the centuries.
In the years immediately following its release many people took Andreas ’ opinions concerning Courtly Love seriously.
In more recent times, however, scholars have come to view the priest's work as satirical.
Many scholars now agree that Andreas was commenting on the materialistic, superficial nature of the nobles of the Middle Ages.
Andreas seems to have been warning young Walter, his protege, about love in the Middle Ages.
The American Civil Liberties Union (ACLU) is a nonprofit organization whose stated mission is "to defend and preserve the individual rights and liberties guaranteed to every person in this country by the Constitution and laws of the United States".
Officially nonpartisan, the organization has been supported and criticized by liberal and conservative organizations alike.
The ACLU works through litigation and lobbying and it has over 1,200,000 members and an annual budget of over $ 100 million.
Local affiliates of the ACLU are active in all 50 states, the District of Columbia, and Puerto Rico.
The ACLU provides legal assistance in cases when it considers civil liberties to be at risk.
Legal support from the ACLU can take the form of direct legal representation or preparation of "amicus curiae" briefs expressing legal arguments when another law firm is already providing representation.
In addition to representing persons and organizations in lawsuits, the ACLU lobbies for policy positions that have been established by its board of directors.
Current positions of the ACLU include: opposing the death penalty; supporting same-sex marriage and the right of LGBT people to adopt; supporting birth control and abortion rights; eliminating discrimination against women, minorities, and LGBT people; supporting the rights of prisoners and opposing torture; and opposing government preference for religion over non-religion, or for particular faiths over others.
Legally, the ACLU consists of two separate but closely affiliated nonprofit organizations: the American Civil Liberties Union, a 501 (c) (4) social welfare group, and the ACLU Foundation, a 501 (c) (3) public charity.
Both organizations engage in civil rights litigation, advocacy, and education, but only donations to the 501 (c) (3) foundation are tax deductible, and only the 501 (c) (4) group can engage in unlimited political lobbying.
The two organizations share office space and employees.
The ACLU was founded in 1920 by a committee including Helen Keller, Roger Baldwin, Crystal Eastman, Walter Nelles, Morris Ernst, Albert DeSilver, Arthur Garfield Hays, Jane Addams, Felix Frankfurter, Elizabeth Gurley Flynn, and Rose Schneiderman.
Its focus was on freedom of speech, primarily for anti-war protesters.
During the 1920 s, the ACLU expanded its scope to include protecting the free speech rights of artists and striking workers, and working with the National Association for the Advancement of Colored People (NAACP) to decrease racism and discrimination.
During the 1930 s, the ACLU started to engage in work combating police misconduct and supporting Native American rights.
Many of the ACLU's cases involved the defense of Communist Party members and Jehovah's Witnesses.
In 1940, the ACLU leadership voted to exclude communists from its leadership positions, a decision rescinded in 1968.
During World War II, the ACLU defended Japanese-American citizens, unsuccessfully trying to prevent their forcible relocation to internment camps.
During the Cold War, the ACLU headquarters was dominated by anti-communists, but many local affiliates defended members of the Communist Party.
By 1964, membership had risen to 80,000, and the ACLU participated in efforts to expand civil liberties.
In the 1960 s, the ACLU continued its decades-long effort to enforce separation of church and state.
It defended several anti-war activists during the Vietnam War.
The ACLU was involved in the "Miranda" case, which addressed conduct by police during interrogations, and in the "New York Times" case, which established new protections for newspapers reporting on government activities.
In the 1970 s and 1980 s, the ACLU ventured into new legal areas, involving the rights of homosexuals, students, prisoners, and the poor.
In the twenty-first century, the ACLU has fought the teaching of creationism in public schools and challenged some provisions of anti-terrorism legislation as infringing on privacy and civil liberties.
Fundraising and membership spiked after the 2016 election; the ACLU's current membership is more than 1.2 million.
The ACLU is led by a president and an executive director, Susan N. Herman and Anthony Romero, respectively, in 2015.
The president acts as chair of the ACLU's board of directors, leads fundraising, and facilitates policy-setting.
The executive director manages the day-to-day operations of the organization.
The board of directors consists of 80 persons, including representatives from each state affiliate, as well as at-large delegates.
The organization has its headquarters in 125 Broad Street, a 40-story skyscraper located in Lower Manhattan, New York City.
The leadership of the ACLU does not always agree on policy decisions; differences of opinion within the ACLU leadership have sometimes grown into major debates.
In 1937, an internal debate erupted over whether to defend Henry Ford's right to distribute anti-union literature.
In 1939, a heated debate took place over whether to prohibit communists from serving in ACLU leadership roles.
During the early 1950 s and Cold War McCarthyism, the board was divided on whether to defend communists.
In 1968, a schism formed over whether to represent Benjamin Spock's anti-war activism.
In 1973, as the Watergate Scandal continued to unfold, leadership was initially divided over whether to call for President Nixon's impeachment and removal from office.
In 2005, there was internal conflict about whether or not a gag rule should be imposed on ACLU employees to prevent publication of internal disputes.
In the year ending March 31, 2014, the ACLU and the ACLU Foundation had a combined income from support and revenue of $ 100.4 million, originating from grants (50.0 %), membership donations (25.4 %), donated legal services (7.6 %), bequests (16.2 %), and revenue (0.9 %).
Membership dues are treated as donations; members choose the amount they pay annually, averaging approximately $ 50 per member per year.
In the year ending March 31, 2014, the combined expenses of the ACLU and ACLU Foundation were $ 133.4 million, spent on programs (86.2 %), management (7.4 %), and fundraising (8.2 %).
(After factoring in other changes in net assets of + $ 30.9 million, from sources such as investment income, the organization had an overall decrease in net assets of $ 2.1 million.)
Over the period from 2011 to 2014 the ACLU Foundation, on the average, has accounted for roughly 70 % of the combined budget, and the ACLU roughly 30 %.
The ACLU solicits donations to its charitable foundation.
The ACLU is accredited by the Better Business Bureau, and the Charity Navigator has ranked the ACLU with a four-star rating.
The local affiliates solicit their own funding; however, some also receive funds from the national ACLU, with the distribution and amount of such assistance varying from state to state.
At its discretion, the national organization provides subsidies to smaller affiliates that lack sufficient resources to be self-sustaining; for example, the Wyoming ACLU chapter received such subsidies until April 2015, when, as part of a round of layoffs at the national ACLU, the Wyoming office was closed.
In October 2004, the ACLU rejected $ 1.5 million from both the Ford Foundation and Rockefeller Foundation because the foundations had adopted language from the USA PATRIOT Act in their donation agreements, including a clause stipulating that none of the money would go to "underwriting terrorism or other unacceptable activities."
The ACLU views this clause, both in federal law and in the donors' agreements, as a threat to civil liberties, saying it is overly broad and ambiguous.
Due to the nature of its legal work, the ACLU is often involved in litigation against governmental bodies, which are generally protected from adverse monetary judgments; a town, state or federal agency may be required to change its laws or behave differently, but not to pay monetary damages except by an explicit statutory waiver.
In some cases, the law permits plaintiffs who successfully sue government agencies to collect money damages or other monetary relief.
In particular, the Civil Rights Attorney's Fees Award Act of 1976 leaves the government liable in some civil rights cases.
Fee awards under this civil rights statute are considered "equitable relief" rather than damages, and government entities are not immune from equitable relief.
Under laws such as this, the ACLU and its state affiliates sometimes share in monetary judgments against government agencies.
In 2006, the Public Expressions of Religion Protection Act sought to prevent monetary judgments in the particular case of violations of church-state separation.
The ACLU has received court awarded fees from opponents, for example, the Georgia affiliate was awarded $ 150,000 in fees after suing a county demanding the removal of a Ten Commandments display from its courthouse; a second Ten Commandments case in the state, in a different county, led to a $ 74,462 judgment.
The State of Tennessee was required to pay $ 50,000, the State of Alabama $ 175,000, and the State of Kentucky $ 121,500, in similar Ten Commandments cases.
Most of the organization's workload is performed by its local affiliates.
There is at least one affiliate organization in each state, as well as one in Washington, D.C., and in Puerto Rico.
California has three affiliates.
The affiliates operate autonomously from the national organization; each affiliate has its own staff, executive director, board of directors, and budget.
Each affiliate consists of two non-profit corporations: a 501 (c) (3) corporation that does not perform lobbying, and a 501 (c) (4) corporation which is entitled to lobby.
ACLU affiliates are the basic unit of the ACLU's organization and engage in litigation, lobbying, and public education.
For example, in a twenty-month period beginning January 2004, the ACLU's New Jersey chapter was involved in fifty-one cases according to their annual report—thirty-five cases in state courts, and sixteen in federal court.
They provided legal representation in thirty-three of those cases, and served as amicus in the remaining eighteen.
They listed forty-four volunteer attorneys who assisted them in those cases.
Alabama Alaska Arizona Arkansas California ACLU of Northern CaliforniaACLU of Southern CaliforniaACLU of San Diego & Imperial Counties Colorado Connecticut Delaware District of Columbia Florida ACLU of Florida Georgia Hawaii ACLU of Hawaii Idaho Illinois Indiana Iowa Kansas Kentucky Louisiana Maine American Civil Liberties Union of Maine Maryland Massachusetts ACLU of Massachusetts Michigan Minnesota Mississippi Missouri ACLU of Missouri Montana Nebraska Nevada New Hampshire New Jersey American Civil Liberties Union of New Jersey New Mexico New York New York Civil Liberties Union North Carolina North Dakota Ohio Oklahoma Oregon Pennsylvania ACLU of Pennsylvania Puerto Rico ACLU of Puerto Rico National Chapter Rhode Island South Carolina South Dakota Tennessee Texas Utah Vermont Virginia Washington West Virginia Wisconsin Wyoming ACLU of Wyoming The ACLU's official position statements,, included the following policies: The ACLU is supported by a variety of persons and organizations.
There were over 1,000,000 members in 2017, and the ACLU annually receives thousands of grants from hundreds of charitable foundations.
Allies of the ACLU in legal actions have included the National Association for the Advancement of Colored People, the American Jewish Congress, People For the American Way, the National Rifle Association, the Electronic Frontier Foundation, Americans United for Separation of Church and State, and the National Organization for Women.
The ACLU has been criticized by liberals, such as when it excluded communists from its leadership ranks, when it defended Neo-Nazis, when it declined to defend Paul Robeson, or when it opposed the passage of the National Labor Relations Act.
Conversely, it has been criticized by conservatives, such as when it argued against official prayer in public schools, or when it opposed the Patriot Act.
The ACLU has supported conservative figures such as Rush Limbaugh, George Wallace, Henry Ford, and Oliver North; and it has supported liberal figures such as Dick Gregory, Rockwell Kent, and Benjamin Spock.
A major source of criticism are legal cases in which the ACLU represents an individual or organization that promotes offensive or unpopular viewpoints, such as the Ku Klux Klan, Neo-Nazis, Nation of Islam, North American Man/Boy Love Association, Westboro Baptist Church or Unite the Right rally.
The ACLU developed from the National Civil Liberties Bureau (CLB), co-founded in 1917 during World War I by Crystal Eastman, an attorney activist, and Roger Nash Baldwin.
The focus of the CLB was on freedom of speech, primarily anti-war speech, and on supporting conscientious objectors who did not want to serve in World War I. Three United States Supreme Court decisions in 1919 each upheld convictions under laws against certain kinds of anti-war speech.
In 1919, the Court upheld the conviction of Socialist Party leader Charles Schenck for publishing anti-war literature.
In 1918, Crystal Eastman resigned from the organization due to health issues.
After assuming sole leadership of the CLB, Baldwin insisted that the organization be reorganized.
He wanted to change its focus from litigation to direct action and public education.
The CLB directors concurred, and on January 19, 1920, they formed an organization under a new name, the American Civil Liberties Union.
Although a handful of other organizations in the United States at that time focused on civil rights, such as the National Association for the Advancement of Colored People (NAACP) and Anti-Defamation League (ADL), the ACLU was the first that did not represent a particular group of persons, or a single theme.
Like the CLB, the NAACP pursued litigation to work on civil rights, including efforts to overturn the disfranchisement of African Americans in the South that had taken place since the turn of the century.
During the first decades of the ACLU, Baldwin continued as its leader.
His charisma and energy attracted many supporters to the ACLU board and leadership ranks.
Baldwin was ascetic, wearing hand-me-down clothes, pinching pennies, and living on a very small salary.
The ACLU was directed by an executive committee, and it was not particularly democratic or egalitarian.
The ACLU's base in New York resulted in its being dominated by people from the city and state.
Most ACLU funding came from philanthropies, such as the Garland Fund.
In the 1920 s, government censorship was commonplace.
Magazines were routinely confiscated under the anti-obscenity Comstock laws; permits for labor rallies were often denied; and virtually all anti-war or anti-government literature was outlawed.
Right-wing conservatives wielded vast amounts of power, and activists that promoted unionization, socialism, or government reform were often denounced as un-American or unpatriotic.
In one typical instance in 1923, author Upton Sinclair was arrested for trying to read the First Amendment during an Industrial Workers of the World rally.
ACLU leadership was divided on how to challenge the civil rights violations.
One faction, including Baldwin, Arthur Garfield Hays and Norman Thomas, believed that direct, militant action was the best path. Hays was the first of many successful attorneys that relinquished their private practices to work for the ACLU.
Another group, including Walter Nelles and Walter Pollak felt that lawsuits taken to the Supreme Court were the best way to achieve change.
Both groups worked in tandem, but equally revered the Bill of Rights and the US Constitution.
During the 1920 s, the ACLU's primary focus was on freedom of speech in general, and speech within the labor movement particularly.
Because most of the ACLU's efforts were associated with the labor movement, the ACLU itself came under heavy attack from conservative groups, such as the American Legion, the National Civic Federation, and Industrial Defense Association and the Allied Patriotic Societies.
In addition to labor, the ACLU also led efforts in non-labor arenas, for example, promoting free speech in public schools.
The ACLU itself was banned from speaking in New York public schools in 1921.
The ACLU, working with the NAACP, also supported racial discrimination cases.
The ACLU defended free speech regardless of the opinions being espoused.
For example, the reactionary, anti-Catholic, anti-black Ku Klux Klan (KKK) was a frequent target of ACLU efforts, but the ACLU defended the KKK's right to hold meetings in 1923.
There were some civil rights that the ACLU did not make an effort to defend in the 1920 s, including censorship of the arts, government search and seizure issues, right to privacy, or wiretapping.
The Communist Party USA was routinely harassed and oppressed by government officials, leading it to be the primary client of the ACLU.
At the same time, the Communists were very aggressive in their tactics, often engaging in illegal conduct such as denying their party membership under oath.
This led to frequent conflicts between the Communists and ACLU.
Communist leaders sometimes attacked the ACLU, particularly when the ACLU defended the free speech rights of conservatives, whereas Communists tried to disrupt speeches by critics of the USSR.
This uneasy relationship between the two groups continued for decades.
When 1925 arrived five years after the ACLU was formed the organization had virtually no success to show for its efforts.
Clarence Darrow, a member of the ACLU National Committee, headed Scopes' legal team.
The prosecution, led by William Jennings Bryan, contended that the Bible should be interpreted literally in teaching creationism in school.
The ACLU lost the case and Scopes was fined $ 100.
The Tennessee Supreme Court later upheld the law but overturned the conviction on a technicality.
The Scopes trial was a phenomenal public relations success for the ACLU.
The ACLU became well known across America, and the case led to the first endorsement of the ACLU by a major US newspaper.
Arkansas "and the 2005 case" Kitzmiller v.
Baldwin himself was involved in an important free speech victory of the 1920 s, after he was arrested for attempting to speak at a rally of striking mill workers in New Jersey.
Although the decision was limited to the state of New Jersey, the appeals court's judgement in 1928 declared that constitutional guarantees of free speech must be given "liberal and comprehensive construction", and it marked a major turning point in the civil rights movement, signaling the shift of judicial opinion in favor of civil rights.
Although the Supreme Court did not overturn Gitlow's conviction, it adopted the ACLU's stance (later termed the incorporation doctrine) that the First Amendment freedom of speech applied to state laws, as well as federal laws.
After the First World War, many native-born Americans had a revival of concerns about assimilation of immigrants and worries about "foreign" values; they wanted public schools to teach children to be American.
Numerous states drafted laws designed to use schools to promote a common American culture, and in 1922, the voters of Oregon passed the Oregon Compulsory Education Act.
The law was primarily aimed at eliminating parochial schools, including Catholic schools.
It was promoted by groups such as the Knights of Pythias, the Federation of Patriotic Societies, the Oregon Good Government League, the Orange Order, and the Ku Klux Klan.
The Oregon Compulsory Education Act required almost all children in Oregon between eight and sixteen years of age to attend public school by 1926.
Associate Director Roger Nash Baldwin, a personal friend of Luke E. Hart, the then–Supreme Advocate and future Supreme Knight of the Knights of Columbus, offered to join forces with the Knights to challenge the law.
The Knights of Columbus pledged an immediate $ 10,000 to fight the law and any additional funds necessary to defeat it.
In a unanimous decision, the court held that the act was unconstitutional and that parents, not the state, had the authority to educate children as they thought best.
It upheld the religious freedom of parents to educate their children in religious schools.
Leaders of the ACLU were divided on the best tactics to use to promote civil liberties.
Felix Frankfurter felt that legislation was the best long-term solution, because the Supreme Court could not (and in his opinion should not) mandate liberal interpretations of the Bill of Rights.
But Walter Pollack, Morris Ernst, and other leaders felt that Supreme Court decisions were the best path to guarantee civil liberties.
A series of Supreme Court decisions in the 1920 s foretold a changing national atmosphere; anti-radical emotions were diminishing, and there was a growing willingness to protect freedom of speech and assembly via court decisions.
Censorship was commonplace in the early 20th century.
State laws and city ordinances routinely outlawed speech deemed to be obscene or offensive, and prohibited meetings or literature that promoted unions or labor organization.
Starting in 1926, the ACLU began to expand its free speech activities to encompass censorship of art and literature.
In that year, H. L. Mencken deliberately broke Boston law by distributing copies of his banned "American Mercury" magazine; the ACLU defended him and won an acquittal.
United States "and" Memoirs v.
The Comstock laws banned distribution of sex education information, based on the premise that it was obscene and led to promiscuous behavior Mary Ware Dennett was fined $ 300 in 1928, for distributing a pamphlet containing sex education material.
The ACLU, led by Morris Ernst, appealed her conviction and won a reversal, in which judge Learned Hand ruled that the pamphlet's main purpose was to "promote understanding".
The success prompted the ACLU to broaden their freedom of speech efforts beyond labor and political speech, to encompass movies, press, radio and literature.
The ACLU formed the National Committee on Freedom from Censorship in 1931 to coordinate this effort.
By the early 1930 s, censorship in the United States was diminishing.
Two major victories in the 1930 s cemented the ACLUs campaign to promote free speech.
The result was the first time the Supreme Court used the Due Process Clause of the 14th amendment to subject states to the requirements of the First Amendment.
The late 1930 s saw the emergence of a new era of tolerance in the United States.
National leaders hailed the Bill of Rights, particularly as it protected minorities, as the essence of democracy.
Even conservative elements, such as the American Bar Association began to campaign for civil liberties, which were long considered to be the domain of left-leaning organizations.
By 1940, the ACLU had achieved many of the goals it set in the 1920 s, and many of its policies were the law of the land.
In 1929, after the Scopes and Dennett victories, Baldwin perceived that there was vast, untapped support for civil liberties in the United States.
Baldwin proposed an expansion program for the ACLU, focusing on police brutality, Native American rights, African American rights, censorship in the arts, and international civil liberties.
The board of directors approved Baldwin's expansion plan, except for the international efforts.
The ACLU played a major role in passing the 1932 Norris–La Guardia Act, a federal law which prohibited employers from preventing employees from joining unions, and stopped the practice of outlawing strikes, unions, and labor organizing activities with the use of injunctions.
The ACLU also played a key role in initiating a nationwide effort to reduce misconduct (such as extracting false confessions) within police departments, by publishing the report "Lawlessness in Law Enforcement" in 1931, under the auspices of Herbert Hoover's Wickersham Commission.
In 1934, the ACLU lobbied for the passage of the Indian Reorganization Act, which restored some autonomy to Native American tribes, and established penalties for kidnapping Native American children.
Although the ACLU deferred to the NAACP for litigation promoting civil liberties for African Americans, the ACLU did engage in educational efforts, and published "Black Justice" in 1931, a report which documented institutional racism throughout the South, including lack of voting rights, segregation, and discrimination in the justice system.
Funded by the Garland Fund, the ACLU also participated in producing the influential Margold Report, which outlined a strategy to fight for civil rights for blacks.
The ACLU's plan was to demonstrate that the "separate but equal" policies governing the Southern discrimination were illegal because blacks were never, in fact, treated equally.
In 1932twelve years after the ACLU was foundedit had achieved significant success; the Supreme Court had embraced the free speech principles espoused by the ACLU, and the general public was becoming more supportive of civil rights in general.
But the Great Depression brought new assaults on civil liberties; the year 1930 saw a large increase in the number of free speech prosecutions, a doubling of the number of lynchings, and all meetings of unemployed persons were banned in Philadelphia.
The Franklin D. Roosevelt administration proposed the New Deal to combat the depression.
ACLU leaders were of mixed opinions about the New Deal, since many felt that it represented an increase in government intervention into personal affairs, and because the National Recovery Administration suspended antitrust legislation.
Roosevelt was not personally interested in civil rights, but did appoint many civil libertarians to key positions, including Interior Secretary Harold Ickes, a member of the ACLU.
The economic policies of the New Deal leaders were often aligned with ACLU goals, but social goals were not.
In particular, movies were subject to a barrage of local ordinances banning screenings that were deemed immoral or obscene.
Even public health films portraying pregnancy and birth were banned; as was "Life" magazine's April 11, 1938, issue which included photos of the birth process.
The ACLU fought these bans, but did not prevail.
The Catholic Church attained increasing political influence in the 1930 s, and used its influence to promote censorship of movies, and to discourage publication of birth control information.
This conflict between the ACLU and the Catholic Church led to the resignation of the last Catholic priest from ACLU leadership in 1934; a Catholic priest would not be represented there again until the 1970 s.
The ACLU took no official position on president Franklin Delano Roosevelt's 1937 court-packing plan, which threatened to increase the number of Supreme Court justices, unless the Supreme Court reversed its course and began approving New Deal legislation.
The Supreme Court responded by making a major shift in policy, and no longer applied strict constitutional limits to government programs, and also began to take a more active role in protecting civil liberties.
The ACLU attorney Osmond Fraenkel, working with International Labor Defense, defended De Jonge in 1937, and won a major victory when the Supreme Court ruled that "peaceable assembly for lawful discussion cannot be made a crime."
The De Jonge case marked the start of an era lasting for a dozen years, during which Roosevelt appointees (led by Hugo Black, William O. Douglas, and Frank Murphy) established a body of civil liberties law.
Senator Robert F. Wagner proposed the National Labor Relations Act in 1935, which empowered workers to unionize.
Ironically, the ACLU, after 15 years of fighting for workers' rights, initially opposed the act (it later took no stand on the legislation) because some ACLU leaders feared the increased power the bill gave to the government.
The newly formed National Labor Relations Board (NLRB) posed a dilemma for the ACLU, because in 1937 it issued an order to Henry Ford, prohibiting Ford from disseminating anti-union literature.
Part of the ACLU leadership habitually took the side of labor, and that faction supported the NLRB's action.
But part of the ACLU supported Ford's right to free speech.
ACLU leader Arthur Garfield Hays proposed a compromise (supporting the auto workers union, yet also endorsing Ford's right to express personal opinions), but the schism highlighted a deeper divide that would become more prominent in the years to come.
The ACLU's support of the NLRB was a major development for the ACLU, because it marked the first time it accepted that a government agency could be responsible for upholding civil liberties.
Until 1937, the ACLU felt that civil rights were best upheld by citizens and private organizations.
Some factions in the ACLU proposed new directions for the organization.
In the late 1930 s, some local affiliates proposed shifting their emphasis from civil liberties appellate actions, to becoming a legal aid society, centered on store front offices in low income neighborhoods.
The ACLU directors rejected that proposal.
Other ACLU members wanted the ACLU to shift focus into the political arena, and to be more willing to compromise their ideals in order to strike deals with politicians.
This initiative was also rejected by the ACLU leadership.
The ACLU's support of defendants with unpopular, sometimes extreme, viewpoints have produced many landmark court cases and established new civil liberties.
One such defendant was the Jehovah's Witnesses, who were involved in a large number of Supreme Court cases.
City of Griffin "(which struck down a city ordinance that required a permit before a person could distribute" literature of any kind ");" Martin v.
Struthers "(which struck down an ordinance prohibiting door-to-door canvassing); and" Cantwell v.
The most important cases involved statutes requiring flag salutes.
The Jehovah's Witnesses felt that saluting a flag was contrary to their religious beliefs.
Two children were convicted in 1938 of not saluting the flag.
The ACLU supported their appeal to the Supreme Court, but the court affirmed the conviction, in 1940.
To underscore its decision, the Supreme Court announced it on Flag Day.
The rise of totalitarian regimes in Germany, Russia, and other countries who rejected freedom of speech and association had a large impact on the civil liberties movement in the US; anti-Communist sentiment rose and civil liberties were curtailed.
The ACLU leadership was divided over whether or not to defend pro-Nazi speech in the United States; pro-labor elements within the ACLU were hostile towards Nazism and fascism, and objected when the ACLU defended Nazis.
Several states passed laws outlawing the hate speech directed at ethnic groups.
The first person arrested under New Jersey's 1935 hate speech law was a Jehovah's Witness who was charged with disseminating anti-Catholic literature.
The ACLU defended the Jehovah's Witnesses, and the charges were dropped.
The ACLU proceeded to defend numerous pro-Nazi groups, defending their rights to free speech and free association.
In the late 1930 s, the ACLU allied itself with the Popular Front, a coalition of liberal organizations coordinated by the United States Communist Party.
The ACLU benefited because affiliates from the Popular Front could often fight local civil rights battles much more effectively than the New York-based ACLU.
The association with the Communist Party led to accusations that the ACLU was a "Communist front", particularly because Harry F. Ward was both chairman of the ACLU and chairman of the American League Against War and Fascism, a Communist organization.
The House Un-American Activities Committee (HUAC) was created in 1938 to uncover sedition and treason within the United States.
When witnesses testified at its hearings, the ACLU was mentioned several times, leading the HUAC to mention the ACLU prominently in its 1939 report.
This damaged the ACLU's reputation severely, even though the report said that it could not "definitely state whether or not" the ACLU was a Communist organization.
While the ACLU rushed to defend its image against allegations of being a Communist front, it also worked to protect witnesses who were being harassed by the HUAC.
The ACLU was one of the few organizations to protest (unsuccessfully) against passage of the Smith Act in 1940, which would later be used to imprison many persons who supported Communism.
The ACLU defended many persons who were prosecuted under the Smith Act, including labor leader Harry Bridges.
ACLU leadership was split on whether to purge its leadership of Communists.
Norman Thomas, John Haynes Holmes, and Morris Ernst were anti-Communists who wanted to distance the ACLU from Communism; opposing them were Harry F. Ward, Corliss Lamont, and Elizabeth Gurley Flynn, who rejected any political test for ACLU leadership.
A bitter struggle ensued throughout 1939, and the anti-Communists prevailed in February 1940, when the board voted to prohibit anyone who supported totalitarianism from ACLU leadership roles.
Ward immediately resigned, andfollowing a contentious six-hour debateFlynn was voted off the ACLU's board.
The 1940 resolution was considered by many to be a betrayal of its fundamental principles.
The resolution was rescinded in 1968, and Flynn was posthumously reinstated to the ACLU in 1970.
When World War II engulfed the United States, the Bill of Rights was enshrined as a hallowed document, and numerous organizations defended civil liberties.
Chicago and New York proclaimed "Civil Rights" weeks, and President Franklin Delano Roosevelt announced a national Bill of Rights day.
Eleanor Roosevelt was the keynote speaker at the 1939 ACLU convention.
In spite of this newfound respect for civil rights, Americans were becoming adamantly anti-communist, and believed that excluding communists from American society was an essential step to preserve democracy.
Contrasted with World War I, there was relatively little violation of civil liberties during World War II.
President Roosevelt was a strong supporter of civil liberties, butmore importantlythere were few anti-war activists during World War II.
The most significant exception was the internment of Japanese Americans.
Two months after the Japanese attack on Pearl Harbor, Roosevelt authorized the creation of military "exclusion zones" with Executive Order 9066, paving the way for the detention of all West Coast Japanese Americans in inland camps.
In addition to the non-citizen Issei (prohibited from naturalization as members of an "unassimilable" race), over two-thirds of those swept up were American-born citizens.
The ACLU immediately protested to Roosevelt, comparing the evacuations to Nazi concentration camps.
The ACLU was the only major organization to object to the internment plan, and their position was very unpopular, even within the organization.
Not all ACLU leaders wanted to defend the Japanese Americans; Roosevelt loyalists such as Morris Ernst wanted to support Roosevelt's war effort, but pacifists such as Baldwin and Norman Thomas felt that Japanese Americans needed access to due process before they could be imprisoned.
In a March 20, 1942, letter to Roosevelt, Baldwin called on the administration to allow Japanese Americans to prove their loyalty at individual hearings, describing the constitutionality of the planned removal "open to grave question."
His suggestions went nowhere, and opinions within the organization became increasingly divided as the Army began the "evacuation" of the West Coast.
In May, the two factions, one pushing to fight the exclusion orders then being issued, the other advocating support for the President's policy of removing citizens whose "presence may endanger national security," brought their opposing resolutions to a vote before the board and the ACLU's national leaders.
They decided not to challenge the eviction of Japanese American citizens, and on June 22 instructions were sent to West Coast branches not to support cases that argued the government had no constitutional right to do so.
The ACLU offices on the West Coast had been more directly involved in addressing the tide of anti-Japanese prejudice from the start, as they were geographically closer to the issue, and were already working on cases challenging the exclusion by this time.
The Seattle office, assisting in Gordon Hirabayashi's lawsuit, created an unaffiliated committee to continue the work the ACLU had started, while in Los Angeles, attorney A.L. Wirin continued to represent Ernest Kinzo Wakayama but without addressing the case's constitutional questions.
(Wirin would lose private clients because of his defense of Wakayama and other Japanese Americans.)
However, the San Francisco branch, led by Ernest Besig, refused to discontinue its support for Fred Korematsu, whose case had been taken on prior to the June 22 directive, and attorney Wayne Collins, with Besig's full support, centered his defense on the illegality of Korematsu's exclusion.
The West Coast offices had wanted a test case to take to court, but had a difficult time finding a Japanese American who was both willing to violate the internment orders and able to meet the ACLU's desired criteria of a sympathetic, Americanized plaintiff.
Of the 120,000 Japanese Americans affected by the order, only 12 disobeyed, and Korematsu, Hirabayashi, and two others were the only resisters whose cases eventually made it to the Supreme Court.
Besig, dissatisfied with Osmond Fraenkel's tamer defense, filed an additional "amicus" brief that directly addressed Hirabayashi's constitutional rights.
The only case to receive a favorable ruling, "ex parte Endo", was also aided by two "amicus" briefs from the ACLU, one from the more conservative Fraenkel and another from the more putative Wayne Collins.
The ACLU board threatened to revoke the San Francisco branch's national affiliation, while Baldwin tried unsuccessfully to convince Collins to step down so he could replace him as lead attorney in the case.
Eventually Collins agreed to present the case alongside Charles Horsky, although their arguments before the Supreme Court remained based in the unconstitutionality of the exclusion order Korematsu had disobeyed.
The case was decided in December 1944, when the Court once again upheld the government's right to relocate Japanese Americans, although Korematsu's, Hirabayashi's and Yasui's convictions were later overturned in "coram nobis" proceedings in the 1980 s.
The national office of the ACLU was even more reluctant to defend anti-war protesters.
A majority of the board passed a resolution in 1942 which declared the ACLU unwilling to defend anyone who interfered with the United States' war effort.
Included in this group were the thousands of Nisei who renounced their US citizenship during the war but later regretted the decision and tried to revoke their applications for "repatriation."
(A significant number of those slated to "go back" to Japan had never actually been to the country and were in fact being deported rather than repatriated.)
Ernest Besig had in 1944 visited the Tule Lake Segregation Center, where the majority of these "renunciants" were concentrated, and subsequently enlisted Wayne Collins' help to file a lawsuit on their behalf, arguing the renunciations had been given under duress.
The national organization prohibited local branches from representing the renunciants, forcing Collins to pursue the case on his own, although Besig and the Northern California office provided some support.
During his 1944 visit to Tule Lake, Besig had also became aware of a hastily constructed stockade in which Japanese American internees were routinely being brutalized and held for months without due process.
Besig was forbidden by the national ACLU office to intervene on behalf of the stockade prisoners or even to visit the Tule Lake camp without prior written approval from Baldwin.
Unable to help directly, Besig turned to Wayne Collins for assistance.
Collins, using the threat of habeas corpus suits managed to have the stockade closed down.
A year later, after learning that the stockade had been reestablished, he returned to the camp and had it closed down for good.
When the war ended in 1945, the ACLU was 25 years old, and had accumulated an impressive set of legal victories.
President Harry S. Truman sent a congratulatory telegram to the ACLU on the occasion of their 25th anniversary.
American attitudes had changed since World War I, and dissent by minorities was tolerated with more willingness.
The Bill of Rights was more respected, and minority rights were becoming more commonly championed.
During their 1945 annual conference, the ACLU leaders composed a list of important civil rights issues to focus on in the future, and the list included racial discrimination and separation of church and state.
The African-American purchasers won the case in 1945.
Anti-Communist sentiment gripped the United States during the Cold War beginning in 1946.
Federal investigations caused many persons with Communist or left-leaning affiliations to lose their jobs, become blacklisted, or be jailed.
During the Cold War, although the United States collectively ignored the civil rights of Communists, other civil liberties—such as due process in law and separation of church and state—continued to be reinforced and even expanded.
The ACLU was internally divided when it purged Communists from its leadership in 1940, and that ambivalence continued as it decided whether to defend alleged Communists during the late 1940 s.
Some ACLU leaders were anti-Communist, and felt that the ACLU should not defend any victims.
Some ACLU leaders felt that Communists were entitled to free speech protections, and the ACLU should defend them.
Other ACLU leaders were uncertain about the threat posed by Communists, and tried to establish a compromise between the two extremes.
This ambivalent state of affairs would last until 1954, when the civil liberties faction prevailed, leading to the resignation of most of the anti-Communist leaders.
In 1947, President Truman issued Executive Order 9835, which created the Federal Loyalty Program.
This program authorized the Attorney General to create a list of organizations which were deemed to be subversive.
Any association with these programs was ground for barring the person from employment.
Listed organizations were not notified that they were being considered for the list, nor did they have an opportunity to present counterarguments; nor did the government divulge any factual basis for inclusion in the list.
Although ACLU leadership was divided on whether to challenge the Federal Loyalty Program, some challenges were successfully made.
Also in 1947, the House Un-American Activities Committee (HUAC) subpoenaed ten Hollywood directors and writers, the "Hollywood Ten", intending to ask them to identify Communists, but the witnesses refused to testify.
All were imprisoned for contempt of Congress.
The ACLU supported the appeals of several of the artists, but lost on appeal.
The Hollywood establishment panicked after the HUAC hearings, and created a blacklist which prohibited anyone with leftist associations from working.
The ACLU supported legal challenges to the blacklist, but those challenges failed.
The ACLU was more successful with an education effort; the 1952 report "The Judges and the Judged", prepared at the ACLU's direction in response to the blacklisting of actress Jean Muir, described the unfair and unethical actions behind the blacklisting process, and it helped gradually turn public opinion against McCarthyism.
The federal government took direct aim at the US Communist Party in 1948 when it indicted its top twelve leaders in the Foley Square trial.
The case hinged on whether or not mere membership in a totalitarian political party was sufficient to conclude that members advocated the overthrow of the United States government.
The ACLU chose to not represent any of the defendants, and they were all found guilty and sentenced to three to five years in prison.
Their defense attorneys were all cited for contempt, went to prison and were disbarred.
When the government indicted additional party members, the defendants could not find attorneys to represent them.
Communists protested outside the courthouse; a bill to outlaw picketing of courthouses was introduced in Congress, and the ACLU supported the anti-picketing law.
The ACLU, in a change of heart, supported the party leaders during their appeal process.
The ACLU issued a public condemnation of the "Dennis" decision, and resolved to fight it.
One reason for the Supreme Court's support of cold war legislation was the 1949 deaths of Supreme Court justices Frank Murphy and Wiley Rutledge, leaving Hugo Black and William O. Douglas as the only remaining civil libertarians on the Court.
The "Dennis" decision paved the way for the prosecution of hundreds of other Communist party members.
The ACLU supported many of the Communists during their appeals (although most of the initiative originated with local ACLU affiliates, not the national headquarters) but most convictions were upheld.
The two California affiliates, in particular, felt the national ACLU headquarters was not supporting civil liberties strongly enough, and they initiated more cold war cases than the national headquarters did.
The ACLU also challenged many loyalty oath requirements across the country, but the courts upheld most of the loyalty oath laws.
California ACLU affiliates successfully challenged the California state loyalty oath.
The Supreme Court, until 1957, upheld nearly every law which restricted the liberties of Communists.
The ACLU, even though it scaled back its defense of Communists during the Cold War, still came under heavy criticism as a "front" for Communism.
Critics included the American Legion, Senator Joseph McCarthy, the HUAC, and the FBI.
Several ACLU leaders were sympathetic to the FBI, and as a consequence, the ACLU rarely investigated any of the many complaints alleging abuse of power by the FBI during the Cold War.
In 1950, Raymond L. Wise, ACLU board member 1933 – 1951, defended William Perl, one of the other spies embroiled in the atomic espionage cases (made famous by the execution of Julius Rosenberg and Ethel Rosenberg).
In 1950, the ACLU board of directors asked executive director Baldwin to resign, feeling that he lacked the organizational skills to lead the 9,000 (and growing) member organization.
Baldwin objected, but a majority of the board elected to remove him from the position, and he was replaced by Patrick Murphy Malin.
Under Malin's guidance, membership tripled to 30,000 by 1955the start of a 24-year period of continual growth leading to 275,000 members in 1974.
Malin also presided over an expansion of local ACLU affiliates.
The ACLU, which had been controlled by an elite of a few dozen New Yorkers, became more democratic in the 1950 s.
In 1951, the ACLU amended its bylaws to permit the local affiliates to participate directly in voting on ACLU policy decisions.
A bi-annual conference, open to the entire membership, was instituted in the same year, and in later decades it became a pulpit for activist members, who suggested new directions for the ACLU, including abortion rights, death penalty, and rights of the poor.
During the early 1950 s, the ACLU continued to steer a moderate course through the Cold War.
When leftist singer Paul Robeson was denied a passport in 1950, even though he was not accused of any illegal acts, the ACLU chose to not defend him.
The ACLU later reversed their stance, and supported William Worthy and Rockwell Kent in their passport confiscation cases, which resulted in legal victories in the late 1950 s.
In response to communist witch-hunts, many witnesses and employees chose to use the fifth amendment protection against self-incrimination to avoid divulging information about their political beliefs.
Government agencies and private organizations, in response, established policies which inferred communist party membership for anyone who invoked the fifth amendment.
The national ACLU was divided on whether to defend employees who had been fired merely for pleading the fifth amendment, but the New York affiliate successfully assisted teacher Harry Slochower in his Supreme Court case which reversed his termination.
The fifth amendment issue became the catalyst for a watershed event in 1954, which finally resolved the ACLU's ambivalence by ousting the anti-communists from ACLU leadership.
In 1953, the anti-communists, led by Norman Thomas and James Fly, proposed a set of resolutions that inferred guilt of persons that invoked the fifth amendment.
These resolutions were the first that fell under the ACLU's new organizational rules permitting local affiliates to participate in the vote; the affiliates outvoted the national headquarters, and rejected the anti-communist resolutions.
Anti-communists leaders refused to accept the results of the vote, and brought the issue up for discussion again at the 1954 bi-annual convention.
ACLU member Frank Graham, president of the University of North Carolina, attacked the anti-communists with a counter-proposal, which stated that the ACLU "stand [s] against guilt by association, judgment by accusation, the invasion of privacy of personal opinions and beliefs, and the confusion of dissent with disloyalty."
The anti-communists continued to battle Graham's proposal, but were outnumbered by the affiliates.
The anti-communists finally gave up and departed the board of directors in late 1954 and 1955, ending an eight-year reign of ambivalence within the ACLU leadership ranks.
Thereafter, the ACLU proceeded with firmer resolve against Cold War anti-communist legislation.
The period from the 1940 resolution (and the purge of Elizabeth Flynn) to the 1954 resignation of the anti-communist leaders is considered by many to be an era in which the ACLU abandoned its core principles.
McCarthyism declined in late 1954 after television journalist Edward R. Murrow and others publicly chastised McCarthy.
The controversies over the Bill of Rights that were generated by the Cold War ushered in a new era in American Civil liberties.
United States "and" Yates v.
The decade from 1954 to 1964 was the most successful period in the ACLU's history.
Membership rose from 30,000 to 80,000, and by 1965 it had affiliates in seventeen states.
During the ACLU's bi-annual conference in Colorado in 1964, the Supreme Court issued rulings on eight cases in which the ACLU was involved; the ACLU prevailed on seven of the eight.
The ACLU played a role in Supreme Court decisions reducing censorship of literature and arts, protecting freedom of association, prohibiting racial segregation, excluding religion from public schools, and providing due process protection to criminal suspects.
The ACLU's success arose from changing public attitudes; the American populace was more educated, more tolerant, and more willing to accept unorthodox behavior.
Legal battles concerning the separation of church and state originated in laws dating to 1938 which required religious instruction in school, or provided state funding for religious schools.
The Catholic church was a leading proponent of such laws; and the primary opponents (the "separationists") were the ACLU, Americans United for Separation of Church and State, and the American Jewish Congress.
Board of Education "case, in which Justice Hugo Black wrote" [t] he First Amendment has erected a wall between church and state ...
It was not clear that the Bill of Rights forbid state governments from supporting religious education, and strong legal arguments were made by religious proponents, arguing that the Supreme Court should not act as a "national school board", and that the Constitution did not govern social issues.
However, the ACLU and other advocates of church/state separation persuaded the Court to declare such activities unconstitutional.
Historian Samuel Walker writes that the ACLU's "greatest impact on American life" was its role in persuading the Supreme Court to "constitutionalize" so many public controversies.
The ACLU also won cases challenging schools in New Mexico which were taught by clergy and had crucifixes hanging in the classrooms.
In the 1960 s, the ACLU, in response to member insistence, turned its attention to in-class promotion of religion.
In 1960, 42 percent of American schools included Bible reading.
In 1962, the ACLU published a policy statement condemning in-school prayers, observation of religious holidays, and Bible reading.
Religious factions across the country rebelled against the anti-prayer decisions, leading them to propose the School Prayer Constitutional Amendment, which declared in-school prayer legal.
The ACLU participated in a lobbying effort against the amendment, and the 1966 congressional vote on the amendment failed to obtain the required two-thirds majority.
However, not all cases were victories; ACLU lost cases in 1949 and 1961 which challenged state laws requiring commercial businesses to close on Sunday, the Christian Sabbath.
The Supreme Court has never overturned such laws, although some states subsequently revoked many of the laws under pressure from commercial interests.
During the 1940 s and 1950 s, the ACLU continued its battle against censorship of art and literature.
In 1948, the New York affiliate of the ACLU received mixed results from the Supreme Court, winning the appeal of Carl Jacob Kunz, who was convicted for speaking without a police permit, but losing the appeal of Irving Feiner who was arrested to prevent a breach of the peace, based on his oration denouncing president Truman and the American Legion.
The ACLU lost the case of Joseph Beauharnais, who was arrested for group libel when he distributed literature impugning the character of African Americans.
v.
The Catholic Church led efforts throughout the 1950 s attempting to persuade local prosecutors to ban various books and movies, leading to conflict with the ACLU when the ACLU published it statement condemning the church's tactics.
Further legal actions by the ACLU successfully defended films such as "M" and "la Ronde", leading the eventual dismantling of movie censorship.
Hollywood continued employing self-censorship with its own Production Code, but in 1956 the ACLU called on Hollywood to abolish the Code.
The ACLU defended beat generation artists, including Allen Ginsberg who was prosecuted for his poem "Howl"; andin an unorthodox case the ACLU helped a coffee house regain its restaurant license which was revoked because its Beat customers were allegedly disturbing the peace and quiet of the neighborhood.
The ACLU lost an important press censorship case when, in 1957, the Supreme Court upheld the obscenity conviction of publisher Samuel Roth for distributing adult magazines.
As late as 1953, books such as "Tropic of Cancer" and "From Here to Eternity" were still banned.
But public standards rapidly became more liberal though the 1960 s, and obscenity was notoriously difficult to define, so by 1971 prosecutions for obscenity had halted.
A major aspect of civil liberties progress after World War II was the undoing centuries of racism in federal, state, and local governments an effort generally associated with the civil rights movement.
Several civil liberties organizations worked together for progress, including the National Association for the Advancement of Colored People (NAACP), the ACLU, and the American Jewish Congress.
The NAACP took primary responsibility for Supreme Court cases (often led by lead NAACP attorney Thurgood Marshall), with the ACLU focusing on police misconduct, and supporting the NAACP with amicus briefs.
Southern states instituted a McCarthyism-style witch-hunt against the NAACP, attempting it to disclose membership lists.
Alabama "(right to an attorney), and including 1942's" Betts v.
Brady "(right to an attorney), and 1951's" Rochin v.
In the late 1940 s, several ACLU local affiliates established permanent committees to address policing issues.
During the 1950 s and 1960 s, the ACLU was responsible for substantially advancing the legal protections against police misconduct.
The Philadelphia affiliate was responsible for causing the City of Philadelphia, in 1958, to create the nation's first civilian police review board.
In 1959, the Illinois affiliate published the first report in the nation, "Secret Detention by the Chicago Police", which documented unlawful detention by police.
Although many law enforcement officials criticized the ACLU for expanding the rights of suspects, police officers themselves took advantage of the ACLU.
For example, when the ACLU represented New York City policemen in their lawsuit which objected to searches of their workplace lockers.
In the late 1960 s, civilian review boards in New York City and Philadelphia were abolished, over the ACLU's objection.
The 1960 s was a tumultuous era in the United States, and public interest in civil liberties underwent an explosive growth.
Civil liberties actions in the 1960 s were often led by young people, and often employed tactics such as sit ins and marches.
Protests were often peaceful, but sometimes employed militant tactics.
The ACLU played a central role in all major civil liberties debates of the 1960 s, including new fields such as gay rights, prisoner's rights, abortion, rights of the poor, and the death penalty.
Membership in the ACLU increased from 52,000 at the beginning of the decade, to 104,000 in 1970.
In 1960, there were affiliates in seven states, and by 1974 there were affiliates in 46 states.
During the 1960 s, the ACLU underwent a major transformation tactics; it shifted emphasis from legal appeals (generally involving amicus briefs submitted to the Supreme Court) to direct representation of defendants when they were initially arrested.
At the same time, the ACLU transformed its style from "disengaged and elitist" to "emotionally engaged".
The ACLU published a breakthrough document in 1963, titled "How Americans Protest", which was borne of frustration with the slow progress in battling racism, and which endorsed aggressive, even militant protest techniques.
African-American protests in the South accelerated in the early 1960 s, and the ACLU assisted at every step.
After four African-American college students staged a sit-in in a segregated North Carolina department store, the sit-in movement gained momentum across the United States.
During 1960 – 61, the ACLU defended black students arrested for demonstrating in North Carolina, Florida, and Louisiana.
The ACLU also provided legal help for the Freedom Rides in 1961, the integration of the University of Mississippi, the Birmingham campaign in 1963, and the 1964 Freedom Summer.
The NAACP was responsible for managing most sit-in related cases that made it to the Supreme Court, winning nearly every decision.
But it fell to the ACLU and other legal volunteer efforts to provide legal representation to hundreds of protestorswhite and blackwho were arrested while protesting in the South.
The ACLU joined with other civil liberties groups to form the Lawyers Constitutional Defense Committee (LCDC) which subsequently provided legal representation to many of the protesters.
The ACLU provided the majority of the funding for the LCDC.
In 1964, the ACLU opened up a major office in Atlanta, Georgia, dedicated to serving Southern issues.
Much of the ACLU's progress in the South was due to Charles Morgan, Jr., the charismatic leader of the Atlanta office.
Georgia "), desegregating prisons (" Lee v.
Another widely publicized case defended by Morgan was that of Army doctor Howard Levy, who was convicted of refusing to train Green Berets.
In 1969, the ACLU won a major victory for free speech, when it defended Dick Gregory after he was arrested for peacefully protesting against the mayor of Chicago.
The ACLU was at the center of several legal aspects of the Vietnam war: defending draft resisters, challenging the constitutionality of the war, the potential impeachment of Richard Nixon, and the use of national security concerns to preemptively censor newspapers.
David J. Miller was the first person prosecuted for burning his draft card.
Thirteen-year-old Junior High student Mary Tinker wore a black armband to school in 1965 to object to the war, and was suspended from school.
This critical case established that the government may not establish "enclaves" such as schools or prisons where all rights are forfeit.
The ACLU defended Sydney Street, who was arrested for burning an American flag to protest the reported assassination of civil rights leader James Meredith.
The ACLU successfully defended Paul Cohen, who was arrested for wearing a jacket with the words "fuck the draft" on its back, while he walked through the Los Angeles courthouse.
A major crisis gripped the ACLU in 1968 when a debate erupted over whether to defend Benjamin Spock and the Boston Five against federal charges that they encouraged draftees to avoid the draft.
The ACLU board was deeply split over whether to defend the activists; half the board harbored anti-war sentiments, and felt that the ACLU should lend its resources to the cause of the Boston Five.
The other half of the board believed that civil liberties were not at stake, and the ACLU would be taking a political stance.
Behind the debate was the longstanding ACLU tradition that it was politically impartial, and provided legal advice without regard to the political views of the defendants.
The board finally agreed to a compromise solution that permitted the ACLU to defend the anti-war activists, without endorsing the activist's political views.
Some critics of the ACLU suggest that the ACLU became a partisan political organization following the Spock case.
After the Kent State shootings in 1970, ACLU leaders took another step towards politics by passing a resolution condemning the Vietnam War.
The resolution was based in a variety of legal arguments, including civil liberties violations and a claim that the war was illegal.
Also in 1968, the ACLU held an internal symposium to discuss its dual roles: providing "direct" legal support (defense for accused in their initial trial, benefiting only the individual defendant), and appellate support (providing amicus briefs during the appeal process, to establish widespread legal precedent).
Historically, the ACLU was known for its appellate work which led to landmark Supreme Court decisions, but by 1968, 90 % of the ACLU's legal activities involved direct representation.
The symposium concluded that both roles were valid for the ACLU.
The ACLU supported "The New York Times" in its 1971 suit against the government, requesting permission to publish the Pentagon papers.
On September 30, 1973, the ACLU became first national organization to publicly call for the impeachment and removal from office of President Richard Nixon.
Six civil liberties violations were cited as grounds: “ specific proved violations of the rights of political dissent; usurpation of Congressional war‐making powers; establishment of a personal secret police which committed crimes; attempted interference in the trial of Daniel Ellsberg; distortion of the system of justice and perversion of other Federal agencies. ”
One month later, after the House of Representatives began an impeachment inquiry against him, the organization released a 56‐page handbook detailing “ 17 things citizens could do to bring about the impeachment of President Nixon.
“ This resolution, when placed beside the earlier resolution opposing the Vietnam war, convinced many ACLU critics, particularly conservatives, that the organization had transformed into a liberal political organization.
The decade from 1965 to 1975 saw an expansion of the field of civil liberties.
Administratively, the ACLU responded by appointing Aryeh Neier to take over from Pemberton as Executive Director in 1970.
Neier embarked on an ambitious program to expand the ACLU; he created the ACLU Foundation to raise funds, and he created several new programs to focus the ACLU's legal efforts.
By 1974, ACLU membership had reached 275,000.
During those years, the ACLU led the way in expanding legal rights in three directions: new rights for persons within government-run "enclaves", new rights for victim groups, and privacy rights for mainstream citizens.
At the same time, the organization grew substantially.
The ACLU helped develop the field of constitutional law that governs "enclaves", which are groups of persons that live in conditions under government control.
Enclaves include mental hospital patients, members of the military, and prisoners, and students (while at school).
Des Moines "case, and expanded it with cases such as" Goss v.
As early as 1945, the ACLU had taken a stand to protect the rights of the mentally ill, when it drafted a model statute governing mental commitments.
In the 1960 s, the ACLU opposed involuntary commitments, unless it could be demonstrated that the person was a danger to himself or the community.
The ACLU has also defended the rights of mentally ill individuals who are not dangerous, but who create disturbances.
The New York chapter of the ACLU defended Billie Boggs, a mentally ill woman who exposed herself and defecated and urinated in public.
Prior to 1960, prisoners had virtually no recourse to the court system, because courts considered prisoners to have no civil rights.
That changed in the late 1950 s, when the ACLU began representing prisoners that were subject to police brutality, or deprived of religious reading material.
In 1968, the ACLU successfully sued to desegregate the Alabama prison system; and in 1969, the New York affiliate adopted a project to represent prisoners in New York prisons.
In 1972, the ACLU consolidated several prison rights efforts across the nation and created the National Prison Project.
The ACLU, during the 1960 s and 1970 s, expanded its scope to include what it referred to as "victim groups", namely women, the poor, and homosexuals.
Heeding the call of female members, the ACLU endorsed the Equal Rights Amendment in 1970 and created the Women's Rights Project in 1971.
Reed "," Frontiero v.
Richardson ", and" Taylor v.
ACLU leader Harriet Pilpel raised the issue of the rights of homosexuals in 1964, and two years later the ACLU formally endorsed gay rights.
In 1972, ACLU cooperating attorneys in Oregon filed the first federal civil rights case involving a claim of unconstitutional discrimination against a gay or lesbian public school teacher.
The US District Court held that a state statute that authorized school districts to fire teachers for "immorality" was unconstitutionally vague, and awarded monetary damages to the teacher.
Burton v.
254 (D. Or.
1972), aff'd 512 F. 2d 850 (1975).
In 1973, the ACLU created the Sexual Privacy Project (later the Gay and Lesbian Rights Project) which combated discrimination against homosexuals.
This support continues even today.
After then-Senator Larry Craig was arrested for soliciting sex in a public restroom, the ACLU wrote an amicus brief for Craig, saying that sex between consenting adults in public places was protected under privacy rights.
Rights of the poor was another area that was expanded by the ACLU.
In 1966 and again in 1968, activists within the ACLU encouraged the organization to adopt a policy overhauling the welfare system, and guaranteeing low-income families a baseline income; but the ACLU board did not approve the proposals.
The Reproductive Freedom Project is an institution founded in 1974 (within the larger context of ACLU) that is committed to defend individuals who feel abused by the government, especially with cases pertaining to a lack of access to abortions, birth control, or sexual education.
The ACLU continues to defend individuals who feel abused or improperly treated by the government.
Often the American Civil Liberties Union is the group to stand up for an individual when being discriminated against because of their religion, sex, gender, sexuality, race, or class, even when they are not the popular opinion.
The Reproductive Freedom Project, however, goes deeper than the ACLU.
The Project promotes sexual and reproductive health by providing lessons about contraception, knowing about one's reproductive rights and assisting with the financial burdens of abortions and all of the logistics that may go into that.
The Reproductive Freedom Project of ACLU, according to their mission statement, actively works provide access to any and all reproductive health care for any human, regardless of race, gender, socioeconomic status, sexual orientation, or political standing.
In some cases, Reproductive Freedom Programs fund ultrasounds and abortions and any lodging, meals, or transportation that go with that.
Because women have reported finding it necessary to cross state lines or wait weeks for an abortion, The Reproductive Freedom Project states that they want to fight for individuals "state by state and law by law" until every individual can pursue the kind of lifestyle they want.
As stated on their website, "states have enacted more restrictions to abortion than they did in the previous 10 years combined".
The ACLU claims to be committed to fighting injustices with access to education on what accessibilities one has to abortions, birth control, religious rights, as well as trying to diminish abstinence-only sexual education, for ACLU claims that abstinence only education promotes a lack of willingness to use contraceptives.
As referenced in the larger ACLU article, in 1929, the ACLU defended Margaret Sanger's right to educate the general public about forms of birth control.
In 1985, the state decided to provide counseling and medical treatment for problems caused by what had happened 5 years prior.
In the 1990 s, the Project provided legal assistance and resource kits to those who were being attacked for educating about sexuality and AIDS.
The Reproductive Freedom Project is presently working on three ideas: (1) to "reverse the shortage of trained abortion providers throughout the country" (2) to "block state and federal welfare" reform "proposals that cut off benefits for children who are born to women already receiving welfare, unmarried women, or teenagers" and (3) to "stop the elimination of vital reproductive health services as a result of hospital mergers and health care networks".
The Project says they are hoping to achieve these goals through legal action and litigation.
The New York affiliate of the ACLU pushed to eliminate anti-abortion laws starting in 1964, a year before "Griswold" was decided, and in 1967 the ACLU itself formally adopted the right to abortion as a policy.
Related to privacy, the ACLU engaged in several battles to ensure that government records about individuals were kept private, and to give individuals the right to review their records.
The ACLU supported several measures, including the 1970 Fair Credit Reporting Act required credit agencies to divulge credit information to individuals; the 1973 Family Educational Rights and Privacy Act, which provided students the right to access their records; and the 1974 Privacy Act which prevented the federal government from disclosing personal information without good cause.
In the early 1970 s, conservatives and libertarians began to criticize the ACLU for being too political and too liberal.
Legal scholar Joseph W. Bishop wrote that the ACLU's trend to partisanship started with its defense of Spock's anti-war protests.
Critics also blamed the ACLU for encouraging the Supreme Court to embrace judicial activism.
Wade "and" Griswold v.
The ACLU became an issue in the 1988 presidential campaign, when Republican candidate George H. W. Bush accused Democratic candidate Michael Dukakis (a member of the ACLU) of being a "card carrying member of the ACLU".
It is the policy of the ACLU to support the civil liberties of defendants regardless of their ideological stance.
The ACLU takes pride in defending individuals with unpopular viewpoints, such as George Wallace, George Lincoln Rockwell, and KKK members.
The ACLU has defended American Nazis many times, and their actions often brought protests, particularly from American Jews.
In 1977, a small group of American Nazis, led by Frank Collin, applied to the town of Skokie, Illinois, for permission to hold a demonstration in the town park.
Skokie at the time had a majority population of Jews, totaling 40,000 of 70,000 citizens, some of whom were survivors of Nazi concentration camps.
Skokie refused to grant permission, and an Illinois judge supported Skokie and prohibited the demonstration.
Skokie immediately passed three ordinances aimed at preventing the group from meeting in Skokie.
The ACLU assisted Collin and appealed to federal court.
676.
The Skokie case was heavily publicized across America, partially because Jewish groups such as the Jewish Defense League and Anti Defamation League strenuously objected to the demonstration, leading many members of the ACLU to cancel their memberships.
The Illinois affiliate of the ACLU lost about 25 % of its membership and nearly one-third of its budget.
The financial strain from the controversy led to layoffs at local chapters.
After the membership crisis died down, the ACLU sent out a fund-raising appeal which explained their rationale for the Skokie case, and raised over $ 500,000 ($ in dollars).
The inauguration of Ronald Reagan as president in 1981, ushered in an eight-year period of conservative leadership in the US government.
Under Reagan's leadership, the government pushed a conservative social agenda.
Fifty years after the Scopes trial, the ACLU found itself fighting another classroom case, the Arkansas 1981 creationism statute, which required schools to teach the biblical account of creation as a scientific alternative to evolution.
In an amicus brief, the ACLU argued that child pornography that violates the three prong obscenity test should be outlawed, but that the law in question was overly restrictive because it outlawed artistic displays and otherwise non-obscene material.
The court did not adopt the ACLU's position.
During the 1988 presidential election, Vice President George H. W. Bush noted that his opponent Massachusetts Governor Michael Dukakis had described himself as a "card-carrying member of the ACLU" and used that as evidence that Dukakis was "a strong, passionate liberal" and "out of the mainstream".
The phrase subsequently was used by the organization in an advertising campaign.
In 1990, the ACLU defended Lieutenant Colonel Oliver North, whose conviction was tainted by coerced testimonya violation of his fifth amendment rightsduring the Iran–Contra affair, where Oliver North was involved in illegal weapons sales to Iran in order to illegally fund the Contra guerillas.
"In 2000, Marvin Johnson, a legislative counsel for the ACLU, stated that proposed anti-spam legislation infringed on free speech by denying anonymity and by forcing spam to be labeled as such," Standardized labeling is compelled speech.
"He also stated," It's relatively simple to click and delete.
As early as 1997, the ACLU had taken a strong position that nearly all spam legislation was improper, although it has supported "opt-out" requirements in some cases.
The ACLU opposed the 2003 CAN-SPAM act suggesting that it could have a chilling effect on speech in cyberspace.
It has been criticized for this position.
In November 2000, 15 African-American residents of Hearne, Texas, were indicted on drug charges after being arrested in a series of "drug sweeps".
"On May 11, 2005, the ACLU and Robertson County announced a confidential settlement of the lawsuit, an outcome which" both sides stated that they were satisfied with.
The 2009 film "American Violet" depicts this case.
The organization was sued because a man who raped and murdered a child had visited the NAMBLA website.
In March 2004, the ACLU, along with Lambda Legal and the National Center for Lesbian Rights, sued the state of California on behalf of six same-sex couples who were denied marriage licenses.
The ACLU, Lambda Legal and the National Center for Lesbian Rights then challenged Proposition 8 and won.
During the 2004 trial regarding allegations of Rush Limbaugh's drug abuse, the ACLU argued that his privacy should not have been compromised by allowing law enforcement examination of his medical records.
In June 2004, the school district in Dover, Pennsylvania, required that its high school biology students listen to a statement which asserted that the theory of evolution is not fact and mentioning intelligent design as an alternative theory.
Several parents called the ACLU to complain, because they believed that the school was promoting a religious idea in the classroom and violating the Establishment Clause of the First Amendment.
The ACLU, joined by Americans United for Separation of Church and State, represented the parents in a lawsuit against the school district.
In April 2006, Edward Jones and the ACLU sued the City of Los Angeles, on behalf of Robert Lee Purrie and five other homeless people, for the city's violation of the 8th and 14th Amendments to the US Constitution, and Article I, sections 7 and 17 of the California Constitution (supporting due process and equal protection, and prohibiting cruel and unusual punishment).
The Court said that the anti-camping ordinance is "one of the most restrictive municipal laws regulating public spaces in the United States".
Jones and the ACLU wanted a compromise in which the LAPD is barred from enforcing section 41.18 (d) (arrest, seizure, and imprisonment) in Skid Row between the hours of 9:00 p.m. and 6:30 am.
The compromise plan permits the homeless to sleep on the sidewalk, provided they are not "within 10 feet of any business or residential entrance" and only between these hours.
One of the motivations for the compromise is the shortage of space in the prison system.
Downtown development business interests and the Central City Association (CCA) were against the compromise.
Police Chief William Bratton said the case had slowed the police effort to fight crime and clean up Skid Row, and that when he was allowed to clean up Skid Row, real estate profited.
On September 20, 2006, the Los Angeles City Council voted to reject the compromise.
On October 3, 2006, police arrested Skid Row's transients for sleeping on the streets for the first time in months.
In 2006, the ACLU of Washington State joined with a pro-gun rights organization, the Second Amendment Foundation, and prevailed in a lawsuit against the North Central Regional Library District (NCRL) in Washington for its policy of refusing to disable restrictions upon an adult patron's request.
Library patrons attempting to access pro-gun web sites were blocked, and the library refused to remove the blocks.
In 2012, the ACLU sued the same library system for refusing to temporarily, at the request of an adult patron, disable Internet filters which blocked access to Google Images.
In 2006, the ACLU challenged a Missouri law that prohibited picketing outside of veterans' funerals.
The suit was filed in support of the Westboro Baptist Church and Shirley Phelps-Roper, who were threatened with arrest.
The Westboro Baptist Church is well known for their picket signs that contain messages such as, "God Hates Fags", "Thank God for Dead Soldiers", and "Thank God for 9/11".
The ACLU issued a statement calling the legislation a "law that infringes on Shirley Phelps-Roper's rights to religious liberty and free speech".
The ACLU prevailed in the lawsuit.
In light of the Supreme Court's "Heller" decision recognizing that the Constitution protects an individual right to bear arms, ACLU of Nevada took a position of supporting "the individual's right to bear arms subject to constitutionally permissible regulations" and pledged to "defend this right as it defends other constitutional rights".
Since 2008, the ACLU has increasingly assisted gun owners in recovering firearms that have been seized illegally by law enforcement.
This stance on the landmark "Citizens United" case caused considerable disagreement within the organization, resulting in a discussion about its future stance during a quarterly board meeting in 2010.
On March 27, 2012, the ACLU reaffirmed its stance in support of the Supreme Court's "Citizens United" ruling, at the same time voicing support for expanded public financing of election campaigns and stating the organization would firmly oppose any future constitutional amendment limiting free speech.
In 2010, the ACLU of Illinois was inducted into the Chicago Gay and Lesbian Hall of Fame as a Friend of the Community.
In 2011, the ACLU started its Don't Filter Me project, countering LGBT-related Internet censorship in public schools in the United States.
Some 181 were expected to receive about $ 13,000 each.
After the September 11 attacks, the federal government instituted a broad range of new measures to combat terrorism, including the passage of the Patriot Act.
The ACLU challenged many of the measures, claiming that they violated rights regarding due process, privacy, illegal searches, and cruel and unusual punishment.
An ACLU policy statement states: During the ensuing debate regarding the proper balance of civil liberties and security, the membership of the ACLU increased by 20 %, bringing the group's total enrollment to 330,000.
The growth continued, and by August 2008 ACLU membership was greater than 500,000.
It remained at that level through 2011.
The ACLU has been a vocal opponent of the USA PATRIOT Act of 2001, the PATRIOT 2 Act of 2003, and associated legislation made in response to the threat of domestic terrorism.
In response to a requirement of the USA PATRIOT Act, the ACLU withdrew from the Combined Federal Campaign charity drive.
The campaign imposed a requirement that ACLU employees must be checked against a federal anti-terrorism watch list.
"In 2004, the ACLU sued the federal government in" American Civil Liberties Union v.
Under the provisions of the Patriot Act, the government had issued national security letters to Merrill to compel him to provide private Internet access information from some of his customers.
In addition, the government placed a gag order on Merrill, forbidding him from discussing the matter with anyone.
On August 17, 2006, that court ruled that the warrantless wiretapping program is unconstitutional and ordered it ended immediately.
However, the order was stayed pending an appeal.
The Bush administration did suspend the program while the appeal was being heard.
In February 2008, the US Supreme Court turned down an appeal from the ACLU to let it pursue a lawsuit against the program that began shortly after the September 11 terror attacks.
The ACLU and other organizations also filed separate lawsuits around the country against telecommunications companies.
On August 10, 2006, the lawsuits against the telecommunications companies were transferred to a federal judge in San Francisco.
In January 2010, the American military released the names of 645 detainees held at the Bagram Theater Internment Facility in Afghanistan, modifying its long-held position against publicizing such information.
This list was prompted by a Freedom of Information Act lawsuit filed in September 2009 by the ACLU, whose lawyers had also requested detailed information about conditions, rules and regulations.
The ACLU has also criticized targeted killings of American citizens who fight against the United States.
In 2011, the ACLU criticized the killing of radical Muslim cleric Anwar al-Awlaki on the basis that it was a violation of his Fifth Amendment right to not be deprived of life, liberty, or property without due process of law.
The ACLU responded by filing a lawsuit against the ban on behalf of Hameed Khalid Darweesh and Haider Sameer Abdulkhaleq Alshawi, who had been detained at JFK International Airport.
On January 28, 2017, a US District Court Judge Ann Donnelly granted a temporary injunction against the immigration order, saying it was difficult to see any harm from allowing the newly arrived immigrants from entering the country.
In response to Trump's order, the ACLU raised more than $ 24 million from more than 350,000 individual online donations in a two-day period.
This amounted to six times what the ACLU normally receives in online donations in a year.
Celebrities donating included Chris Sacca (who offered to match other people's donations and ultimately gave $ 150,000), Rosie O'Donnell, Judd Apatow, Sia, John Legend, and Adele.
The number of members of the ACLU doubled in the time from the election to end of January to 1 million.
Grants and contributions increased from $ 106,628,381 USD reported by the 2016 year-end income statement to $ 274,104,575 by the 2017 year-end statement.
The primary source of revenue from the segment came from individual contributions in response to the Trump presidency's infringements on civil liberties.
The surge in donations more than doubled the total support and revenue of the non-profit organization year over year from 2016 to 2017.
Besides filing more lawsuits than during previous presidential administrations, the ACLU has spent more money on advertisements and messaging as well, weighing in on elections and pressing political concerns.
This increased public profile has drawn some accusations that the organization has become more politically partisan than in previous decades.
On May 11, 2017, as Glenn Funk, the district attorney of Davidson County, decided not to prosecute police officer Joshua Lippert, they called for an independent community review board and for Nashville police officers to wear body cameras, which was approved by local voters in a referendum.
Speech that denigrates such groups can inflict serious harms and is intended to and often will impede progress toward equality, "the ACLU declared in guidelines governing case selection and" Conflicts Between Competing Values or Priorities.
The ACLU argued that a Massachusetts law, later unanimously struck down by the Supreme Court, was constitutional.
The law prohibited sidewalk counselors from approaching women outside abortion facilities and offering them alternatives to abortion but allowed escorts to speak with them and accompany them into the building.
In overturning the law in McCullen v.
Coakley, the Supreme Court unanimously ruled that it violated the counselors' freedom of speech and that it was viewpoint discrimination.
Adobe Inc.
It has historically focused upon the creation of multimedia and creativity software products, with a more recent foray towards digital marketing software.
Adobe is best known for its Adobe Flash web software ecosystem, Photoshop image editing software, Adobe Illustrator vector graphics editor, Acrobat Reader, the Portable Document Format (PDF), and Adobe Creative Suite, as well as its successor Adobe Creative Cloud.
Adobe was founded in December 1982 by John Warnock and Charles Geschke, who established the company after leaving Xerox PARC in order to develop and sell the PostScript page description language.
In 1985, Apple Computer licensed PostScript for use in its LaserWriter printers, which helped spark the desktop publishing revolution.
, Adobe has more than 21,000 employees worldwide, about 40 % of whom work in San Jose.
Adobe also has major development operations in Newton, Massachusetts; New York City, New York; Minneapolis, Minnesota; Lehi, Utah; Seattle, Washington; and San Francisco, California in the United States.
It also has major development operations in Noida and Bangalore in India.
The company was started in John Warnock's garage.
The name of the company, "Adobe", comes from Adobe Creek in Los Altos, California, which ran behind Warnock's house.
Adobe's corporate logo features a stylized "A" and was designed by Marva Warnock, graphic designer and John Warnock's wife.
Steve Jobs attempted to buy the company for five million dollars in 1982, but Warnock and Geschke refused.
Their investors urged them to work something out with Jobs, so they agreed to sell him shares worth 19 percent of the company.
Jobs paid a five-times multiple of their company's valuation at the time, plus a five-year license fee for PostScript, in advance.
The purchase and advance made Adobe the first company in the history of Silicon Valley to become profitable in its first year.
Warnock and Geschke considered various business options including a copy-service business and a turnkey system for office printing.
Then they chose to focus on developing specialized printing software and created the Adobe PostScript page description language.
PostScript was the first truly international standard for computer printing as it included algorithms describing the letter-forms of many languages.
Adobe added kanji printer products in 1988.
Warnock and Geschke were also able to bolster the credibility of Postscript by connecting with a typesetting manufacturer.
They weren't able to work with Compugraphic, but then worked with Linotype to license the Helvetica and Times Roman fonts (through the Linotron 100).
By 1987, PostScript had become the industry-standard printer language with more than 400 third-party software programs and licensing agreements with 19 printer companies.
Warnock described the language as "extensible", in its ability to apply graphic arts standards to office printing.
Adobe's first products after PostScript were digital fonts, which they released in a proprietary format called Type 1, worked on by Bill Paxton after he left Stanford.
Apple subsequently developed a competing standard, TrueType, which provided full scalability and precise control of the pixel pattern created by the font's outlines, and licensed it to Microsoft.
In the mid-1980 s, Adobe entered the consumer software market with Illustrator, a vector-based drawing program for the Apple Macintosh.
Illustrator, which grew from the firm's in-house font-development software, helped popularize PostScript-enabled laser printers.
Adobe entered NASDAQ in August 1986.
Its revenue has grown from roughly $ 1 billion in 1999 to $ 4 billion in 2012.
Adobe's fiscal years run from December to November.
For example, the 2007 fiscal year ended on November 30, 2007.
In 1989, Adobe introduced what was to become its flagship product, a graphics editing program for the Macintosh called Photoshop.
Stable and full-featured, Photoshop 1.0 was ably marketed by Adobe and soon dominated the market.
In 1993, Adobe introduced PDF, the Portable Document Format, and its Adobe Acrobat and Reader software.
PDF is now an International Standard: ISO 32000 - 1:20 08.
In December 1991, Adobe released Adobe Premiere, which Adobe rebranded as Adobe Premiere Pro in 2003.
In 1992, Adobe acquired OCR Systems, Inc.
In 1994, Adobe acquired Aldus and added PageMaker and After Effects to its product line later in the year; it also controls the TIFF file format.
In the same year, Adobe acquired LaserTools Corp and Compution Inc.
In 1995, Adobe added FrameMaker, the long-document DTP application, to its product line after Adobe acquired Frame Technology Corp. In 1996, Adobe Inc added Ares Software Corp. In 2002, Adobe acquired Canadian company Accelio (also known as JetForm).
On December 3, 2005, Adobe acquired its main rival, Macromedia, in a stock swap valued at about $ 3.4 billion, adding ColdFusion, Contribute, Captivate, Adobe Connect (formerly Macromedia Breeze), Director, Dreamweaver, Fireworks, Flash, FlashPaper, Flex, FreeHand, HomeSite, JRun, Presenter, and Authorware to Adobe's product line.
Adobe released Adobe Media Player in April 2008.
On April 27, Adobe discontinued development and sales of its older HTML/web development software, GoLive in favor of Dreamweaver.
Adobe offered a discount on Dreamweaver for GoLive users and supports those who still use GoLive with online tutorials and migration assistance.
On June 1, Adobe launched Acrobat.
com, a series of web applications geared for collaborative work.
Creative Suite 4, which includes Design, Web, Production Premium, and Master Collection came out in October 2008 in six configurations at prices from about US $ 1,700 to $ 2,500 or by individual application.
The Windows version of Photoshop includes 64-bit processing.
On December 3, 2008, Adobe laid off 600 of its employees (8 % of the worldwide staff) citing the weak economic environment.
On November 10, 2009, the company laid off a further 680 employees.
Adobe announced it was investigating a "coordinated attack" against corporate network systems in China, managed by the company.
Adobe's 2010 was marked by continuing front-and-back arguments with Apple over the latter's non-support for Adobe Flash on its iPhone, iPad and other products.
Former Apple CEO Steve Jobs claimed that Flash was not reliable or secure enough, while Adobe executives have argued that Apple wish to maintain control over the iOS platform.
In April 2010, Steve Jobs published a post titled "Thoughts on Flash" where he outlined his thoughts on Flash and the rise of HTML 5.
In July 2010, Adobe bought Day Software integrating their line of CQ Products: WCM, DAM, SOCO, and Mobile In January 2011, Adobe acquired DemDex, Inc.
with the intent of adding DemDex's audience-optimization software to its online marketing suite.
At Photoshop World 2011, Adobe unveiled a new mobile photo service.
Carousel is a new application for iPhone, iPad, and Mac that uses Photoshop Lightroom technology for users to adjust and fine-tune images on all platforms.
Carousel will also allow users to automatically sync, share and browse photos.
The service was later renamed to "Adobe Revel".
In October 2011, Adobe acquired Nitobi Software, the makers of the mobile application development framework "PhoneGap".
As part of the acquisition, the source code of PhoneGap was submitted to the Apache Foundation, where it became Apache Cordova.
On November 9, 2011, Adobe announced that they would cease development of Flash for mobile devices following version 11.1.
Instead, it would focus on HTML 5 for mobile devices.
On December 1, 2011, Adobe announced that it entered into a definitive agreement to acquire privately held Efficient Frontier.
In December 2012, Adobe opened a new 280,000 square foot corporate campus in Lehi, Utah.
In 2013, Adobe Systems endured a major security breach.
Vast portions of the source code for the company's software were stolen and posted online and over 150 million records of Adobe's customers have been made readily available for download.
In 2012, about 40 million sets of payment card information were compromised by a hack of Adobe.
A class-action lawsuit alleging that the company suppressed employee compensation was filed against Adobe, and three other Silicon Valley-based companies in a California federal district court in 2013.
In May 2014, it was revealed the four companies, Adobe, Apple, Google, and Intel had reached agreement with the plaintiffs, 64,000 employees of the four companies, to pay a sum of $ 324.5 million to settle the suit.
On March 28, 2018, at Adobe Summit, the company and NVIDIA publicized a key association to quickly upgrade their industry-driving AI and profound learning innovations.
Expanding on years of coordinated effort, the organizations will work to streamline the Adobe Sensei AI and machine learning structure for NVIDIA GPUs.
The joint effort will speed time to showcase and enhance the execution of new Sensei-powered services for Adobe Creative Cloud and Experience Cloud clients and engineers.
Adobe and NVIDIA have co-operated for over 10 years on empowering GPU quickening for a wide arrangement of Adobe's creative and computerized encounter items.
This incorporates Sensei-powered features, for example, auto lip sync in Adobe Character Animator CC and face aware editing in Photoshop CC, and also cloud-based AI/ML items and features, for example, picture investigation for Adobe Stock and Lightroom CC and auto-labeling in Adobe Experience Supervisor.
On May 22, 2018, Adobe stated they would buy e-commerce services provider Magento Commerce from private equity firm Permira for $ 1.68 billion.
This deal will help bolster its Experience Cloud business, which provides services including analytics, advertising, and marketing.
The deal is expected to close during Adobe's fiscal third quarter in 2018.
On September 20, 2018, Adobe announced its acquisition of marketing automation software company Marketo.
On October 3, 2018, Adobe officially changed its name from Adobe Systems Incorporated to Adobe Inc.
On January 23, 2019, Adobe announced its acquisition of 3D texturing company Allegorithmic.
+ Development since 2005 2005 1,966 30.77 2006 2,575 506 35.60 2007 3,158 724 41.97 2008 3,580 872 35.33 2009 2,946 387 28.63 2010 3,800 775 31.21 2011 4,216 833 31.12 2012 4,404 833 32.67 2013 4,055 290 46.80 11,847 2014 4,147 268 12,499 2015 4,796 80.97 13,893 2016 5,854 1,169 97.32 15,706 2017 7,302 1,694 144.00 17,973 2018 9,030 2,591 226.24 21,357 Adobe Stock A microstock agency that presently provides over 57 million high-resolution, royalty-free images and videos available to license (via subscription or credit purchase methods).
On December 11, 2014, Adobe announced it was buying Fotolia for $ 800 million in cash, aiming at integrating the service to its Creative Cloud solution.
The purchase was completed in January 2015.
It is run as a stand-alone website.
Adobe Experience Platform In March 2019, Adobe released its Adobe Experience Platform, which consists family of content, development, and customer relationship management products, with what it calls the "next generation" of its Sensei artificial intelligence and machine learning framework.
Since 1995, "Fortune" has ranked Adobe as "an outstanding place to work".
Adobe was rated the 5th best U.S. company to work for in 2003, 6th in 2004, 31st in 2007, 40th in 2008, 11th in 2008, 42nd in 2010, 65th in 2011, 41st in 2012, and 83rd in 2013.
In October 2008, Adobe Systems Canada Inc.
was named one of "Canada's Top 100 Employers" by Mediacorp Canada Inc.
and was featured in "Maclean's" newsmagazine.
Adobe has a five star privacy rating from the Electronic Frontier Foundation.
Adobe has been criticized for its pricing practices, with retail prices being up to twice as much in non-US countries.
For example, it is significantly cheaper to pay for a return airfare ticket to the United States and purchase one particular collection of Adobe's software there than to buy it locally in Australia.
After Adobe revealed the pricing for the Creative Suite 3 Master Collection, which was £ 1,000 higher for European customers, a petition to protest over "unfair pricing" was published and signed by 10,000 users.
In June 2009, Adobe further increased its prices in the UK by 10 % in spite of weakening of the pound against the dollar, and UK users were not allowed to buy from the US store.
Adobe's Reader and Flash programs were listed on "The 10 most hated programs of all time" article by "TechRadar".
Hackers have exploited vulnerabilities in Adobe programs, such as Adobe Reader, to gain unauthorized access to computers.
Adobe's Flash Player has also been criticized for, among other things, suffering from performance, memory usage and security problems (see criticism of Flash Player).
A report by security researchers from Kaspersky Lab criticized Adobe for producing the products having top 10 security vulnerabilities.
Observers noted that Adobe was spying on its customers by including spyware in the Creative Suite 3 software and quietly sending user data to a firm named Omniture.
When users became aware, Adobe explained what the suspicious software did and admitted that they: "could and should do a better job taking security concerns into account".
When a security flaw was later discovered in Photoshop CS5, Adobe sparked outrage by saying it would leave the flaw unpatched, so anyone who wanted to use the software securely would have to pay for an upgrade.
Following a fierce backlash Adobe decided to provide the software patch.
Adobe has been criticized for pushing unwanted software including third-party browser toolbars and free virus scanners, usually as part of the Flash update process, and for pushing a third-party scareware program designed to scare users into paying for unneeded system repairs.
On October 3, 2013, the company initially revealed that 2.9 million customers' sensitive and personal data was stolen in security breach which included encrypted credit card information.
Adobe later admitted that 38 million active users have been affected and the attackers obtained access to their IDs and encrypted passwords, as well as to many inactive Adobe accounts.
The company did not make it clear if all the personal information was encrypted, such as email addresses and physical addresses, though data privacy laws in 44 states require this information to be encrypted.
A 3.8 GB file stolen from Adobe and containing 152 million usernames, reversibly encrypted passwords and unencrypted password hints was posted on AnonNews.
org. LastPass, a password security firm, said that Adobe failed to use best practices for securing the passwords and has not salted them.
Another security firm, Sophos, showed that Adobe used a weak encryption method permitting the recovery of a lot of information with very little effort.
According to IT expert Simon Bain, Adobe has failed its customers and ' should hang their heads in shame '.
Many of the credit cards were tied to the Creative Cloud software-by-subscription service.
Adobe offered its affected US customers a free membership in a credit monitoring service, but no similar arrangements have been made for non-US customers.
When a data breach occurs in the US, penalties depend on the state where the victim resides, not where the company is based.
After stealing the customers' data, cyber-thieves also accessed Adobe's source code repository, likely in mid-August 2013.
Because hackers acquired copies of the source code of Adobe proprietary products, they could find and exploit any potential weaknesses in its security, computer experts warned.
Security researcher Alex Holden, chief information security officer of Hold Security, characterized this Adobe breach, which affected Acrobat, ColdFusion and numerous other applications, as "one of the worst in US history".
Adobe also announced that hackers stole parts of the source code of Photoshop, which according to commentators could allow programmers to copy its engineering techniques and would make it easier to pirate Adobe's expensive products.
Published on a server of a Russian-speaking hacker group, the "disclosure of encryption algorithms, other security schemes, and software vulnerabilities can be used to bypass protections for individual and corporate data" and may have opened the gateway to new generation zero-day attacks.
Hackers already used ColdFusion exploits to make off with usernames and encrypted passwords of PR Newswire's customers, which has been tied to the Adobe security breach.
They also used a ColdFusion exploit to breach Washington state court and expose up to 200,000 Social Security numbers.
In 1994, Adobe acquired Aldus Corp., a software vendor that sold FreeHand, a competing product.
Freehand was direct competition to Adobe Illustrator, Adobe's flagship vector-graphics editor.
The Federal Trade Commission intervened and forced Adobe to sell FreeHand back to Altsys, and also banned Adobe from buying back FreeHand or any similar program for the next 10 years (1994 - 2004).
Altsys was then bought by Macromedia, which released versions 5 to 11.
When Adobe acquired Macromedia in December 2005, it stalled development of Freehand in 2007, effectively rendering it obsolete.
With FreeHand and Illustrator, Adobe controlled the only two products that compete in the professional illustration program market for Macintosh operating systems.
In 2011, a group of 5,000 Freehand graphic designers convened under the banner "Free Freehand", and filed a civil antitrust complaint in the US District Court for the Northern District of California against Adobe.
The suit alleged that "Adobe has violated federal and state antitrust laws by abusing its dominant position in the professional vector graphic illustration software market" and that "Adobe has engaged in a series of exclusionary and anti-competitive acts and strategies designed to kill FreeHand, the dominant competitor to Adobe's Illustrator software product, instead of competing on the basis of product merit according to the principals of free market capitalism."
Adobe had no response to the claims and the lawsuit was eventually settled.
The FreeHand community believes Adobe should release the product to an open-source community if it cannot update it internally.
, on its FreeHand product page, Adobe stated, "While we recognize FreeHand has a loyal customer base, we encourage users to migrate to the new Adobe Illustrator CS4 software which supports both PowerPC and Intel-based Macs and Microsoft Windows XP and Windows Vista."
, the Freehand page no longer exists and simply redirects to the Illustrator page.
Adobe's software FTP server still contains a directory for FreeHand, but it is empty.
The Alexander Technique, named after its creator Frederick Matthias Alexander, is an educational process that was created to retrain habitual patterns of movement and posture.
Alexander believed that poor habits in posture and movement damaged spatial self-awareness as well as health, and that movement efficiency could support overall physical well-being.
He saw the technique as a mental training technique as well.
Alexander began developing his technique's principles in the 1890 s in an attempt to address voice loss during public speaking.
He credited his method with allowing him to pursue his passion for reciting in Shakespearean theater.
Some proponents of the Alexander Technique say that it addresses a variety of health conditions related to cumulative physical behaviors, but there is little evidence to support many of the claims made about the technique.
As of 2015 there was evidence suggesting the Alexander Technique may be helpful for long-term back pain, long-term neck pain, and may help people cope with Parkinson's disease.
However, both Aetna and the Australian Department of Health have conducted reviews and concluded that the technique has insufficient evidence to warrant insurance coverage.
The Alexander Technique is used and taught by classically trained vocal coaches and musicians in schools and private lessons.
Its advocates state that it allows for a balanced use of all aspects of the vocal tract by consciously increasing air-flow, allowing improved vocal skill and tone.
The method is said by actors to reduce stage fright and to increase spontaneity.
The Alexander Technique is a frequent component in acting training, because it can assist the actor in being more natural in performance.
According to Alexander Technique instructor Michael J. Gelb, people tend to study the Alexander Technique for reasons of personal development.
But the evidence in these areas is limited and more studies are needed.
A 2012 Cochrane systematic review found that there is no conclusive evidence that the Alexander technique is effective for treating asthma, and randomized clinical trials are needed in order to assess the effectiveness of this type of treatment approach.
A review by Aetna last updated in 2016 stated: "Aetna considers the following alternative medicine interventions experimental and investigational, because there is inadequate evidence in the peer-reviewed published medical literature of their effectiveness."
Included is Alexander technique in that list.
A review published in 2015 and conducted for the Australia Department of Health in order to determine what services the Australian government should pay for, reviewed clinical trials published to date and found that: "Overall, the evidence was limited by the small number of participants in the intervention arms, wide confidence intervals or a lack of replication of results."
Subsequently in 2017 the Australian government named the Alexander Technique as a practice that would not qualify for insurance subsidy, saying this step would "ensure taxpayer funds are expended appropriately and not directed to therapies lacking evidence".
The Alexander Technique is most commonly taught privately in a series of 10 to 40 private lessons which may last from 30 minutes to an hour.
Students are often performers, such as actors, dancers, musicians, athletes and public speakers, people who work on computers, or those who are in frequent pain for other reasons.
Instructors observe their students, then show them how to move with better poise and less strain.
Sessions include chair work – often in front of a mirror, during which the instructor and the student will stand, sit and lie down, moving efficiently while maintaining a comfortable relationship between the head, neck and spine, and table work or physical manipulation.
To qualify as a teacher of Alexander Technique, instructors are required to complete 1,600 hours, spanning three years, of supervised teacher training.
The result must be satisfactory to qualified peers to gain membership in professional societies.
Alexander's approach emphasizes awareness strategies applied to conducting oneself while in action, (which could be now called "mindful" action, though in his four books he did not use that term.)
Actions such as sitting, squatting, lunging or walking are often selected by the teacher.
Other actions may be selected by the student that is tailored to their interests or work activities; hobbies, computer use, lifting, driving or artistic performance or practice, sports, speech or horseback riding.
Alexander teachers often use themselves as examples.
They demonstrate, explain, and analyze a student's moment-to-moment responses as well as using mirrors, video feedback or classmate observations.
Guided modelling with a highly skilled light hand contact is the primary tool for detecting and guiding the student into a more coordinated state in movement and at rest during in-person lessons.
Suggestions for improvements are often student-specific, as everyone starts out with slightly different habits.
Exercise as a teaching tool is deliberately omitted because of a common mistaken assumption that there exists a "correct" position.
There are only two specific procedures that are practiced by the student; the first is lying semi-supine.
Resting in this way uses "mechanical advantage" as a means of redirecting long-term and short-term accumulated muscular tension into a more integrated and balanced state.
This position is sometimes referred to as "constructive rest", or "the balanced resting state".
It's also a specific time to practice Alexander's principle of conscious "directing" without "doing".
The second exercise is the "Whispered Ah", which is used to co-ordinate freer breathing and vocal production.
Freedom, efficiency and patience are the prescribed values.
Proscribed are unnecessary effort, self-limiting habits as well as mistaken perceptual conclusions about the nature of training and experimentation.
Students are led to change their largely automatic routines that are interpreted by the teacher to currently or cumulatively be physically limiting, inefficient, or not in keeping with best "use" of themselves as a whole.
The Alexander teacher provides verbal coaching while monitoring, guiding and preventing unnecessary habits at their source with a specialized hands-on assistance.
This specialized hands-on skill also allows Alexander teachers to bring about a balanced working of the student's supportive musculature as it relates to gravity's downward pull from moment to moment.
Often, students require a great deal of hands-on work in order to first gain an experience of a fully poised relation to gravity and themselves.
The hands-on skill requires Alexander teachers to maintain in themselves from moment-to-moment their own improved psycho-physical co-ordination that the teacher is communicating to the student.
A mere thought, as a projection of intention, shapes preparatory movement below the level of sensing it.
Alexander used these words for reshaping these subliminal preparations: "The neck to be free, the head to go forward and up, the back to lengthen and widen".
Whichever is used, all "Directing" is suggestively thought, (rather than willfully accomplished.)
This is because the neuro-muscular responses to "Directing" often occur underneath one's ability to perceive how they are actually carried out neuro-physiologically and neuro-cognitively.
As freedom of expression or movement is the objective, the most appropriate responses cannot be anticipated or expected, only observed and chosen in the moment.
Teacher trainees gradually learn to include a constant attending to their lengthening in stature in every movement.
It becomes a basis for initiating and continuing every action, every response to stimuli or while remaining constructively at rest.
Frederick Matthias Alexander (1869 – 1955) was a Shakespearean orator from Tasmania, who developed voice loss during his unamplified performances.
After doctors found no physical cause, Alexander reasoned that he was inadvertently damaging himself while speaking.
He observed himself in multiple mirrors and saw that he was contracting his posture in preparation for any speech.
He hypothesized that a habitual conditioned pattern (of pulling his head backwards and downwards) needlessly was disrupting the normal working of his total postural, breathing, and vocal processes.
With experimentation, Alexander developed the ability to stop the unnecessary and habitual contracting in his neck, displacement of his head, and shortening of his stature.
As he became practised at speaking without these interferences, he found that his problem with recurrent voice loss was resolved.
While on a recital tour in New Zealand (1895), he came to believe in the wider significance of improved carriage for overall physical functioning although evidence from his own publications appears to indicate it happened less systematically and over a long period of time.
The American philosopher and educator John Dewey became impressed with the Alexander Technique after his headaches, neck pains, blurred vision, and stress symptoms largely improved during the time he used Alexander's advice to change his posture.
In 1923, Dewey wrote the introduction to Alexander's "Constructive Conscious Control of the Individual".
Aldous Huxley had transformative lessons with Alexander, and continued doing so with other teachers after moving to the US.
He rated Alexander's work highly enough to base the character of the doctor who saves the protagonist in "Eyeless in Gaza" (an experimental form of autobiographical work) on F.M. Alexander, putting many of his phrases into the character's mouth.
Huxley's work "The Art of Seeing" also discusses his views on the technique.
Sir Stafford Cripps, George Bernard Shaw, Henry Irving and other stage grandees, Lord Lytton and other eminent people of the era also wrote positive appreciations of his work after taking lessons with Alexander.
Since Alexander's work in the field came at the start of the 20th century, his ideas influenced many originators in the field of mind-body improvement.
Fritz Perls, who originated Gestalt therapy, credited Alexander as an inspiration for his psychological work.
Andrea Alciato (8 May 149212 January 1550), commonly known as Alciati (Andreas Alciatus), was an Italian jurist and writer.
He is regarded as the founder of the French school of legal humanists.
Alciati was born in Alzate Brianza, near Milan, and settled in France in the early 16th century.
He displayed great literary skill in his exposition of the laws, and was one of the first to interpret the civil law by the history, languages and literature of antiquity, and to substitute original research for the servile interpretations of the glossators.
He published many legal works, and some annotations on Tacitus and accumulated a sylloge of Roman inscriptions from Milan and its territories, as part of his preparation for his history of Milan, written in 1504 - 05.
Alciati is most famous for his "Emblemata," published in dozens of editions from 1531 onward.
This collection of short Latin verse texts and accompanying woodcuts created an entire European genre, the emblem book, which attained enormous popularity in continental Europe and Great Britain.
Alciati died at Pavia in 1550.
An object's apparent magnitude depends on its intrinsic luminosity, its distance from Earth, and any extinction of the object's light by interstellar dust along the line of sight to the observer.
The magnitude scale is reverse logarithmic such that having a magnitude 5 "higher" than another object's means that it is 100 times "dimmer".
Consequently, a difference of 1.0 in magnitude corresponds to a brightness ratio of or about 2.512.
The brighter an object is, the lower its magnitude.
For example, a star of magnitude 2.0 is 2.512 times brighter than a star of magnitude 3.0, or 100 times brighter than one of magnitude 7.0.
The brightest astronomical objects have negative apparent magnitudes: for example, Venus at − 4.2 or Sirius at − 1.46.
The faintest naked-eye stars visible on the darkest night have apparent magnitudes of about + 6.5.
The apparent magnitudes of known objects range from the Sun at − 26.7 to objects in deep Hubble Space Telescope images of around magnitude + 30.
Measurement of the apparent magnitude of celestial objects is termed photometry.
Photometric measurements are made in various ultraviolet, visible, or infrared wavelength bands, as defined by standard passband filters belonging to photometric systems such as the UBV system or the Strömgren "uvbyβ" system.
Absolute magnitude differs from apparent magnitude in that it is a measure of the intrinsic luminosity rather than the apparent brightness of a celestial object, expressed on the same reverse logarithmic scale.
Absolute magnitude is defined as the apparent magnitude that a star or object would have if it were observed from a distance of 10 parsecs.
When simply referring to "magnitude" (in the context of astronomy), apparent magnitude rather than absolute magnitude is normally understood.
− 1.0 251 % 1 (Sirius) 0.0 100 % 4 1.0 40 % 15 2.0 16 % 48 3.0 6.3 % 171 4.0 2.5 % 513 5.0 1.0 % 7.0 0.16 % 8.0 0.063 % 9.0 0.025 % 10.0 0.010 % The scale used to indicate magnitude originates in the Hellenistic practice of dividing stars visible to the naked eye into six "magnitudes".
The brightest stars in the night sky were said to be of first magnitude (= 1), whereas the faintest were of sixth magnitude (= 6), which is the limit of human visual perception (without the aid of a telescope).
Each grade of magnitude was considered twice the brightness of the following grade (a logarithmic scale), although that ratio was subjective as no photodetectors existed.
This rather crude scale for the brightness of stars was popularized by Ptolemy in his "Almagest" and is generally believed to have originated with Hipparchus.
In 1856, Norman Robert Pogson formalized the system by defining a first magnitude star as a star that is 100 times as bright as a sixth-magnitude star, thereby establishing the logarithmic scale still in use today.
This implies that a star of magnitude is about 2.512 times as bright as a star of magnitude.
This figure, the fifth root of 100, became known as Pogson's Ratio.
The zero point of Pogson's scale was originally defined by assigning Polaris a magnitude of exactly 2.
Astronomers later discovered that Polaris is slightly variable, so they switched to Vega as the standard reference star, assigning the brightness of Vega as the definition of zero magnitude at any specified wavelength.
Apart from small corrections, the brightness of Vega still serves as the definition of zero magnitude for visible and near infrared wavelengths, where its spectral energy distribution (SED) closely approximates that of a black body for a temperature of.
However, with the advent of infrared astronomy it was revealed that Vega's radiation includes an infrared excess presumably due to a circumstellar disk consisting of dust at warm temperatures (but much cooler than the star's surface).
At shorter (e.g. visible) wavelengths, there is negligible emission from dust at these temperatures.
However, in order to properly extend the magnitude scale further into the infrared, this peculiarity of Vega should not affect the definition of the magnitude scale.
Therefore, the magnitude scale was extrapolated to "all" wavelengths on the basis of the black-body radiation curve for an ideal stellar surface at uncontaminated by circumstellar radiation.
On this basis the spectral irradiance (usually expressed in janskys) for the zero magnitude point, as a function of wavelength, can be computed.
Small deviations are specified between systems using measurement apparatuses developed independently so that data obtained by different astronomers can be properly compared, but of greater practical importance is the definition of magnitude not at a single wavelength but applying to the response of standard spectral filters used in photometry over various wavelength bands.
With the modern magnitude systems, brightness over a very wide range is specified according to the logarithmic definition detailed below, using this zero reference.
In practice such apparent magnitudes do not exceed 30 (for detectable measurements).
The brightness of Vega is exceeded by four stars in the night sky at visible wavelengths (and more at infrared wavelengths) as well as the bright planets Venus, Mars, and Jupiter, and these must be described by "negative" magnitudes.
For example, Sirius, the brightest star of the celestial sphere, has a magnitude of − 1.4 in the visible.
Negative magnitudes for other very bright astronomical objects can be found in the table below.
Astronomers have developed other photometric zeropoint systems as alternatives to the Vega system.
The most widely used is the AB magnitude system, in which photometric zeropoints are based on a hypothetical reference spectrum having constant flux per unit frequency interval, rather than using a stellar spectrum or blackbody curve as the reference.
The AB magnitude zeropoint is defined such that an object's AB and Vega-based magnitudes will be approximately equal in the V filter band.
Precision measurement of magnitude (photometry) requires calibration of the photographic or (usually) electronic detection apparatus.
This generally involves contemporaneous observation, under identical conditions, of standard stars whose magnitude using that spectral filter is accurately known.
Moreover, as the amount of light actually received by a telescope is reduced due to transmission through the Earth's atmosphere, the airmasses of the target and calibration stars must be taken into account.
Typically one would observe a few different stars of known magnitude which are sufficiently similar.
Calibrator stars close in the sky to the target are favoured (to avoid large differences in the atmospheric paths).
If those stars have somewhat different zenith angles (altitudes) then a correction factor as a function of airmass can be derived and applied to the airmass at the target's position.
Such calibration obtains the brightnesses as would be observed from above the atmosphere, where apparent magnitude is defined.
The dimmer an object appears, the higher the numerical value given to its magnitude, with a difference of 5 magnitudes corresponding to a brightness factor of exactly 100.
Therefore, the magnitude, in the spectral band, would be given by which is more commonly expressed in terms of common (base-10) logarithms as where is the observed flux density using spectral filter, and is the reference flux (zero-point) for that photometric filter.
Since an increase of 5 magnitudes corresponds to a decrease in brightness by a factor of exactly 100, each magnitude increase implies a decrease in brightness by the factor ≈ 2.512 (Pogson's ratio).
Inverting the above formula, a magnitude difference implies a brightness factor of "What is the ratio in brightness between the Sun and the full Moon?"
The apparent magnitude of the Sun is − 26.74 (brighter), and the mean magnitude of the full moon is − 12.74 (dimmer).
Difference in magnitude: Brightness factor: The Sun appears about times brighter than the full moon.
Sometimes one might wish to add brightnesses.
For example, photometry on closely separated double stars may only be able to produce a measurement of their combined light output.
How would we reckon the combined magnitude of that double star knowing only the magnitudes of the individual components?
This can be done by adding the brightnesses (in linear units) corresponding to each magnitude.
Solving for formula_7 yields where is the resulting magnitude after adding the brightnesses referred to by and.
While magnitude generally refers to a measurement in a particular filter band corresponding to some range of wavelengths, the apparent or absolute bolometric magnitude (m) is a measure of an object's apparent or absolute brightness integrated over all wavelengths of the electromagnetic spectrum (also known as the object's irradiance or power, respectively).
The zeropoint of the apparent bolometric magnitude scale is based on the definition that an apparent bolometric magnitude of 0 mag is equivalent to a received irradiance of 2.518 × 10 W · m (Watts per square metre.)
While apparent magnitude is a measure of the brightness of an object as seen by a particular observer, absolute magnitude is a measure of the "intrinsic" brightness of an object.
Flux decreases with distance according to an inverse-square law, so the apparent magnitude of a star depends on both its absolute brightness and its distance (and any extinction).
For example, a star at one distance will have the same apparent magnitude as a star four times brighter at twice that distance.
In contrast, the intrinsic brightness of an astronomical object, does not depend on the distance of the observer or any extinction.
The absolute magnitude, of a star or astronomical object is defined as the apparent magnitude it would have as seen from a distance of 10 parsecs (about 32.6 light-years).
The absolute magnitude of the Sun is 4.83 in the V band (green) and 5.48 in the B band (blue).
In the case of a planet or asteroid, the absolute magnitude rather means the apparent magnitude it would have if it were 1 astronomical unit from both the observer and the Sun, and fully illuminated (a configuration that is only theoretically achievable, with the observer situated on the surface of the Sun).
+ Standard apparent magnitudes and fluxes for typical bands The magnitude scale is a reverse logarithmic scale.
A common misconception is that the logarithmic nature of the scale is because the human eye itself has a logarithmic response.
In Pogson's time this was thought to be true (see Weber–Fechner law), but it is now believed that the response is a power law (see Stevens' power law).
Magnitude is complicated by the fact that light is not monochromatic.
The sensitivity of a light detector varies according to the wavelength of the light, and the way it varies depends on the type of light detector.
For this reason, it is necessary to specify how the magnitude is measured for the value to be meaningful.
For this purpose the UBV system is widely used, in which the magnitude is measured in three different wavelength bands: U (centred at about 350 nm, in the near ultraviolet), B (about 435 nm, in the blue region) and V (about 555 nm, in the middle of the human visual range in daylight).
The V band was chosen for spectral purposes and gives magnitudes closely corresponding to those seen by the human eye.
When an apparent magnitude is discussed without further qualification, the V magnitude is generally understood.
Because cooler stars, such as red giants and red dwarfs, emit little energy in the blue and UV regions of the spectrum their power is often under-represented by the UBV scale.
Indeed, some L and T class stars have an estimated magnitude of well over 100, because they emit extremely little visible light, but are strongest in infrared.
Measures of magnitude need cautious treatment and it is extremely important to measure like with like.
On early 20th century and older orthochromatic (blue-sensitive) photographic film, the relative brightnesses of the blue supergiant Rigel and the red supergiant Betelgeuse irregular variable star (at maximum) are reversed compared to what human eyes perceive, because this archaic film is more sensitive to blue light than it is to red light.
Magnitudes obtained from this method are known as photographic magnitudes, and are now considered obsolete.
For objects within the Milky Way with a given absolute magnitude, 5 is added to the apparent magnitude for every tenfold increase in the distance to the object.
For objects at very great distances (far beyond the Milky Way), this relationship must be adjusted for redshifts and for non-Euclidean distance measures due to general relativity.
For planets and other Solar System bodies the apparent magnitude is derived from its phase curve and the distances to the Sun and observer.
+ Apparent visual magnitudes of known celestial objects It would be seen as a large very bright bluish disk of 35 ° apparent diameter.
About 400,000 times brighter than mean full moon maximum brightness of perigee + perihelion + full moon (mean distance value is − 12.74, though values are about 0.18 magnitude brighter when including the opposition effect) which was the brightest Kreutz Sungrazer of modern times maximum brightness the brightest stellar event in recorded history (7200 light-years away) when the ISS is at its perigee and fully lit by the Sun maximum brightness when illuminated as a crescent mean brightness maximum brightness of 4.7 million years ago, the historical brightest star of the last and next five million years minimum brightness when it is on the far side of the Sun maximum brightness maximum brightness minimum brightness maximum brightness at superior conjunction (unlike Venus, Mercury is at its brightest when on the far side of the Sun, the reason being their different phase curves) mean brightness minimum brightness Brightest star except for the Sun at visible wavelengths apparent brightness as a supernova impostor in April 1843 2nd brightest star in night sky maximum brightness near opposition and perihelion when the rings are angled toward Earth Expected apparent magnitude at 2061 passage Combined magnitude (3rd brightest star in night sky) 4th brightest star to the naked eye 4th brightest "individual" star visible telescopically in the night sky which was originally chosen as a definition of the zero point mean brightness mean brightness mean brightness minimum brightness minimum brightness in the Large Magellanic Cloud (160,000 light-years away) M31 Orion Nebula seen from Earth M42 maximum brightness (moon of Jupiter and the largest moon in the Solar System) an open cluster that may have been seen by Aristotle Sagittarius Dwarf Spheroidal Galaxy seen from Earth maximum brightness maximum brightness mean brightness which is used as a test for naked eye seeing under dark skies Peak visual magnitude (the "Clarke Event") seen on Earth on March 19, 2008 from a distance of 7.5 billion light-years.
minimum brightness maximum brightness maximum brightness maximum brightness This is an extreme naked-eyetarget that pushes human eyesight and the Bortle scale to the limit minimum brightness maximum brightness mean brightness minimum brightness maximum brightness; largest moon of Saturn; mean opposition magnitude 8.4 star UY Scuti seen from Earth Maximum brightness; largest known star by radius maximum brightness maximum brightness, brightest when west of Saturn and takes 40 days to switch sides Luhman 16 seen from Earth Closest brown dwarfs star Proxima Centauri seen from Earth 2nd closest star moon Phobos seen from Earth Maximum brightness; brightest moon of Mars star R136a1 seen from Earth Most luminous and massive star known moon Deimos seen from Earth Maximum brightness brightest (luminosity distance of 2.4 billion light-years) Maximum brightness maximum brightness, 725 times fainter than magnitude 6.5 naked eye skies moon Titania seen from Earth Maximum brightness; brightest moon of Uranus star WR 102 seen from Earth Hottest known star maximum brightness maximum brightness (the largest moon of Pluto) Current opposition brightness Current opposition brightness Current opposition brightness maximum brightness of Pluto's moon maximum brightness of Pluto's moon id = 24 id = 25 id = 27 in 2003 when it was 28 AU from the Sun, imaged using 3 of 4 synchronised individual scopes in the ESO's Very Large Telescope array using a total exposure time of about 9 hours observed magnitude of ≈ 15-kilometer Kuiper belt object Seen by the Hubble Space Telescope (HST) in 2003, dimmest known directly-observed asteroid.
expected magnitude of dimmest known asteroid, a 950-meter Kuiper belt object discovered by the HST passing in front of a star in 2009.
a luminous blue variable star, expected magnitude at visible wavelengths due to interstellar extinction Some of the above magnitudes are only approximate.
Telescope sensitivity also depends on observing time, optical bandpass, and interfering light from scattering and airglow.
An object's absolute magnitude is defined to be equal to the apparent magnitude that the object would have if it were viewed from a distance of exactly, without extinction (or dimming) of its light due to absorption by interstellar matter and cosmic dust.
By hypothetically placing all objects at a standard reference distance from the observer, their luminosities can be directly compared on a magnitude scale.
As with all astronomical magnitudes, the absolute magnitude can be specified for different wavelength ranges corresponding to specified filter bands or passbands; for stars a commonly quoted absolute magnitude is the absolute visual magnitude, which uses the visual (V) band of the spectrum (in the UBV photometric system).
Absolute magnitudes are denoted by a capital M, with a subscript representing the filter band used for measurement, such as M for absolute magnitude in the V band.
The more luminous an object, the smaller the numerical value of its absolute magnitude.
A difference of 5 magnitudes between the absolute magnitudes of two objects corresponds to a ratio of 100 in their luminosities, and a difference of n magnitudes in absolute magnitude corresponds to a luminosity ratio of 100.
For example, a star of absolute magnitude M =3.
0 would be 100 times more luminous than a star of absolute magnitude M = 8.0 as measured in the V filter band.
The Sun has absolute magnitude M =+ 4.83.
Highly luminous objects can have negative absolute magnitudes: for example, the Milky Way galaxy has an absolute B magnitude of about − 20.8.
An object's absolute "bolometric" magnitude (M) represents its total luminosity over all wavelengths, rather than in a single filter band, as expressed on a logarithmic magnitude scale.
To convert from an absolute magnitude in a specific filter band to absolute bolometric magnitude, a bolometric correction (BC) is applied.
For Solar System bodies that shine in reflected light, a different definition of absolute magnitude (H) is used, based on a standard reference distance of one astronomical unit.
In stellar and galactic astronomy, the standard distance is 10 parsecs (about 32.616 light-years, 308.57 petameters or 308.57 trillion kilometres).
A star at 10 parsecs has a parallax of 0.1 ″ (100 milliarcseconds).
Galaxies (and other extended objects) are much larger than 10 parsecs, their light is radiated over an extended patch of sky, and their overall brightness cannot be directly observed from relatively short distances, but the same convention is used.
A galaxy's magnitude is defined by measuring all the light radiated over the entire object, treating that integrated brightness as the brightness of a single point-like or star-like source, and computing the magnitude of that point-like source as it would appear if observed at the standard 10 parsecs distance.
Consequently, the absolute magnitude of any object "equals" the apparent magnitude it "would have" if it were 10 parsecs away.
The measurement of absolute magnitude is made with an instrument called a bolometer.
When using an absolute magnitude, one must specify the type of electromagnetic radiation being measured.
When referring to total energy output, the proper term is bolometric magnitude.
The bolometric magnitude usually is computed from the visual magnitude plus a bolometric correction,.
This correction is needed because very hot stars radiate mostly ultraviolet radiation, whereas very cool stars radiate mostly infrared radiation (see Planck's law).
Some stars visible to the naked eye have such a low absolute magnitude that they would appear bright enough to outshine the planets and cast shadows if they were at 10 parsecs from the Earth.
Examples include Rigel (− 7.0), Deneb (− 7.2), Naos (− 6.0), and Betelgeuse (− 5.6).
For comparison, Sirius has an absolute magnitude of 1.4, which is brighter than the Sun, whose absolute visual magnitude is 4.83 (it actually serves as a reference point).
The Sun's absolute bolometric magnitude is set arbitrarily, usually at 4.75.
Absolute magnitudes of stars generally range from − 10 to + 17.
The absolute magnitudes of galaxies can be much lower (brighter).
For example, the giant elliptical galaxy M87 has an absolute magnitude of − 22 (i.e. as bright as about 60,000 stars of magnitude − 10).
The Greek astronomer Hipparchus established a numerical scale to describe the brightness of each star appearing in the sky.
The brightest stars in the sky were assigned an apparent magnitude, and the dimmest stars visible to the naked eye are assigned.
The difference between them corresponds to a factor of 100 in brightness.
For objects within the immediate neighborhood of the Sun, the absolute magnitude and apparent magnitude from any distance (in parsecs) is related by: where is the radiant flux measured at distance (in parsecs), the radiant flux measured at distance.
The relation can be written in terms of logarithm: where the insignificance of extinction by gas and dust is assumed.
Typical extinction rates within the galaxy are 1 to 2 magnitudes per kiloparsec, when dark clouds are taken into account.
For objects at very large distances (outside the Milky Way) the luminosity distance (distance defined using luminosity measurements) must be used instead of (in parsecs), because the Euclidean approximation is invalid for distant objects and general relativity must be taken into account.
Moreover, the cosmological redshift complicates the relation between absolute and apparent magnitude, because the radiation observed was shifted into the red range of the spectrum.
To compare the magnitudes of very distant objects with those of local objects, a K correction might have to be applied to the magnitudes of the distant objects.
The absolute magnitude can also be approximated using apparent magnitude and stellar parallax: or using apparent magnitude and distance modulus: Rigel has a visual magnitude of 0.12 and distance about 860 light-years Vega has a parallax of 0.129 ″, and an apparent magnitude of 0.03 The Black Eye Galaxy has a visual magnitude of 9.36 and a distance modulus of 31.06 The bolometric magnitude, takes into account electromagnetic radiation at all wavelengths.
It includes those unobserved due to instrumental passband, the Earth's atmospheric absorption, and extinction by interstellar dust.
It is defined based on the luminosity of the stars.
In the case of stars with few observations, it must be computed assuming an effective temperature.
Classically, the difference in bolometric magnitude is related to the luminosity ratio according to: which makes by inversion: where In August 2015, the International Astronomical Union passed Resolution B2 defining the zero points of the absolute and apparent bolometric magnitude scales in SI units for power (watts) and irradiance (W/m), respectively.
Although bolometric magnitudes had been used by astronomers for many decades, there had been systematic differences in the absolute magnitude-luminosity scales presented in various astronomical references, and no international standardization.
This led to systematic differences in bolometric corrections scales.
Combined with incorrect assumed absolute bolometric magnitudes for the Sun could lead to systematic errors in estimated stellar luminosities (and stellar properties calculated which rely on stellar luminosity, such as radii, ages, and so on).
Resolution B2 defines an absolute bolometric magnitude scale where corresponds to luminosity, with the zero point luminosity set such that the Sun (with nominal luminosity) corresponds to absolute bolometric magnitude 4.74.
Placing a radiation source (e.g. star) at the standard distance of 10 parsecs, it follows that the zero point of the apparent bolometric magnitude scale corresponds to irradiance.
Following Resolution B2, the relation between a star's absolute bolometric magnitude and its luminosity is no longer directly tied to the Sun's (variable) luminosity: where The new IAU absolute magnitude scale permanently disconnects the scale from the variable Sun.
However, on this SI power scale, the nominal solar luminosity corresponds closely to 4.74, a value that was commonly adopted by astronomers before the 2015 IAU resolution.
The luminosity of the star in watts can be calculated as a function of its absolute bolometric magnitude as: using the variables as defined previously.
+ Abs Mag (H) and Diameterfor asteroids (albedo = 0.15) For planets and asteroids a definition of absolute magnitude that is more meaningful for non-stellar objects is used.
The absolute magnitude, commonly called formula_12, is defined as the apparent magnitude that the object would have if it were one Astronomical Unit (AU) from both the Sun and the observer, and in conditions of ideal solar opposition (an arrangement that is impossible in practice).
Solar System bodies are illuminated by the Sun, therefore the magnitude varies as a function of illumination conditions, described by the phase angle.
This relationship is referred to as the phase curve.
The absolute magnitude is the brightness at phase angle zero, an arrangement known as opposition.
The absolute magnitude formula_12 can be used to calculate the apparent magnitude formula_14 of a body.
For an object reflecting sunlight, formula_12 and formula_14 are connected by the relation where formula_18 is the phase angle, the angle between the body-Sun and body–observer lines.
formula_19 is the phase integral (the integration of reflected light; a number in the 0 to 1 range).
By the law of cosines, we have: Distances: The value of formula_19 depends on the properties of the reflecting surface, in particular on its roughness.
In practice, different approximations are used based on the known or assumed properties of the surface.
Planetary bodies can be approximated reasonably well as ideal diffuse reflecting spheres.
Let formula_18 be the phase angle in degrees, then A full-phase diffuse sphere reflects two-thirds as much light as a diffuse flat disk of the same diameter.
A quarter phase (formula_25) has formula_26 as much light as full phase (formula_27).
For contrast, a "diffuse disk reflector model" is simply formula_28, which isn't realistic, but it does represent the opposition surge for rough surfaces that reflect more uniform light back at low phase angles.
The definition of the geometric albedo formula_29, a measure for the reflectivity of planetary surfaces, is based on the diffuse disk reflector model.
The absolute magnitude formula_12, diameter formula_31 (in kilometers) and geometric albedo formula_29 of a body are related by Example: The Moon's absolute magnitude formula_12 can be calculated from its diameter formula_35 and geometric albedo formula_36: We have formula_38, formula_39 At quarter phase, formula_40 (according to the diffuse reflector model), this yields an apparent magnitude of formula_41 The actual value is somewhat lower than that, formula_42 The phase curve of the Moon is too complicated for the diffuse reflector model.
Because Solar System bodies are never perfect diffuse reflectors, astronomers use different models to predict apparent magnitudes based on known or assumed properties of the body.
For planets, approximations for the correction term formula_43 in the formula for have been derived empirically, to match observations at different phase angles.
The approximations recommended by the Astronomical Almanac are (with formula_18 in degrees): Earth formula_52 Jupiter Saturn Uranus formula_68 (for formula_69) formula_70 (for formula_71 and formula_72) Here formula_73 is the effective inclination of Saturn's rings (their tilt relative to the observer), which as seen from Earth varies between 0 ° and 27 ° over the course of one Saturn orbit, and formula_74 is a small correction term depending on Uranus' sub-Earth and sub-solar latitudes.
formula_75 is the Common Era year.
Neptune's absolute magnitude is changing slowly due to seasonal effects as the planet moves along its 165-year orbit around the Sun, and the approximation above is only valid after the year 2000.
For some circumstances, like formula_76 for Venus, no observations are available, and the phase curve is unknown in those cases.
Example: On 1 January 2019, Venus was formula_77 from the Sun, and formula_78 from Earth, at a phase angle of formula_79 (near quarter phase).
Under full-phase conditions, Venus would have been visible at formula_80 Accounting for the high phase angle, the correction term above yields an actual apparent magnitude of formula_81 This is close to the value of formula_82 predicted by the Jet Propulsion Laboratory.
Earth's albedo varies by a factor of 6, from 0.12 in the cloud-free case to 0.76 in the case of altostratus cloud.
The absolute magnitude here corresponds to an albedo of 0.434.
Earth's apparent magnitude cannot be predicted as accurately as that of most other planets.
If an object has an atmosphere, it reflects light more or less isotropically in all directions, and its brightness can be modelled as a diffuse reflector.
Atmosphereless bodies, like asteroids or moons, tend to reflect light more strongly to the direction of the incident light, and their brightness increases rapidly as the phase angle approaches formula_83.
This rapid brightening near opposition is called the opposition effect.
Its strength depends on the physical properties of the body's surface, and hence it differs from asteroid to asteroid.
In 1985, the IAU adopted the semi-empirical formula_84 - system, based on two parameters formula_12 and formula_86 called "absolute magnitude" and "slope", to model the opposition effect for the ephemerides published by the Minor Planet Center.
where and This relation is valid for phase angles formula_96, and works best when formula_97.
The slope parameter formula_86 relates to the surge in brightness, typically, when the object is near opposition.
It is known accurately only for a small number of asteroids, hence for most asteroids a value of formula_99 is assumed.
In rare cases, formula_86 can be negative.
An example is 101955 Bennu, with formula_101.
In 2012, the formula_84 - system was officially replaced by an improved system with three parameters formula_12, formula_104 and formula_105, which produces more satisfactory results if the opposition effect is very small or restricted to very small phase angles.
However, as of 2019, this formula_106 - system has not been adopted by either the Minor Planet Center nor Jet Propulsion Laboratory.
The apparent magnitude of asteroids varies as they rotate, on time scales of seconds to weeks depending on their rotation period, by up to formula_107 or more.
In addition, their absolute magnitude can vary with the viewing direction, depending on their axial tilt.
In many cases, neither the rotation period nor the axial tilt are known, limiting the predictability.
The models presented here do not capture those effects.
The brightness of comets is given separately as "total magnitude" (formula_108, the brightness integrated over the entire visible extend of the coma) and "nuclear magnitude" (formula_109, the brightness of the core region alone).
Both are different scales than the magnitude scale used for planets and asteroids, and can not be used for a size comparison with an asteroid's absolute magnitude.
The activity of comets varies with their distance from the Sun.
Their brightness can be approximated as where formula_112 are the total and nuclear apparent magnitudes of the comet, respectively, formula_113 are its "absolute" total and nuclear magnitudes, formula_114 and formula_115 are the body-sun and body-observer distances, formula_116 is the Astronomical Unit, and formula_117 are the slope parameters characterising the comet's activity.
For formula_118, this reduces to the formula for a purely reflecting body.
For example, the lightcurve of comet C/2011 L4 (PANSTARRS) can be approximated by formula_119 On the day of its perihelion passage, 10 March 2013, comet PANSTARRS was formula_120 from the Sun and formula_121 from Earth.
The total apparent magnitude formula_108 is predicted to have been formula_123 at that time.
The Minor Planet Center gives a value close to that, formula_124.
+ Absolute magnitudes and sizes of comet nuclei Comet Sarabat − 3.0 ≈ 100 km?
Comet Hale-Bopp − 1.3 60 ± 20 km Comet Halley 4.0 14.9 x 8.2 km average new comet 6.5 ≈ 2 km 289P/Blanpain (during 1819 outburst) 8.5 320 m 289P/Blanpain (normal activity) 22.9 320 m At the same distance, Comet Hale-Bopp is about 130 times brighter than Comet Halley.
The absolute magnitude of any given comet can vary dramatically.
It can change as the comet becomes more or less active over time, or if it undergoes an outburst.
This makes it difficult to use the absolute magnitude for a size estimate.
When comet 289P/Blanpain was discovered in 1819, its absolute magnitude was estimated as formula_126.
It was subsequently lost, and was only rediscovered in 2003.
At that time, its absolute magnitude had decreased to formula_127, and it was realised that the 1819 apparition coincided with an outburst.
289P/Blanpain reached naked eye brightness (5 – 8 mag) in 1819, even though it is the comet with the smallest nucleus that has ever been physically characterised, and usually doesn't become brighter than 18 mag. For some comets that have been observed at heliocentric distances large enough to distinguish between light reflected from the coma, and light from the nucleus itself, an absolute magnitude analogous to that used for asteroids has been calculated, allowing to estimate the sizes of their nuclei.
For a meteor, the standard distance for measurement of magnitudes is at an altitude of at the observer's zenith.
/5 } </ math >, where formula_128, the absolute magnitude of the Sun, and formula_129 </ ref >
