Cauchy's writings covered notable topics including: the theory of series, where he developed the notion of convergence and discovered many of the basic formulas for q-series.
In the theory of numbers and complex quantities, he was the first to define complex numbers as pairs of real numbers.
He also wrote on the theory of groups and substitutions, the theory of functions, differential equations and determinants.
In the theory of light he worked on Fresnel's wave theory and on the dispersion and polarization of light.
He also contributed significant research in mechanics, substituting the notion of the continuity of geometrical displacements for the principle of the continuity of matter.
He wrote on the equilibrium of rods and elastic membranes and on waves in elastic media.
He introduced a 3 × 3 symmetric matrix of numbers that is now known as the Cauchy stress tensor.
In elasticity, he originated the theory of stress, and his results are nearly as valuable as those of Siméon Poisson.
Other significant contributions include being the first to prove the Fermat polygonal number theorem.
Cauchy is most famous for his single-handed development of complex function theory.
The first pivotal theorem proved by Cauchy, now known as "Cauchy's integral theorem", was the following: where "f" ("z") is a complex-valued function holomorphic on and within the non-self-intersecting closed curve "C" (contour) lying in the complex plane.
The "contour integral" is taken along the contour "C".
The rudiments of this theorem can already be found in a paper that the 24-year - old Cauchy presented to the Académie des Sciences (then still called "First Class of the Institute") on August 11, 1814.
In full form the theorem was given in 1825.
The 1825 paper is seen by many as Cauchy's most important contribution to mathematics.
In 1826 Cauchy gave a formal definition of a residue of a function.
This concept regards functions that have poles—isolated singularities, i.e., points where a function goes to positive or negative infinity.
If the complex-valued function "f" ("z") can be expanded in the neighborhood of a singularity "a" as where φ ("z") is analytic (i.e., well-behaved without singularities), then "f" is said to have a pole of order "n" in the point "a".
If "n" = 1, the pole is called simple.
The coefficient "B" is called by Cauchy the residue of function "f" at "a".
If "f" is non-singular at "a" then the residue of "f" is zero at "a".
Clearly the residue is in the case of a simple pole equal to, where we replaced "B" by the modern notation of the residue.
In 1831, while in Turin, Cauchy submitted two papers to the Academy of Sciences of Turin.
In the first he proposed the formula now known as Cauchy's integral formula, where "f" ("z") is analytic on "C" and within the region bounded by the contour "C" and the complex number "a" is somewhere in this region.
The contour integral is taken counter-clockwise.
Clearly, the integrand has a simple pole at "z" = "a".
In the second paper he presented the residue theorem, where the sum is over all the "n" poles of "f" ("z") on and within the contour "C".
These results of Cauchy's still form the core of complex function theory as it is taught today to physicists and electrical engineers.
For quite some time, contemporaries of Cauchy ignored his theory, believing it to be too complicated.
Only in the 1840 s the theory started to get response, with Pierre Alphonse Laurent being the first mathematician, besides Cauchy, making a substantial contribution (his Laurent series published in 1843).
In his book "Cours d'Analyse" Cauchy stressed the importance of rigor in analysis.
"Rigor" in this case meant the rejection of the principle of "Generality of algebra" (of earlier authors such as Euler and Lagrange) and its replacement by geometry and infinitesimals.
Judith Grabiner wrote Cauchy was "the man who taught rigorous analysis to all of Europe."
The book is frequently noted as being the first place that inequalities, and formula_6 arguments were introduced into Calculus.
Here Cauchy defined continuity as follows: "The function f (x) is continuous with respect to x between the given limits if, between these limits, an infinitely small increment in the variable always produces an infinitely small increment in the function itself."
M. Barany claims that the École mandated the inclusion of infinitesimal methods against Cauchy's better judgement.
Gilain notes that when the portion of the curriculum devoted to "Analyse Algébrique" was reduced in 1825, Cauchy insisted on placing the topic of continuous functions (and therefore also infinitesimals) at the beginning of the Differential Calculus.
Laugwitz (1989) and Benis-Sinaceur (1973) point out that Cauchy continued to use infinitesimals in his own research as late as 1853.
Cauchy gave an explicit definition of an infinitesimal in terms of a sequence tending to zero.
There has been a vast body of literature written about Cauchy's notion of "infinitesimally small quantities", arguing they lead from everything from the usual "epsilontic" definitions or to the notions of non-standard analysis.
The consensus is that Cauchy omitted or left implicit the important ideas to make clear the precise meaning of the infinitely small quantities he used.
He was the first to prove Taylor's theorem rigorously, establishing his well-known form of the remainder.
He wrote a textbook (see the illustration) for his students at the École Polytechnique in which he developed the basic theorems of mathematical analysis as rigorously as possible.
In this book he gave the necessary and sufficient condition for the existence of a limit in the form that is still taught.
Also Cauchy's well-known test for absolute convergence stems from this book: Cauchy condensation test.
In 1829 he defined for the first time a complex function of a complex variable in another textbook.
In spite of these, Cauchy's own research papers often used intuitive, not rigorous, methods; thus one of his theorems was exposed to a "counter-example" by Abel, later fixed by the introduction of the notion of uniform continuity.
In a paper published in 1855, two years before Cauchy's death, he discussed some theorems, one of which is similar to the "Argument Principle" in many modern textbooks on complex analysis.
In modern control theory textbooks, the Cauchy argument principle is quite frequently used to derive the Nyquist stability criterion, which can be used to predict the stability of negative feedback amplifier and negative feedback control systems.
Thus Cauchy's work has a strong impact on both pure mathematics and practical engineering.
Cauchy was very productive, in number of papers second only to Leonhard Euler.
It took almost a century to collect all his writings into 27 large volumes: His greatest contributions to mathematical science are enveloped in the rigorous methods which he introduced; these are mainly embodied in his three great treatises: His other works include: Augustin-Louis Cauchy grew up in the house of a staunch royalist.
This made his father flee with the family to Arcueil during the French Revolution.
Their life there during that time was apparently hard; Augustin-Louis's father, Louis François, spoke of living on rice, bread, and crackers during the period.
A paragraph from an undated letter from Louis François to his mother in Rouen says: He was an equally staunch Catholic and a member of the Society of Saint Vincent de Paul.
He also had links to the Society of Jesus and defended them at the Academy when it was politically unwise to do so.
His zeal for his faith may have led to his caring for Charles Hermite during his illness and leading Hermite to become a faithful Catholic.
It also inspired Cauchy to plead on behalf of the Irish during the Potato Famine.
His royalism and religious zeal also made him contentious, which caused difficulties with his colleagues.
He felt that he was mistreated for his beliefs, but his opponents felt he intentionally provoked people by berating them over religious matters or by defending the Jesuits after they had been suppressed.
Niels Henrik Abel called him a "bigoted Catholic" and added he was "mad and there is nothing that can be done about him", but at the same time praised him as a mathematician.
Cauchy's views were widely unpopular among mathematicians and when Guglielmo Libri Carucci dalla Sommaja was made chair in mathematics before him he, and many others, felt his views were the cause.
When Libri was accused of stealing books he was replaced by Joseph Liouville rather than Cauchy, which caused a rift between Liouville and Cauchy.
Another dispute with political overtones concerned Jean Marie Constant Duhamel and a claim on inelastic shocks.
Cauchy was later shown, by Jean-Victor Poncelet, to be wrong.
Archimedes of Syracuse (;;) was a Greek mathematician, physicist, engineer, inventor, and astronomer.
Although few details of his life are known, he is regarded as one of the leading scientists in classical antiquity.
Generally considered the greatest mathematician of antiquity and one of the greatest of all time, Archimedes anticipated modern calculus and analysis by applying concepts of infinitesimals and the method of exhaustion to derive and rigorously prove a range of geometrical theorems, including the area of a circle, the surface area and volume of a sphere, and the area under a parabola.
Other mathematical achievements include deriving an accurate approximation of pi, defining and investigating the spiral bearing his name, and creating a system using exponentiation for expressing very large numbers.
He was also one of the first to apply mathematics to physical phenomena, founding hydrostatics and statics, including an explanation of the principle of the lever.
He is credited with designing innovative machines, such as his screw pump, compound pulleys, and defensive war machines to protect his native Syracuse from invasion.
Archimedes died during the Siege of Syracuse when he was killed by a Roman soldier despite orders that he should not be harmed.
Cicero describes visiting the tomb of Archimedes, which was surmounted by a sphere and a cylinder, which Archimedes had requested be placed on his tomb to represent his mathematical discoveries.
Unlike his inventions, the mathematical writings of Archimedes were little known in antiquity.
Mathematicians from Alexandria read and quoted him, but the first comprehensive compilation was not made until by Isidore of Miletus in Byzantine Constantinople, while commentaries on the works of Archimedes written by Eutocius in the sixth century AD opened them to wider readership for the first time.
The relatively few copies of Archimedes' written work that survived through the Middle Ages were an influential source of ideas for scientists during the Renaissance, while the discovery in 1906 of previously unknown works by Archimedes in the Archimedes Palimpsest has provided new insights into how he obtained mathematical results.
Archimedes was born c.
287 BC in the seaport city of Syracuse, Sicily, at that time a self-governing colony in Magna Graecia.
The date of birth is based on a statement by the Byzantine Greek historian John Tzetzes that Archimedes lived for 75 years.
In "The Sand Reckoner", Archimedes gives his father's name as Phidias, an astronomer about whom nothing else is known.
Plutarch wrote in his "Parallel Lives" that Archimedes was related to King Hiero II, the ruler of Syracuse.
A biography of Archimedes was written by his friend Heracleides but this work has been lost, leaving the details of his life obscure.
It is unknown, for instance, whether he ever married or had children.
During his youth, Archimedes may have studied in Alexandria, Egypt, where Conon of Samos and Eratosthenes of Cyrene were contemporaries.
He referred to Conon of Samos as his friend, while two of his works ("The Method of Mechanical Theorems" and the "Cattle Problem") have introductions addressed to Eratosthenes.
Archimedes died c.
212 BC during the Second Punic War, when Roman forces under General Marcus Claudius Marcellus captured the city of Syracuse after a two-year-long siege.
According to the popular account given by Plutarch, Archimedes was contemplating a mathematical diagram when the city was captured.
A Roman soldier commanded him to come and meet General Marcellus but he declined, saying that he had to finish working on the problem.
The soldier was enraged by this, and killed Archimedes with his sword.
Plutarch also gives a account of the death of Archimedes which suggests that he may have been killed while attempting to surrender to a Roman soldier.
According to this story, Archimedes was carrying mathematical instruments, and was killed because the soldier thought that they were valuable items.
General Marcellus was reportedly angered by the death of Archimedes, as he considered him a valuable scientific asset and had ordered that he must not be harmed.
Marcellus called Archimedes "a geometrical Briareus".
The last words attributed to Archimedes are "Do not disturb my circles", a reference to the circles in the mathematical drawing that he was supposedly studying when disturbed by the Roman soldier.
This quote is often given in Latin as "" Noli turbare circulos meos "," but there is no reliable evidence that Archimedes uttered these words and they do not appear in the account given by Plutarch.
Valerius Maximus, writing in "Memorable Doings and Sayings" in the 1st century AD, gives the phrase as "" ...
but protecting the dust with his hands, said ' I beg of you, do not disturb this.
"(" Mē mou tous kuklous taratte!
The tomb of Archimedes carried a sculpture illustrating his favorite mathematical proof, consisting of a sphere and a cylinder of the same height and diameter.
Archimedes had proven that the volume and surface area of the sphere are two thirds that of the cylinder including its bases.
In 75 BC, 137 years after his death, the Roman orator Cicero was serving as quaestor in Sicily.
He had heard stories about the tomb of Archimedes, but none of the locals were able to give him the location.
Eventually he found the tomb near the Agrigentine gate in Syracuse, in a neglected condition and overgrown with bushes.
Cicero had the tomb cleaned up, and was able to see the carving and read some of the verses that had been added as an inscription.
A tomb discovered in the courtyard of the Hotel Panorama in Syracuse in the early 1960 s was claimed to be that of Archimedes, but there was no compelling evidence for this and the location of his tomb today is unknown.
The standard versions of the life of Archimedes were written long after his death by the historians of Ancient Rome.
The account of the siege of Syracuse given by Polybius in his "The Histories" was written around seventy years after Archimedes' death, and was used subsequently as a source by Plutarch and Livy.
It sheds little light on Archimedes as a person, and focuses on the war machines that he is said to have built in order to defend the city.
The most widely known anecdote about Archimedes tells of how he invented a method for determining the volume of an object with an irregular shape.
According to Vitruvius, a votive crown for a temple had been made for King Hiero II of Syracuse, who had supplied the pure gold to be used, and Archimedes was asked to determine whether some silver had been substituted by the dishonest goldsmith.
Archimedes had to solve the problem without damaging the crown, so he could not melt it down into a regularly shaped body in order to calculate its density.
While taking a bath, he noticed that the level of the water in the tub rose as he got in, and realized that this effect could be used to determine the volume of the crown.
For practical purposes water is incompressible, so the submerged crown would displace an amount of water equal to its own volume.
By dividing the mass of the crown by the volume of water displaced, the density of the crown could be obtained.
This density would be lower than that of gold if cheaper and less dense metals had been added.
"(," heúrēka "!"
, meaning "I have found [it]!"
).
The test was conducted successfully, proving that silver had indeed been mixed in.
The story of the golden crown does not appear in the known works of Archimedes.
Moreover, the practicality of the method it describes has been called into question, due to the extreme accuracy with which one would have to measure the water displacement.
Archimedes may have instead sought a solution that applied the principle known in hydrostatics as Archimedes' principle, which he describes in his treatise "On Floating Bodies".
This principle states that a body immersed in a fluid experiences a buoyant force equal to the weight of the fluid it displaces.
Using this principle, it would have been possible to compare the density of the crown to that of pure gold by balancing the crown on a scale with a pure gold reference sample of the same weight, then immersing the apparatus in water.
The difference in density between the two samples would cause the scale to tip accordingly.
Galileo considered it "probable that this method is the same that Archimedes followed, since, besides being very accurate, it is based on demonstrations found by Archimedes himself."
In a 12th - century text titled "Mappae clavicula" there are instructions on how to perform the weighings in the water in order to calculate the percentage of silver used, and thus solve the problem.
The Latin poem "Carmen de ponderibus et mensuris" of the 4th or 5th century describes the use of a hydrostatic balance to solve the problem of the crown, and attributes the method to Archimedes.
A large part of Archimedes' work in engineering arose from fulfilling the needs of his home city of Syracuse.
The Greek writer Athenaeus of Naucratis described how King Hiero II commissioned Archimedes to design a huge ship, the "Syracusia", which could be used for luxury travel, carrying supplies, and as a naval warship.
The "Syracusia" is said to have been the largest ship built in classical antiquity.
According to Athenaeus, it was capable of carrying 600 people and included garden decorations, a gymnasium and a temple dedicated to the goddess Aphrodite among its facilities.
Since a ship of this size would leak a considerable amount of water through the hull, the Archimedes' screw was purportedly developed in order to remove the bilge water.
Archimedes' machine was a device with a revolving screw-shaped blade inside a cylinder.
It was turned by hand, and could also be used to transfer water from a body of water into irrigation canals.
The Archimedes' screw is still in use today for pumping liquids and granulated solids such as coal and grain.
The Archimedes' screw described in Roman times by Vitruvius may have been an improvement on a screw pump that was used to irrigate the Hanging Gardens of Babylon.
The world's first seagoing steamship with a screw propeller was the SS "Archimedes", which was launched in 1839 and named in honor of Archimedes and his work on the screw.
The Claw of Archimedes is a weapon that he is said to have designed in order to defend the city of Syracuse.
Also known as "the ship shaker", the claw consisted of a crane-like arm from which a large metal grappling hook was suspended.
When the claw was dropped onto an attacking ship the arm would swing upwards, lifting the ship out of the water and possibly sinking it.
There have been modern experiments to test the feasibility of the claw, and in 2005 a television documentary entitled "Superweapons of the Ancient World" built a version of the claw and concluded that it was a workable device.
Archimedes may have used mirrors acting collectively as a parabolic reflector to burn ships attacking Syracuse.
The 2nd century AD author Lucian wrote that during the Siege of Syracuse (c.
214 – 212 BC), Archimedes destroyed enemy ships with fire.
Centuries later, Anthemius of Tralles mentions burning-glasses as Archimedes' weapon.
The device, sometimes called the "Archimedes heat ray", was used to focus sunlight onto approaching ships, causing them to catch fire.
In the modern era, similar devices have been constructed and may be referred to as a heliostat or solar furnace.
This purported weapon has been the subject of ongoing debate about its credibility since the Renaissance.
René Descartes rejected it as false, while modern researchers have attempted to recreate the effect using only the means that would have been available to Archimedes.
It has been suggested that a large array of highly polished bronze or copper shields acting as mirrors could have been employed to focus sunlight onto a ship.
A test of the Archimedes heat ray was carried out in 1973 by the Greek scientist Ioannis Sakkas.
The experiment took place at the Skaramagas naval base outside Athens.
On this occasion 70 mirrors were used, each with a copper coating and a size of around five by three feet (1.5 by 1 m).
The mirrors were pointed at a plywood of a Roman warship at a distance of around 160 feet (50 m).
When the mirrors were focused accurately, the ship burst into flames within a few seconds.
The plywood ship had a coating of tar paint, which may have aided combustion.
A coating of tar would have been commonplace on ships in the classical era.
In October 2005 a group of students from the Massachusetts Institute of Technology carried out an experiment with 127 one-foot (30 cm) square mirror tiles, focused on a wooden ship at a range of around 100 feet (30 m).
Flames broke out on a patch of the ship, but only after the sky had been cloudless and the ship had remained stationary for around ten minutes.
It was concluded that the device was a feasible weapon under these conditions.
The MIT group repeated the experiment for the television show "MythBusters", using a wooden fishing boat in San Francisco as the target.
Again some charring occurred, along with a small amount of flame.
In order to catch fire, wood needs to reach its autoignition temperature, which is around 300 °C (570 °F).
When "MythBusters" broadcast the result of the San Francisco experiment in January 2006, the claim was placed in the category of "busted" (or failed) because of the length of time and the ideal weather conditions required for combustion to occur.
It was also pointed out that since Syracuse faces the sea towards the east, the Roman fleet would have had to attack during the morning for optimal gathering of light by the mirrors.
"MythBusters" also pointed out that conventional weaponry, such as flaming arrows or bolts from a catapult, would have been a far easier way of setting a ship on fire at short distances.
In December 2010, "MythBusters" again looked at the heat ray story in a special edition entitled "President's Challenge".
Several experiments were carried out, including a large scale test with 500 schoolchildren aiming mirrors at a of a Roman sailing ship 400 feet (120 m) away.
In all of the experiments, the sail failed to reach the 210 °C (410 °F) required to catch fire, and the verdict was again "busted".
The show concluded that a more likely effect of the mirrors would have been blinding, dazzling, or distracting the crew of the ship.
While Archimedes did not invent the lever, he gave an explanation of the principle involved in his work "On the Equilibrium of Planes".
Earlier descriptions of the lever are found in the Peripatetic school of the followers of Aristotle, and are sometimes attributed to Archytas.
According to Pappus of Alexandria, Archimedes' work on levers caused him to remark: "Give me a place to stand on, and I will move the Earth."
Archimedes has also been credited with improving the power and accuracy of the catapult, and with inventing the odometer during the First Punic War.
The odometer was described as a cart with a gear mechanism that dropped a ball into a container after each mile traveled.
Cicero (106 – 43 BC) mentions Archimedes briefly in his dialogue "De re publica", which portrays a fictional conversation taking place in 129 BC.
After the capture of Syracuse c.
212 BC, General Marcus Claudius Marcellus is said to have taken back to Rome two mechanisms, constructed by Archimedes and used as aids in astronomy, which showed the motion of the Sun, Moon and five planets.
Cicero mentions similar mechanisms designed by Thales of Miletus and Eudoxus of Cnidus.
The dialogue says that Marcellus kept one of the devices as his only personal loot from Syracuse, and donated the other to the Temple of Virtue in Rome.
Marcellus' mechanism was demonstrated, according to Cicero, by Gaius Sulpicius Gallus to Lucius Furius Philus, who described it thus: This is a description of a planetarium or orrery.
Pappus of Alexandria stated that Archimedes had written a manuscript (now lost) on the construction of these mechanisms entitled.
Modern research in this area has been focused on the Antikythera mechanism, another device built BC that was probably designed for the same purpose.
Constructing mechanisms of this kind would have required a sophisticated knowledge of differential gearing.
This was once thought to have been beyond the range of the technology available in ancient times, but the discovery of the Antikythera mechanism in 1902 has confirmed that devices of this kind were known to the ancient Greeks.
While he is often regarded as a designer of mechanical devices, Archimedes also made contributions to the field of mathematics.
Plutarch wrote: "He placed his whole affection and ambition in those purer speculations where there can be no reference to the vulgar needs of life."
Archimedes was able to use infinitesimals in a way that is similar to modern integral calculus.
Through proof by contradiction (reductio ad absurdum), he could give answers to problems to an arbitrary degree of accuracy, while specifying the limits within which the answer lay.
This technique is known as the method of exhaustion, and he employed it to approximate the value of π.
In "Measurement of a Circle" he did this by drawing a larger regular hexagon outside a circle and a smaller regular hexagon inside the circle, and progressively doubling the number of sides of each regular polygon, calculating the length of a side of each polygon at each step.
As the number of sides increases, it becomes a more accurate approximation of a circle.
After four such steps, when the polygons had 96 sides each, he was able to determine that the value of π lay between 3 (approximately 3.1429) and 3 (approximately 3.1408), consistent with its actual value of approximately 3.1416.
He also proved that the area of a circle was equal to π multiplied by the square of the radius of the circle (πr).
In "On the Sphere and Cylinder", Archimedes postulates that any magnitude when added to itself enough times will exceed any given magnitude.
This is the Archimedean property of real numbers.
In "Measurement of a Circle", Archimedes gives the value of the square root of 3 as lying between (approximately 1.7320261) and (approximately 1.7320512).
The actual value is approximately 1.7320508, making this a very accurate estimate.
He introduced this result without offering any explanation of how he had obtained it.
This aspect of the work of Archimedes caused John Wallis to remark that he was: "as it were of set purpose to have covered up the traces of his investigation as if he had grudged posterity the secret of his method of inquiry while he wished to extort from them assent to his results."
It is possible that he used an iterative procedure to calculate these values.
In "The Quadrature of the Parabola", Archimedes proved that the area enclosed by a parabola and a straight line is times the area of a corresponding inscribed triangle as shown in the figure at right.
He expressed the solution to the problem as an infinite geometric series with the common ratio: If the first term in this series is the area of the triangle, then the second is the sum of the areas of two triangles whose bases are the two smaller secant lines, and so on.
This proof uses a variation of the series which sums to.
In "The Sand Reckoner", Archimedes set out to calculate the number of grains of sand that the universe could contain.
In doing so, he challenged the notion that the number of grains of sand was too large to be counted.
He wrote: "There are some, King Gelo (Gelo II, son of Hiero II), who think that the number of the sand is infinite in multitude; and I mean by the sand not only that which exists about Syracuse and the rest of Sicily but also that which is found in every region whether inhabited or uninhabited."
To solve the problem, Archimedes devised a system of counting based on the myriad.
The word is from the Greek "murias", for the number 10,000.
He proposed a number system using powers of a myriad of myriads (100 million) and concluded that the number of grains of sand required to fill the universe would be 8 vigintillion, or 8.
The works of Archimedes were written in Doric Greek, the dialect of ancient Syracuse.
The written work of Archimedes has not survived as well as that of Euclid, and seven of his treatises are known to have existed only through references made to them by other authors.
Pappus of Alexandria mentions "On Sphere-Making" and another work on polyhedra, while Theon of Alexandria quotes a remark about refraction from the "Catoptrica".
During his lifetime, Archimedes made his work known through correspondence with the mathematicians in Alexandria.
The writings of Archimedes were first collected by the Byzantine Greek architect Isidore of Miletus (c.
530 AD), while commentaries on the works of Archimedes written by Eutocius in the sixth century AD helped to bring his work a wider audience.
Archimedes' work was translated into Arabic by Thābit ibn Qurra (836 – 901 AD), and Latin by Gerard of Cremona (c.
1114 – 1187 AD).
During the Renaissance, the "Editio Princeps" (First Edition) was published in Basel in 1544 by Johann Herwagen with the works of Archimedes in Greek and Latin.
Around the year 1586 Galileo Galilei invented a hydrostatic balance for weighing metals in air and water after apparently being inspired by the work of Archimedes.
Archimedes' "Book of Lemmas" or "Liber Assumptorum" is a treatise with fifteen propositions on the nature of circles.
The earliest known copy of the text is in Arabic.
The scholars T.L. Heath and Marshall Clagett argued that it cannot have been written by Archimedes in its current form, since it quotes Archimedes, suggesting modification by another author.
The "Lemmas" may be based on an earlier work by Archimedes that is now lost.
It has also been claimed that Heron's formula for calculating the area of a triangle from the length of its sides was known to Archimedes.
However, the first reliable reference to the formula is given by Heron of Alexandria in the 1st century AD. The foremost document containing the work of Archimedes is the Archimedes Palimpsest.
In 1906, the Danish professor Johan Ludvig Heiberg visited Constantinople and examined a 174-page goatskin parchment of prayers written in the 13th century AD. He discovered that it was a palimpsest, a document with text that had been written over an erased older work.
Palimpsests were created by scraping the ink from existing works and reusing them, which was a common practice in the Middle Ages as vellum was expensive.
The older works in the palimpsest were identified by scholars as 10th century AD copies of previously unknown treatises by Archimedes.
The parchment spent hundreds of years in a monastery library in Constantinople before being sold to a private collector in the 1920 s.
On October 29, 1998 it was sold at auction to an anonymous buyer for $ 2 million at Christie's in New York.
The palimpsest holds seven treatises, including the only surviving copy of "On Floating Bodies" in the original Greek.
It is the only known source of "The Method of Mechanical Theorems", referred to by Suidas and thought to have been lost forever.
"Stomachion" was also discovered in the palimpsest, with a more complete analysis of the puzzle than had been found in previous texts.
The palimpsest is now stored at the Walters Art Museum in Baltimore, Maryland, where it has been subjected to a range of modern tests including the use of ultraviolet and light to read the overwritten text.
The treatises in the Archimedes Palimpsest are: a.
In the preface to "On Spirals" addressed to Dositheus of Pelusium, Archimedes says that "many years have elapsed since Conon's death."
Conon of Samos lived, suggesting that Archimedes may have been an older man when writing some of his works.
b.
The treatises by Archimedes known to exist only through references in the works of other authors are: "On Sphere-Making" and a work on polyhedra mentioned by Pappus of Alexandria; "Catoptrica", a work on optics mentioned by Theon of Alexandria; "Principles", addressed to Zeuxippus and explaining the number system used in "The Sand Reckoner"; "On Balances and Levers"; "On Centers of Gravity"; "On the Calendar".
Of the surviving works by Archimedes, T.L. Heath offers the following suggestion as to the order in which they were written: "On the Equilibrium of Planes I", "The Quadrature of the Parabola", "On the Equilibrium of Planes II", "On the Sphere and the Cylinder I, II", "On Spirals", "On Conoids and Spheroids", "On Floating Bodies I, II", "On the Measurement of a Circle", "The Sand Reckoner".
c.
Arabic scholars also attribute to Archimedes the ' theorem on the broken chord ' ...
d.
"It was usual to smear the seams or even the whole hull with pitch or with pitch and wax".
In Νεκρικοὶ Διάλογοι ("Dialogues of the Dead"), Lucian refers to coating the seams of a skiff with wax, a reference to pitch (tar) or wax.
Alternative medicine describes any practice that aims to achieve the healing effects of medicine, but which lacks biological plausibility and is untested, untestable or proven ineffective.
Complementary medicine (CM), complementary and alternative medicine (CAM), integrated medicine or integrative medicine (IM), and holistic medicine are among many rebrandings of the same phenomenon.
Alternative therapies share in common that they reside outside medical science, and rely on pseudoscience.
Traditional practices become "alternative" when used outside their original settings without proper scientific explanation and evidence.
Frequently used derogatory terms for the alternative are new-age or pseudo, with little distinction from quackery.
Some alternative practices are based on theories that contradict the science of how the human body works; others resort to the supernatural or superstitious to explain their effect.
In others, the practice is plausibly effective but has too many side-effects.
Alternative medicine is distinct from experimental medicine, which employs the scientific method to test plausible therapies by way of responsible and ethical clinical trials, producing evidence of either effect or of no effect.
Research into alternative therapies often fails to follow proper research protocols (such as placebo-controlled trials, blind experiments and calculation of prior probability), providing invalid results.
Much of the perceived effect of an alternative practice arises from a belief that it will be effective (the placebo effect), or from the treated condition resolving on its own (the natural course of disease).
This is further exacerbated by the tendency to turn to alternative therapies upon the failure of medicine, at which point the condition will be at its worst and most likely to spontaneously improve.
In the absence of this bias, especially for diseases that are not expected to get better by themselves such as cancer or HIV infection, multiple studies have shown significantly worse outcomes if patients turn to alternative therapies.
While this may be because these patients avoid effective treatment, some alternative therapies are actively harmful (e.g. cyanide poisoning from amygdalin, or the intentional ingestion of hydrogen peroxide) or actively interfere with effective treatments.
The alternative sector is a highly profitable industry with a strong lobby, and faces far less regulation over the use and marketing of unproven treatments.
Its marketing often advertises the treatments as being "natural" or "holistic", in comparison to those offered by "big pharma".
Billions of dollars have been spent studying alternative medicine, with little to no positive results.
Some of the successful practices are only considered alternative under very specific definitions, such as those which include all physical activity under the umbrella of "alternative medicine".
The terms "alternative medicine", "complementary medicine", "integrative medicine," "holistic medicine", "natural medicine", "unorthodox medicine", "fringe medicine", "unconventional medicine", and "new age medicine" are used interchangeably as having the same meaning, and are almost synonymous in most contexts.
Terminology has shifted over time, reflecting the preferred branding of practitioners.
For example, the United States National Institutes of Health department studying alternative medicine, currently named the National Center for Complementary and Integrative Health (NCCIH), was established as the "Office of Alternative Medicine" (OAM) and was renamed the "National Center for Complementary and Alternative Medicine" (NCCAM) before obtaining its current name.
Therapies are often framed as "natural" or "holistic", implicitly and intentionally suggesting that conventional medicine is "artificial" and "narrow in scope".
The meaning of the term "alternative" in the expression "alternative medicine", is not that it is an effective alternative to medical science, although some alternative medicine promoters may use the loose terminology to give the appearance of effectiveness.
Loose terminology may also be used to suggest meaning that a dichotomy exists when it does not, e.g., the use of the expressions "Western medicine" and "Eastern medicine" to suggest that the difference is a cultural difference between the Asiatic east and the European west, rather than that the difference is between evidence-based medicine and treatments that do not work.
Alternative medicine is defined loosely as a set of products, practices, and theories that are believed or perceived by their users to have the healing effects of medicine, but whose effectiveness has not been established using scientific methods, or whose theory and practice is not part of biomedicine, or whose theories or practices are directly contradicted by scientific evidence or scientific principles used in biomedicine.
"Biomedicine" or "medicine" is that part of medical science that applies principles of biology, physiology, molecular biology, biophysics, and other natural sciences to clinical practice, using scientific methods to establish the effectiveness of that practice.
Unlike medicine, an alternative product or practice does not originate from using scientific methods, but may instead be based on hearsay, religion, tradition, superstition, belief in supernatural energies, pseudoscience, errors in reasoning, propaganda, fraud, or other unscientific sources.
Some other definitions seek to specify alternative medicine in terms of its social and political marginality to mainstream healthcare.
This can refer to the lack of support that alternative therapies receive from medical scientists regarding access to research funding, sympathetic coverage in the medical press, or inclusion in the standard medical curriculum.
For example, a widely used definition devised by the US NCCIH calls it "" a group of diverse medical and health care systems, practices, and products that are not generally considered part of conventional medicine "".
However, these descriptive definitions are inadequate in the present-day when some conventional doctors offer alternative medical treatments and introductory courses or modules can be offered as part of standard undergraduate medical training; alternative medicine is taught in more than half of US medical schools and US health insurers are increasingly willing to provide reimbursement for alternative therapies.
Complementary medicine (CM) or integrative medicine (IM) is when alternative medicine is used together with functional medical treatment, in a belief that it improves the effect of treatments.
For example, acupuncture (piercing the body with needles to influence the flow of a supernatural energy) might be believed to increase the effectiveness or "complement" science-based medicine when used at the same time.
Instead, significant drug interactions caused by alternative therapies may make treatments less effective, notably in cancer therapy.
Besides the usual issues with alternative medicine, integrative medicine has been described as an attempt to bring pseudoscience into academic science-based medicine, leading to the pejorative term "quackademic medicine".
Due to its many names, the field has been criticized for intense rebranding of what are essentially the same practices.
CAM is an abbreviation of the phrase "complementary and alternative medicine".
It has also been called sCAM or SCAM with the addition of "so-called" or "supplements".
Traditional medicine refers to the pre-scientific practices of a certain culture, in contrast to what is typically practiced in cultures where medical science dominates.
"Eastern medicine" typically refers to the traditional medicines of Asia where conventional bio-medicine penetrated much later.
Holistic medicine is another rebranding of alternative medicine.
In this case, the words "balance" and "holism" are often used alongside "complementary" or "integrative", claiming to take into account a "whole" person, in contrast to the supposed reductionism of medicine.
Prominent members of the science and biomedical science community say that it is not meaningful to define an alternative medicine that is separate from a conventional medicine, because the expressions "conventional medicine", "alternative medicine", "complementary medicine", "integrative medicine", and "holistic medicine" do not refer to any medicine at all.
Others say that alternative medicine cannot be precisely defined because of the diversity of theories and practices it includes, and because the boundaries between alternative and conventional medicine overlap, are porous, and change.
Healthcare practices categorized as alternative may differ in their historical origin, theoretical basis, diagnostic technique, therapeutic practice and in their relationship to the medical mainstream.
Under a definition of alternative medicine as "non-mainstream", treatments considered alternative in one location may be considered conventional in another.
Critics say the expression is deceptive because it implies there is an effective alternative to science-based medicine, and that "complementary" is deceptive because it implies that the treatment increases the effectiveness of (complements) science-based medicine, while alternative medicines that have been tested nearly always have no measurable positive effect compared to a placebo.
It has been said that "there is really no such thing as alternative medicine, just medicine that works and medicine that doesn't", and that the very idea of "alternative" treatments is paradoxical because any treatment proven to work is by definition "medicine."
Alternative medicine consists of a wide range of health care practices, products, and therapies.
The shared feature is a claim to heal that is not based on the scientific method.
Alternative medicine practices are diverse in their foundations and methodologies.
Alternative medicine practices may be classified by their cultural origins or by the types of beliefs upon which they are based.
Methods may incorporate or be based on traditional medicinal practices of a particular culture, folk knowledge, superstition, spiritual beliefs, belief in supernatural energies (antiscience), pseudoscience, errors in reasoning, propaganda, fraud, new or different concepts of health and disease, and any bases other than being proven by scientific methods.
Different cultures may have their own unique traditional or belief based practices developed recently or over thousands of years, and specific practices or entire systems of practices.
Alternative medicine, such as using naturopathy or homeopathy in place of conventional medicine, is based on belief systems not grounded in science.
Naturopathic medicine is based on a belief that the body heals itself using a supernatural vital energy that guides bodily processes.
In conflict with the paradigm of evidence-based medicine.
Many naturopaths have opposed vaccination, and "scientific evidence does not support claims that naturopathic medicine can cure cancer or any other disease".
A belief that a substance that causes the symptoms of a disease in healthy people cures similar symptoms in sick people.
Developed before knowledge of atoms and molecules, or of basic chemistry, which shows that repeated dilution as practiced in homeopathy produces only water, and that homeopathy is not scientifically valid.
Alternative medical systems may be based on traditional medicine practices, such as traditional Chinese medicine (TCM), Ayurveda in India, or practices of other cultures around the world.
Some useful applications of traditional medicines have been researched and accepted within ordinary medicine, however the underlying belief systems are seldom scientific and are not accepted.
Traditional medicine is considered alternative when it is used outside its home region; or when it is used together with or instead of known functional treatment; or when it can be reasonably expected that the patient or practitioner knows or should know that it will not work – such as knowing that the practice is based on superstition.
Traditional Chinese medicine Traditional practices and beliefs from China, together with modifications made by the Communist party make up TCM.
Common practices include herbal medicine, acupuncture (insertion of needles in the body at specified points), massage (Tui na), exercise (qigong), and dietary therapy.
The practices are based on belief in a supernatural energy called qi, considerations of Chinese Astrology and Chinese numerology, traditional use of herbs and other substances found in China – a belief that the tongue contains a map of the body that reflects changes in the body, and an incorrect model of the anatomy and physiology of internal organs.
Ayurveda Traditional medicine of India.
Ayurveda believes in the existence of three elemental substances, the doshas (called Vata, Pitta and Kapha), and states that a balance of the doshas results in health, while imbalance results in disease.
Such disease-inducing imbalances can be adjusted and balanced using traditional herbs, minerals and heavy metals.
Ayurveda stresses the use of plant-based medicines and treatments, with some animal products, and added minerals, including sulfur, arsenic, lead and copper sulfate.
Safety concerns have been raised about Ayurveda, with two U.S. studies finding about 20 percent of Ayurvedic Indian-manufactured patent medicines contained toxic levels of heavy metals such as lead, mercury and arsenic.
A 2015 study of users in the United States also found elevated blood lead levels in 40 percent of those tested.
Other concerns include the use of herbs containing toxic compounds and the lack of quality control in Ayurvedic facilities.
Incidents of heavy metal poisoning have been attributed to the use of these compounds in the United States.
Bases of belief may include belief in existence of supernatural energies undetected by the science of physics, as in biofields, or in belief in properties of the energies of physics that are inconsistent with the laws of physics, as in energy medicine.
Biofield therapy Intended to influence energy fields that, it is purported, surround and penetrate the body.
Writers such as noted astrophysicist and advocate of skeptical thinking (Scientific skepticism) Carl Sagan (1934 – 1996) have described the lack of empirical evidence to support the existence of the putative energy fields on which these therapies are predicated.
Bioelectromagnetic therapy Use verifiable electromagnetic fields, such as pulsed fields, alternating-current, or direct-current fields in an unconventional manner.
Asserts that magnets can be used to defy the laws of physics to influence health and disease.
Chiropractic Spinal manipulation aims to treat "vertebral subluxations" which are claimed to put pressure on nerves.
Chiropractic was developed in the belief that manipulating the spine affects the flow of a supernatural vital energy and thereby affects health and disease.
Vertebral subluxation is a pseudoscientific concept and has not been proven to exist.
Reiki Practitioners place their palms on the patient near Chakras that they believe are centers of supernatural energies in the belief that these supernatural energies can transfer from the practitioner's palms to heal the patient.
Lacks credible scientific evidence.
Substance based practices use substances found in nature such as herbs, foods, non-vitamin supplements and megavitamins, animal and fungal products, and minerals, including use of these products in traditional medical practices that may also incorporate other methods.
Examples include healing claims for nonvitamin supplements, fish oil, Omega-3 fatty acid, glucosamine, echinacea, flaxseed oil, and ginseng.
Herbal medicine, or phytotherapy, includes not just the use of plant products, but may also include the use of animal and mineral products.
It is among the most commercially successful branches of alternative medicine, and includes the tablets, powders and elixirs that are sold as "nutritional supplements".
Only a very small percentage of these have been shown to have any efficacy, and there is little regulation as to standards and safety of their contents.
This may include use of known toxic substances, such as use of the poison lead in traditional Chinese medicine.
[citation needed] Christian faith healing There is a divine or spiritual intervention in healing.
Lack of evidence for effectiveness.
Unwanted outcomes, such as death and disability, "have occurred when faith healing was elected instead of medical care for serious injuries or illnesses".
A 2001 double-blind study of 799 discharged coronary surgery patients found that "intercessory prayer had no significant effect on medical outcomes after hospitalization in a coronary care unit."
A US agency, National Center on Complementary and Integrative Health (NCCIH), has created a classification system for branches of complementary and alternative medicine that divides them into five major groups.
These groups have some overlap, and distinguish two types of energy medicine: "veritable" which involves scientifically observable energy (including magnet therapy, colorpuncture and light therapy) and "putative", which invokes physically undetectable or unverifiable energy.
None of these energies have any evidence to support that they effect the body in any positive or health promoting way.
The history of alternative medicine may refer to the history of a group of diverse medical practices that were collectively promoted as "alternative medicine" beginning in the 1970 s, to the collection of individual histories of members of that group, or to the history of western medical practices that were labeled "irregular practices" by the western medical establishment.
It includes the histories of complementary medicine and of integrative medicine.
Before the 1970 s, western practitioners that were not part of the increasingly science-based medical establishment were referred to "irregular practitioners", and were dismissed by the medical establishment as unscientific and as practicing quackery.
Until the 1970 s, irregular practice became increasingly marginalized as quackery and fraud, as western medicine increasingly incorporated scientific methods and discoveries, and had a corresponding increase in success of its treatments.
In the 1970 s, irregular practices were grouped with traditional practices of nonwestern cultures and with other unproven or disproven practices that were not part of biomedicine, with the entire group collectively marketed and promoted under the single expression "alternative medicine".
Use of alternative medicine in the west began to rise following the counterculture movement of the 1960 s, as part of the rising new age movement of the 1970 s.
This was due to misleading mass marketing of "alternative medicine" being an effective "alternative" to biomedicine, changing social attitudes about not using chemicals and challenging the establishment and authority of any kind, sensitivity to giving equal measure to beliefs and practices of other cultures (cultural relativism), and growing frustration and desperation by patients about limitations and side effects of science-based medicine.
At the same time, in 1975, the American Medical Association, which played the central role in fighting quackery in the United States, abolished its quackery committee and closed down its Department of Investigation.
By the early to mid 1970 s the expression "alternative medicine" came into widespread use, and the expression became mass marketed as a collection of "natural" and effective treatment "alternatives" to science-based biomedicine.
By 1983, mass marketing of "alternative medicine" was so pervasive that the British Medical Journal (BMJ) pointed to "an apparently endless stream of books, articles, and radio and television programmes urge on the public the virtues of (alternative medicine) treatments ranging from meditation to drilling a hole in the skull to let in more oxygen".
An analysis of trends in the criticism of complementary and alternative medicine (CAM) in five prestigious American medical journals during the period of reorganization within medicine (1965 – 1999) was reported as showing that the medical profession had responded to the growth of CAM in three phases, and that in each phase, changes in the medical marketplace had influenced the type of response in the journals.
Changes included relaxed medical licensing, the development of managed care, rising consumerism, and the establishment of the USA Office of Alternative Medicine (later National Center for Complementary and Alternative Medicine, currently National Center for Complementary and Integrative Health).
Mainly as a result of reforms following the Flexner Report of 1910 medical education in established medical schools in the US has generally not included alternative medicine as a teaching topic.
Typically, their teaching is based on current practice and scientific knowledge about: anatomy, physiology, histology, embryology, neuroanatomy, pathology, pharmacology, microbiology and immunology.
Medical schools' teaching includes such topics as doctor-patient communication, ethics, the art of medicine, and engaging in complex clinical reasoning (medical decision-making).
Writing in 2002, Snyderman and Weil remarked that by the early twentieth century the Flexner model had helped to create the 20th - century academic health center, in which education, research, and practice were inseparable.
While this had much improved medical practice by defining with increasing certainty the pathophysiological basis of disease, a single-minded focus on the pathophysiological had diverted much of mainstream American medicine from clinical conditions that were not well understood in mechanistic terms, and were not effectively treated by conventional therapies.
By 2001 some form of CAM training was being offered by at least 75 out of 125 medical schools in the US.
Exceptionally, the School of Medicine of the University of Maryland, Baltimore includes a research institute for integrative medicine (a member entity of the Cochrane Collaboration).
Medical schools are responsible for conferring medical degrees, but a physician typically may not legally practice medicine until licensed by the local government authority.
Licensed physicians in the US who have attended one of the established medical schools there have usually graduated Doctor of Medicine (MD).
All states require that applicants for MD licensure be graduates of an approved medical school and complete the United States Medical Licensing Exam (USMLE).
There is a general scientific consensus that alternative therapies lack the requisite scientific validation, and their effectiveness is either unproved or disproved.
Many of the claims regarding the efficacy of alternative medicines are controversial, since research on them is frequently of low quality and methodologically flawed.
Selective publication bias, marked differences in product quality and standardisation, and some companies making unsubstantiated claims call into question the claims of efficacy of isolated examples where there is evidence for alternative therapies.
"The Scientific Review of Alternative Medicine" points to confusions in the general population – a person may attribute symptomatic relief to an otherwise-ineffective therapy just because they are taking something (the placebo effect); the natural recovery from or the cyclical nature of an illness (the regression fallacy) gets misattributed to an alternative medicine being taken; a person not diagnosed with science-based medicine may never originally have had a true illness diagnosed as an alternative disease category.
Edzard Ernst characterized the evidence for many alternative techniques as weak, nonexistent, or negative and in 2011 published his estimate that about 7.4 % were based on "sound evidence", although he believes that may be an overestimate.
Ernst has concluded that 95 % of the alternative therapies he and his team studied, including acupuncture, herbal medicine, homeopathy, and reflexology, are "statistically indistinguishable from placebo treatments", but he also believes there is something that conventional doctors can usefully learn from the chiropractors and homeopath: this is the therapeutic value of the placebo effect, one of the strangest phenomena in medicine.
In 2003, a project funded by the CDC identified 208 condition-treatment pairs, of which 58 % had been studied by at least one randomized controlled trial (RCT), and 23 % had been assessed with a meta-analysis.
According to a 2005 book by a US Institute of Medicine panel, the number of RCTs focused on CAM has risen dramatically.
, the Cochrane Library had 145 CAM-related Cochrane systematic reviews and 340 non-Cochrane systematic reviews.
An analysis of the conclusions of only the 145 Cochrane reviews was done by two readers.
In 83 % of the cases, the readers agreed.
In the 17 % in which they disagreed, a third reader agreed with one of the initial readers to set a rating.
These studies found that, for CAM, 38.4 % concluded positive effect or possibly positive (12.4 %), 4.8 % concluded no effect, 0.7 % concluded harmful effect, and 56.6 % concluded insufficient evidence.
An assessment of conventional treatments found that 41.3 % concluded positive or possibly positive effect, 20 % concluded no effect, 8.1 % concluded net harmful effects, and 21.3 % concluded insufficient evidence.
However, the CAM review used the more developed 2004 Cochrane database, while the conventional review used the initial 1998 Cochrane database.
Alternative therapies do not "complement" (improve the effect of, or mitigate the side effects of) functional medical treatment.
Significant drug interactions caused by alternative therapies may instead negatively impact functional treatment by making prescription drugs less effective, such as interference by herbal preparations with warfarin.
In the same way as for conventional therapies, drugs, and interventions, it can be difficult to test the efficacy of alternative medicine in clinical trials.
In instances where an established, effective, treatment for a condition is already available, the Helsinki Declaration states that withholding such treatment is unethical in most circumstances.
Use of standard-of-care treatment in addition to an alternative technique being tested may produce confounded or difficult-to-interpret results.
Cancer researcher Andrew J. Vickers has stated: A placebo is a medical treatment with no intended therapeutic value.
An example of a placebo is an inert pill, but it can include more dramatic interventions like sham surgery.
The "placebo effect" is the concept that patients will perceive an improvement after being treated with an inert treatment.
The opposite of the placebo effect is the "nocebo effect", when patients who expect a treatment to be harmful will perceive harmful effects after taking it.
Placebos do not have a physical effect on diseases or improve overall outcomes, but patients may report improvements in subjective outcomes such as pain and nausea.
A 1955 study suggested that a substantial part of a medicine's impact was due to the placebo effect.
However, reassessments found the study to have flawed methodology.
This and other modern reviews suggest that other factors like natural recovery and reporting bias should also be considered.
All of these are reasons why alternative therapies may be credited for improving a patient's condition even though the objective effect is non-existent, or even harmful.
David Gorski argues that alternatives treatments should be treated as a placebo, rather than as medicine.
Almost none have performed significantly better than a placebo in clinical trials.
Furthermore, distrust of conventional medicine may lead to patients experiencing the nocebo effect when taking effective medication.
A patient who receives an inert treatment may report improvements afterwards that it did not cause.
Assuming it was the cause without evidence is an example of the regression fallacy.
This may be due to a natural recovery from the illness, or a fluctuation in the symptoms of a long-term condition.
The concept of regression toward the mean implies that an extreme result is more likely to be followed by a less extreme result.
There are also reasons why a placebo treatment group may outperform a "no-treatment" group in a test which are not related to a patient's experience.
These include patients reporting more favourable results than they really felt due to politeness or "experimental subordination", observer bias, and misleading wording of questions.
In their 2010 systematic review of studies into placebos, Asbjørn Hróbjartsson and Peter C. Gøtzsche write that "even if there were no true effect of placebo, one would expect to record differences between placebo and no-treatment groups due to bias associated with lack of blinding."
Alternative therapies may also be credited for perceived improvement through decreased use or effect of medical treatment, and therefore either decreased side effects or nocebo effects towards standard treatment.
Practitioners of complementary medicine usually discuss and advise patients as to available alternative therapies.
Patients often express interest in mind-body complementary therapies because they offer a non-drug approach to treating some health conditions.
In addition to the social-cultural underpinnings of the popularity of alternative medicine, there are several psychological issues that are critical to its growth, notably psychological effects, such as the will to believe, cognitive biases that help maintain self-esteem and promote harmonious social functioning, and the "post hoc, ergo propter hoc" fallacy.
Alternative medicine is a highly profitable industry, with a strong lobby.
This fact is often overlooked by media or intentionally kept hidden, with alternative practice being portrayed positively when compared to "big pharma".
The popularity of complementary & alternative medicine (CAM) may be related to other factors that Edzard Ernst mentioned in an interview in "The Independent": Paul Offit proposed that "alternative medicine becomes quackery" in four ways: by recommending against conventional therapies that are helpful, promoting potentially harmful therapies without adequate warning, draining patients' bank accounts, or by promoting "magical thinking."
Promoting alternative medicine has been called dangerous and unethical.
Authors have speculated on the socio-cultural and psychological reasons for the appeal of alternative medicines among the minority using them "in lieu" of conventional medicine.
There are several socio-cultural reasons for the interest in these treatments centered on the low level of scientific literacy among the public at large and a concomitant increase in antiscientific attitudes and new age mysticism.
Related to this are vigorous marketing of extravagant claims by the alternative medical community combined with inadequate media scrutiny and attacks on critics.
Alternative medicine is criticized for taking advantage of the least fortunate members of society.
There is also an increase in conspiracy theories toward conventional medicine and pharmaceutical companies, mistrust of traditional authority figures, such as the physician, and a dislike of the current delivery methods of scientific biomedicine, all of which have led patients to seek out alternative medicine to treat a variety of ailments.
Many patients lack access to contemporary medicine, due to a lack of private or public health insurance, which leads them to seek out lower-cost alternative medicine.
Medical doctors are also aggressively marketing alternative medicine to profit from this market.
Patients can be averse to the painful, unpleasant, and sometimes-dangerous side effects of biomedical treatments.
Treatments for severe diseases such as cancer and HIV infection have well-known, significant side-effects.
Even low-risk medications such as antibiotics can have potential to cause life-threatening anaphylactic reactions in a very few individuals.
Many medications may cause minor but bothersome symptoms such as cough or upset stomach.
In all of these cases, patients may be seeking out alternative therapies to avoid the adverse effects of conventional treatments.
According to recent research, the increasing popularity of the CAM needs to be explained by moral convictions or lifestyle choices rather than by economic reasoning.
In developing nations, access to essential medicines is severely restricted by lack of resources and poverty.
Traditional remedies, often closely resembling or forming the basis for alternative remedies, may comprise primary healthcare or be integrated into the healthcare system.
In Africa, traditional medicine is used for 80 % of primary healthcare, and in developing nations as a whole over one-third of the population lack access to essential medicines.
Some have proposed adopting a prize system to reward medical research.
However, public funding for research exists.
In the US increasing the funding for research on alternative medicine is the purpose of the US National Center for Complementary and Alternative Medicine (NCCAM).
NCCAM has spent more than US $ 2.5 billion on such research since 1992 and this research has not demonstrated the efficacy of alternative therapies.
The NCCAM's sister organization in the NIC Office of Cancer Complementary and Alternative Medicine gives grants of around $ 105 million every year.
Testing alternative medicine that has no scientific basis has been called a waste of scarce research resources.
That alternative medicine has been on the rise "in countries where Western science and scientific method generally are accepted as the major foundations for healthcare, and ' evidence-based ' practice is the dominant paradigm" was described as an "enigma" in the Medical Journal of Australia.
In the United States, the 1974 Child Abuse Prevention and Treatment Act (CAPTA) required that for states to receive federal money, they had to grant religious exemptions to child neglect and abuse laws regarding religion-based healing practices.
Thirty-one states have child-abuse religious exemptions.
The use of alternative medicine in the US has increased, with a 50 percent increase in expenditures and a 25 percent increase in the use of alternative therapies between 1990 and 1997 in America.
Americans spend many billions on the therapies annually.
Most Americans used CAM to treat and/or prevent musculoskeletal conditions or other conditions associated with chronic or recurring pain.
In 2008, more than 37 % of American hospitals offered alternative therapies, up from 27 percent in 2005, and 25 % in 2004.
More than 70 % of the hospitals offering CAM were in urban areas.
A survey of Americans found that 88 percent thought that "there are some good ways of treating sickness that medical science does not recognize".
Use of magnets was the most common tool in energy medicine in America, and among users of it, 58 percent described it as at least "sort of scientific", when it is not at all scientific.
The most common CAM therapies used in the US in 2002 were prayer (45 %), herbalism (19 %), breathing meditation (12 %), meditation (8 %), chiropractic medicine (8 %), yoga (5 – 6 %), body work (5 %), diet-based therapy (4 %), progressive relaxation (3 %), mega-vitamin therapy (3 %) and Visualization (2 %) In Britain, the most often used alternative therapies were Alexander technique, Aromatherapy, Bach and other flower remedies, Body work therapies including massage, Counseling stress therapies, hypnotherapy, Meditation, Reflexology, Shiatsu, Ayurvedic medicine, Nutritional medicine, and Yoga.
Ayurvedic medicine remedies are mainly plant based with some use of animal materials.
Safety concerns include the use of herbs containing toxic compounds and the lack of quality control in Ayurvedic facilities.
According to the National Health Service (England), the most commonly used complementary and alternative medicines (CAM) supported by the NHS in the UK are: acupuncture, aromatherapy, chiropractic, homeopathy, massage, osteopathy and clinical hypnotherapy.
Complementary therapies are often used in palliative care or by practitioners attempting to manage chronic pain in patients.
From its early experiences of care for the dying, palliative care took for granted the necessity of placing patient values and lifestyle habits at the core of any design and delivery of quality care at the end of life.
If the patient desired complementary therapies, and as long as such treatments provided additional support and did not endanger the patient, they were considered acceptable.
"The non-pharmacologic interventions of complementary medicine can employ mind-body interventions designed to" reduce pain and concomitant mood disturbance and increase quality of life.
Some professions of complementary/traditional/alternative medicine, such as chiropractic, have achieved full regulation in North America and other parts of the world and are regulated in a manner similar to that governing science-based medicine.
In contrast, other approaches may be partially recognized and others have no regulation at all.
In some cases, promotion of alternative therapies is allowed when there is demonstrably no effect, only a tradition of use.
Despite laws making it illegal to market or promote alternative therapies for use in cancer treatment, many practitioners promote them.
Regulation and licensing of alternative medicine ranges widely from country to country, and state to state.
In Austria and Germany complementary and alternative medicine is mainly in the hands of doctors with MDs, and half or more of the American alternative practitioners are licensed MDs.
In Germany herbs are tightly regulated: half are prescribed by doctors and covered by health insurance.
Government bodies in the US and elsewhere have published information or guidance about alternative medicine.
The U.S. Food and Drug Administration (FDA), has issued online warnings for consumers about medication health fraud.
This includes a section on Alternative Medicine Fraud, such as a warning that Ayurvedic products generally have not been approved by the FDA before marketing.
Many of the claims regarding the safety and efficacy of alternative medicine are controversial.
Some alternative therapies have been associated with unexpected side effects, which can be fatal.
A commonly voiced concerns about complementary alternative medicine (CAM) is the way it's regulated.
There have been significant developments in how CAMs should be assessed prior to re-sale in the United Kingdom and the European Union (EU) in the last 2 years.
Despite this, it has been suggested that current regulatory bodies have been ineffective in preventing deception of patients as many companies have re-labelled their drugs to avoid the new laws.
There is no general consensus about how to balance consumer protection (from false claims, toxicity, and advertising) with freedom to choose remedies.
Advocates of CAM suggest that regulation of the industry will adversely affect patients looking for alternative ways to manage their symptoms, even if many of the benefits may represent the placebo affect. Some contend that alternative medicines should not require any more regulation than over-the-counter medicines that can also be toxic in overdose (such as paracetamol).
Forms of alternative medicine that are biologically active can be dangerous even when used in conjunction with conventional medicine.
Examples include immuno-augmentation therapy, shark cartilage, bioresonance therapy, oxygen and ozone therapies, and insulin potentiation therapy.
Some herbal remedies can cause dangerous interactions with chemotherapy drugs, radiation therapy, or anesthetics during surgery, among other problems.
An example of these dangers was reported by Associate Professor Alastair MacLennan of Adelaide University, Australia regarding a patient who almost bled to death on the operating table after neglecting to mention that she had been taking "natural" potions to "build up her strength" before the operation, including a powerful anticoagulant that nearly caused her death.
To "ABC Online", MacLennan also gives another possible mechanism: Conventional treatments are subjected to testing for undesired side-effects, whereas alternative therapies, in general, are not subjected to such testing at all.
Any treatment – whether conventional or alternative – that has a biological or psychological effect on a patient may also have potential to possess dangerous biological or psychological side-effects.
An exception to the normal thinking regarding side-effects is Homeopathy.
They are, thus, considered safe on that count, but "their products are exempt from good manufacturing practice requirements related to expiration dating and from finished product testing for identity and strength", and their alcohol concentration may be much higher than allowed in conventional drugs.
Alternative medicine may discourage people from getting the best possible treatment.
Those having experienced or perceived success with one alternative therapy for a minor ailment may be convinced of its efficacy and persuaded to extrapolate that success to some other alternative therapy for a more serious, possibly life-threatening illness.
For this reason, critics argue that therapies that rely on the placebo effect to define success are very dangerous.
According to mental health journalist Scott Lilienfeld in 2002, "unvalidated or scientifically unsupported mental health practices can lead individuals to forgo effective treatments" and refers to this as opportunity cost.
Individuals who spend large amounts of time and money on ineffective treatments may be left with precious little of either, and may forfeit the opportunity to obtain treatments that could be more helpful.
In short, even innocuous treatments can indirectly produce negative outcomes.
Between 2001 and 2003, four children died in Australia because their parents chose ineffective naturopathic, homeopathic, or other alternative medicines and diets rather than conventional therapies.
These alternative cancer cures have often been described as' unproven, ' suggesting that appropriate clinical trials have not been conducted and that the therapeutic value of the treatment is unknown.
"However," many alternative cancer treatments have been investigated in good-quality clinical trials, and they have been shown to be ineffective ...
The label ' unproven ' is inappropriate for such therapies; it is time to assert that many alternative cancer therapies have been ' disproven '.
Practitioners of science-based medicine also discard practices and treatments when they are shown ineffective, while alternative practitioners do not.
Funding for research is also sparse making it difficult to do further research for effectiveness of CAM.
Most funding for CAM is funded by government agencies.
Proposed research for CAM are rejected by most private funding agencies because the results of research are not reliable.
The research for CAM has to meet certain standards from research ethics committees, which most CAM researchers find almost impossible to meet.
Even with the little research done on it, CAM has not been proven to be effective.
Studies that have been done will be cited by CAM practitioners in an attempt to claim a basis in science.
These studies tend to have a variety of problems, such as small samples, various biases, poor research design, lack of controls, negative results, etc.
Even those with positive results can be better explained as resulting in false positives due to bias and noisy data.
Alternative medicine may lead to a false understanding of the body and of the process of science.
It is possible for a method to change categories (proven vs. unproven), based on increased knowledge of its effectiveness or lack thereof.
A prominent supporter of this position is George D. Lundberg, former editor of the Journal of the American Medical Association (JAMA).
Writing in 1999 in "CA: A Cancer Journal for Clinicians" Barrie R. Cassileth mentioned a 1997 letter to the US Senate Subcommittee on Public Health and Safety, which had deplored the lack of critical thinking and scientific rigor in OAM-supported research, had been signed by four Nobel Laureates and other prominent scientists.
(This was supported by the National Institutes of Health (NIH).
) In March 2009, a staff writer for "the Washington Post" reported that the impending national discussion about broadening access to health care, improving medical practice and saving money was giving a group of scientists an opening to propose shutting down the National Center for Complementary and Alternative Medicine.
Writers such as Carl Sagan, a noted astrophysicist, advocate of scientific skepticism and the author of "The Demon-Haunted World: Science as a Candle in the Dark" (1996), have lambasted the lack of empirical evidence to support the existence of the putative energy fields on which these therapies are predicated.
Sampson has also pointed out that CAM tolerated contradiction without thorough reason and experiment.
Barrett has pointed out that there is a policy at the NIH of never saying something doesn't work, only that a different version or dose might give different results.
Barrett also expressed concern that, just because some "alternatives" have merit, there is the impression that the rest deserve equal consideration and respect even though most are worthless, since they are all classified under the one heading of alternative medicine.
Some critics of alternative medicine are focused upon health fraud, misinformation, and quackery as public health problems, notably Wallace Sampson and Paul Kurtz founders of Scientific Review of Alternative Medicine and Stephen Barrett, co-founder of The National Council Against Health Fraud and webmaster of Quackwatch.
Grounds for opposing alternative medicine include that: Many alternative medical treatments are not patentable, which may lead to less research funding from the private sector.
In addition, in most countries, alternative therapies (in contrast to pharmaceuticals) can be marketed without any proof of efficacy – also a disincentive for manufacturers to fund scientific research.
CAM is also often less regulated than conventional medicine.
There are ethical concerns about whether people who perform CAM have the proper knowledge to treat patients.
CAM is often done by non-physicians who do not operate with the same medical licensing laws which govern conventional medicine, and it is often described as an issue of non-maleficence.
According to two writers, Wallace Sampson and K. Butler, marketing is part of the training required in alternative medicine, and propaganda methods in alternative medicine have been traced back to those used by Hitler and Goebels in their promotion of pseudoscience in medicine.
So far, alternative medicine has remained an ethics-free zone.
It is time to change this.
Edzard Ernst has said that most researchers into alternative medicine are at risk of "unidirectional bias" because of a generally uncritical belief in their chosen subject.
Ernst cites as evidence the phenomenon whereby 100 % of a sample of acupuncture trials originating in China had positive conclusions.
David Gorski contrasts evidence-based medicine, in which researchers try to disprove hyphotheses, with what he says is the frequent practice in pseudoscience-based research, of striving to confirm pre-existing notions.
Harriet Hall writes that there is a contrast between the circumstances of alternative medicine practitioners and disinterested scientists: in the case of acupuncture, for example, an acupuncturist would have "a great deal to lose" if acupuncture were rejected by research; but the disinterested skeptic would not lose anything if its effects were confirmed; rather their change of mind would enhance their skeptical credentials.
diverting research time, money, and other resources from more fruitful lines of investigation in order to pursue a theory that has no basis in biology.
"Research methods expert and author of" Snake Oil Science ", R. Barker Bausell, has stated that" it's become politically correct to investigate nonsense.
In geometry, an Archimedean solid is one of the 13 solids first enumerated by Archimedes.
They are the convex uniform polyhedra composed of regular polygons meeting in identical vertices, excluding the 5 Platonic solids (which are composed of only one type of polygon) and excluding the prisms and antiprisms.
They differ from the Johnson solids, whose regular polygonal faces do not meet in identical vertices.
"Identical vertices" means that each two vertices are symmetric to each other: A global isometry of the entire solid takes one vertex to the other while laying the solid directly on its initial position.
observed that a 14th polyhedron, the elongated square gyrobicupola (or pseudo-rhombicuboctahedron), meets a weaker definition of an Archimedean solid, in which "identical vertices" means merely that the faces surrounding each vertex are of the same types (i.e. each vertex looks the same from close up), so only a local isometry is required.
Grünbaum pointed out a frequent error in which authors define Archimedean solids using this local definition but omit the 14th polyhedron.
If only 13 polyhedra are to be listed, the definition must use global symmetries of the polyhedron rather than local neighborhoods.
Prisms and antiprisms, whose symmetry groups are the dihedral groups, are generally not considered to be Archimedean solids, even though their faces are regular polygons and their symmetry groups act transitively on their vertices.
Excluding these two infinite families, there are 13 Archimedean solids.
All the Archimedean solids (but not the elongated square gyrobicupola) can be made via Wythoff constructions from the Platonic solids with tetrahedral, octahedral and icosahedral symmetry.
The Archimedean solids take their name from Archimedes, who discussed them in a now-lost work.
Pappus refers to it, stating that Archimedes listed 13 polyhedra.
During the Renaissance, artists and mathematicians valued "pure forms" with high symmetry, and by around 1620 Johannes Kepler had completed the rediscovery of the 13 polyhedra, as well as defining the prisms, antiprisms, and the non-convex solids known as Kepler-Poinsot polyhedra.
The reader may find more information about the rediscovery of the Archimedean solids during the renaissance in the paper by Peter Schreiber et al., published in 2008 (see References below).
Kepler may have also found the elongated square gyrobicupola (pseudorhombicuboctahedron): at least, he once stated that there were 14 Archimedean solids.
However, his published enumeration only includes the 13 uniform polyhedra, and the first clear statement of the pseudorhombicuboctahedron's existence was made in 1905, by Duncan Sommerville.
There are 13 Archimedean solids (not counting the elongated square gyrobicupola; 15 if the mirror images of two enantiomorphs, the snub cube and snub dodecahedron, are counted separately).
Here the "vertex configuration" refers to the type of regular polygons that meet at any given vertex.
For example, a vertex configuration of (4,6,8) means that a square, hexagon, and octagon meet at a vertex (with the order taken to be clockwise around the vertex).
8 triangles < br > 18 squares 32 triangles < br > 6 squares 20 triangles < br > 12 decagons 30 squares < br > 20 hexagons < br > 12 decagons Some definitions of semiregular polyhedron include one more figure, the elongated square gyrobicupola or "pseudo-rhombicuboctahedron".
The number of vertices is 720 ° divided by the vertex angle defect.
The cuboctahedron and icosidodecahedron are edge-uniform and are called quasi-regular.
The duals of the Archimedean solids are called the Catalan solids.
Together with the bipyramids and trapezohedra, these are the face-uniform solids with regular vertices.
The snub cube and snub dodecahedron are known as "chiral", as they come in a left-handed (Latin: levomorph or laevomorph) form and right-handed (Latin: dextromorph) form.
When something comes in multiple forms which are each other's three-dimensional mirror image, these forms may be called enantiomorphs.
(This nomenclature is also used for the forms of certain chemical compounds).
The different Archimedean and Platonic solids can be related to each other using a handful of general constructions.
Starting with a Platonic solid, truncation involves cutting away of corners.
To preserve symmetry, the cut is in a plane perpendicular to the line joining a corner to the center of the polyhedron and is the same for all corners.
Depending on how much is truncated (see table below), different Platonic and Archimedean (and other) solids can be created.
If the truncation is exactly deep enough such that each pair of faces from adjacent vertices shares exactly one point, it is known as a rectification.
An expansion, or cantellation, involves moving each face away from the center (by the same distance so as to preserve the symmetry of the Platonic solid) and taking the convex hull.
Expansion with twisting also involves rotating the faces, thus splitting each rectangle corresponding to an edge into two triangles by one of the diagonals of the rectangle.
The last construction we use here is truncation of both corners and edges.
Ignoring scaling, expansion can also be viewed the rectification of the rectification.
Likewise, the cantitruncation can be viewed as the truncation of the rectification.
+ Construction of Archimedean Solids Note the duality between the cube and the octahedron, and between the dodecahedron and the icosahedron.
Also, partially because the tetrahedron is self-dual, only one Archimedean solid that has at most tetrahedral symmetry.
(All Platonic solids have at least tetrahedral symmetry, as tetrahedral symmetry is a symmetry operation of (i.e. is included in) octahedral and isohedral symmetries, which is demonstrated by the fact that an octahedron can be viewed as a rectified tetrahedron, and an icosahedron can be used as a snub tetrahedron.
)
bgcolor =# e7dcc3Typeuniform polyhedron bgcolor =# e7dcc3Faces2 "n" - gons, 2 "n" triangles bgcolor =# e7dcc3Edges4 "n" bgcolor =# e7dcc3Vertices2 "n" bgcolor =# e7dcc3Conway polyhedron notationA "n" bgcolor =# e7dcc3Vertex configuration3.
3.3.
"n" bgcolor =# e7dcc3Coxeter diagrams < br > bgcolor =# e7dcc3Symmetry groupD, [2,2 "n"], (2 * "n"), order 4 "n" bgcolor =# e7dcc3Rotation groupD, [2, "n"], (22 "n"), order 2 "n" bgcolor =# e7dcc3Dual polyhedrontrapezohedron bgcolor =# e7dcc3Propertiesconvex, semi-regular vertex-transitive bgcolor =# e7dcc3Net In geometry, an "n" - sided antiprism is a polyhedron composed of two parallel copies of some particular "n" - sided polygon, connected by an alternating band of triangles.
Antiprisms are a subclass of the prismatoids and are a (degenerate) type of snub polyhedron.
Antiprisms are similar to prisms except the bases are twisted relative to each other, and that the side faces are triangles, rather than quadrilaterals.
In the case of a regular "n" - sided base, one usually considers the case where its copy is twisted by an angle.
Extra regularity is obtained when the line connecting the base centers is perpendicular to the base planes, making it a right antiprism.
As faces, it has the two "n" - gonal bases and, connecting those bases, 2 "n" isosceles triangles.
A uniform antiprism has, apart from the base faces, 2 "n" equilateral triangles as faces.
As a class, the uniform antiprisms form an infinite series of vertex-uniform polyhedra, as do the uniform prisms.
For we have as degenerate case the regular tetrahedron as a "digonal antiprism", and for the non-degenerate regular octahedron as a "triangular antiprism".
The dual polyhedra of the antiprisms are the trapezohedra.
Their existence was discussed and their name was coined by Johannes Kepler, though it is possible that they were previously known to Archimedes as they satisfy the same conditions on vertices as the Archimedean solids.
< BR > A3 < BR > A4 < BR > A5 < BR > A6 < BR > A7 < BR > A8 Cartesian coordinates for the vertices of a right antiprism with "n" - gonal bases and isosceles triangles are with "k" ranging from 0 to 2 "n" − 1; if the triangles are equilateral, Let "a" be the edge-length of a uniform antiprism.
Then the volume is and the surface area is There are an infinite set of truncated antiprisms, including a lower-symmetry form of the truncated octahedron (truncated triangular antiprism).
These can be alternated to create snub antiprisms, two of which are Johnson solids, and the "snub triangular antiprism" is a lower symmetry form of the icosahedron.
s { 2,4 } s { 2,6 } s { 2,8 } s { 2,10 } ts { 2,6 } ss { 2,4 } ss { 2,6 } ss { 2,8 } ss { 2,2 n } The symmetry group of a right "n" - sided antiprism with regular base and isosceles side faces is D of order 4 "n", except in the case of a tetrahedron, which has the larger symmetry group T of order 24, which has three versions of D as subgroups, and the octahedron, which has the larger symmetry group O of order 48, which has four versions of D as subgroups.
The symmetry group contains inversion if and only if "n" is odd.
The rotation group is D of order 2 "n", except in the case of a tetrahedron, which has the larger rotation group T of order 12, which has three versions of D as subgroups, and the octahedron, which has the larger rotation group O of order 24, which has four versions of D as subgroups.
colspan =3 < BR > 5/2-antiprism colspan =3 < BR > 5/3-antiprism colspan = 2 < BR > 9/2-antiprism colspan = 2 < BR > 9/4-antiprism colspan = 2 < BR > 9/5-antiprism Uniform star antiprisms are named by their star polygon bases, { "p"/"q" }, and exist in prograde and retrograde (crossed) solutions.
Crossed forms have intersecting vertex figures, and are denoted by inverted fractions, "p"/("p" - "q") instead of "p"/"q", e.g. 5/3 instead of 5/2.
In the retrograde forms but not in the prograde forms, the triangles joining the star bases intersect the axis of rotational symmetry.
Some retrograde star antiprisms with regular star polygon bases cannot be constructed with equal edge lengths, so are not uniform polyhedra.
Star antiprism compounds also can be constructed where "p" and "q" have common factors; thus a 10/4 antiprism is the compound of two 5/2 star antiprisms.
colspan = 4 colspan =3 colspan = 4
The natural history of Africa encompasses some of the well known megafauna of that continent.
Natural history is the study and description of organisms and natural objects, especially their origins, evolution, and interrelationships.
The vegetation of Africa follows very closely the distribution of heat and moisture.
The northern and southern temperate zones have a flora distinct from that of the continent generally, which is tropical.
In the countries bordering the Mediterranean, there are groves of orange and olive trees, evergreen oaks, cork trees and pines, intermixed with cypresses, myrtles, arbutus and fragrant tree-heaths.
South of the Atlas Range the conditions alter.
The zones of minimum rainfall have a very scanty flora, consisting of plants adapted to resist the great dryness.
Characteristic of the Sahara is the date palm, which flourishes where other vegetation can scarcely maintain existence, while in the semidesert regions the acacia, from which gum arabic is obtained, is abundant.
The more humid regions have a richer vegetation; dense forest where the rainfall is greatest and variations of temperature least, conditions found chiefly on the tropical coasts, and in the west African equatorial basin with its extension towards the upper Nile; and savanna interspersed with trees on the greater part of the plateaus, passing as the desert regions are approached into a scrub vegetation consisting of thorny acacias, etc.
Forests also occur on the humid slopes of mountain ranges up to a certain elevation.
In the coast regions the typical tree is the mangrove, which flourishes wherever the soil is of a swamp character.
The dense forests of West Africa contain, in addition to a great variety of hardwoods, two palms, "Elaeis guineensis" (oil palm) and "Raphia vinifera" (bamboo palm), not found, generally speaking, in the savanna regions.
"Bombax" or silk-cotton trees attain gigantic proportions in the forests, which are the home of the India rubber-producing plants and of many valuable kinds of timber trees, such as odum ("Chlorophora excelsa"), ebony, mahogany ("Khaya senegalensis"), Oldfieldia ("Oldfieldia africana") and camwood ("Baphia nitida").
The climbing plants in the tropical forests are exceedingly luxuriant and the undergrowth or "bush" is extremely dense.
In the savannas the most characteristic trees are the monkey bread tree or baobab ("Adansonia digitata"), doum palm ("Hyphaene") and euphorbias.
The coffee plant grows wild in such widely separated places as Liberia and southern Ethiopia.
The higher mountains have a special flora showing close agreement over wide intervals of space, as well as affinities with the mountain flora of the eastern Mediterranean, the Himalaya and Indo-China.
In the swamp regions of north-east Africa papyrus and associated plants, including the soft-wooded ambach, flourished in immense quantities, and little else is found in the way of vegetation.
South Africa is largely destitute of forest save in the lower valleys and coast regions.
Tropical flora disappears, and in the semi-desert plains the fleshy, leafless, contorted species of kapsias, mesembryanthemums, aloes and other succulent plants make their appearance.
There are, too, valuable timber trees, such as the Yellow-wood ("Podocarpus elongatus"), stinkwood ("Ocotea"), sneezewood or Cape ebony ("Pteroxylon utile") and ironwood.
Extensive miniature woods of heaths are found in almost endless variety and covered throughout the greater part of the year with innumerable blossoms in which red is very prevalent.
Of the grasses of Africa alfa is very abundant in the plateaus of the Atlas range.
The fauna again shows the effect of the characteristics of the vegetation.
The open savannas are the home of large ungulates, especially antelopes, the giraffe (peculiar to Africa), zebra, buffalo, wild donkey and four species of rhinoceros; and of carnivores, such as the lion, leopard, hyena, etc.
The okapi (a genus restricted to Africa) is found only in the dense forests of the Congo basin.
Bears are confined to the Atlas region, wolves and foxes to North Africa.
The elephant (though its range has become restricted through the attacks of hunters) is found both in the savannas and forest regions, the latter being otherwise poor in large game, though the special habitat of the chimpanzee and gorilla.
Baboons and mandrills, with few exceptions, are peculiar to Africa.
The single-humped camel, as a domestic animal, is especially characteristic of the northern deserts and steppes.
The rivers in the tropical zone abound with hippopotami and crocodiles, the former entirely confined to Africa.
The vast herds of game, formerly so characteristic of many parts of Africa, have much diminished with the increase of intercourse with the interior.
Game reserves have, however, been established in South Africa, British Central Africa, British East Africa, Somaliland, etc., while measures for the protection of wild animals were laid down in an international convention signed in May 1900.
The ornithology of northern Africa presents a close resemblance to that of southern Europe, scarcely a species being found which does not also occur in the other countries bordering the Mediterranean.
Among the birds most characteristic of Africa are the ostrich and the secretary-bird.
The ostrich is widely dispersed, but is found chiefly in the desert and steppe regions.
The secretary-bird is common in the south.
The weaver birds and their allies, including the long-tailed whydahs, are abundant, as are, among game-birds, the francolin and guineafowl.
Many of the smaller birds, such as the sunbirds, bee-eaters, the parrots and kingfishers, as well as the larger plantain-eaters, are noted for the brilliance of their feathers.
Of reptiles the lizard and chameleon are common, and there are a number of venomous snakes, though these are not so numerous as in other tropical countries.
The scorpion is abundant.
Of insects Africa has many thousand different kinds; of these the locust is the proverbial scourge of the continent, and the ravages of the termites are almost incredible.
The spread of malaria by means of mosquitoes is common.
The tsetse fly, whose bite is fatal to all domestic animals, is common in many districts of South and East Africa.
It is found nowhere outside Africa.
Africa is a continent comprising 63 political territories, representing the largest of the great southward projections from the main mass of Earth's surface.
Within its regular outline, it comprises an area of, excluding adjacent islands.
Its highest mountain is Mount Kilimanjaro, its largest lake is Lake Victoria.
Separated from Europe by the Mediterranean Sea and from much of Asia by the Red Sea, Africa is joined to Asia at its northeast extremity by the Isthmus of Suez (which is transected by the Suez Canal), wide.
For geopolitical purposes, the Sinai Peninsula of Egypt – east on the Suez Canal – is often considered part of Africa.
From the most northerly point, Ras ben Sakka in Tunisia, at 37 ° 21 ′ N, to the more southerly point, Cape Agulhas in South Africa, 34 ° 51 ′ 15 ″ S, is a distance approximately of; from Cap-Vert, 17 ° 31 ′ 13 ″ W, the westernmost point, to Ras Hafun in the Somali Puntland region, in the Horn of Africa, 51 ° 27 ′ 52 ″ E, the most easterly projection, is a distance (also approximately) of.
The main structural lines of the continent show both the east-to-west direction characteristic, at least in the eastern hemisphere, of the more northern parts of the world, and the north-to-south direction seen in the southern peninsulas.
Africa is thus mainly composed of two segments at right angles, the northern running from east to west, and the southern from north to south.
The average elevation of the continent approximates closely to above sea level, roughly near to the mean elevation of both North and South America, but considerably less than that of Asia,.
In contrast with other continents, it is marked by the comparatively small area of either very high or very low ground, lands under occupying an unusually small part of the surface; while not only are the highest elevations inferior to those of Asia or South America, but the area of land over is also quite insignificant, being represented almost entirely by individual peaks and mountain ranges.
Moderately elevated tablelands are thus the characteristic feature of the continent, though the surface of these is broken by higher peaks and ridges.
(So prevalent are these isolated peaks and ridges that a specialised term ["Inselberg-Landschaft", island mountain landscape] has been adopted in Germany to describe this kind of country, thought to be in great part the result of wind action.
) As a general rule, the higher tablelands lie to the east and south, while a progressive diminution in altitude towards the west and north is observable.
Apart from the lowlands and the Atlas mountain range, the continent may be divided into two regions of higher and lower plateaus, the dividing line (somewhat concave to the north-west) running from the middle of the Red Sea to about 6 deg.
S. on the west coast.
Africa can be divided into a number of geographic zones: The high southern and eastern plateaus, rarely falling below, have a mean elevation of about.
The South African Plateau, as far as about 12 ° S, is bounded east, west and south by bands of high ground which fall steeply to the coasts.
On this account South Africa has a general resemblance to an inverted saucer.
Due south, the plateau rim is formed by three parallel steps with level ground between them.
The largest of these level areas, the Great Karoo, is a dry, barren region, and a large tract of the plateau proper is of a still more arid character and is known as the Kalahari Desert.
The South African Plateau is connected towards East African plateau, with probably a slightly greater average elevation, and marked by some distinct features.
It is formed by a widening out of the eastern axis of high ground, which becomes subdivided into a number of zones running north and south and consisting in turn of ranges, tablelands and depressions.
The most striking feature is the existence of two great lines of depression, due largely to the subsidence of whole segments of the Earth's crust, the lowest parts of which are occupied by vast lakes.
Towards the south the two lines converge and give place to one great valley (occupied by Lake Nyasa), the southern part of which is less distinctly due to rifting and subsidence than the rest of the system.
Farther north the western hollow, known as the Albertine Rift, is occupied for more than half its length by water, forming the Great Lakes of Tanganyika, Kivu, Lake Edward and Lake Albert, the first-named over long and the longest freshwater lake in the world.
Associated with these great valleys are a number of volcanic peaks, the greatest of which occur on a meridional line east of the eastern trough.
The eastern branch of the East African Rift, contains much smaller lakes, many of them brackish and without outlet, the only one comparable to those of the western trough being Lake Turkana or Basso Norok.
A short distance east of this rift-valley is Mount Kilimanjaro — with its two peaks Kibo and Mawenzi, the latter being, and the culminating point of the whole continent — and Mount Kenya, which is.
Hardly less important is the Ruwenzori Range, over, which lies east of the western trough.
Other volcanic peaks rise from the floor of the valleys, some of the Kirunga (Mfumbiro) group, north of Lake Kivu, being still partially active.
This could cause most of the cities and states to be flooded with lava and ash.
The third division of the higher region of Africa is formed by the Ethiopian Highlands, a rugged mass of mountains forming the largest continuous area of its altitude in the whole continent, little of its surface falling below, while the summits reach heights of 4400 m to 4550 m.
This block of country lies just west of the line of the great East African Trough, the northern continuation of which passes along its eastern escarpment as it runs up to join the Red Sea.
There is, however, in the centre a circular basin occupied by Lake Tsana.
Both in the east and west of the continent the bordering highlands are continued as strips of plateau parallel to the coast, the Ethiopian mountains being continued northwards along the Red Sea coast by a series of ridges reaching in places a height of.
In the west the zone of high land is broader but somewhat lower.
The most mountainous districts lie inland from the head of the Gulf of Guinea (Adamawa, etc.)
, where heights of are reached.
Exactly at the head of the gulf the great peak of the Cameroon, on a line of volcanic action continued by the islands to the south-west, has a height of, while Clarence Peak, in Fernando Po, the first of the line of islands, rises to over.
Towards the extreme west the Futa Jallon highlands form an important diverging point of rivers, but beyond this, as far as the Atlas chain, the elevated rim of the continent is almost wanting.
Much of Africa is made up of plains of the pediplain and etchplain type often occurring as steps.
The etchplains are commonly associated with laterite soil and inselbergs.
Inselberg-dotted plains are common in Africa including Tanzania, the Anti-Atlas of Morocco, Namibia, and the interior of Angola.
One of the most wideaspread plain is the African Surface, a composite etchplain occurring across much of the continent.
The area between the east and west coast highlands, which north of 17 ° N is mainly desert, is divided into separate basins by other bands of high ground, one of which runs nearly centrally through North Africa in a line corresponding roughly with the curved axis of the continent as a whole.
The best marked of the basins so formed (the Congo basin) occupies a circular area bisected by the equator, once probably the site of an inland sea.
Running along the south of desert is the plains region known as the Sahel.
The arid region, the Sahara — the largest hot desert in the world, covering — extends from the Atlantic to the Red Sea.
Though generally of slight elevation, it contains mountain ranges with peaks rising to Bordered N.W. by the Atlas range, to the northeast a rocky plateau separates it from the Mediterranean; this plateau gives place at the extreme east to the delta of the Nile.
That river (see below) pierces the desert without modifying its character.
The Atlas range, the north-westerly part of the continent, between its seaward and landward heights encloses elevated steppes in places broad.
From the inner slopes of the plateau numerous wadis take a direction towards the Sahara.
The greater part of that now desert region is, indeed, furrowed by old water-channels.
The mountains are an exception to Africa's general landscape.
Geographers came up with the idea of "high Africa" and "low Africa" to help distinguish the difference in Geography; "high Africa" extending from Ethiopia down south to South Africa and the Cape of Good Hope while "low Africa" representing the plains of the rest of the continent.
The following table gives the details of the chief mountains and ranges of the continent: From the outer margin of the African plateaus, a large number of streams run to the sea with comparatively short courses, while the larger rivers flow for long distances on the interior highlands, before breaking through the outer ranges.
The main drainage of the continent is to the north and west, or towards the basin of the Atlantic Ocean.
To the main African rivers belong: Nile (the longest river of Africa), Congo (river with the highest water discharge on the continent) and the Niger, which flows half of its length through the arid areas.
The largest lakes are the following: Lake Victoria (Lake Ukerewe), Lake Chad, in the centre of the continent, Lake Tanganyika, lying between the Democratic Republic of Congo, Burundi, Tanzania and Zambia.
There is also the considerably large Lake Malawi stretching along the eastern border of one of the poorest countries in the world - Malawi.
There are also numerous water dams throughout the continent: Kariba on the river of Zambezi, Asuan in Egypt on the river of Nile and the biggest dam of the continent lying completely in The republic of Ghana is called Akosombo on the Volta river (Fobil 2003).
The high lake plateau of the African Great Lakes region contains the headwaters of both the Nile and the Congo.
The break-up of Gondwana in Late Cretaceous and Cenozoic times led to a major reorganization of the river courses of various large African rivers including the Congo, Niger, Nile, Orange, Limpopo and Zambezi rivers.
The upper Nile receives its chief supplies from the mountainous region adjoining the Central African trough in the neighborhood of the equator.
From there, streams pour eastward into Lake Victoria, the largest lake in Africa (covering over 26,000 square m.)
, and to the west and north into Lake Edward and Lake Albert.
To the latter of these, the effluents of the other two lakes add their waters.
Issuing from there, the Nile flows northward, and between the latitudes of 7 and 10 degrees north it traverses a vast marshy level, where its course is liable to being blocked by floating vegetation.
After receiving the Bahr-el-Ghazal from the west and the Sobat, Blue Nile and Atbara from the Ethiopian Highlands (the chief gathering ground of the flood-water), it separates the great desert with its fertile watershed, and enters the Mediterranean at a vast delta.
The most remote head-stream of the Congo is the Chambezi, which flows southwest into the marshy Lake Bangweulu.
From this lake issues the Congo, known in its upper course by various names.
Flowing first south, it afterwards turns north through Lake Mweru and descends to the forest-clad basin of west equatorial Africa.
Traversing this in a majestic northward curve, and receiving vast supplies of water from many great tributaries, it finally turns southwest and cuts a way to the Atlantic Ocean through the western highlands.
The area of the Congo basin is greater than that of any other river except the Amazon, while the African inland drainage area is greater than that of any continent but Asia, where the corresponding area is.
West of Lake Chad is the basin of the Niger, the third major river of Africa.
With its principal source in the far west, it reverses the direction of flow exhibited by the Nile and Congo, and ultimately flows into the Atlantic — a fact that eluded European geographers for many centuries.
An important branch, however — the Benue—flows from the southeast.
These four river basins occupy the greater part of the lower plateaus of North and West Africa — the remainder consists of arid regions watered only by intermittent streams that do not reach the sea.
Of the remaining rivers of the Atlantic basin, the Orange, in the extreme south, brings the drainage from the Drakensberg on the opposite side of the continent, while the Kunene, Kwanza, Ogowe and Sanaga drain the west coastal highlands of the southern limb; the Volta, Komoe, Bandama, Gambia and Senegal the highlands of the western limb.
North of the Senegal, for over of coast, the arid region reaches to the Atlantic.
Farther north are the streams, with comparatively short courses, reaching the Atlantic and Mediterranean from the Atlas mountains.
Of the rivers flowing to the Indian Ocean, the only one draining any large part of the interior plateaus is the Zambezi, whose western branches rise in the western coastal highlands.
The main stream has its rise in 11 ° 21 ′ 3 ″ S 24 ° 22 ′ E, at an elevation of.
It flows to the west and south for a considerable distance before turning eastward.
All the largest tributaries, including the Shire, the outflow of Lake Nyasa, flow down the southern slopes of the band of high ground stretching across the continent from 10 ° to 12 ° S. In the southwest, the Zambezi system interlaces with that of the Taukhe (or Tioghe), from which it at times receives surplus water.
The rest of the water of the Taukhe, known in its middle course as the Okavango, is lost in a system of swamps and saltpans that was formerly centred in Lake Ngami, now dried up.
Farther south, the Limpopo drains a portion of the interior plateau, but breaks through the bounding highlands on the side of the continent nearest its source.
The Rovuma, Rufiji and Tana principally drain the outer slopes of the African Great Lakes highlands.
In the Horn region to the north, the Jubba and the Shebelle rivers begin in the Ethiopian Highlands.
These rivers mainly flow southwards, with the Jubba emptying in the Indian Ocean.
The Shebelle River reaches a point to the southwest.
After that, it consists of swamps and dry reaches before finally disappearing in the desert terrain near the Jubba River.
Another large stream, the Hawash, rising in the Ethiopian mountains, is lost in a saline depression near the Gulf of Aden.
Between the basins of the Atlantic and Indian Oceans, there is an area of inland drainage along the centre of the Ethiopian plateau, directed chiefly into the lakes in the Great Rift Valley.
The largest river is the Omo, which, fed by the rains of the Ethiopian highlands, carries down a large body of water into Lake Rudolf.
The rivers of Africa are generally obstructed either by bars at their mouths, or by cataracts at no great distance upstream.
But when these obstacles have been overcome, the rivers and lakes afford a vast network of navigable waters.
North of the Congo basin, and separated from it by a broad undulation of the surface, is the basin of Lake Chad – a flat-shored, shallow lake filled principally by the Chari coming from the southeast.
The principal lakes of Africa are situated in the African Great Lakes plateau.
The lakes found within the Great Rift Valley have steep sides and are very deep.
This is the case with the two largest of the type, Tanganyika and Nyasa, the latter with depths of.
Others, however, are shallow, and hardly reach the steep sides of the valleys in the dry season.
Such are Lake Rukwa, in a subsidiary depression north of Nyasa, and Eiassi and Manyara in the system of the Great Rift Valley.
Lakes of the broad type are of moderate depth, the deepest sounding in Lake Victoria being under.
Besides the African Great Lakes, the principal lakes on the continent are: Lake Chad, in the northern inland watershed; Bangweulu and Mweru, traversed by the head-stream of the Congo; and Lake Mai-Ndombe and Ntomba (Mantumba), within the great bend of that river.
All, except possibly Mweru, are more or less shallow, and Lake Chad appears to be drying up.
Divergent opinions have been held as to the mode of origin of the African Great Lakes, especially Tanganyika, which some geologists have considered to represent an old arm of the sea, dating from a time when the whole central Congo basin was under water; others holding that the lake water has accumulated in a depression caused by subsidence.
The former view is based on the existence in the lake of organisms of a decidedly marine type.
They include jellyfish, molluscs, prawns, crabs, etc.
With the exception of Madagascar, the African islands are small.
Madagascar, with an area of, is, after Greenland, New Guinea and Borneo, the fourth largest island on the Earth.
It lies in the Indian Ocean, off the S.E. coast of the continent, from which it is separated by the deep Mozambique channel, wide at its narrowest point.
Madagascar in its general structure, as in flora and fauna, forms a connecting link between Africa and southern Asia.
East of Madagascar are the small islands of Mauritius and Réunion.
There are also islands in the Gulf of Guinea on which lies the Republic of São Tomé and Príncipe (islands of São Tomé and Príncipe).
Part of the Republic of Equatorial Guinea is lying on the island of Bioko (with the capital Malabo and the town of Lubu) and the island of Annobón.
Socotra lies E.N.E. of Cape Guardafui.
Off the north-west coast are the Canary and Cape Verde archipelagoes.
which, like some small islands in the Gulf of Guinea, are of volcanic origin.
The South Atlantic Islands of Saint Helena and Ascension are classed as Africa but are situated on the Mid-Atlantic Ridge half way to South America.
Lying almost entirely within the tropics, and equally to north and south of the equator, Africa does not show excessive variations of temperature.
Great heat is experienced in the lower plains and desert regions of North Africa, removed by the great width of the continent from the influence of the ocean, and here, too, the contrast between day and night, and between summer and winter, is greatest.
(The rarity of the air and the great radiation during the night cause the temperature in the Sahara to fall occasionally to freezing point.)
Farther south, the heat is to some extent modified by the moisture brought from the ocean, and by the greater elevation of a large part of the surface, especially in East Africa, where the range of temperature is wider than in the Congo basin or on the Guinea coast.
In the extreme north and south the climate is a warm temperate one, the northern countries being on the whole hotter and drier than those in the southern zone; the south of the continent being narrower than the north, the influence of the surrounding ocean is more felt.
The most important climatic differences are due to variations in the amount of rainfall.
The wide heated plains of the Sahara, and in a lesser degree the corresponding zone of the Kalahari in the south, have an exceedingly scanty rainfall, the winds which blow over them from the ocean losing part of their moisture as they pass over the outer highlands, and becoming constantly drier owing to the heating effects of the burning soil of the interior; while the scarcity of mountain ranges in the more central parts likewise tends to prevent condensation.
In the inter-tropical zone of summer precipitation, the rainfall is greatest when the sun is vertical or soon after.
It is therefore greatest of all near the equator, where the sun is twice vertical, and less in the direction of both tropics.
The rainfall zones are, however, somewhat deflected from a due west-to-east direction, the drier northern conditions extending southwards along the east coast, and those of the south northwards along the west. Within the equatorial zone certain areas, especially on the shores of the Gulf of Guinea and in the upper Nile basin, have an intensified rainfall, but this rarely approaches that of the rainiest regions of the world.
The rainiest district in all Africa is a strip of coastland west of Mount Cameroon, where there is a mean annual rainfall of about as compared with a mean of at Cherrapunji, in Meghalaya, India.
The two distinct rainy seasons of the equatorial zone, where the sun is vertical at half-yearly intervals, become gradually merged into one in the direction of the tropics, where the sun is overhead but once.
Snow falls on all the higher mountain ranges, and on the highest the climate is thoroughly Alpine.
The countries bordering the Sahara are much exposed to a very dry wind, full of fine particles of sand, blowing from the desert towards the sea.
Known in Egypt as the khamsin, on the Mediterranean as the sirocco, it is called on the Guinea coast the harmattan.
This wind is not invariably hot; its great dryness causes so much evaporation that cold is not infrequently the result.
Similar dry winds blow from the Kalahari Desert in the south.
On the eastern coast the monsoons of the Indian Ocean are regularly felt, and on the southeast hurricanes are occasionally experienced.
The climate of Africa lends itself to certain environmental diseases, the most serious of which are: malaria, sleeping sickness and yellow fever.
Malaria is the most deadly environmental disease in Africa.
It is transmitted by a genus of mosquito (anopheles mosquito) native to Africa, and can be contracted over and over again.
There is not yet a vaccine for malaria, which makes it difficult to prevent the disease from spreading in Africa.
Recently, the dissemination of mosquito netting has helped lower the rate of malaria.
Yellow fever is a disease also transmitted by mosquitoes native to Africa.
Unlike malaria, it cannot be contracted more than once.
Like chicken pox, it is a disease that tends to be severe the later in life a person contracts the disease.
Sleeping sickness, or African trypanosomiasis, is a disease that usually affects animals, but has been known to be fatal to some humans as well.
It is transmitted by the tsetse fly and is found almost exclusively in Sub-Saharan Africa.
This disease has had a significant impact on African development not because of its deadly nature, like Malaria, but because it has prevented Africans from pursuing agriculture (as the sleeping sickness would kill their livestock).
These are the points that are farther north, south, east or west than any other location on the continent.
The highest point in Africa is Mount Kilimanjaro, in Tanzania.
The lowest point is Lake Asal, below sea level, in Djibouti.
Richard Grant 2014.
Africa.
Geographies of Change.
New York: Oxford University Press.
Approval voting is a single-winner electoral system where each voter may select ("approve") any number of candidates.
The winner is the most-approved candidate.
Robert J. Weber coined the term "Approval Voting" in 1971.
Guy Ottewell described the system in 1977.
It was more fully published in 1978 by political scientist Steven Brams and mathematician Peter Fishburn.
Approval voting ballots show a list of the candidates running for that seat for each office being contested.
Next to each name is a checkbox (or another similar way to mark "Yes" or "No" for that candidate).
Each candidate may be treated as a separate question: "Do you approve of this person for the job?".
Approval voting lets each voter indicate support for one, some, or all candidates.
All votes count equally, and everyone gets the same number of votes: one vote per candidate, either for or against.
Final tallies show how many voters support each candidate, and the winner is the candidate whom the most voters support.
Ballots on which the voter marked every candidate the same (whether yes or no) usually have no effect on the outcome of the election.
Each ballot separates candidates into two groups: those supported and those that are not.
Each candidate approved is considered preferred to any candidate not approved, while the voter's preferences among approved candidates is unspecified, and likewise, the voter's preferences among unapproved candidates is also unspecified.
Approval voting can be considered a form of range voting, with the range restricted to two values, 0 and 1—or a form of majority judgment, with grades restricted to "good" and "poor".
Approval Voting can also be compared to plurality voting, without the rule that discards ballots that vote for more than one candidate.
Approval voting has been used in privately administered nomination contests by the Independent Party of Oregon in 2011, 2012, 2014, and 2016.
Oregon is a fusion voting state, and the party has cross-nominated legislators and statewide officeholders using this method; its 2016 presidential preference primary did not identify a potential nominee due to no candidate earning more than 32 % support.
It is also used in internal elections by the American Solidarity Party, the Green Parties of Texas and Ohio, the Libertarian parties of Texas and Colorado, the US Modern Whig party, and the German Pirate Party.
In 2018, Fargo, North Dakota passed a ballot initiative adopting approval voting for local elections, becoming the first United States city and jurisdiction to adopt approval voting.
Historically, several voting methods that incorporate aspects of approval voting have been used: When several seats are to be simultaneously filled, various forms of approval ballots are often used.
Strictly speaking, these "Multiwinner Approval Voting" rules should not be confused with Approval Voting as a single-winner voting rule.
The idea of approval was adopted by X. Hu and Lloyd Shapley in 2003 in studying authority distribution in organizations.
Approval voting has been adopted by several learned societies: the Society for Social Choice and Welfare (1992), Mathematical Association of America (1986), the American Mathematical Society, the Institute of Management Sciences (1987) (now the Institute for Operations Research and the Management Sciences), the American Statistical Association (1987), and the Institute of Electrical and Electronics Engineers (1987).
The IEEE board in 2002 rescinded its decision to use approval voting.
IEEE Executive Director Daniel J. Senese stated that approval voting was abandoned because "few of our members were using it and it was felt that it was no longer needed."
Because none of these associations report results to their members and the public, it is difficult to evaluate Senese's claim and whether it is also true of other associations; Steven Brams' analysis of the 5-candidate 1987 Mathematical Association of America presidential election shows that 79 % of voters cast a ballot for one candidate, 16 % for 2 candidates, 5 % for 3, and 1 % for 4, with the winner earning the approval of 1,267 (32 %) of 3,924 voters.
Approval voting was used for Dartmouth Alumni Association elections for seats on the College Board of Trustees, but after some controversy it was replaced with traditional runoff elections by an alumni vote of 82 % to 18 % in 2009.
Dartmouth students started to use approval voting to elect their student body president in 2011.
In the first election, the winner secured the support of 41 % of voters against several write-in candidates.
In 2012, Suril Kantaria won with the support of 32 % of the voters.
In 2013, 2014 and 2016, the winners also earned the support of under 40 % of the voters.
Results reported in The Dartmouth show that in the 2014 and 2016 elections, more than 80 percent of voters approved of only one candidate.
Students replaced approval voting with plurality before the 2017 elections.
"This would result in the group going to Kombucha, even though 6 of the 10 people did not vote for Kombucha (especially if some people despise Kombucha)."
An approval voting system would work by asking the group on which places they are ok with, allowing them multiple votes and simply tallying up which place has the most votes, appropriate for a social situation, as figuring out preferences and proportion can take too long for simple decisions such as lunch.
Approval voting advocates Steven Brams and Dudley R. Herschbach predict that approval voting should increase voter participation, prevent minor-party candidates from being spoilers, and reduce negative campaigning.
The effect of this system as an electoral reform measure is not without critics, however.
FairVote has a position paper arguing that approval voting has three flaws that undercut it as a method of voting and political vehicle.
They argue that it can result in the defeat of a candidate who would win an absolute majority in a plurality election, can allow a candidate to win who might not win "any" support in a plurality election, and has incentives for tactical voting.
The first two "flaws" are considered advantages by advocates of approval voting, as it chooses centrist candidates with broad appeal rather than polarizing candidates who appeal only to the majority.
Supporters also point out that any voting method is subject to strategic voting with more than two candidates, as pointed out in Gibbard's theorem.
One study showed that approval voting would not have chosen the same two winners as plurality voting (Chirac and Le Pen) in France's presidential election of 2002 (first round) – it instead would have chosen Chirac and Jospin as the top two to proceed to a runoff.
Le Pen lost by a very high margin in the runoff, 82.2 % to 17.8 %, a sign that the true top two had not been found.
Straight approval voting without a runoff, from the study, still would have selected Chirac, but with an approval percentage of only 36.7 %, compared to Jospin at 32.9 %.
Le Pen, in that study, would have received 25.1 %.
In the real primary election, the top three were Chirac, 19.9 %, Le Pen, 16.9 %, and Jospin, 16.2 %.
A study of various "evaluative voting" methods (approval voting and score voting) during the French presidential election, 2012 showed that "unifying" candidates tended to do better, and polarizing candidates did worse, via the evaluative voting methods than via the plurality system.
A generalized version of the Burr dilemma applies to approval voting when two candidates are appealing to the same subset of voters.
Although approval voting differs from the voting system used in the Burr dilemma, approval voting can still leave candidates and voters with the generalized dilemma of whether to compete or cooperate.
While in the modern era there have been relatively few competitive approval voting elections where tactical voting is more likely, Brams argues that approval voting usually elects Condorcet winners in practice.
Critics of the use of approval voting in the alumni elections for the Dartmouth Board of Trustees in 2009 placed its ultimately successful repeal before alumni voters, arguing that the system has not been electing the most centrist candidates.
Approval voting allows voters to select all the candidates who they consider reasonable choices.
"Strategic approval" voting differs from ranked choice voting methods where voters might "reverse" the preference order of two options, which if done on a larger scale causes an unpopular candidate to win.
Strategic Approval voting, with more than two options, involves the voter changing their approval threshold.
The voter decides which options to give the "same" rating, even if they were to have a preference order between them.
Approval voting allows for Bullet Voting and Compromising, while it is immune to Push-Over and Burying.
Bullet Voting occurs when a voter approves "only" candidate ' a ' instead of "both" ' a ' and ' b ' for the reason that voting for ' b ' can cause ' a ' to lose.
The voter would be satisfied with either ' a ' or ' b ' but has a moderate preference for ' a '.
Were ' b ' to win, this hypothetical voter would still be satisfied.
Compromising occurs when a voter approves an "additional" candidate who is otherwise considered unacceptable to the voter to prevent an even worse alternative from winning.
that directly reflect the true preferences of a voter, i.e., that do not report preferences' falsely.
They also give a specific definition of a sincere approval vote in terms of the voter's ordinal preferences as being any vote that, if it votes for one candidate, it also votes for any more preferred candidate.
This definition allows a sincere vote to treat strictly preferred candidates the same, ensuring that every voter has at least one sincere vote.
The definition also allows a sincere vote to treat equally preferred candidates differently.
When there are two or more candidates, every voter has at least three sincere approval votes to choose from.
Two of those sincere approval votes do not distinguish between any of the candidates: vote for none of the candidates and vote for all of the candidates.
When there are three or more candidates, every voter has more than one sincere approval vote that distinguishes between the candidates.
Based on the definition above, if there are four candidates, A, B, C, and D, and a voter has a strict preference order, preferring A to B to C to D, then the following are the voter's possible sincere approval votes: If the voter instead equally prefers B and C, while A is still the most preferred candidate and D is the least preferred candidate, then all of the above votes are sincere and the following combination is also a sincere vote: The decision between the above ballots is equivalent to deciding an arbitrary "approval cutoff."
All candidates preferred to the cutoff are approved, all candidates less preferred are not approved, and any candidates equal to the cutoff may be approved or not arbitrarily.
A sincere voter with multiple options for voting sincerely still has to choose which sincere vote to use.
Voting strategy is a way to make that choice, in which case strategic approval voting includes sincere voting, rather than being an alternative to it.
This differs from other voting systems that typically have a unique sincere vote for a voter.
When there are three or more candidates, the winner of an approval voting election can change, depending on which sincere votes are used.
In some cases, approval voting can sincerely elect any one of the candidates, including a Condorcet winner and a Condorcet loser, without the voter preferences changing.
To the extent that electing a Condorcet winner and not electing a Condorcet loser is considered desirable outcomes for a voting system, approval voting can be considered vulnerable to sincere, strategic voting.
In one sense, conditions where this can happen are robust and are not isolated cases.
On the other hand, the variety of possible outcomes has also been portrayed as a virtue of approval voting, representing the flexibility and responsiveness of approval voting, not just to voter ordinal preferences, but cardinal utilities as well.
Approval voting avoids the issue of multiple sincere votes in special cases when voters have dichotomous preferences.
For a voter with dichotomous preferences, approval voting is strategy-proof (also known as strategy-free).
When all voters have dichotomous preferences and vote the sincere, strategy-proof vote, approval voting is guaranteed to elect the Condorcet winner, if one exists.
However, having dichotomous preferences when there are three or more candidates is not typical.
It is an unlikely situation for all voters to have dichotomous preferences when there are more than a few voters.
Having dichotomous preferences means that a voter has bi-level preferences for the candidates.
All of the candidates are divided into two groups such that the voter is indifferent between any two candidates in the same group and any candidate in the top-level group is preferred to any candidate in the bottom-level group.
A voter that has strict preferences between three candidates—prefers A to B and B to C—does not have dichotomous preferences.
Being strategy-proof for a voter means that there is a unique way for the voter to vote that is a strategically best way to vote, regardless of how others vote.
In approval voting, the strategy-proof vote, if it exists, is a sincere vote.
Another way to deal with multiple sincere votes is to augment the ordinal preference model with an approval or acceptance threshold.
An approval threshold divides all of the candidates into two sets, those the voter approves of and those the voter does not approve of.
A voter can approve of more than one candidate and still prefer one approved candidate to another approved candidate.
Acceptance thresholds are similar.
With such a threshold, a voter simply votes for every candidate that meets or exceeds the threshold.
With threshold voting, it is still possible to not elect the Condorcet winner and instead elect the Condorcet loser when they both exist.
However, according to Steven Brams, this represents a strength rather than a weakness of approval voting.
Without providing specifics, he argues that the pragmatic judgements of voters about which candidates are acceptable should take precedence over the Condorcet criterion and other social choice criteria.
Voting strategy under approval is guided by two competing features of approval voting.
On the one hand, approval voting fails the later-no-harm criterion, so voting for a candidate can cause that candidate to win instead of a more preferred candidate.
On the other hand, approval voting satisfies the monotonicity criterion, so not voting for a candidate can never help that candidate win, but can cause that candidate to lose to a less preferred candidate.
Either way, the voter can risk getting a less preferred election winner.
A voter can balance the risk-benefit trade-offs by considering the voter's cardinal utilities, particularly via the von Neumann–Morgenstern utility theorem, and the probabilities of how others vote.
A rational voter model described by Myerson and Weber specifies an approval voting strategy that votes for those candidates that have a positive prospective rating.
This strategy is optimal in the sense that it maximizes the voter's expected utility, subject to the constraints of the model and provided the number of other voters is sufficiently large.
An optimal approval vote always votes for the most preferred candidate and not for the least preferred candidate.
However, an optimal vote can require voting for a candidate and not voting for a more preferred candidate if there 4 candidates or more.
Other strategies are also available and coincide with the optimal strategy in special situations.
For example: Another strategy is to vote for the top half of the candidates, the candidates that have an above-median utility.
When the voter thinks that others are balancing their votes randomly and evenly, the strategy maximizes the voter's power or efficacy, meaning that it maximizes the probability that the voter will make a difference in deciding which candidate wins.
Optimal strategic approval voting fails to satisfy the Condorcet criterion and can elect a Condorcet loser.
Strategic approval voting can guarantee electing the Condorcet winner in some special circumstances.
For example, if all voters are rational and cast a strategically optimal vote based on a common knowledge of how all the other voters vote except for small-probability, statistically independent errors in recording the votes, then the winner will be the Condorcet winner, if one exists.
In the example election described, assume that the voters in each faction share the following von Neumann–Morgenstern utilities, fitted to the interval between 0 and 100.
The utilities are consistent with the rankings given earlier and reflect a strong preference each faction has for choosing its city, compared to weaker preferences for other factors such as the distance to the other cities.
+ Voter utilities for each candidate city Using these utilities, voters choose their optimal strategic votes based on what they think the various pivot probabilities are for pairwise ties.
In each of the scenarios summarized below, all voters share a common set of pivot probabilities.
+ Approval voting results for scenarios using optimal strategic voting In the first scenario, voters all choose their votes based on the assumption that all pairwise ties are equally likely.
As a result, they vote for any candidate with an above-average utility.
Most voters vote for only their first choice.
Only the Knoxville faction also votes for its second choice, Chattanooga.
As a result, the winner is Memphis, the Condorcet loser, with Chattanooga coming in second place.
In the second scenario, all of the voters expect that Memphis is the likely winner, that Chattanooga is the likely runner-up, and that the pivot probability for a Memphis-Chattanooga tie is much larger than the pivot probabilities of any other pair-wise ties.
As a result, each voter votes for any candidate they prefer more than the leading candidate, and also vote for the leading candidate if they prefer that candidate more than the expected runner-up.
Each remaining scenario follows a similar pattern of expectations and voting strategies.
In the second scenario, there is a three-way tie for first place.
This happens because the expected winner, Memphis, was the Condorcet loser and was also ranked last by any voter that did not rank it first.
Only in the last scenario does the actual winner and runner-up match the expected winner and runner-up.
As a result, this can be considered a stable strategic voting scenario.
In the language of game theory, this is an "equilibrium."
In this scenario, the winner is also the Condorcet winner.
As this voting method is cardinal rather than ordinal, it is possible to model voters in a way that does not simplify to an ordinal method.
Modelling voters with a ' dichotomous cutoff ' assumes a voter has an immovable approval cutoff, while having meaningful cardinal preferences.
This means that rather than voting for their top 3 candidates, or all candidates above the average approval (which may result in their vote changing if one candidate drops out, resulting in a system that does not satisfy IIA), they instead vote for all candidates above a certain approval ' cutoff ' that they have decided.
This cutoff does not change, regardless of which and how many candidates are running, so when all available alternatives are either above or below the cutoff, the voter votes for all or none of the candidates, despite preferring some over others.
While this extreme appears unrealistic, it actually reflects reality in the way that many voters become disenfranchised and apathetic if they see no candidates they approve of.
In this way, there is evidence to suggest that many voters may have an internal cutoff, and would not simply vote for their top 3, or the above average candidates, although that is not to say that it is necessarily entirely immovable.
For example, in this scenario, voters are voting for candidates with approval above 50 % (bold signifies that the voters voted for the candidate): C wins with 65 % of the voters' approval, beating B with 60 %, D with 40 % and A with 35 % If voters' threshold for receiving a vote is that the candidate has an above average approval, or they vote for their two most approved of candidates, this is not a dichotomous cutoff, as this can change if candidates drop out.
On the other hand, if voters' threshold for receiving a vote is fixed (say 50 %), this is a dichotomous cutoff, and satisfies IIA as shown below: + A drops out, candidates voting for above average approval B now wins with 60 %, beating C with 55 % and D with 40 % + A drops out, candidates voting for approval > 50 % With dichotomous cutoff, C still wins.
+ D drops out, candidates voting for top 2 candidates B now wins with 70 %, beating C and A with 65 % + D drops out, candidates voting for approval > 50 % With dichotomous cutoff, C still wins.
Most of the mathematical criteria by which voting systems are compared were formulated for voters with ordinal preferences.
In this case, approval voting requires voters to make an additional decision of where to put their approval cutoff (see examples above).
Depending on how this decision is made, approval voting satisfies different sets of criteria.
There is no ultimate authority on which criteria should be considered, but the following are criteria that many voting theorists accept and consider desirable: Approval voting can be extended to multiple winner elections.
A simple way to do so is as "block approval voting," a simple variant on block voting where each voter can select an unlimited number of candidates and the candidates with the most approval votes win.
This does not provide proportional representation and is subject to the Burr dilemma, among other problems.
Other ways of extending Approval voting to multiple winner elections have been devised.
Among these are satisfaction approval voting and proportional approval voting for determining a proportional assembly, and minimax approval for determining a consensus assembly where the least satisfied voter is satisfied the most.
Approval ballots can be of at least four semi-distinct forms.
The simplest form is a blank ballot on which voters hand-write the names of the candidates they support.
A more structured ballot lists all candidates, and voters mark each candidate they support.
A more explicit structured ballot can list the candidates and provide two choices by each.
(Candidate list ballots can include spaces for write-in candidates as well.)
All four ballots are theoretically equivalent.
The more structured ballots may aid voters in offering clear votes so they explicitly know all their choices.
The Yes/No format can help to detect an "undervote" when a candidate is left unmarked and allow the voter a second chance to confirm the ballot markings are correct.
The "single bubble" format is incapable of producing invalid ballots (which might otherwise be rejected in counting).
Unless the second or fourth format is used, fraudulently adding votes to an approval voting ballot does not invalidate the ballot (that is, it does not make it appear inconsistent).
Thus, approval voting raises the importance of ensuring that the "chain of custody" of ballots is secure.
Arizona State University (commonly referred to as ASU or Arizona State) is a public metropolitan research university on five campuses across the Phoenix metropolitan area, and four regional learning centers throughout Arizona.
ASU is one of the largest public universities by enrollment in the U.S. As of fall 2019, the university had nearly 90,000 students attending classes across its metro campuses, more than 38,000 students attending online, including 83,000 - plus undergraduates and more nearly 20,000 postgraduates.
The university is organized into 17 colleges, featuring more than 170 cross-discipline centers and institutes.
ASU offers 350 degree options for undergraduates students, as well as more than 400 graduate degree and certificate programs.
ASU has nearly 600 ASU scholar-athletes across 26 varsity-level sports.
The Arizona State Sun Devils compete in the Pac-12 Conference and have won 59 Pac-10/Pac-12 championships dating to 1979, and have captured 24 NCAA championships dating to its first (baseball) title in 1965.
In addition to its athletic program, the university is home to over 1,100 registered student organizations.
ASU's charter, approved by the board of regents in 2014, is based on the "New American University" model created by ASU President Michael M. Crow upon his appointment as the institution's 16th president in 2002.
It defines ASU as "a comprehensive public research university, measured not by whom it excludes, but rather by whom it includes and how they succeed; advancing research and discovery of public value; and assuming fundamental responsibility for the economic, social, cultural and overall health of the communities it serves."
Since 2005, ASU has been ranked among the top research universities in the U.S., public and private, based on research output, innovation, development, research expenditures, number of awarded patents and awarded research grant proposals.
The 2019 university ratings by "U.S. News & World Report" rank ASU No. 1 among the Most Innovative Schools in America for the fourth year in a row.
"U.S. News & World Report" shows 83 % of the student applications get accepted.
A diverse faculty of more than 4,700 scholars includes 4 Nobel laureates, 6 Pulitzer Prize winners, 4 MacArthur Fellows Program "Genius Grant" members and 19 National Academy of Sciences members.
Additionally, among the faculty are 180 Fulbright Program American Scholars, 72 National Endowment for the Humanities fellows, 38 American Council of Learned Societies fellows, 36 members of the Guggenheim Fellowship, 21 members of the American Academy of Arts and Sciences, 9 National Academy of Engineering members and 3 National Academy of Medicine members.
The National Academies has bestowed "highly prestigious" recognition on 227 ASU faculty members.
Arizona State University was established as the Territorial Normal School at Tempe on March 12, 1885, when the 13th Arizona Territorial Legislature passed an act to create a normal school to train teachers for the Arizona Territory.
The campus consisted of a single, four-room schoolhouse on a 20-acre plot largely donated by Tempe residents George and Martha Wilson.
Classes began with 33 students on February 8, 1886.
The curriculum evolved over the years and the name was changed several times; the institution was also known as Tempe Normal School of Arizona (1889 – 1903), Tempe Normal School (1903 – 1925), Tempe State Teachers College (1925 – 1929), Arizona State Teachers College (1929 – 1945), Arizona State College (1945 – 1958) and, by a 2 – 1 margin of the state's voters, Arizona State University in 1958.
In 1923, the school stopped offering high school courses and added a high school diploma to the admissions requirements.
In 1925, the school became the Tempe State Teachers College and offered four-year Bachelor of Education degrees as well as two-year teaching certificates.
In 1929, the 9th Arizona State Legislature authorized Bachelor of Arts in Education degrees as well, and the school was renamed the Arizona State Teachers College.
Under the 30-year tenure of president Arthur John Matthews (1900 – 1930), the school was given all-college student status.
The first dormitories built in the state were constructed under his supervision in 1902.
Of the 18 buildings constructed while Matthews was president, six are still in use.
Matthews envisioned an "evergreen campus," with many shrubs brought to the campus, and implemented the planting of 110 Mexican Fan Palms on what is now known as Palm Walk, a century-old landmark of the Tempe campus.
During the Great Depression, Ralph Waldo Swetman was hired to succeed President Matthews, coming to Arizona State Teachers College in 1930 from Humboldt State Teachers College where he had served as president.
He served a three-year term, during which he focused on improving teacher-training programs.
During his tenure, enrollment at the college doubled, topping the 1,000 mark for the first time.
Matthews also conceived of a self-supported summer session at the school at Arizona State Teachers College, a first for the school.
In 1933, Grady Gammage, then president of Arizona State Teachers College at Flagstaff, became president of Arizona State Teachers College at Tempe, beginning a tenure that would last for nearly 28 years, second only to Swetman's 30 years at the college's helm.
Like President Arthur John Matthews before him, Gammage oversaw the construction of several buildings on the Tempe campus.
He also guided the development of the university's graduate programs; the first Master of Arts in Education was awarded in 1938, the first Doctor of Education degree in 1954 and 10 non-teaching master's degrees were approved by the Arizona Board of Regents in 1956.
During his presidency, the school's name was changed to Arizona State College in 1945, and finally to Arizona State University in 1958.
At the time, two other names were considered: Tempe University and State University at Tempe.
Among Gammage's greatest achievements in Tempe was the Frank Lloyd Wright-designed construction of what is Grady Gammage Memorial Auditorium/ASU Gammage.
One of the university's hallmark buildings, ASU Gammage was completed in 1964, five years after the president's (and Wright's) death.
Gammage was succeeded by Harold D. Richardson, who had served the school earlier in a variety of roles beginning in 1939, including director of graduate studies, college registrar, dean of instruction, dean of the College of Education and academic vice president.
Although filling the role of acting president of the university for just nine months (Dec. 1959 to Sept. 1960), Richardson laid the groundwork for the future recruitment and appointment of well-credentialed research science faculty.
By the 1960 s, under G. Homer Durham, the university's 11th president, ASU began to expand its curriculum by establishing several new colleges and, in 1961, the Arizona Board of Regents authorized doctoral degree programs in six fields, including Doctor of Philosophy.
By the end of his nine-year tenure, ASU had more than doubled enrollment, reporting 23,000 in 1969.
The next three presidents—Harry K. Newburn (1969 – 71), John W. Schwada (1971 – 81) and J. Russell Nelson (1981 – 89), including and Interim President Richard Peck (1989), led the university to increased academic stature, the establishment of the ASU West campus in 1984 and its subsequent construction in 1986, a focus on computer-assisted learning and research, and rising enrollment.
Under the leadership of Lattie F. Coor, president from 1990 to 2002, ASU grew through the creation of the Polytechnic campus and extended education sites.
Increased commitment to diversity, quality in undergraduate education, research, and economic development occurred over his 12-year tenure.
Part of Coor's legacy to the university was a successful fundraising campaign: through private donations, more than $ 500 million was invested in areas that would significantly impact the future of ASU.
Among the campaign's achievements were the naming and endowing of Barrett, The Honors College, and the Herberger Institute for Design and the Arts; the creation of many new endowed faculty positions; and hundreds of new scholarships and fellowships.
In 2002, Michael M. Crow became the university's 16th president.
At his inauguration, he outlined his vision for transforming ASU into a "New American University" — one that would be open and inclusive, and set a goal for the university to meet Association of American Universities criteria and to become a member.
Crow initiated the idea of transforming ASU into "One university in many places" — a single institution comprising several campuses, sharing students, faculty, staff and accreditation.
Subsequent reorganizations combined academic departments, consolidated colleges and schools, and reduced staff and administration as the university expanded its West and Polytechnic campuses.
ASU's Downtown Phoenix campus was also expanded, with several colleges and schools relocating there.
The university established learning centers throughout the state, including the ASU Colleges at Lake Havasu City and programs in Thatcher, Yuma, and Tucson.
Students at these centers can choose from several ASU degree and certificate programs.
During Crow's tenure, and aided by hundreds of millions of dollars in donations, ASU began a years-long research facility capital building effort that led to the establishment of the Biodesign Institute at Arizona State University, the Julie Ann Wrigley Global Institute of Sustainability, and several large interdisciplinary research buildings.
Along with the research facilities, the university faculty was expanded, including the addition of five Nobel Laureates.
Since 2002, the university's research expenditures have tripled and more than 1.5 million square feet of space has been added to the university's research facilities.
The economic downturn that began in 2008 took a particularly hard toll on Arizona, resulting in large cuts to ASU's budget.
In response to these cuts, ASU capped enrollment, closed some four dozen academic programs, combined academic departments, consolidated colleges and schools, and reduced university faculty, staff and administrators; however, with an economic recovery underway in 2011, the university continued its campaign to expand the West and Polytechnic Campuses, and establish a low-cost, teaching-focused extension campus in Lake Havasu City.
As of 2011, an article in "Slate" reported that, "the bottom line looks good," noting that: Since Crow's arrival, ASU's research funding has almost tripled to nearly $ 350 million.
Degree production has increased by 45 percent.
And thanks to an ambitious aid program, enrollment of students from Arizona families below poverty is up 647 percent.
In 2015, the Thunderbird School of Global Management became the fifth ASU campus, as the Thunderbird School of Global Management at ASU.
Partnerships for education and research with Mayo Clinic established collaborative degree programs in health care and law, and shared administrator positions, laboratories and classes at the Mayo Clinic Arizona campus.
The Beus Center for Law and Society, the new home of ASU's Sandra Day O'Connor College of Law, opened in fall 2016 on the Downtown Phoenix campus, relocating faculty and students from the Tempe campus to the state capital.
The Arizona Board of Regents governs Arizona State University as well as the state's other public universities; University of Arizona and Northern Arizona University.
The Board of Regents is composed of 12 members including 11 who are voting members, and one non-voting member.
Members of the board include the state governor and superintendent of public instruction acting as ex-officio members, eight volunteer Regents members with eight-year terms who are appointed by the Governor, and two student regents, each with two-year terms, and each serving a one-year term as non-voting apprentices.
ABOR provides policy guidance to the state universities of Arizona.
ASU has four campuses in metropolitan Phoenix, Arizona including the Tempe campus in Tempe; the West campus in Glendale; the Downtown Phoenix campus; and the Polytechnic campus in Mesa.
ASU also offers courses and degrees through ASU Online and at the ASU Colleges at Lake Havasu City in western Arizona, and offers regional learning programs in Thatcher, Yuma and Tucson.
The Arizona Board of Regents appoints and elects the president of the university, who is considered the institution's chief executive officer and the chief budget officer.
The president executes measures enacted by the Board of Regents, controls the university's property, and acts as the university's official representative to the Board of Regents.
The chief executive officer is assisted through the administration of the institution by the provost, vice presidents, deans, faculty, directors, department chairs, and other officers.
The president also selects and appoints administrative officers and general counsels.
The 16th ASU president is Michael M. Crow, who has served since July 1, 2002.
Academic programs are spread across four distinct campuses in the Phoenix Metropolitan Area; however, unlike most multi-campus institutions, ASU describes itself as "one university in many places," inferring there is "not a system with separate campuses, and not one main campus with branch campuses."
The university considers each campus "distinctive" and academically focused on certain aspects of the overall university mission.
The Tempe campus is the university's research and graduate school center.
Undergraduate studies on the Tempe campus are research-based programs that prepare students for graduate school, professional school, or employment.
The Polytechnic campus is designed with an emphasis on professional and technological programs for direct workforce preparation.
The Polytechnic campus is the site of many of the university's simulators and laboratories dedicated for project-based learning.
The West campus is focused on interdisciplinary degrees and the liberal arts, while maintaining professional programs with a direct impact on the community and society.
The Downtown Phoenix campus focuses on direct urban and public programs such as nursing, public policy, criminal justice, mass communication, and journalism.
ASU recently relocated some nursing and health related programs to its new ASU-Mayo Medical School campus.
Inter-campus shuttles and light rail allow students and faculty to easily travel between the campuses.
In addition to the physical campuses, ASU's "virtual campus" at the university's SkySong Innovation Center, provides online and extended education.
The Arizona Board of Regents reports the ASU facilities inventory totals more than 23 million gross square feet.
ASU's Tempe campus is in downtown Tempe, Arizona, about east of downtown Phoenix.
The campus is considered urban, and is approximately in size.
It is arranged around broad pedestrian malls and is completely encompassed by an arboretum.
The Tempe campus is also the largest of ASU's campuses, with more than 70,000 students enrolled in at least one class on campus in fall 2017.
The campus is considered to range from the streets Rural Road on the east to Mill Avenue on the west, and Apache Boulevard on the south to Rio Salado Parkway on the north.
The Tempe campus is ASU's original campus, and Old Main, the first building constructed, still stands.
Today's university and the Tempe campus were founded as the Territorial Normal School when first constructed, and was originally a teachers college.
There are many notable landmarks on campus, including Grady Gammage Memorial Auditorium, designed by Frank Lloyd Wright; Palm Walk, which is lined by 111 palm trees; Charles Trumbull Hayden Library; the University Club building; Margaret Gisolo Dance Theatre; and University Bridge.
In addition, the campus has an extensive public art collection; It was named "the single most impressive venue for contemporary art in Arizona" by "Art in America" magazine.
Against the northwest edge of campus is the Mill Avenue district (part of downtown Tempe), which has a college atmosphere that attracts many students to its restaurants and bars.
Students also have Tempe Marketplace, a shopping, dining and entertainment center with an outdoor setting near the northeast border of the campus.
The Tempe campus is also home to all of the university's athletic facilities.
Established in 1984 by the Arizona legislature, the West campus sits on in a suburban area of northwest Phoenix.
The West campus lies about northwest of downtown Phoenix, and about northwest of the Tempe campus.
The West campus is designated as a Phoenix Point of Pride and is nearly completely powered by a solar array.
The campus serves more than 4,000 students enrolled in at least a single course and offers more than 100 degree programs from the New College of Interdisciplinary Arts and Sciences, the Mary Lou Fulton Teachers College, W. P. Carey School of Business, College of Public Service and Community Solutions, College of Health Solutions, and the College of Nursing and Health Innovation.
Patterned after the University of Oxford's architecture, the West campus provides modern amenities in its residence halls, dining facilities and the Sun Devil Fitness Complex and swimming pool.
Subtropical landscaping, fountains and outdoor enclaves are third-space opportunities for students to socialize or collaborate while pursuing any of the undergraduate and graduate degree programs available.
Founded in 1996 as "ASU East," the ASU Polytechnic campus serves more than 4,800 students and is home to more than 130 bachelor's, master's and doctoral degrees in professional and technical programs through the W. P. Carey School of Business/Morrison School of Management and Agribusiness, Mary Lou Fulton Teachers College, Ira A. Fulton Schools of Engineering, and College of Integrative Sciences and Arts, and focuses on professional and technological programs including simulators and lab space in various fields of study.
The campus is in southeast Mesa, Arizona, approximately southeast of the Tempe campus, and southeast of downtown Phoenix.
The Polytechnic campus sits on the former Williams Air Force Base.
The Downtown Phoenix campus was established in 2006 on the north side of Downtown Phoenix.
The campus has an urban design, with several large modern academic buildings intermingled with commercial and retail office buildings.
In addition to the new buildings, the campus included the adaptive reuse of several existing structures, including a 1930 s era Post Office that is on the National Register of Historic Places.
Serving 11,465 students, the campus houses the College of Health Solutions, College of Integrative Arts and Sciences, College of Nursing and Health Innovation, College of Public Service and Community Solutions, Mary Lou Fulton Teachers College, and Walter Cronkite School of Journalism and Mass Communication.
In 2013, the campus added the Sun Devil Fitness Center in conjunction with the original YMCA building.
ASU's Sandra Day O'Connor College of Law relocated from Tempe to the Downtown Phoenix campus in 2016.
In response to demands for lower-cost public higher education in Arizona, ASU developed the small, undergraduate-only college in Lake Havasu City.
ASU Colleges are teaching-focused and provide a selection of popular undergraduate majors.
The Lake Havasu City campus offers undergraduate degrees at lower tuition rates than other Arizona research universities and a 15-to - 1 student-to-faculty ratio.
ASU Online offers more than 150 undergraduate and graduate degree programs through an online platform.
The degree programs delivered online hold the same accreditation as the university's traditional face-to-face programs.
ASU Online is headquartered at ASU's SkySong campus in Scottsdale, Arizona.
ASU Online was ranked in the Top 4 for Best Online Bachelor's Programs by "U.S. News & World Report".
Online students are taught by the same faculty and receive the same diploma as on-campus students.
ASU online programs allow students to learn in highly interactive environments through student collaboration and through technological personalized learning environments.
In April 2015, ASU Online announced a partnership with edX to form a one of a kind program called the Global Freshman Academy.
The program is open to all potential students.
The students do not need to submit a high school transcript or GPA to apply for the courses.
They only pay for the courses ($ 600 per credit) after they have passed the course if they want to earn the credits.
As of spring 2017, more than 25,000 students were enrolled through ASU Online.
In June 2014, ASU Online and Starbucks announced a partnership called the Starbucks College Achievement Plan.
The Starbucks College Achievement Plan offers all benefits-eligible employees full-tuition coverage when they enroll in any one of ASU Online's undergraduate degree programs.
In 2016, Mayo Clinic and ASU formed a new platform for health care education and research: the Mayo Clinic and Arizona State University Alliance for Health Care.
Beginning in 2017, Mayo Clinic School of Medicine students in Phoenix and Scottsdale are among the first to earn a certificate in the Science of Health Care Delivery, with the option to earn a master's degree in the Science of Health Care Delivery through ASU.
Thunderbird School of Global Management is one of the newest units of "Arizona State University Knowledge Enterprise."
The flagship campus was in Glendale, Arizona, at Thunderbird Field No. 1, a former military airfield from which it derives its name, until 2018 when the Thunderbird School relocated to the Downtown area.
Following a nearly 15-year presence in the city through more minor means, ASU opened the Barrett and O'Connor Center in 2018 to solidify the University's contacts with the capital city.
The center houses ASU's Washington, D.C. - based academic programs, including the Washington Bureau of the Walter Cronkite School of Journalism and Mass Communication, the Sandra Day O’Connor College of Law Rule of Law and Governance program, the Capital Scholars program, and the McCain Institute's Next Generation Leaders program, among many others.
In addition to hosting classes and internships on-site, special lectures and seminars taught from the Barrett & O’Connor Washington Center are connected to classrooms in Arizona through video-conferencing technology.
The Barrett and O'Connor center is located at 1800 I St NW, Washington, DC 20006, very close to the White House.
ASU's California Center is located in Santa Monica, California and serves as a gateway to the Los Angeles market for ASU undergraduate and graduate students.
The Center offers classes for the Sandra Day O'Connor College of Law, among other graduate programs at ASU.
+ "Fall Freshman Statistics" 34,181 28,096 82.2 10,278 3.53 For fall 2017, ASU admitted 82 % of all freshman applicants and is considered a "more selective" university by "U.S. News & World Report".
Average GPA of enrolling freshman was 3.53; the average SAT score was 1216 for critical reading and math combined; and the average ACT composite score was 25.0.
Barrett, The Honors College is ranked among the top honors programs in the nation.
Although there are no set minimum admissions criteria for Barrett College, the average GPA of Fall 2017 incoming freshmen was 3.78, with an average SAT score of 1380 and an average ACT score of 29.
The Honors college has 7,236 students, with 719 National Merit Scholars.
ASU enrolls 10,268 international students, 14.3 % of the total student population.
The international student body represents more than 150 nations.
The Institute of International Education ranked ASU as the top public university in the U.S. for hosting international students in 2016 – 2017.
+ "Undergraduate and Graduate Enrollment" ASU offers over 350 majors to undergraduate students, and more than 100 graduate programs leading to numerous masters and doctoral degrees in the liberal arts and sciences, design and arts, engineering, journalism, education, business, law, nursing, public policy, technology, and sustainability.
These programs are divided into 16 colleges and schools which are spread across ASU's six campuses.
ASU also offers the 4 + 1 accelerated program, which allows students in their senior year to attain their master's degree the following year.
However the 4 + 1 accelerated program is not associated with all majors, for example in the Mary Lou Fulton Teachers College the 4 + 1 accelerated program only works with Education Exploratory majors.
ASU uses a plus-minus grading system with highest cumulative GPA awarded of 4.0 (at time of graduation).
Arizona State University is accredited by the Higher Learning Commission.
The 2020 "U.S. News & World Report" ratings ranked ASU tied for 53rd among public universities, tied for 117th among national universities, tied for 145th in the world's top 1,250 global universities and 1st for "most innovative" university in the U.S. The innovation ranking, new for 2016, was determined by a poll of top college officials nationwide asking them to name institutions "that are making the most innovative improvements in terms of curriculum, faculty, students, campus life, technology or facilities."
ASU is ranked 51st – 61st in the U.S. and 101st – 150th in the world among the top 500 universities in the 2016 Academic Ranking of World Universities (ARWU), and 56th U.S./102nd world by the 2016 Center for World University Rankings.
"Money Magazine" ranked ASU 162nd of 711 U.S. schools it evaluated for its 2017 Best Colleges ranking.
"The Daily Beast" ranked ASU 172nd of nearly 2,000 U.S. schools in its 2014 Best Colleges ranking.
"The Wall Street Journal" ranks ASU 5th in the nation for producing the best-qualified graduates, determined by a nationwide poll of corporate recruiters, and "Forbes" magazine named ASU one of America's best college buys.
In 2018, Times High Education metrics identified Arizona State University as 81st in the World and 38th among US institutions.
ASU's Walter Cronkite School of Journalism and Mass Communication has been named one of America's top 10 journalism schools by national publications and organizations for more than a decade.
The rankings include: College Magazine (10th), Quality Education and Jobs (6th), and International Student (1st).
For its efforts as a national leader in campus sustainability, ASU was named one of the top 6 "Cool Schools" by the Sierra Club in 2017, was named one of the Princeton Review's most sustainable schools in 2015 and earned an "A -" grade on the 2011 College Sustainability Green Report Card.
ASU's online bachelor's degree programs have been ranked 4th in the nation by U.S. News & World Report, with its graduate business programs ranked 3rd, online MBA ranked 5th, online graduate criminal justice ranked 5th and graduate engineering ranked 13th.
ASU was also ranked the # 1 college offering an online bachelor's degree in communications and # 5 in the top 100 Best Online Colleges by Online College Plan.
ASU is currently ranked among the top 10 universities—without a traditional medical school—for research expenditures.
It shares this designation with schools such as Caltech, Georgia Tech, MIT, Purdue, Rockefeller, UC Berkeley, and the University of Texas at Austin.
ASU is classified as "R1: Doctoral Universities – Highest Research Activity" by the Carnegie Classification of Institutions of Higher Education.
The university is one of the fastest growing research enterprises in the United States, receiving $ 618 million in fiscal year 2018.
ASU is a NASA designated national space-grant institute and a member of the Universities Research Association.
The university is currently in the top 10 for NASA-funded research expenditures.
ASU is one of the nation's most successful universities in terms of creating start-up companies through research.
The university has raised more than $ 700 million in external funding, and 126 companies based on ASU innovations have been launched through the university's exclusive intellectual property management company, Skysong Innovations.
ASU ranks # 2 in the nation for proprietary start-ups "created for every $ 10 million in research expenditures."
ASU is in the top 10 of all universities worldwide for U.S. patents awarded in 2018, tied with the University of Michigan.
ASU jumped to 10th place from 17th in 2017, according to the U.S. National Academy of Inventors and the Intellectual Property Owners Association.
Since its inception, Skysong Innovations has fostered the launch of more than 120 companies based on ASU innovations, and attracted more than $ 700 million in venture funding, including $ 96 million in fiscal year 2016 alone.
According to the Sweden-based University Business Incubator (UBI) Index for 2013, ASU is one of the top universities in the world for business incubation, ranking 17th.
UBI reviewed 550 universities and associated business incubators from around the world using an assessment framework that takes more than 50 performance indicators into consideration.
As an example, one of ASU's spin-offs (Heliae Development, LLC) raised more than $ 28 million in venture capital in 2013 alone.
In June 2016, ASU received the Entrepreneurial University Award from the Deshpande Foundation, a philanthropic organization that supports social entrepreneurship and innovation.
The university's push to create various institutes has led to greater funding and an increase in the number of researchers in multiple fields.
ASU Knowledge Enterprise Development (KED) advances research, innovation, strategic partnerships, entrepreneurship, economic development and international development.
KED is led by Sethuraman Panchanathan.
KED supports several interdisciplinary research institutes and initiatives: Institute for Humanities Research, NewSpace Initiative, Biodesign Institute, Institute for the Science of Teaching and Learning, Julie Ann Wrigley Global Institute of Sustainability, Institute for Social Science Research, LightWorks, McCain Institute for International Leadership, Decision Theater Network, Flexible Electronics and Display Center, Complex Adaptive Systems @ ASU, Global Security Initiative.
Other notable and famed institutes at ASU are The Institute of Human Origins, L. William Seidman Research Institute (W. P. Carey School of Business), Learning Sciences Institute, Herberger Research Institute, and the Hispanic Research Center.
The Biodesign Institute for instance, conducts research on issues such as biomedical and health care outcomes as part of a collaboration with Mayo Clinic to diagnose and treat diseases.
Biodesign Institute researchers have also developed various techniques for reading and detecting biosignatures which expanded in 2006 with an $ 18 million grant from the National Human Genome Research Institute of the National Institutes of Health.
The institute also is heavily involved in sustainability research, primarily through reuse of CO via biological feedback and various biomasses (e.g. algae) to synthesize clean biofuels.
Heliae is a Biodesign Institute spin-off and much of its business centers on algal-derived, high value products.
Furthermore, the institute is heavily involved in security research including technology that can detect biological and chemical changes in the air and water.
The university has received more than $ 30 million in funding from the Department of Defense for adapting this technology for use in detecting the presence of biological and chemical weapons.
Research conducted at the Biodesign Institute by ASU professor Charles Arntzen made possible the production of Ebola antibodies in specially modified tobacco plants that researchers at Mapp Biopharmaceutical used to create the Ebola therapeutic ZMapp.
The treatment is credited with saving the lives of two aid workers.
For his work, Arntzen was named the No. 1 honoree among Fast Company's annual "100 Most Creative People in Business" 2015 awards.
World-renowned scholars have been integral to the successes of the institutes associated with the university.
ASU students and researchers have been selected as Marshall, Truman, Rhodes, and Fulbright Scholars with the university ranking 1st overall in the U.S. for Fulbright Scholar awards to faculty and 5th overall for recipients of Fulbright U.S. Student awards in the 2015 – 2016 academic year.
ASU faculty includes Nobel Laureates, Royal Society members, National Academy members, and members of the National Institutes of Health, to name a few.
ASU Professor Donald Johanson, who discovered the 3.18 million year old fossil hominid Lucy (Australopithecus) in Ethiopia, established the Institute of Human Origins (IHO) in 1981.
The institute was first established in Berkeley, California and later moved to ASU in 1997.
As one of the leading research organization in the United States devoted to the science of human origins, IHO pursues a transdisciplinary strategy for field and analytical paleoanthropological research.
The Herberger Institute Research Center supports the scholarly inquiry, applied research and creative activity of more than 400 faculty and nearly 5,000 students.
The renowned ASU Art Museum, Herberger Institute Community Programs, urban design, and other outreach and initiatives in the arts community round out the research and creative activities of the Herberger Institute.
Among well known professors within the Herberger Institute is Johnny Saldaña of the School of Theatre and Film.
Saldaña received the 1996 Distinguished Book Award and the prestigious Judith Kase Cooper Honorary Research Award, both from the American Alliance for Theatre Education (AATE).
The Julie Ann Wrigley Global Institute of Sustainability is the center of ASU's initiatives focusing on practical solutions to environmental, economic, and social challenges.
The institute has partnered with various cities, universities, and organizations from around the world to address issues affecting the global community.
ASU is also involved with NASA in the field of space exploration.
To meet the needs of NASA programs, ASU built the LEED Gold Certified, 298,000 - square-foot Interdisciplinary Science and Technology Building IV (ISTB 4) at a cost of $ 110 million in 2012.
The building includes space for the School of Earth and Space Exploration (SESE) and includes labs and other facilities for the Ira A. Fulton Schools of Engineering.
One of the main projects at ISTB 4 includes the OSIRIS-REx Thermal Emission Spectrometer (OTES).
Although ASU built the spectrometers aboard the Martian rovers Spirit and Opportunity, OTES will be the first major scientific instrument completely designed and built at ASU for a NASA space mission.
Phil Christensen, the principal investigator for the Mars Global Surveyor Thermal Emission Spectrometer (TES), is a Regents' Professor at ASU.
He also serves as the principal investigator for the Mars Odyssey THEMIS instruments, as well as co-investigator for the Mars Exploration Rovers.
ASU scientists are responsible for the Mini-TES instruments aboard the Mars Exploration Rovers.
The Center for Meteorite Studies, which is home to rare Martian meteorites and exotic fragments from space, and the Mars Space Flight Facility are on ASU's Tempe campus.
In 2017, Lindy Elkins-Tanton of ASU, was selected by NASA to lead a deep space mission to Psyche, a metal asteroid believed to be a planetary core.
The $ 450 million project is the first NASA mission led by the university.
The Army Research Laboratory extended funding for the Arizona State University Flexible Display Center (FDC) in 2009 with a $ 50 million grant.
The university has partnered with the Pentagon on such endeavors since 2004 with an initial $ 43.7 million grant.
In 2012, researchers at the center created the world's largest flexible full-color organic light-emitting diode (OLED), which at the time was 7.4 inches.
The following year, the FEDC staff broke their own world record, producing a 14.7 - inch version of the display.
The technology delivers high-performance while remaining cost-effective during the manufacturing process.
Vibrant colors, high switching speeds for video and reduced power consumption are some of the features the center has integrated into the technology.
In 2012, ASU eliminated the need for specialized equipment and processing, thereby reducing costs compared to competitive approaches.
ASU's faculty and students are served by nine libraries across five campuses: Hayden Library, Noble Library, Music Library and Design and the Arts Library on the Tempe campus; Fletcher Library on the West campus; Downtown Phoenix campus library and Ross-Blakley Law Library at the Downtown Phoenix campus; Polytechnic campus library; and the Thunderbird Library at the Thunderbird campus.
, ASU's libraries held 4.5 million volumes.
The Arizona State University library system is ranked the 34th largest research library in the United States and Canada, according to criteria established by the Association of Research Libraries that measures various aspects of quality and size of the collection.
The University continues to grow its rare special collections, such as the recent addition of a privately held collection of manuscripts by poet Rubén Darío.
Hayden Library is on Cady Mall in the center of the Tempe campus and is currently under renovation.
It opened in 1966 and is the largest library facility at ASU.
An expansion in 1989 created the subterranean entrance underneath Hayden Lawn and is attached to the above-ground portion of the original library.
There are two floors underneath Hayden Lawn with a landmark known as the "" Beacon of Knowledge "" rising from the center.
The underground library lights the beacon at night.
The 2013 Capital Improvement Plan, approved by the Arizona Board of Regents, incorporates a $ 35 million repurposing and renovation project for Hayden Library.
The open air moat area that serves as an outdoor study space will be enclosed to increase indoor space for the library.
Along with increasing space and renovating the facility, the front entrance of Hayden Library will be rebuilt.
, ASU was the top institution of higher education in the United States for solar generating capacity.
Today, the university generates over 24 megawatts (MW) of electricity from on-campus solar arrays.
This is an increase over the June 2012 total of 15.3 MW.
ASU has 88 solar photovoltaic (PV) installations containing 81,424 solar panels across four campuses and the ASU Research Park.
An additional 29 MWdc solar installation was dedicated at Red Rock, Arizona in January 2017, bringing the university's solar generating capacity to 50 MWdc.
Additionally, six wind turbines installed on the roof of the Julie Ann Wrigley Global Institute of Sustainability building on the Tempe campus have operated since October 2008.
Under normal conditions, the six turbines produce enough electricity to power approximately 36 computers.
ASU's School of Sustainability was the first school in the United States to introduce degrees in the field of sustainability.
ASU's School of Sustainability is part of the Wrigley Global Institute of Sustainability.
The School was established in spring 2007 and began enrolling undergraduates in fall 2008.
The school offers majors, minors, and a number of certificates in sustainability.
ASU is also home to the Sustainability Consortium which was founded by Jay Golden in 2009.
The School of Sustainability has been essential in establishing the university as "a leader in the academics of sustainable business."
The university is widely considered to be one of the most ambitious and principled organizations for embedding sustainable practices into its operating model.
The university has embraced several challenging sustainability goals.
Among the numerous benchmarks outlined in the university's prospectus, is the creation of a large recycling and composting operation that will eliminate 30 % and divert 90 % of waste from landfills.
This endeavor will be aided by educating students about the benefits of avoiding overconsumption that contributes to excessive waste.
Sustainability courses have been expanded to attain this goal and many of the university's individual colleges and schools have integrated such material into their lectures and courses.
Second, ASU is on track to reduce its rate of water consumption by 50 %.
The university's most aggressive benchmark is to be the first, large research university to achieve carbon neutrality as it pertains to its Scope 1, 2 and non-transportation Scope 3 greenhouse gas (GHG) emissions.
Gold is the oldest color associated with Arizona State University and dates back to 1896 when the school was named the Tempe Normal School.
Maroon and white were later added to the color scheme in 1898.
Gold signifies the "golden promise" of ASU.
The promise includes every student receiving a valuable educational experience.
Gold also signifies the sunshine Arizona is famous for; including the power of the sun and its influence on the climate and the economy.
The first uniforms worn by athletes associated with the university were black and white when the "Normals" were the name of the athletic teams.
The student section, known as The Inferno, wears gold on game days.
Maroon signifies sacrifice and bravery while white represents the balance of negativity and positivity.
As it is in the city of Tempe, Arizona, the school's colors adorn the neighboring buildings during big game days and festive events.
Sparky the Sun Devil is the mascot of Arizona State University and was named by vote of the student body on November 8, 1946.
Sparky often travels with the team across the country and has been at every football bowl game in which the university has participated.
The university's mascot is not to be confused with the athletics department's logo, the "Pitchfork" or hand gesture used by those associated with the university.
The new logo is used on various sport facilities, uniforms and athletics documents.
Arizona State Teacher's College had a different mascot and the sports teams were known as the Owls and later, the Bulldogs.
When the school was first established, the Tempe Normal School's teams were simply known as the Normals.
Sparky is visible on the sidelines of every home game played in Sun Devil Stadium or other ASU athletic facilities.
His routine at football games includes pushups after every touchdown scored by the Sun Devils.
He is aided by Sparky's Crew, male yell leaders that must meet physical requirements to participate as members.
The female members are known as the Spirit Squad and are categorized into a dance line and spirit line.
They are the official squad that represents ASU.
The spirit squad competes every year at the ESPN Universal Dance Association (UDA) College Nationals in the Jazz and Hip-Hop categories.
They were chosen by the UDA to represent the US at the World Dance Championship 2013 in the Jazz category.
A letter has existed on the slope of the mountain since 1918.
A "T" followed by an "N" were the first letters to grace the landmark.
Tempe Butte, home to "A" Mountain, has had the "A" installed on the slope of its south face since 1938 and is visible from campus just to the south.
The original "A" was destroyed by vandals in 1952 with pipe bombs and a new "A", constructed of reinforced concrete, was built in 1955.
The vandals were never identified but many speculate the conspirators were students from the rival in-state university (University of Arizona).
Many ancient Hohokam petroglyphs were destroyed by the bomb; nevertheless, many of these archeological sites around the mountain remain.
There are many traditions surrounding "A" Mountain, including a revived "guarding of the ' A '" in which students camp on the mountainside before games with rival schools.
"Whitewashing" of the "A" is a tradition in which incoming freshmen paint the letter white during orientation week and is repainted gold before the first football game of the season.
Whitewashing dates back to the 1930 s and it grows in popularity every year, with thousands of students going up to paint the "A" every year.
The Lantern Walk is one of the oldest traditions at ASU and dates back to 1917.
It is considered one of ASU's "most cherished" traditions and is an occasion used to mark the work of those associated with ASU throughout history.
Anyone associated with ASU is free to participate in the event, including students, alumni, faculty, employees, and friends.
This differs slightly from the original tradition in which the seniors would carry lanterns up "A" Mountain followed by the freshman.
The senior class president would describe ASU's traditions and the freshman would repeat an oath of allegiance to the university.
It was described as a tradition of "good will between the classes" and a way of ensuring new students would continue the university's traditions with honor.
In modern times, the participants walk through campus and follow a path up to "A" Mountain to "light up" Tempe.
Keynote speakers, performances, and other events are used to mark the occasion.
The night is culminated with a fireworks display.
The Lantern Walk was held after the Spring Semester (June) but is now held the week before Homecoming, a tradition that dates to 1924 at ASU.
It is held in the fall and in conjunction with a football game.
In 2012, Arizona State University reintroduced the tradition of ringing a bell after each win for the football team.
The ROTC cadets associated with the university transport the bell to various events and ring it after Sun Devil victories.
The first Victory Bell, in various forms, was used in the 1930 s but the tradition faded in the 1970 s when the bell was removed from Memorial Union for renovations.
The bell cracked and was no longer capable of ringing.
That bell is on the southeast corner of Sun Devil Stadium, near the entrance to the student section.
That bell, given to the university in the late 1960 s, is painted gold and is a campus landmark.
The Arizona State University Sun Devil Marching Band, created in 1915 and known as the "Pride of the Southwest", was the first of only two marching bands in the Pac-12 to receive the prestigious Sudler Trophy.
The John Philip Sousa Foundation awarded the band the trophy in 1991.
The Sun Devil Marching Band remains one of only 28 bands in the nation to have earned the designation.
The band performs at every football game played in Sun Devil Stadium.
In addition, the Sun Devil Marching Band has made appearances in the Fiesta Bowl, the Rose Bowl, the Holiday Bowl, and the Super Bowl XLII, in addition to many others.
Smaller ensembles of band members perform at other sport venues including basketball games at Wells Fargo Arena and baseball games.
The Devil Walk is held in Wells Fargo Arena by the football team and involves a more formal introduction of the players to the community; a new approach to the tradition added in 2012 with the arrival of head coach Todd Graham.
It begins 2 hours and 15 minutes prior to the game and allows the players to establish rapport with the fans.
The walk ends as the team passes the band and fans lined along the path to Sun Devil Stadium.
The most recognizable songs played by the band are "Alma Mater" and ASU's fight songs titled "Maroon and Gold" and the "Al Davis Fight Song".
"Alma Mater" was composed by former Music Professor and Director of Sun Devil Marching Band (then known as Bulldog Marching Band), Miles A. Dresskell, in 1937.
"Maroon and Gold" was authored by former Director of Sun Devil Marching Band, Felix E. McKernan, in 1948.
The "Al Davis Fight Song" (also known as "Go, Go Sun Devils" and "Arizona State University Fight Song") was composed by ASU alumnus Albert Oliver Davis in the 1940 s without any lyrics.
Recently lyrics were added to the song.
Arizona State University has an active extracurricular involvement program.
Located on the second floor of the Student Pavilion at the Tempe campus, Educational Outreach and Student Services (EOSS) provides opportunities for student involvement through clubs, sororities, fraternities, community service, leadership, student government, and co-curricular programming.
Changemaker Central is a student-run centralized resource hub for student involvement in social entrepreneurship, civic engagement, service learning and community service that catalyzes student-driven social change.
Changemaker Central locations have opened on all campuses in fall 2011, providing flexible, creative workspaces for everyone in the ASU community.
The project is entirely student run and advances ASU's institutional commitments to social embeddedness and entrepreneurship.
The space allows students to meet, work and join new networks and collaborative enterprises while taking advantage of ASU's many resources and opportunities for engagement.
Changemaker Central has signature programs, including Changemaker Challenge, that support students in their journey to become changemakers by creating communities of support around new solutions/ideas and increasing access to early stage seed funding.
The Changemaker Challenge seeks undergraduate and graduate students from across the university who are dedicated to making a difference in our local and global communities through innovation.
Students can win up to $ 10,000 to make their innovative project, prototype, venture or community partnership ideas happen.
In addition to Changemaker Central, the Greek community (Greek Life) at Arizona State University has been important in binding students to the university, and providing social outlets.
ASU is also home to one of the nation's first and fastest growing gay fraternities, Sigma Phi Beta, founded in 2003; considered a sign of the growing university's commitment to supporting diversity and inclusion.
The second Eta chapter of Phrateres, a non-exclusive, non-profit social-service club, was installed here in 1958 and became inactive in the 1990 s.
There are multiple councils for Greek Life, including the Interfraternity Council (IFC), Multicultural Greek Council (MGC), National Association of Latino Fraternal Organizations (NALFO), National Pan-Hellenic Council (NPHC), Panhellenic Association (PHA), and the Professional Fraternity Council (PFC).
"The State Press" is the university's independent, student-operated news publication.
"The State Press" covers news and events on all four ASU campuses.
Student editors and managers are solely responsible for the content of the "State Press" website.
These publications are overseen by an independent board and guided by a professional adviser employed by the university.
"The Downtown Devil" is a student-run news publication website for the Downtown Phoenix Campus, produced by students at the Walter Cronkite School of Journalism and Mass Communication.
ASU has two radio stations.
KASC The Blaze 1330 AM, is a broadcast station owned and funded by the Cronkite School of Journalism, and is completely student-run save for a faculty and professional adviser.
The Blaze broadcasts music 24 hours a day and features news and sports updates at the top and bottom of every hour.
W7ASU is an amateur radio station that was first organized in 1935.
W7ASU has about 30 members that enjoy amateur radio, and is primarily a contesting club.
Associated Students of Arizona State University (ASASU) is the student government at Arizona State University.
It is composed of the Undergraduate Student Government and the Graduate & Professional Student Association (GPSA).
Each ASU campus has a specific USG; USG Tempe (Tempe), USGD (Downtown), USG Polytechnic (Polytechnic) and USG West (West).
Members and officers of ASASU are elected annually by the student body.
The Residence Hall Association (RHA) of Arizona State University is the student government for every ASU student living on-campus.
Each ASU campus has an RHA that operates independently.
RHA's purpose is to improve the quality of residence hall life and provide a cohesive voice for the residents by addressing the concerns of the on-campus populations to university administrators and other campus organizations; providing cultural, diversity, educational, and social programming; establishing and working with individual community councils.
Arizona State University offers undergraduate student housing on four metropolitan Phoenix campuses (Tempe, Polytechnic, Downtown Phoenix, and West), plus the ASU Colleges at Lake Havasu City.
On the Tempe campus it includes dorms such as Palo Verde East, Palo Verde West, Tooker House (formerly Palo Verde Main), University Towers, Arcadia, Manzanita, Hassayampa Academic Village, San Pablo (otherwise known as "CLAS Academy"), the Sonora Center, and multiple Barrett dorms.
Recently, ASU has added Vista Del Sol on Apache road to the on campus living for upper class honors students.
Each dormitory is identified with a specific college, institute, major, or sport, and are relatively close to all the classes the student would be taking according to their major (excluding the Sonora Center which is meant to house ' overflow ' students that do not fit in the other dormitory complexes, as well as students who have declared their major as' exploratory ').
For example, Tooker House is strictly freshmen engineering students.
Aside from the on-campus dorms, ASU also offers residential halls for upper-division housing and Greek life housing.
Greek housing is only available for sororities that are members of ASU Panhellenic.
There are 12 sororities residing in Greek life housing.
Sororities are housed in a gated complex called Adelphi Commons and it is only accessible to members of the sororities.
Arizona State University's Division I athletic teams are called the Sun Devils, which is also the nickname used to refer to students and alumni of the university.
They compete in the Pac-12 Conference in 20 varsity sports.
Historically, the university has highly performed in men's, women's, and mixed archery; men's, women's, and mixed badminton; women's golf; women's swimming and diving; baseball; and football.
Arizona State University's NCAA Division I-A program competes in 9 varsity sports for men and 11 for women.
ASU's athletic director is Ray Anderson, former executive vice president of football operations for the National Football League.
Anderson replaced Steve Patterson, who was appointed to the position in 2012, replacing Lisa Love, the former Senior Associate Athletic Director at the University of Southern California.
Love was responsible for the hiring of coaches Herb Sendek, the men's basketball coach, and Dennis Erickson, the men's football coach.
Erickson was fired in 2011 and replaced by Todd Graham.
In December 2017, ASU announced that Herm Edwards would replace Graham as the head football coach.
The rival to Arizona State University is University of Arizona.
ASU has won 24 national collegiate team championships in the following sports: baseball (5), men's golf (2), women's golf (8), men's gymnastics (1), softball (2), men's indoor track (1), women's indoor track (2), men's outdoor track (1), women's outdoor track (1), and wrestling (1).
In September 2009, criticism over the seven-figure salaries earned by various coaches at Arizona's public universities (including ASU) prompted the Arizona Board of Regents to re-evaluate the salary and benefit policy for athletic staff.
With the 2011 expansion of the Pac-12 Conference, a new $ 3 billion contract for revenue sharing among all the schools in the conference was established.
With the infusion of funds, the salary issue and various athletic department budgeting issues at ASU were addressed.
The Pac-12's new media contract with ESPN allowed ASU to hire a new coach in 2012.
A new salary and bonus package (maximum bonus of $ 2.05 million) was instituted and is one of the most lucrative in the conference.
ASU also plans to expand its athletic facilities with a public-private investment strategy to create an amateur sports district that can accommodate the Pan American Games and operate as an Olympic Training Center.
The athletic district will include a $ 300 million renovation of Sun Devil Stadium that will include new football facilities.
The press box and football offices in Sun Devil Stadium were remodeled in 2012.
Arizona State Sun Devils football was founded in 1896 under coach Fred Irish.
The team has played in the 2012 Fight Hunger Bowl, the 2011 Las Vegas bowl, the 2016 Cactus Bowl, and the 2007 Holiday Bowl.
The Sun Devils played in the 1997 Rose Bowl and won the Rose Bowl in 1987.
The team has appeared in the Fiesta Bowl in 1983, 1977, 1975, 1973, 1972, and 1971 winning 5 of 6.
In 1970, and 1975, they were champions of the NCAA Division I FBS National Football Championship.
The Sun Devils were Pac-12 Champions in 1986, 1996, and 2007.
Altogether, the football team has 17 Conference Championships and has participated in a total of 29 bowl games as of the 2015 – 2016 season with a 14 – 14 – 1 record in those games.
ASU Sun Devils Hockey competed with NCAA Division 1 schools for the first time in 2012, largely due to the success of the program.
In 2016, they began as a full-time Division I team.
Eight members of ASU's Women's Swimming and Diving Team were selected to the Pac-10 All-Academic Team on April 5, 2010.
In addition, five member of ASU's Men's Swimming and Diving Team were selected to the Pac-10 All-Academic Team on April 6, 2010.
In April 2015, Bobby Hurley was hired as the men's basketball coach, replacing Herb Sendek.
Previously, Hurley was the head coach at the University of Buffalo as well as an assistant coach at Rhode Island and Wagner University.
In 2015, Bob Bowman was hired as the head swim coach.
Previously, Bowman trained Michael Phelps through his Olympic career.
As of Fall 2015, ASU students, including those enrolled in online courses, may avail of a free ticket to all ASU athletic events upon presentation of a valid student ID.
Arizona State University has produced over 400,000 alumni worldwide.
The university has produced many notable figures over its 125-year history, including influential U.S. senator Carl Hayden, and Silver Star recipient Pat Tillman, who left his National Football League career to enlist in the United States Army in the aftermath of the September 11, 2001 terrorist attacks.
Barbara Barrett, who served as U.S. Ambassador to Finland under President George W. Bush and has been nominated by President Donald J. Trump as the next Secretary of the U.S. Air Force, attained her bachelor's, master's, and law degrees from ASU.
Other notable alumni include nine current or former U.S. Representatives, including Barry Goldwater, Jr., Ed Pastor, and Matt Salmon.
Arizona governors Doug Ducey, Jane Dee Hull, and Evan Mecham also attended ASU.
Attorney General Mark Brnovich is an ASU alumnus.
Peterson Zah, who was the first Navajo President and the last Chairman of the Navajo Nation, is an ASU graduate.
The economy minister of the United Arab Emirates, Sultan bin Saeed Al Mansoori, is another ASU alumnus.
Business leaders that attended ASU include: Ira A. Fulton, philanthropist and founder of Fulton Homes; Kate Spade, namesake and co-Founder of Kate Spade New York; and Larry Carter, CFO of Cisco Systems.
Kevin Warren is the COO of the Minnesota Vikings, and the highest ranking African-American executive working on the business side of an NFL team.
In addition to Pat Tillman, ASU has had many renowned athletes attend the school.
Those athletes include: World Golf Hall of Fame member Phil Mickelson, Baseball Hall of Fame member Reggie Jackson, Major League Baseball home run king Barry Bonds, National Basketball Association All-Star James Harden, and 2011 NFL Defensive Player of the Year Terrell Suggs.
ASU alumni enshrined in the Pro Football Hall of Fame include: Curley Culp, Mike Haynes, John Henry Johnson, Randall McDaniel, and Charley Taylor.
Other notable athletes that attended ASU are: Major League Baseball All-Stars Dustin Pedroia, Sal Bando, and Paul Lo Duca; National Basketball Association All-Stars Lionel Hollins and Fat Lever, and NBA All-Star coach Byron Scott; National Football League Pro Bowl selections Jake Plummer and Danny White, as well as Miami Dolphins quarterback Brock Osweiler; and three-time Olympic gold medalist swimmers Melissa Belote and Jan Henne, and two-time Olympian and double-Olympic gold medalist Megan Jendrick.
Celebrities who have attended ASU include: "Jimmy Kimmel Live!"
host Jimmy Kimmel; Steve Allen, who was the original host of "The Tonight Show"; Academy Award-nominated actor Nick Nolte; 11-Time Grammy Award winning singer Linda Ronstadt; singer-songwriter Carolyne Mas; "Saturday Night Live" and "Tommy Boy" actor David Spade; "Wonder Woman" actress Lynda Carter; and "Road to Perdition" actor Tyler Hoechlin.
Influential writers and novelists include: Allison Dubois, whose novels and work inspired the TV miniseries "Medium"; novelist Amanda Brown; author and spiritual teacher Howard Falco; and best-selling author and Doctor of Animal Science Temple Grandin.
Journalists and commentators include former Monday Night Football announcer, and Sunday Night Football announcer Al Michaels, and writer and cartoonist Jerry Dumas, who is best known for his "Sam and Silo" comic strip.
Radio host Michael Reagan, the son of President Ronald Reagan and actress Jane Wyman, also briefly attended.
Among American research universities, Arizona State is ranked 7th for sending students abroad through the prestigious Fulbright Scholarship program in the 2017 – 2018 academic year.
ASU has made this list for more than 9 consecutive years.
The Arizona State University Alumni Association is on the Tempe campus in Old Main.
The Alumni Association continues many of the university's traditions.
ASU faculty have included former CNN host Aaron Brown, meta-analysis developer Gene V. Glass, feminist and author Gloria Feldt, physicist Paul Davies, and Pulitzer Prize winner and "The Ants" coauthor Bert Hölldobler.
Donald Johanson, who discovered the 3.18 million year old fossil hominid Lucy (Australopithecus) in Ethiopia, is also a professor at ASU, as well as George Poste, Chief Scientist for the Complex Adaptive Systems Initiative.
Nobel laureate faculty include Leland Hartwell, and Edward C. Prescott.
On June 12, 2012 Elinor Ostrom, ASU's third Nobel laureate, died at the age of 78.
ASU faculty's achievements include: Arizona State University has been visited by nine United States presidents.
President Theodore Roosevelt was the first president to visit campus, speaking on the steps of Old Main on March 20, 1911, while in Arizona to dedicate the Roosevelt Dam.
President Lyndon B. Johnson spoke at ASU's Grady Gammage Memorial Auditorium on January 29, 1972, at a memorial service for ASU alumnus Senator Carl T. Hayden.
Future president Gerald R. Ford debated Senator Albert Gore, Sr. at Grady Gammage Memorial Auditorium on April 28, 1968, and Ford returned to the same building as a former president to give a lecture on February 24, 1984.
President Jimmy Carter visited Arizona PBS at ASU's Walter Cronkite School of Journalism and Mass Communication on July 31, 2015, to promote a memoir.
Future president Ronald Reagan gave a political speech at the school's Memorial Union in 1957, and returned to campus as a former president on March 20, 1989, delivering his first ever post-presidential speech at ASU's Wells Fargo Arena.
President George H. W. Bush gave a lecture at Wells Fargo Arena on May 5, 1998.
President Bill Clinton became the first sitting president to visit ASU on October 31, 1996, speaking on the Grady Gammage Memorial Auditorium lawn.
He returned to ASU in 2006, and in 2014, President Clinton, Hillary Clinton, and Chelsea Clinton came to campus to host the Clinton Global Initiative University.
President George W. Bush became the second sitting president to visit the school's campus when he debated Senator John Kerry at the university's Grady Gammage Memorial Auditorium on October 13, 2004.
President Barack Obama visited ASU as sitting president on May 13, 2009.
President Obama delivered the commencement speech for the Spring 2009 Commencement Ceremony.
President Obama had previously visited the school as a United States senator.
President Richard Nixon did not visit ASU as president, but visited Phoenix as president on October 31, 1970, at an event that included a performance by the Arizona State University Band, which President Nixon acknowledged.
As part of President Nixon's remarks, he stated that, "when I am in Arizona, Arizona State is number one."
On May 1, 2014, ASU was listed as one of fifty five higher education institutions under investigation by the Office of Civil Rights "for possible violations of federal law over the handling of sexual violence and harassment complaints" by Barack Obama's White House Task Force To Protect Students from Sexual Assault.
The publicly announced investigation followed two Title IX suits.
In July 2014, a group of at least nine current and former students who alleged they were harassed or assaulted asked the federal investigation be expanded.
In August 2014 ASU President Michael Crow appointed a task force comprising faculty and staff, students, and members of the university police force to review the university's efforts to address sexual violence.
Crow accepted the recommendations of the task force in November 2014.
In 2011, Professor Matthew Whitaker was accused of plagiarizing material in six books he had written, as well as in a speech he made to local high school students.
After watching a video of the speech, a plagiarism analyst said he could pretty much read along from a newspaper article as Whitaker spoke.
To the intense consternation of ASU faculty members (the chairman of the tenure committee resigned in protest) an investigating committee concluded there was no pattern of deceit and the copying had been inadvertent.
It all popped up again in 2014 with another Whitaker book, "Peace Be Still: Modern Black America From World War II to Barack Obama."
A blogger writing under an apparent pseudonym set out side-by-side excerpts from Whitaker's book and material available on the Web at sites like infoplease.
com and the Archive of American Television.
They are more than just similar in tone.
Whitaker has also been accused of appropriating training materials produced by the Chicago Police Department which he used as the basis for a lucrative contract with the Phoenix Police Department.
Whitaker was to receive $ 268,800 to provide "cultural-consciousness training" to Phoenix police.
The Phoenix Police Department wants back the $ 21,900 it has paid thus far.
He was placed on administrative leave on September 17, 2015, while the university investigated allegations "his behavior has fallen short of expectations as a faculty member and a scholar."
The Arizona Attorney General, Mark Brnovich filed a lawsuit in late 2017 against ABOR due to tuition practices and DACA.
The attorney general's lawsuit succeeded, and in a decision by the court, led to the discontinuation of the in-state tuition rate for undocumented immigrants in the state based on Arizona Prop 300, which passed in 2006.
Private corporations leasing public land from the university in furtherance of their corporate mission (which in the case of private employers includes making profit) are revealed to pay no taxes to the state because the land is owned by a state public entity.
Taxpayers were never given a vote to permit profit-seeking ventures on state lands which have historically existed to serve the public good.
The state universities later lobby the Arizona legislature to keep the loophole open for future use by the universities.
This scheme, called a "tax dodge" by its detractors, avoids the private businesses from "paying $ 90 million to $ 120 million in property taxes" to the state of Arizona.
Arizona State, one of the in-state colleges requires its students to pay a mandatory sports and athletic fee, regardless of if the students participate in such activities.
The fees are a part of a total $ 10.6 million in fees collected from students.
The fees go to non-academic programs including "Game day operations, marketing, game-day giveaways and maintenance.".
Students may not opt-out of the fees.
While ASU has increased tuition over 100 % over the 2007 - 2018 timeframe, the university found the money to demolish and rebuild a stadium with smaller capacity than before at a cost to taxpayers and students of approximately $ 307 million.
Critics argue ASU was offering private corporations tax-advantaged deals to develop on state property in exchange for funding the new stadium.
Michael M. Crow, ASU president counters the tax-advantaged deal is "no scheme" to hurt schools which might have otherwise benefited from the tax receipts.
The Arizona legislature appropriated $ 5 million for the development of Koch brothers-affiliated conservative think tanks at ASU dubbed "School of Civic and Economic Thought Leadership."
According to ThinkProgress, a progressive-leaning publication, "Koch-funded professors and advisers have suggested that educational initiatives that are disguised as being more neutral in their approach but that support a libertarian ideology."
According to "The New York Times", "Republican legislatures have been taking a greater interest in the affairs of their state universities to counteract what they see as excessive liberalism on campus.".
At the same time as the legislature funded the think tank, "steady cuts left state universities with $ 390 million less in taxpayer support in 2017 than they had before the 2008 recession, requiring steep tuition increases".
Astoria, Oregon Astoria is a port city and the seat of Clatsop County, Oregon, United States.
Founded in 1811, Astoria is the oldest city in the state of Oregon and was the first American settlement west of the Rocky Mountains.
Astoria is located on the south shore of the Columbia River, where the river meets the Pacific Ocean.
The city is named for John Jacob Astor, an investor from New York City whose American Fur Company founded Fort Astoria at the site.
Astoria was incorporated by the Oregon Legislative Assembly on October 20, 1876.
The city is served by the deepwater Port of Astoria.
Transportation includes the Astoria Regional Airport with U.S. Route 30 and U.S. Route 101 as the main highways, and the Astoria–Megler Bridge connecting to neighboring Washington across the river.
The population was 9,477 at the 2010 census.
The Lewis and Clark Expedition spent the winter of 1805 – 1806 at Fort Clatsop, a small log structure southwest of modern-day Astoria.
The expedition had hoped a ship would come by to take them back east, but instead they endured a torturous winter of rain and cold, later returning the way they came.
Today the fort has been recreated and is now a historical park.
In 1811, British explorer David Thompson, the first person known to have navigated the entire length of the Columbia River, reached the partially constructed Fort Astoria near the mouth of the river.
He arrived just two months after the Pacific Fur Company's ship, the "Tonquin".
The fort constructed by the Tonquin party established Astoria as a U.S., rather than a British, settlement, became a vital post for American exploration of the continent and was later used as an American claim in the Oregon boundary dispute with European nations.
The Pacific Fur Company, a subsidiary of John Jacob Astor's American Fur Company, was created to begin fur trading in the Oregon Country.
During the War of 1812, in 1813, the company's officers sold its assets to their Canadian rivals, the North West Company.
The fur trade would remain under British control until U.S. pioneers following the Oregon Trail began filtering into the town in the mid-1840 s.
The Treaty of 1818 established joint U.S. – British occupancy of the Oregon Country.
In 1846, the Oregon Treaty divided the mainland at the 49th parallel north, and the southern portion of Vancouver Island south of this line was awarded to the British.
Washington Irving, a prominent American writer with a European reputation, was approached by John Jacob Astor to mythologize the three-year reign of his Pacific Fur Company.
"Astoria" (1835), written while Irving was Astor's guest, cemented the importance of the region in the American psyche.
In Irving's words, the fur traders were "Sinbads of the wilderness", and their venture was a staging point for the spread of American economic power into both the continental interior and into the Pacific.
As the Oregon Territory grew and became increasingly more colonized by Americans, Astoria likewise grew as a port city near the mouth of the great river that provided the easiest access to the interior.
The first U.S. post office west of the Rocky Mountains was established in Astoria in 1847 and official state incorporation in 1876.
Astoria attracted a host of immigrants beginning in the late 19th century: Nordic settlers, primarily Finns, and Chinese soon became larger parts of the population.
The Finns mostly lived in Uniontown, near the present-day end of the Astoria–Megler Bridge, and took fishing jobs; the Chinese tended to do cannery work, and usually lived either downtown or in bunkhouses near the canneries.
By the late 1800 s, 22 % of Astoria's population was Chinese.
In 1883, and again in 1922, downtown Astoria was devastated by fire, partly because it was mostly wood and entirely raised off the marshy ground on pilings.
Even after the first fire, the same format was used, and the second time around the flames spread quickly again, as collapsing streets took out the water system.
Frantic citizens resorted to dynamite, blowing up entire buildings to stop the fire from going further.
Astoria has served as a port of entry for over a century and remains the trading center for the lower Columbia basin, although it has long since been eclipsed by Portland, Oregon, and Seattle, Washington, as an economic hub on the coast of the Pacific Northwest.
Astoria's economy centered on fishing, fish processing, and lumber.
In 1945, about 30 canneries could be found along the Columbia; however, in 1974, the Bumble Bee Seafoods corporation moved its headquarters out of Astoria and gradually reduced its presence until closing its last Astoria cannery in 1980.
The lumber industry likewise declined; Astoria Plywood Mill, the city's largest employer, closed in 1989, and the Burlington Northern and Santa Fe Railway discontinued service to Astoria in 1996.
From 1921 to 1966, a ferry route across the Columbia River connected Astoria with Pacific County, Washington.
In 1966, the Astoria–Megler Bridge was opened.
The bridge completed U.S. Route 101 and linked Astoria with Washington on the opposite shore of the Columbia, replacing the ferry service.
Today, tourism, Astoria's growing art scene, and light manufacturing are the main economic activities of the city.
Logging and fishing persist, but at a fraction of their former levels.
It is a port of call for cruise ships since 1982, after $ 10 million in pier improvements to accommodate these larger ships.
To avoid Mexican ports of call during the Swine Flu outbreak of 2009, many cruises were re-routed to include Astoria.
The floating residential community MS "The World" visited Astoria in June 2009.
The town's seasonal sport fishing tourism has been active for several decades In addition to the replicated Fort Clatsop, another point of interest is the Astoria Column, a tower high, built atop Coxcomb Hill above the town, with an inner circular staircase allowing visitors to climb to see a panoramic view of the town, the surrounding lands, and the Columbia flowing into the Pacific.
The tower was built in 1926 with financing by the Great Northern Railway and Vincent Astor of the Astor family, the great-grandson of John Jacob Astor, in commemoration of the city's role in the family's business history and the region's early history.
Since 1998, artistically-inclined fishermen and women from Alaska and the Pacific Northwest have traveled to Astoria for the Fisher Poets Gathering, where poets and singers tell their tales to honor the fishing industry and lifestyle.
Another popular annual event is the Dark Arts Festival, which features music, art, dance, and demonstrations of craft such as blacksmithing and glassblowing in combination with a large array of dark craft brews.
Dark Arts Festival began as a small gathering at a community arts space.
Now Fort George Brewery hosts the event, which draws hundreds of visitors and tour buses from Seattle.
Astoria is also the western terminus of the TransAmerica Bicycle Trail, a coast-to-coast bicycle touring route created in 1976 by the Adventure Cycling Association.
Three United States Coast Guard cutters: the "Steadfast", "Alert", and "Fir", call the port of Astoria home.
According to the United States Census Bureau, the city has a total area of, of which is land and is water.
Astoria lies within the Mediterranean climate zone (Köppen "Csb"), with cool winters and mild summers, although short heat waves can occur.
Rainfall is most abundant in late fall and winter and is lightest in July and August, averaging approximately of rain each year.
Snowfall is relatively rare, occurring in only three-fifths of years.
Nevertheless, when conditions are ripe, significant snowfalls can occur.
Astoria is tied with Lake Charles, Louisiana, and Port Arthur, Texas, as the city with the highest average relative humidity in the contiguous United States.
The average relative humidity in Astoria is 89 % in the morning and 73 % in the afternoon.
Annually, there are an average of only 4.2 afternoons with temperatures reaching or higher, and readings are rare.
Normally there are only one or two nights per year when the temperature remains at or above.
There are an average of 31 mornings with minimum temperatures at or below the freezing mark.
The record high temperature was on July 1, 1942.
The record low temperature was on December 8, 1972, and on December 21, 1990.
There are an average of 191 days with measurable precipitation.
The wettest "water year", defined as October 1 through September 30 of the next year, was from 1915 – 16 with and the driest from 2000 – 2001 with.
The most rainfall in one month was in December 1933, and the most in 24 hours was on November 25, 1998.
The most snowfall in one month was in January 1950, and the most snow in 24 hours was on December 11, 1922.
As of the 2010 census, there were 9,477 people, 4,288 households, and 2,274 families residing in the city.
The population density was.
There were 4,980 housing units at an average density of.
The racial makeup of the city was 89.2 % White, 0.6 % African American, 1.1 % Native American, 1.8 % Asian, 0.1 % Pacific Islander, 3.9 % from other races, and 3.3 % from two or more races.
Hispanic or Latino of any race were 9.8 % of the population.
There were 4,288 households, of which 24.6 % had children under the age of 18 living with them, 37.9 % were married couples living together, 10.8 % had a female householder with no husband present, 4.3 % had a male householder with no wife present, and 47.0 % were non-families.
38.8 % of all households were made up of individuals and 15.1 % had someone living alone who was 65 years of age or older.
The average household size was 2.15 and the average family size was 2.86.
The median age in the city was 41.9 years.
20.3 % of residents were under the age of 18; 8.6 % were between the ages of 18 and 24; 24.3 % were from 25 to 44; 29.9 % were from 45 to 64; and 17.1 % were 65 years of age or older.
The gender makeup of the city was 48.4 % male and 51.6 % female.
As of the 2000 census, there were 9,813 people, 4,235 households, and 2,469 families residing in the city.
The population density was 1,597.6 people per square mile (617.1 per km ²).
There were 4,858 housing units at an average density of 790.9 per square mile (305.5 per km ²).
The racial makeup of the city was: 5.98 % of the population were Hispanic or Latino of any race.
14.2 % were of German, 11.4 % Irish, 10.2 % English, 8.3 % United States or American, 6.1 % Finnish, 5.6 % Norwegian, and 5.4 % Scottish ancestry according to the 2000 United States Census.
There were 4,235 households out of which 28.8 % had children under the age of 18 living with them, 43.5 % were married couples living together, 11.2 % had a female householder with no husband present, and 41.7 % were non-families.
35.4 % of all households were made up of individuals and 13.6 % had someone living alone who was 65 years of age or older.
The average household size was 2.26 and the average family size was 2.93.
In the city the population was spread out with: The median age was 38 years.
For every 100 females, there were 92.3 males.
For every 100 females age 18 and over, there were 89.9 males.
The median income for a household in the city was $ 33,011, and the median income for a family was $ 41,446.
Males had a median income of $ 29,813 versus $ 22,121 for females.
The per capita income for the city was $ 18,759.
About 11.6 % of families and 15.9 % of the population were below the poverty line, including 22.0 % of those under age 18 and 9.6 % of those age 65 or over.
Astoria operates under a council–manager form of city government.
Voters elect four councilors by ward and a mayor, who each serve four-year terms.
The mayor and council appoint a city manager to conduct the ordinary business of the city.
The current mayor is Bruce Jones, a retired US Coast Guard Captain, who took office in January 2019.
His predecessor, Arline Lamear served from 2015 - 2018 The Astoria School District has four primary and secondary schools, including Astoria High School.
Clatsop Community College is the city's two-year college.
The city also has a library and many parks with historical significance, plus the second oldest Job Corps facility (Tongue Point Job Corps) in the nation.
"The Daily Astorian" is the main newspaper serving Astoria, it was established nearly, in 1873, and has been in publication continuously since that time.
The "Coast River Business Journal" is a monthly business magazine covering Astoria, Clatsop County, and the Northwest Oregon coast.
It, as with The Daily Astorian, is part of the EO Media Group (formerly the East Oregonian Publishing Company) family of Oregon and Washington newspapers.
The local NPR station is KMUN 91.9, and KAST 1370 is a local news-talk radio station.
"Shanghaied in Astoria" is a musical about Astoria's history that has been performed in Astoria every year since 1984.
Astoria was the setting of the 1985 film "The Goonies", which was filmed on location.
Other notable movies filmed in Astoria include "Short Circuit", "The Black Stallion", "Kindergarten Cop", "Free Willy", "", "Teenage Mutant Ninja Turtles III", "Benji the Hunted", "Come See the Paradise," "The Ring Two", "Into the Wild", The Guardian "," and "Green Room."
It is claimed that the actor Clark Gable began his career at the Astoria Theatre in 1922.
The early 1960 s television series "Route 66" filmed the episode entitled "One Tiger to a Hill" in Astoria; it was broadcast on September 21, 1962.
Leroy E. "Ed" Parsons, called the "Father of Cable Television", developed one of the first community antenna television stations (CATV) in the United States in Astoria.
Pop punk band The Ataris' fourth album was titled "So Long, Astoria" as an allusion to "The Goonies".
A song of the same title is the album's first track.
The album's back cover features news clippings from Astoria, including a picture of the port's water tower from a 2002 article on its demolition.
Pop punk band Marianas Trench have an album titled "Astoria".
The band states the album was inspired by 1980 s fantasy and adventure films, and "The Goonies" in particular.
That film inspired the title, as it was set in Astoria, the album's artwork, as well as the title of their accompanying US tour ("Hey You Guys !!"
).
Two U.S. Navy cruisers were named USS "Astoria": A New Orleans-class heavy cruiser (CA-34) and a Cleveland class light cruiser (CL-90).
The former was lost in the Pacific Ocean in combat at the Battle of Savo Island in August 1942, during World War II, and the latter was scrapped in 1971 after being removed from active duty in 1949.
Astoria has one sister city, as designated by Sister Cities International:
Alarums and Excursions (A&E) is an amateur press association (APA) started in June 1975 by Lee Gold; publication continues to the present day.
It was one of the first publications to focus solely on role-playing games.
In 1964, Bruce Pelz of the Los Angeles Science Fiction Society (LASFS) began a monthly amateur press association known as "APA-L".
In 1974, with the publication of "Dungeons & Dragons" by TSR, Inc., articles and comments about the new roleplaying game began to fill the pages of "APA-L".
Pelz felt the discussion was taking up too much space, and he asked Lee Gold to start a new APA that would take this material and focus entirely on roleplaying games.
The first issue of "Alarums and Excursions" appeared in June 1975, the title taken from an Elizabethan drama stage direction that moved soldiers across a stage.
In addition to removing roleplaying games discussion out of "APA-L", the initial aim of the publication was to prevent roleplaying games from becoming so divergent that people couldn't participate in games together.
The June 2017 collation of "Alarums and Excursions" was # 500, with a color cover drawn by Lee Moyer and printed by Rob Heinsoo.
Each issue is a collection of contributions from different authors, often featuring game design discussions, rules variants, write-ups of game sessions, reviews, and comments on others contributions.
Although game reports and social reactions are common parts of many "A&E" contributions, it has also, over the years, become a testing ground for new ideas on the development of the RPG as a genre and an art form.
The idea that role-playing games "are" an art form took strong root in this zine, and left a lasting impression on many of the RPG professionals who contributed.
The 1992 role-playing game "Over the Edge" was inspired by discussions in "A&E".
Over the years, contributors have included: In the February 1976 issue of "Strategic Review" (Issue 6), Gary Gygax complimented the new APA, calling it "an excellent source of ideas, inspirations and fun."
To date, "Alarums and Excursions" has been a winner of the Charles Roberts/Origins Award four times:
Alfred Jarry (; 8 September 1873 – 1 November 1907) was a French symbolist writer who is best known for his play "Ubu Roi" (1896), a pataphysical work which depicts the bourgeoisie as the super-mediocre.
He coined the term and philosophical concept of pataphysics, which uses absurd irony to portray symbolic truths (and playfully vice versa).
Jarry was born in Laval, Mayenne, France, and his mother was from Brittany.
He was associated with the Symbolist movement.
His play "Ubu Roi" is often cited as a forerunner of Dada and the Surrealist and Futurist movements of the 1920 s and 1930 s.
He wrote in a variety of hybrid genres and styles, prefiguring the postmodern, including novels, poems, short plays and opéras bouffes, absurdist essays and speculative journalism.
His texts are considered examples of absurdist literature and postmodern philosophy.
His father Anselme Jarry (1837 - 1895) was a salesman who descended into alcoholism; his mother Caroline, née Quernest (1842 - 1893), was interested in music and literature, but her family had a streak of insanity, and her mother and brother were institutionalized.
The couple had two surviving children, a daughter Caroline-Marie, called Charlotte (1865 - 1925), and Alfred.
In 1879 Caroline left Anselme and took the children to Saint-Brieuc in Brittany.
In 1888 the family moved to Rennes, where Jarry entered the lycée at 15.
There he led a group of boys who enjoyed poking fun at their well-meaning, but obese and incompetent physics teacher, a man named Hébert.
Jarry and his classmate, Henri Morin, wrote a play they called "Les Polonais" and performed it with marionettes in the home of one of their friends.
The main character, "Père Heb", was a blunderer with a huge belly, three teeth (one of stone, one of iron and one of wood), a single, retractable ear and a misshapen body.
In Jarry's later work "Ubu Roi", Père Heb would develop into Ubu, one of the most monstrous and astonishing characters in French literature.
At 17 Jarry passed his baccalauréat and moved to Paris to prepare for admission to the École Normale Supérieure.
Though he was not admitted, he soon gained attention for his original poems and prose-poems.
A collection of his work, "Les minutes de sable mémorial", was published in 1893.
That same year, Jarry contracted influenza.
His mother and sister tended him, but once he recovered his mother fell ill of the disease and died; two years later his father perished from influenza as well, leaving Jarry a small inheritance which he quickly spent.
Jarry had meantime discovered the pleasures of alcohol, which he called "my sacred herb" or, when referring to absinthe, the "green goddess."
A story is told that he once painted his face green and rode through town on his bicycle in its honour (and possibly under its influence).
When he was drafted into the army in 1894, his gift for turning notions upside down defeated attempts to instill military discipline.
The sight of the small man in a uniform much too large for his less than 5-foot frame—the army did not issue uniforms small enough—was so disruptively funny that he was excused from parades and marching drills.
Eventually the army discharged him for medical reasons.
His military experience eventually inspired his novel "Days and Nights".
Jarry returned to Paris and applied himself to writing, drinking and the company of friends who appreciated his witty, sweet-tempered and unpredictable conversation.
This period is marked by his intense involvement with Remy de Gourmont in the publication of "L'Ymagier," a luxuriously produced "art" magazine devoted to the symbolic analysis of medieval and popular prints.
Symbolism as an art movement was in full swing at this time, and "L'Ymagier" provided a nexus for many of its key contributors.
Jarry's play "Caesar Antichrist" (1895) drew on this movement for material.
This is a work that bridges the gap between serious symbolic meaning and the type of critical absurdity with which Jarry would soon become associated.
Using the biblical Book of Revelation as a point of departure, "Caesar Antichrist" presents a parallel world of extreme formal symbolism in which Christ is resurrected not as an agent of spirituality but as an agent of the Roman Empire that seeks to dominate spirituality.
It is a unique narrative that effectively links the domination of the soul to contemporaneous advances in the field of Egyptology such as the 1894 excavation of the Narmer Palette, an ancient artifact used for situating the rebus within hermeneutics.
The character Ubu Roi first appears in this play.
The spring of 1896 saw the publication, in Paul Fort's review "Le Livre d'art", of Jarry's 5-act play "Ubu Roi," the rewritten and expanded "Les Polonais" of his school days.
"Ubu Roi" s savage humor and monstrous absurdity, unlike anything thus far performed in French theater, seemed unlikely to ever actually be performed on stage.
However, impetuous theater director Aurélien-Marie Lugné-Poe took the risk, producing the play at his Théâtre de l'Œuvre.
On opening night (10 December 1896), with traditionalists and the avant-garde in the audience, King Ubu (played by Firmin Gémier) stepped forward and intoned the opening word, "Merdre!"
(often translated as "Pshit" or "Shittr!"
in English).
A quarter of an hour of pandemonium ensued: outraged cries, booing, and whistling by the offended parties, countered by cheers and applause by the more degenerate contingent.
Such interruptions continued through the evening.
At the time, only the dress rehearsal and opening night performance were held, and the play was not revived until after Jarry's death.
The play brought fame to the 23-year - old Jarry, and he immersed himself in the fiction he had created.
Gémier had modeled his portrayal of Ubu on Jarry's own staccato, nasal vocal delivery, which emphasized each syllable (even the silent ones).
From then on, Jarry would always speak in this style.
He adopted Ubu's ridiculous and pedantic figures of speech; for example, he referred to himself using the royal "we", and called the wind "that which blows" and the bicycle he rode everywhere "that which rolls."
Jarry moved into a flat which the landlord had created through the unusual expedient of subdividing a larger flat by means of a horizontal rather than a vertical partition.
The diminutive Jarry could just manage to stand up in the place, but guests had to bend or crouch.
Jarry also took to carrying a loaded revolver.
In response to a neighbor's complaint that his target shooting endangered her children, he replied, "If that should ever happen, ma-da-me, we should ourselves be happy to get new ones with you."
With Franc-Nohain and Claude Terrasse he co-founded the Théatre des Pantins, which in 1898 was the site of marionette performances of "Ubu Roi".
Living in worsening poverty, neglecting his health and drinking excessively, Jarry went on to write the novel "Le Surmâle" ("The Supermale"), which is partly a satire on the Symbolist ideal of self-transcendence.
Unpublished until after his death, his fiction "Exploits and Opinions of Dr. Faustroll, Pataphysician" ("Gestes et opinions du docteur Faustroll, pataphysicien") describes the exploits and teachings of a sort of antiphilosopher who, born at age 63, travels through a hallucinatory Paris in a sieve and subscribes to the tenets of "' pataphysics".
' Pataphysics deals with "the laws which govern exceptions and will explain the universe supplementary to this one."
In ' pataphysics, every event in the universe is accepted as an extraordinary event.
Jarry once wrote, expressing some of the bizarre logic of ' pataphysics, "If you let a coin fall and it falls, the next time it is just by an infinite coincidence that it will fall again the same way; hundreds of other coins on other hands will follow this pattern in an infinitely unimaginable fashion."
In his final years, he was a legendary and heroic figure to some of the young writers and artists in Paris.
Guillaume Apollinaire, André Salmon and Max Jacob sought him out in his truncated apartment.
Pablo Picasso was fascinated with Jarry.
After Jarry's death Picasso acquired his revolver and wore it on his nocturnal expeditions in Paris.
He later bought many of his manuscripts as well as executing a fine drawing of him.
Jarry died in Paris on 1 November 1907 of tuberculosis, aggravated by drug and alcohol use.
When he could not afford alcohol, he drank ether.
It is recorded that his last request was for a toothpick.
He was interred in the Cimetière de Bagneux, near Paris.
The complete works of Alfred Jarry are published in three volumes by Gallimard in the collection "Bibliothèque de la Pléiade".
Amalric or Amalaric (also Americ, Almerich, Emeric, Emerick and other variations) is a personal name derived from the tribal name "Amal" (referring to the Gothic Amali) and "ric" (Gothic "reiks") meaning "ruler, prince".
Equivalents in different languages include:
Amalric (;; 113611 July 1174) was King of Jerusalem from 1163, and Count of Jaffa and Ascalon before his accession.
He was the second son of Melisende and Fulk of Jerusalem, and succeeded his older brother Baldwin III.
During his reign, Jerusalem became more closely allied with the Byzantine Empire, and the two states launched an unsuccessful invasion of Egypt. Meanwhile, the Muslim territories surrounding Jerusalem began to be united under Nur ad-Din and later Saladin.
He was the father of three future rulers of Jerusalem, Sibylla, Baldwin IV, and Isabella I. Older scholarship mistook the two names Amalric and Aimery as variant spellings of the same name, so these historians erroneously added numbers, making Amalric to be Amalric I (1163 – 74) and King Aimery (1197 – 1205) to be "Amalric II".
Now scholars recognize that the two names were not the same and no longer add the number for either king.
Confusion between the two names was common even among contemporaries.
Amalric was born in 1136 to King Fulk, the former count of Anjou married to the heiress of the kingdom, Queen Melisende.
After the death of Fulk in a hunting accident in 1143, the throne passed jointly to Melisende and Amalric's older brother Baldwin III, who was still only 13 years old.
Melisende did not step down when Baldwin came of age two years later, and by 1150 the two were becoming increasingly hostile towards each other.
In 1152 Baldwin had himself crowned sole king, and civil war broke out, with Melisende retaining Jerusalem while Baldwin held territory further north.
Amalric, who had been given the County of Jaffa as an apanage when he reached the age of majority in 1151, remained loyal to Melisende in Jerusalem, and when Baldwin invaded the south, Amalric was besieged in the Tower of David with his mother.
Melisende was defeated in this struggle and Baldwin ruled alone thereafter.
In 1153 Baldwin captured the Egyptian fortress of Ascalon, which was then added to Amalric's fief of Jaffa (see Battle of Ascalon).
Amalric married Agnes of Courtenay in 1157.
Agnes, daughter of Joscelin II of Edessa, had lived in Jerusalem since the western regions of the former crusader County of Edessa were lost in 1150.
Patriarch Fulcher objected to the marriage on grounds of consanguinity, as the two shared a great-great-grandfather, Guy I of Montlhéry, and it seems that they waited until Fulcher's death to marry.
Agnes bore Amalric three children: Sibylla, the future Baldwin IV (both of whom would come to rule the kingdom in their own right), and Alix, who died in childhood.
Baldwin III died on 10 February 1163 and the kingdom passed to Amalric, although there was some opposition among the nobility to Agnes; they were willing to accept the marriage in 1157 when Baldwin III was still capable of siring an heir, but now the "Haute Cour" refused to endorse Amalric as king unless his marriage to Agnes was annulled.
The hostility to Agnes, it must be admitted, may be exaggerated by the chronicler William of Tyre, whom she prevented from becoming Latin Patriarch of Jerusalem decades later, as well as from William's continuators like Ernoul, who hints at a slight on her moral character: "car telle n'est que roine doie iestre di si haute cite comme de Jherusalem" ("there should not be such a queen for so holy a city as Jerusalem").
Nevertheless, consanguinity was enough for the opposition.
Amalric agreed and ascended the throne without a wife, although Agnes continued to hold the title Countess of Jaffa and Ascalon and received a pension from that fief's income.
Agnes soon thereafter married Hugh of Ibelin, to whom she had been engaged before her marriage with Amalric.
The church ruled that Amalric and Agnes' children were legitimate and preserved their place in the order of succession.
Through her children Agnes would exert much influence in Jerusalem for almost 20 years.
During Baldwin III's reign, the County of Edessa, the first crusader state established during the First Crusade, was conquered by Zengi, the Turkic emir of Aleppo.
Zengi united Aleppo, Mosul, and other cities of northern Syria, and intended to impose his control on Damascus in the south.
The Second Crusade in 1148 had failed to conquer Damascus, which soon fell to Zengi's son Nur ad-Din.
Jerusalem also lost influence to Byzantium in northern Syria when the Empire imposed its suzerainty over the Principality of Antioch.
Jerusalem thus turned its attention to Egypt, where the Fatimid dynasty was suffering from a series of young caliphs and civil wars.
The crusaders had wanted to conquer Egypt since the days of Baldwin I, who died during an expedition there.
The capture of Ascalon by Baldwin III made the conquest of Egypt more feasible.
Amalric led his first expedition into Egypt in 1163, claiming that the Fatimids had not paid the yearly tribute that had begun during the reign of Baldwin III.
The vizier, Dirgham, had recently overthrown the vizier Shawar, and marched out to meet Amalric at Pelusium, but was defeated and forced to retreat to Bilbeis.
The Egyptians then opened up the Nile dams and let the river flood, hoping to prevent Amalric from invading any further.
Amalric returned home but Shawar fled to the court of Nur ad-Din, who sent his general Shirkuh to settle the dispute in 1164.
In response Dirgham sought help from Amalric, but Shirkuh and Shawar arrived before Amalric could intervene and Dirgham was killed.
Shawar, however, feared that Shirkuh would seize power for himself, and he too looked to Amalric for assistance.
Amalric returned to Egypt in 1164 and besieged Shirkuh in Bilbeis until Shirkuh retreated to Damascus.
Amalric could not follow up on his success in Egypt because Nur ad-Din was active in Syria, having taken Bohemund III of Antioch and Raymond III of Tripoli prisoner at the Battle of Harim during Amalric's absence.
Amalric rushed to take up the regency of Antioch and Tripoli and secured Bohemund's ransom in 1165 (Raymond remained in captivity until 1173).
The year 1166 was relatively quiet, but Amalric sent envoys to the Byzantine Empire seeking an alliance and a Byzantine wife, and throughout the year had to deal with raids by Nur ad-Din, who captured Banias.
In 1167, Nur ad-Din sent Shirkuh back to Egypt and Amalric once again followed him, establishing a camp near Cairo; Shawar again allied with Amalric and a treaty was signed with the caliph al-Adid himself.
Shirkuh encamped on the opposite side of the Nile.
After an indecisive battle, Amalric retreated to Cairo and Shirkuh marched north to capture Alexandria; Amalric followed and besieged Shirkuh there, aided by a Pisan fleet from Jerusalem.
Shirkuh negotiated for peace and Alexandria was handed over to Amalric.
However, Amalric could not remain there indefinitely, and returned to Jerusalem after exacting an enormous tribute.
After his return to Jerusalem in 1167, Amalric married Maria Comnena, a great-grandniece of Byzantine emperor Manuel I Comnenus.
The negotiations had taken two years, mostly because Amalric insisted that Manuel return Antioch to Jerusalem.
Once Amalric gave up on this point he was able to marry Maria in Tyre on August 29, 1167.
During this time the queen dowager, Baldwin III's widow Theodora, eloped with her cousin Andronicus to Damascus, and Acre, which had been in her possession, reverted into the royal domain of Jerusalem.
It was also around this time that William of Tyre was promoted to archdeacon of Tyre, and was recruited by Amalric to write a history of the kingdom.
In 1168 Amalric and Manuel negotiated an alliance against Egypt, and William of Tyre was among the ambassadors sent to Constantinople to finalize the treaty.
Although Amalric still had a peace treaty with Shawar, Shawar was accused of attempting to ally with Nur ad-Din, and Amalric invaded.
The Knights Hospitaller eagerly supported this invasion, while the Knights Templar refused to have any part in it.
In October, without waiting for any Byzantine assistance (and in fact without even waiting for the ambassadors to return), Amalric invaded and seized Bilbeis.
The inhabitants were either massacred or enslaved.
Amalric then marched to Cairo, where Shawar offered Amalric two million pieces of gold.
Meanwhile, Nur ad-Din sent Shirkuh back to Egypt as well, and upon his arrival Amalric retreated.
In January 1169 Shirkuh had Shawar assassinated.
Shirkuh became vizier, although he himself died in March, and was succeeded by his nephew Saladin.
Amalric became alarmed and sent Frederick de la Roche, Archbishop of Tyre, to seek help from the kings and nobles of Europe, but no assistance was forthcoming.
Later that year however a Byzantine fleet arrived, and in October Amalric launched yet another invasion and besieged Damietta by sea and by land.
The siege was long and famine broke out in the Christian camp; the Byzantines and crusaders blamed each other for the failure, and a truce was signed with Saladin.
Amalric returned home.
Now Jerusalem was surrounded by hostile enemies.
In 1170 Saladin invaded Jerusalem and took the city of Eilat, severing Jerusalem's connection with the Red Sea.
Saladin, who was set up as Vizier of Egypt, was declared Sultan in 1171 upon the death of the last Fatimid caliph.
Saladin's rise to Sultan was an unexpected reprieve for Jerusalem, as Nur ad-Din was now preoccupied with reining in his powerful vassal.
Nevertheless, in 1171 Amalric visited Constantinople himself and envoys were sent to the kings of Europe for a second time, but again no help was received.
Over the next few years the kingdom was threatened not only by Saladin and Nur ad-Din, but also by the Hashshashin; in one episode, the Knights Templar murdered some Hashshashin envoys, leading to further disputes between Amalric and the Templars.
Nur ad-Din died in 1174, upon which Amalric immediately besieged Banias.
On the way back after giving up the siege he fell ill from dysentery, which was ameliorated by doctors but turned into a fever in Jerusalem.
William of Tyre explains that "after suffering intolerably from the fever for several days, he ordered physicians of the Greek, Syrian, and other nations noted for skill in diseases to be called and insisted that they give him some purgative remedy."
Neither they nor Latin doctors could help, and he died on July 11, 1174.
Maria Comnena had borne Amalric two daughters: Isabella, who would eventually marry four husbands in turn and succeed as queen, was born in 1172; and a stillborn child some time later.
On his deathbed Amalric bequeathed Nablus to Maria and Isabella, both of whom would retire there.
The leprous child Baldwin IV succeeded his father and brought his mother Agnes of Courtenay (now married to her fourth husband) back to court.
William was a good friend of Amalric and described him in great detail.
Like his brother Baldwin III, he was more of an academic than a warrior, who studied law and languages in his leisure time: "He was well skilled in the customary law by which the kingdom was governed – in fact, he was second to no one in this respect."
He was probably responsible for an assize making all rear-vassals directly subject to the king and eligible to appear at the Haute Cour.
Amalric had an enormous curiosity, and William was reportedly astonished to find Amalric questioning, during an illness, the resurrection of the body.
He especially enjoyed reading and being read to, spending long hours listening to William read early drafts of his history.
He did not enjoy games or spectacles, although he liked to hunt.
He was trusting of his officials, perhaps too trusting, and it seems that there were many among the population who despised him, although he refused to take any action against those who insulted him publicly.
A comely and very full beard covered his cheeks and chin.
He did not overeat or drink to excess, but his corpulence grew in his later years, decreasing his interest in military operations; according to William, he "was excessively fat, with breasts like those of a woman hanging down to his waist."
Amalric was pious and attended mass every day, although he also "is said to have absconded himself without restraint to the sins of the flesh and to have seduced married women ..."
Despite his piety he taxed the clergy, which they naturally opposed.
As William says, "he was a man of wisdom and discretion, fully competent to hold the reins of government in the kingdom."
He is considered the last of the early kings of Jerusalem.
Within a few years, Emperor Manuel died as well, and Saladin remained the only strong leader in the east.
Aimery of Lusignan (,, "Amorí"; before 11551 April 1205), erroneously referred to as Amalric or Amaury in earlier scholarship, was the first King of Cyprus, reigning from 1196 to his death.
He also reigned as King of Jerusalem from his marriage to Isabella I in 1197 to his death.
He was the younger son of Hugh VIII of Lusignan, a nobleman in Poitou.
After participating in a rebellion against Henry II of England in 1168, he went to the Holy Land and settled in the Kingdom of Jerusalem.
His marriage to Eschiva of Ibelin (whose father, Baldwin of Ibelin was an influential nobleman) strengthened his position in the kingdom.
His younger brother, Guy, married Sibylla, the sister of and heir to Baldwin IV of Jerusalem.
Baldwin made Aimery Constable of Jerusalem around 1180.
He was one of the commanders of the Christian army in the Battle of Hattin, which ended with decisive defeat at the hands of the army of Saladin, the Ayyubid sultan of Egypt and Syria, on 4 July 1187.
Aimery supported his brother, Guy, even after Guy had lost his claim to the Kingdom of Jerusalem according to most barons of the realm, because of the death of Sibylla and their two daughters.
The new king of Jerusalem, Henry of Champagne, arrested him for a short period.
After his release, he retired to Jaffa which was the fief of his elder brother, Geoffrey of Lusignan, who had left the Holy Land.
After Guy died in May 1194, his vassals in Cyprus elected Aimery as their lord.
He accepted the suzerainty of the Holy Roman Emperor, Henry VI.
With the emperor's authorization, Aimery was crowned King of Cyprus in September 1197.
He soon married Henry of Champagne's widow, Isabella I of Jerusalem.
He and his wife were crowned king and queen of Jerusalem in January 1198.
He signed a truce with Al-Adil I, the Ayyubid sultan of Egypt, which secured the Christian possession of the coastline from Acre to Antioch.
His rule was a period of peace and stability in both of his realms.
Aimery was born before 1155.
He was the fifth son of Hugh VIII of Lusignan and his wife, Burgundia of Rancon.
His family had been noted for generations of crusaders in their native Poitou.
His great-grandfather, Hugh VI of Lusignan, died in the Battle of Ramla in 1102; Aimery's grandfather, Hugh VII of Lusignan, took part in the Second Crusade.
Aimery's father also came to the Holy Land and died in a Muslim prison in the 1160 s.
Earlier scholarship erroneously referred to him as Amalric (or Amaury, its French form), but documentary evidence shows he was actually called "Aimericus", which is a distinct name (although it was sometimes confused with "Amalricus" already in the Middle Ages).
Runciman and other modern historians erroneously refer to him as Amalric II of Jerusalem, because they confused his name with that of Amalric "I" of Jerusalem.
Aimery joined a rebellion against Henry II of England (who also ruled Poitou) in 1168, according to Robert of Torigni's chronicle, but Henry crushed the rebellion.
Aimery left for the Holy Land and settled in the Kingdom of Jerusalem.
He was captured in a battle and held in captivity in Damascus.
A popular tradition (which was first recorded by the 13th - century Philip of Novara and John of Ibelin) held, the king of Jerusalem, Amalric, ransomed him personally.
Ernoul (whose reliability is questioned) claimed, Aimery was a lover of Amalric of Jerusalem's former wife, Agnes of Courtenay.
Aimery married Eschiva of Ibelin, a daughter of Baldwin of Ibelin, who was one of the most powerful noblemen in the Kingdom of Jerusalem.
Amalric of Jerusalem, who died on 11 July 1174, was succeeded by his thirteen-year-old son by Agnes of Courtenay, Baldwin IV who suffered from leprosy.
Aimery became the member of the royal court with his father-in-law's support.
Aimery's youngest brother, Guy, married Baldwin IV's widowed sister, Sibylla, in April 1180.
Ernoul wrote, it was Aimery who had spoken of his brother to her and her mother, Agnes of Courtenay, describing him as a handsome and charming young man.
Aimery, continued Ernoul, hurried back to Poitou and persuaded Guy to come to the kingdom, although Sibylla had promised herself to Aimery's father-in-law.
Another source, William of Tyre, did not mention that Aimery had played any role in the marriage of his brother and the king's sister.
Consequently, many elements of Ernoul's report (especially Aimery's alleged journey to Poitou) were most probably invented.
Aimery was first mentioned as Constable of Jerusalem on 24 February 1182.
According to Steven Runciman and Malcolm Barber, he had already been granted the office shortly after his predecessor, Humphrey II of Toron, died in April 1179.
Historian Bernard Hamilton writes, Aimery's appointment was the consequence of the growing influence of his brother and he was appointed only around 1181.
Saladin, the Ayyubid sultan of Egypt and Syria, launched a campaign against the Kingdom of Jerusalem on 29 September 1183.
Aimery defeated the sultan's troops in a minor skirmish with the support of his father-in-law and his brother, Balian of Ibelin.
After the victory, the crusaders' main army could advance as far as a spring near Saladin's camp, forcing him to retreat nine days later.
During the campaign, it turned out that most barons of the realm were unwilling to cooperate with Aimery's brother, Guy, who was the designated heir to Baldwin IV.
The ailing king dismissed Guy and made his five-year-old nephew (Guy's stepson), Baldwin V, his co-ruler on 20 November 1183.
In early 1185, Baldwin IV decreed that the pope, the Holy Roman Emperor and the kings of France and England were to be approached to choose between his sister, Sybilla, and their half-sister, Isabella, if Baldwin V died before reaching the age of majority.
The leper king died in April or May 1185, his nephew in late summer of 1186.
Ignoring Baldwin IV's decree, Sybilla was proclaimed queen by her supporters and she crowned her husband, Guy, king.
Aimery was not listed among those who were present at the ceremony, but he obviously supported his brother and sister-in-law, according to Hamilton.
As constable, Aimery organised the army of the Kingdom of Jerusalem into units before the Battle of Hattin, which ended with the decisive victory of Saladin on 4 July 1187.
Along with most commanders of the Christian army, Aimery fell into captivity in the battlefield.
During the siege of Ascalon, Saladin promised the defenders that he would set free ten persons whom they named if they surrendered.
Aimery and Guy were among those whom the defenders named before surrendering on 4 September, but Saladin postponed their release until the spring of 1188.
Aimery remained a loyal supporter of his brother even after Guy had lost his claim to the Kingdom of Jerusalem with the death of Sybilla and their two daughters in the autumn of 1190, according to most barons of the realm.
Guy's opponents supported Conrad of Montferrat who married Sybilla's half-sister, Isabella in late November.
An assembly of the noblemen of the realm unanimously declared Conrad the lawful king on 16 April 1192.
Although Conrad was murdered twelve days later, his widow soon married Henry of Champagne, who was elected king of Jerusalem.
To compensate Guy for the loss of Jerusalem, Richard I of England authorized him to purchase the island of Cyprus (that Richard had conquered in May 1191) from the Knights Templar.
He was also to pay 40,000 bezants to Richard who donated the right to collect the sum from Guy to Henry of Champagne.
Guy settled in Cyprus in early May.
Aimery remained in the Kingdom of Jerusalem, which was reduced to a narrow strip of land along the coast of the Mediterranean Sea from Jaffa to Tyre.
Henry of Champagne ordered the expulsion of the merchants from Pisa from Acre in May, because he accused them of plotting with Guy of Lusignan.
After Aimery intervened on behalf of the merchants, the king had him arrested.
Aimery was only released at the demand of the grand masters of the Templars and the Hospitallers.
He retired to Jaffa that Richard of England had granted to Aimery's eldest brother, Geoffrey of Lusignan.
Guy of Lusignan died in May 1194, and bequeathed Cyprus to his elder brother, Geoffrey.
However, Geoffrey had already returned to Poitou, thus Guy's vassals elected Aimery their new lord.
Henry of Champagne demanded the right to be consulted about the succession in Cyprus, but the Cypriote noblemen ignored him.
Around the same time, Henry of Champagne replaced Aimery with John of Ibelin as constable of Jerusalem.
Aimery realized that the treasury of Cyprus was almost empty, because his brother had granted most landed property in the island to his supporters, according to Ernoul.
He summoned his vassals to an assembly.
After emphasizing that each of them owned more land than he had, he persuaded them one by one "either by force, or by friendship, or by agreement" to surrender some their rents and lands.
Aimery dispatched an embassy to Pope Celestine III, asking him to set up Roman Catholic dioceses in Cyprus.
He also sent his representative, Rainier of Jebail, to the Holy Roman Emperor, Henry VI, proposing that he would acknowledge the emperor's suzerainty, if the emperor sent a royal crown to him.
Aimery primarily wanted to secure the emperor's assistance against a potential Byzantine invasion of Cyprus, but he also wanted to strengthen his own legitimacy as king.
Rainier of Jebail swore loyalty to Henry VI on behalf of Aimery in Gelnhausen in October 1196.
The emperor who had decided to lead a crusade to the Holy Land promised that he would personally crown Aimery king.
He dispatched the archbishops of Brindisi and Trani to take a golden sceptre to Aimery as a symbol of his right to rule Cyprus.
Henry VI's two envoys landed in Cyprus in April or May 1196.
Aimery may have adopted the title of king around that time, because Pope Celestin styled him as king already in a letter in December 1196.
In the same month, the pope set up a Roman Catholic archdiocese in Nicosia with three suffragan bishops in Famagusta, Limassol and Paphos.
The Greek Orthodox bishops were not expelled, but their property and income was seized by the new Catholic prelates.
Henry VI's chancellor, Conrad, Bishop of Hildesheim, crowned Aimery king in Nicosia in September 1197.
Aimery did homage to the chancellor.
The noblemen who owned fiefs in both Cyprus and the Kingdom of Jerusalem wanted to bring about a reconciliation between Aimery and Henry of Champagne.
One of them, Baldwin of Beisan, Constable of Cyprus, persuaded Henry of Champage to visit Cyprus in early 1197.
The two kings made peace, agreeing that Aimery's three sons were to marry Henry's three daughters.
Henry also renounced the debt that Aimery still owed to him for Cyprus and allowed Aimery to garrison his troops at Jaffa.
Aimery sent Reynald Barlais to take possession of Jaffa.
Aimery again used the title of Constable of Jerusalem in November 1197, which suggests that he had also recovered that office as a consequence of his treaty with Henry of Champagne.
Henry of Champagne fell from the window of his palace and died in Acre on 10 September 1197.
The aristocratic, but impoverished Raoul of Saint Omer was one of the possible candidates to succeed him, but the grand masters of the military orders opposed him vehemently.
A few days later, Al-Adil I, the Ayyubid sultan of Egypt, occupied Jaffa.
Conrad of Wittelsbach, Archbishop of Mainz, who arrived to Acre on 20 September, was the first to propose that the crown should be offered to Aimery.
Since Aimery's first wife had died, he could marry the widowed Isabella I of Jerusalem, who was the queen.
Although Aymar, Patriarch of Jerusalem, stated that the marriage would be uncanonical, Joscius, Archbishop of Tyre, started negotiations with Aimery who accepted the offer.
The patriarch also withdrew his objections and crowned Aimery and Isabella king and queen in Tyre in January 1198.
The Cypriot army fought for the Kingdom of Jerusalem during Aimery's rule, but otherwise he administered his two realms separately.
Even before his coronation, Aimery united his forces with the German crusaders who were under the command of Henry I, Duke of Brabant to launch a campaign against the Ayyubid troops.
They forced Al-Adil to withdraw and captured Beirut on 21 October.
He laid siege to Toron, but he had to lift the siege on 2 February, because the German crusaders decided to return to the Holy Roman Empire after learning that Emperor Henry VI had died.
Aimery was riding at Tyre when four German knights attacked him in March 1198.
His retainers rescued him and captured the four knights.
Aimery accused Raoul of Saint Omer of hiring the assailants and sentenced him to banishment without a trial by his peers.
At Raoul's demand, the case was submitted to the High Court of Jerusalem which held that Aimery had unlawfully banished Raoul.
Nevertheless, Raoul voluntarily left the kingdom and settled in Tripoli, because he knew that he had lost Aimery's goodwill.
Aimery signed a truce with Al-Adil on 1 July 1198, securing the possession of the coast from Acre as far as to Antioch for the crusaders for five years and eight months.
The Byzantine Emperor, Alexios III Angelos, did not abandon the idea of recovering Cyprus.
He promised that he would help a new crusade if Pope Innocent III excommunicated Aimery to enable a Byzantine invasion in 1201, but the pope refuted him, emphasizing that the Byzantines had lost their right to Cyprus when Richard I conquered the island in 1191.
Aimery kept the peace with the Muslims, even when Reynald II of Dampierre, who arrived at the head of 300 French crusaders demanded him to launch a campaign against the Muslims in early 1202.
After Aimery reminded him that more than 300 soldiers were needed to wage war against the Ayyubids, Reynald left the Kingdom of Jerusalem for the Principality of Antioch.
An Egyptian emir seized a fortress near Sidon and made plundering raids against the neighboring territory.
After Al-Adil failed to stop the emir, Aimery's fleet captured 20 Egyptian ships and he broke into Al-Adil's realm.
In retaliation, Al-Adil's son, Al-Mu ' azzam Isa plundered the region of Acre.
In May 1204, the fleet of Aimery sack a small town at the Nile Delta in Egypt. The envoys of Aimery and Al-Adil signed a new truce for six years in September 1204.
Al-Adil ceded Jaffa and Ramleh to the Kingdom of Jerusalem and simplified the Christian pilgrims' visits in Jerusalem and Nazareth.
After eating excess of white mullet, Aimery fell seriously ill.
He died after a short illness on 1 April 1205.
His six-year-old son, Hugh I, succeeded him in Cyprus; and his widow continued to rule the Kingdom of Jerusalem.
Historian Mary Nickerson Hardwicke described Aimery as a "self-assured, politically astute, sometimes hard, seldom sentimentally indulgent" ruler.
His rule was a period of peace and consolidation.
The lawyers of the Kingdom of Jerusalem especially held him in high esteem.
He decided to revise the laws of the Kingdom of Jerusalem to specify royal prerogatives.
John of Ibelin emphasized that Aimery had governed both Cyprus and Jerusalem "well and wisely" until his death.
Aimery's first wife, Eschiva of Ibelin, was the elder daughter of Baldwin of Ibelin, Lord of Mirabel and Ramleh, and Richelda of Beisan.
Their children: Aimery's second wife, Isabella I of Jerusalem, was the only daughter of Amalric I of Jerusalem and Maria Komnene.
Their children:
Anthemius of Tralles (, Medieval Greek:, "Anthémios o Trallianós"; – 533 558) was a Greek from Tralles who worked as a geometer and architect in Constantinople, the capital of the Byzantine Empire.
With Isidore of Miletus, he designed the Hagia Sophia for Justinian I. Anthemius was one of the five sons of Stephanus of Tralles, a physician.
His brothers were Dioscorus, Alexander, Olympius, and Metrodorus.
Dioscorus followed his father's profession in Tralles; Alexander did so in Rome and became one of the most celebrated medical men of his time; Olympius became a noted lawyer; and Metrodorus worked as a grammarian in Constantinople.
Anthemius was said to have annoyed his neighbor Zeno in two ways: first, by engineering a miniature earthquake by sending steam through leather tubes he had fixed among the joists and flooring of Zeno's parlor while he was entertaining friends and, second, by simulating thunder and lightning and flashing intolerable light into Zeno's eyes from a slightly hollowed mirror.
In addition to his familiarity with steam, some dubious authorities credited Anthemius with a knowledge of gunpowder or other explosive compound.
Anthemius was a capable mathematician.
In the course of his treatise "On Burning Glasses", intended to facilitate the construction of surfaces to reflect light to a single point, he described the string construction of the ellipse and assumed a property of ellipses not found in Apollonius of Perga's "Conics": the equality of the angles subtended at a focus by two tangents drawn from a point.
His work also includes the first practical use of the directrix: having given the focus and a double ordinate, he used the focus and directrix to obtain any number of points on a parabola.
This work was later known to Arab mathematicians such as Alhazen.
Eutocius's commentary on Apollonius's "Conics" was dedicated to Anthemius.
As an architect, Anthemius is best known for his work designing the Hagia Sophia.
He was commissioned with Isidore of Miletus by Justinian I shortly after the earlier church on the site burned down in 532 but died early on in the project.
He is also said to have repaired the flood defenses at Daras.
Attribution:
Absalon or Axel (21 March 1201) was a Danish archbishop and statesman, who was the Bishop of Roskilde from 1158 to 1192 and Archbishop of Lund from 1178 until his death.
He was the foremost politician and churchfather of Denmark in the second half of the 12th century, and was the closest advisor of King Valdemar I of Denmark.
He was a key figure in the Danish policies of territorial expansion in the Baltic Sea, Europeanization in close relationship with the Holy See, and reform in the relation between the Church and the public.
He combined the ideals of Gregorian Reform with loyal support of a strong monarchical power.
Absalon was born into the powerful "Hvide" clan, and owned great land possessions.
He endowed several church institutions, most prominently his family's Sorø Abbey.
He was granted lands by the crown, and built the first fortification of the city that evolved into modern-day Copenhagen.
His titles were passed on to his nephews Anders Sunesen and Peder Sunesen.
He died in 1201, and was interred at Sorø Abbey.
Absalon was born around 1128 near Sorø, Zealand.
Due to his name being unusual in Denmark, it is speculated that he was baptized on the Danish "Absalon" name day, October 30.
He was the son of Asser Rig, a magnate of the "Hvide" clan from Fjenneslev on Zealand, and Inger Eriksdotter.
He was also a kinsman of Archbishop Eskil of Lund.
He grew up at the castle of his father, and was brought up alongside his older brother Esbern Snare and the young prince Valdemar, who later became King Valdemar I of Denmark.
During the civil war following the death of Eric III of Denmark in 1146, Absalon travelled abroad to study theology in Paris, while Esbern fought for Valdemar's ascension to the throne.
At Paris, he was influenced by the Gregorian Reform ideals of churchly independence from Monarchical rule.
He also befriended the canon William of Æbelholt at the Abbey of St Genevieve, whom he later made abbott of Eskilsø Abbey.
Absalon first appears in Saxo Grammaticus's contemporary chronicle "Gesta Danorum" at the end of the civil war, at the brokering of the peace agreement between Sweyn III and Valdemar at St. Alban's Priory, Odense.
He was a guest at the following Roskilde banquet given in 1157 by Sweyn to his rivals Canute V and Valdemar.
Both Absalon and Valdemar narrowly escaped assassination at the hands of Sweyn on this occasion, and escaped to Jutland, whither Sweyn followed them.
Absalon probably did not take part in the following battle of Grathe Heath in 1157, in which Sweyn was defeated and slain, which led to Valdemar ascending to the Danish throne.
On Good Friday 1158, bishop Asser of Roskilde died, and Absalon was eventually elected bishop of Roskilde on Zealand with the help of Valdemar, as the king's reward for the "Hvide" family support.
Absalon was a close counsellor of Valdemar, and chief promoter of the Danish crusades against the Wends.
During the Danish civil war, Denmark had been open to coastal raids by the Wends.
It was Absalon's intention to clear the Baltic Sea of the Wendish pirates who inhabited its southern littoral zone which was later called Pomerania.
The pirates had raided the Danish coasts during the civil war of Sweyn III, Canute V, and Valdemar, to the point where at the accession of Valdemar one-third of Denmark lay wasted and depopulated.
Absalon formed a guardian fleet, built coastal defenses, and led several campaigns against the Wends.
He even advocated forgiving the earlier enemies of Valdemar, which helped stabilize Denmark internally.
The first expedition against the Wends, that was conducted by Absalon in person, set out in 1160.
These expeditions were successful, but brought no lasting victories.
What started out as mere retribution, eventually evolved into full-fledged campaigns of expansion with religious motives.
In 1164 began twenty years of crusades against the Wends, sometimes with the help of German duke Henry the Lion, sometimes in opposition to him.
In 1168 the chief Wendish fortress at Arkona in Rügen, containing the sanctuary of their god Svantevit, was conquered.
The Wends agreed to accept Danish suzerainty and the Christian religion at the same time.
From Arkona, Absalon proceeded by sea to Charenza, in the midst of Rügen, the political capital of the Wends and an all but impregnable stronghold.
But the unexpected fall of Arkona had terrified the garrison, which surrendered unconditionally at the first appearance of the Danish ships.
Absalon, with only Bishop Sweyn of Aarhus and twelve "housecarls", thereupon disembarked, passed between a double row of Wendish warriors, 6000 strong, along the narrow path winding among the morasses, to the gates of the fortress, and, proceeding to the temple of the seven-headed god Rugievit, caused the idol to be hewn down, dragged forth and burnt.
The whole population of Garz was then baptized, and Absalon laid the foundations of twelve churches in the isle of Rügen.
Rügen was then subjected to Absalon's Bishopric of Roskilde.
The destruction of this chief sally-port of the Wendish pirates enabled Absalon considerably to reduce the Danish fleet.
But he continued to keep a watchful eye over the Baltic, and in 1170 destroyed another pirate stronghold, farther eastward, at Dziwnów on the isle of Wolin.
Absalon's last military exploit came in 1184, off Stralsund at Whitsun, when he soundly defeated a Pomeranian fleet that had attacked Denmark's vassal, Jaromar of Rügen.
Absalon's main political goal was to free Denmark from entanglements with the Holy Roman Empire.
Absalon reformed the Danish church organisation to closer match Holy See praxis, and worked to keep Denmark a close ally of the Holy See.
However, during the schism between Pope Alexander III and Antipope Victor IV, Absalon stayed loyal to Valdemar even as he joined the Holy Roman Emperor Frederick Barbarossa in supporting Victor IV.
This caused a split within the Danish church, as it possibly forced Eskil into exile around 1161, despite Abaslon's attempts to keep the Danish church united.
It was contrary to Absalon's advice and warnings that Valdemar I rendered fealty to the emperor Frederick Barbarossa at Dole in 1162.
When Valdemar returned to Denmark, he was convinced into strengthening the Danevirke fortifications at the German border, with the support of Absalon.
Absalon built churches and monasteries, supporting international religious orders like the Cistercians and Augustinians, founding schools and doing his utmost to promote civilization and enlightenment.
In 1162, Absalon transformed the Sorø Abbey of his family from Benedictine to Cistercian, granting it lands from his personal holdings.
In 1167, Absalon was granted the land around the city of "Havn" (English: Harbour), and built there a castle in the coastal defense against the Wends.
Havn quickly expanded as one of Scandinavia's most important centers of trade, and eventually evolved into modern-day Copenhagen.
It was also Absalon who held the first Danish Synod at Lund in 1167.
He was also interested in history and culture, and commissioned Saxo Grammaticus to write "Gesta Danorum", a comprehensive chronicle of the history of the Danes.
Violation of the law was specified as subject to a secular legal process.
Archbishop Eskil returned from exile in 1167.
Eskil agreed on canonizing Valdemar's father Knud Lavard in 1170, with Absalon assisting him at the feast.
When Eskil stepped down as Archbishop of Lund in 1177, he chose Absalon as his successor.
Absalon initially resisted the new position, as he did not want to lose his power position on Zealand, but complied with Papal orders to do so in 1178.
By a unique Papal dispensation, Absalon was allowed to simultaneously maintain his post as Bishop of Roskilde.
As the Archbishop of Lund, Absalon utilized ombudsmen from Zealand, demanded unfree labour from the peasantry, and instituted tithes.
He was a harsh and effective ruler, who cleared all Orthodox Christian liturgical remnants in favour of Papal standards.
A rebellion in the Scanian peasantry forced him to flee to Zealand in 1180, from where he returned and subdued the Scanians with the help of Valdemar.
When Valdemar died in 1182, his son succeeded him as Canute VI, and Absalon served as Canute VI's counsellor.
Under Canute VI, Absalon was the chief policymaker in Danish politics.
Absalon kept his hostile attitude to the Holy Roman Empire.
On the accession of Canute VI in 1182, an imperial ambassador arrived at Roskilde to get the new king to swear fealty to Frederick Barbarossa, but Absalon resolutely withstood him.
When Absalon retired from military service in 1184 at the age of fifty-seven, he resigned the command of fleets and armies to younger men, like Duke Valdemar, the later king Valdemar II.
He instead confined himself to the administration of the Danish empire.
In 1192, Absalon made his nephew Peder Sunesen his successor as Bishop of Roskilde, while his other nephew Anders Sunesen was named the chancellor of Canute VI.
Absalon died at Sorø Abbey on March 21, 1201, 73 years old, with his last will granting his personal holdings to the Abbey, apart from Fjenneslev which went to Esbern Snarre.
He had already given Copenhagen to the Bishopric of Roskilde.
Absalon was interred at Sorø Abbey, and was succeeded as Archbishop of Lund by Anders Sunesen.
Saxo Grammaticus' "Gesta Danorum" was not finished until after the death of Absalon, but Absalon was one of the chief heroic figures of the chronicle, which was to be the main source of knowledge about early Danish history.
Absalon left a legacy as the foremost politician and churchfather of Denmark in the 12th century.
Absalon was equally great as churchman, statesman, and warrior.
His policy of expansion was to give Denmark the dominion of the Baltic for three generations.
That he enjoyed warfare there can be no doubt; yet he was not like the ordinary fighting bishops of the Middle Ages, whose sole indication of their religious role was to avoid the "shedding of blood" by using a mace in battle instead of a sword.
Absalon never neglected his ecclesiastical duties.
In the 2000 s, "Absalon" was adopted as the name for a class of Royal Danish Navy vessels, and the lead vessel of the class.
HDMS Absalon (L16) and "Esbern Snare" (L17) were launched and commissioned by Denmark in 2004 and 2005.
Adhemar (also known as Adémar, Aimar, or Aelarz) de Monteil (died 1 August 1098) was one of the principal figures of the First Crusade and was bishop of Puy-en-Velay from before 1087.
He was the chosen representative of Pope Urban II for the expedition to the Holy Land.
Remembered for his martial prowess, he led knights and men into battle and fought beside them, particularly at Dorylaeum and Antioch.
Adhemar is said to have carried the Holy Lance in the Crusaders ’ desperate breakout at Antioch on 28 June 1098, in which superior Islamic forces under the atabeg Kerbogha were routed, securing the city for the Crusaders.
He later died in 1098, due to illness.
Born around 1045 into the family of the Counts of Valentinois and elected Bishop of Le Puy around 1080, he was an advocate of the Gregorian Reform, and among his supporters were the future Pope Urban II and Raymond of Saint-Gilles, Count of Toulouse and the richest, most powerful nobleman in France.
He was also said to have gone on pilgrimage to Jerusalem around 1086.
He was the brother of William Hugh of Monteil, who was also a Crusader during the First Crusade.
Adhemar most likely met Pope Urban II, when he visited Puy in August 1095.
At the Council of Clermont in 1095, Adhemar showed great zeal for the crusade (there is evidence that Urban II had conferred with Adhemar before the council).
Adhemar was named apostolic legate and appointed to lead the crusade by Pope Urban II on 27 November 1095.
In part, Adhemar was selected to lead because he had already undertaken a pilgrimage to Jerusalem in 1086 and 1087.
Following the announcement of the Crusade Adhemar spent the next year raising money and recruiting men.
Departing on 15 August 1096, he accompanied Raymond of Toulouse in his army to the east.
Whilst Raymond and the other leaders often quarrelled with each other over the leadership of the crusade, Adhemar was always recognized as the spiritual leader of the crusade and was widely respected by the majority of the Crusaders.
During the leg of the trip from Durazzo to Constantinople, in the Valley of Pelagonia, Adhemar was set upon by a group of Pecheneg mercenaries, when he had wandered too far from the majority of the Crusader forces.
The Pechenegs beat and robbed Adhemar, but began to fight among themselves over his belongings; Adhemar was saved by Crusader forces who had noticed the disturbance.
Once the army had reached Thessalonica, Adhemar decided to stay there for some time, due to sickness, whilst the Crusader forces moved onward.
Following this delay Adhemar, eventually was able to regroup with the Crusaders.
Adhemar negotiated with Alexius I Comnenus at Constantinople, reestablished some discipline among the crusaders at Nicaea, fought a crucial role at the Battle of Dorylaeum and was largely responsible for sustaining morale during the siege of Antioch through various religious rites including fasting and special observances of holy days.
One such time he did this, was after an earthquake during the siege of Antioch, he had the Crusaders fast for three days and had the priests and clergy perform mass and prayers.
Adhemar during the Siege of Antioch, also had ordered the Crusaders to shave and wear a cross in an attempt to stop Crusaders from attacking one another by accident.
After the capture of the city in June 1098 and the subsequent siege led by Kerbogha, Adhemar organized a procession through the streets and had the gates locked so that the Crusaders, many of whom had begun to panic, would be unable to leave the city.
He was extremely skeptical of Peter Bartholomew's discovery in Antioch of the Holy Lance, especially because he knew such a relic already existed in Constantinople; however, he was willing to let the Crusader army believe it was real if it raised their morale.
Adhemar was protected by a band of Crusaders led by Henry of Esch to preserve the (albeit suspect) relic.
In June 1098 Adhemar fell prey to sickness and in the following months his condition would continue to deteriorate.
When Kerbogha was defeated, Adhemar organized a council in an attempt to settle the leadership disputes, but he died on 1 August 1098, probably of typhus.
Following his death, Adhemar was buried in Antioch within the Basilica of St Peter.
The disputes among the higher nobles went unsolved and the march to Jerusalem was delayed for months.
However, the lower-class soldiers continued to think of Adhemar as a leader.
Following his death, Adhemar reportedly appeared in several visions seen by various different Crusaders.
One of the first visions was reported by Peter Bartholomew who stated that Adhemar appeared to him stating that due to his skeptism of the Holy Lance he had spent a few days in hell and was only rescued because a candle had been burned in his memory, he had given a gift to the Shrine where the Holy Lance was kept, and due to the prayers of Bohemond.
At the siege of Jerusalem Peter Desiderius claimed that to have received a vision from Adhemar, himself.
It was in this vision, that Peter claimed Adhemar had instructed him to have the Crusaders fast and lead a procession around the Walls of Jerusalem.
This was done and Jerusalem was taken by the Crusaders in 1099.
Later on, Stephen of Valence also claimed to have had visions featuring Adhemar in which Adhemar spoke to Stephen of several relics.
Adhemar told Stephen great reverence should be given to the cross Adhemar had taken with him on the crusade.
He also told Stephen how the Holy Lance should be treated and told Stephen to give Stephen's ring to Count Raymond.
He told Stephen that through this ring Count Raymond would be able to call upon the power of Mary.
Alphonse or Alfonso (11 November 122021 August 1271) was the Count of Poitou from 1225 and Count of Toulouse (as Alphonse II) from 1249.
As count of Toulouse, he also governed the Marquisate of Provence.
Born at Poissy, Alphonse was a son of Louis VIII, King of France and Blanche of Castile.
He was a younger brother of Louis IX of France and an older brother of Charles I of Sicily.
In 1229, his mother, who was regent of France, forced the Treaty of Paris on Raymond VII of Toulouse after his rebellion.
It stipulated that a brother of King Louis was to marry Joan of Toulouse, daughter of Raymond VII of Toulouse, and so in 1237 Alphonse married her.
Since she was Raymond's only child, they became rulers of Toulouse at Raymond's death in 1249.
By the terms of his father's will he received an "appanage" of Poitou and Auvergne.
To enforce this Louis IX won the battle of Taillebourg in the Saintonge War together with Alphonse against a revolt allied with king Henry III of England, who also participated in the battle.
Alphonse took part in two crusades with his brother, St Louis, in 1248 (the Seventh Crusade) and in 1270 (the Eighth Crusade).
For the first of these, he raised a large sum and a substantial force, arriving in Damietta on 24 October 1249, after the town had already been captured.
He sailed for home on 10 August 1250.
His father-in-law had died while he was away, and he went directly to Toulouse to take possession.
There was some resistance to his accession as count, which was suppressed with the help of his mother Blanche of Castile who was acting as regent in the absence of Louis IX.
The county of Toulouse, since then, was joined to Alphonse's "appanage".
In 1252, on the death of his mother, Blanche of Castile, Alphonse was joint regent with Charles of Anjou until the return of Louis IX.
During that time he took a great part in the campaigns and negotiations which led to the Treaty of Paris in 1259, under which King Henry III of England recognized his loss of continental territory to France (including Normandy, Maine, Anjou, and Poitou) in exchange for France withdrawing support from English rebels.
Aside from the crusades, Alphonse stayed primarily in Paris, governing his estates by officials, inspectors who reviewed the officials' work, and a constant stream of messages.
His main work was on his own estates.
There he repaired the evils of the Albigensian war and made a first attempt at administrative centralization, thus preparing the way for union with the crown.
He is remembered for founding the bastide town of Villeneuve-sur-Lot which straddles the River Lot and still contains many of its original structures, including one of the first bridges across the river.
The charter known as "Alphonsine," granted to the town of Riom, became the code of public law for Auvergne.
Honest and moderate, protecting the middle classes against exactions of the nobles, he exercised a happy influence upon the south, in spite of his naturally despotic character and his continual and pressing need of money.
He is noted for ordering the first recorded local expulsion of Jews, when he did so in Poitou in 1249.
When Louis IX again engaged in a crusade (the Eighth Crusade), Alphonse again raised a large sum of money and accompanied his brother.
This time, however, he did not return to France, dying while on his way back, probably at Savona in Italy, on 21 August 1271.
Alphonse's death without heirs raised some questions as to the succession to his lands.
One possibility was that they should revert to the crown, another that they should be redistributed to his family.
The latter was claimed by Charles of Anjou, but in 1283 Parlement decided that the County of Toulouse should revert to the crown, if there were no male heirs.
Alphonse's wife Joan (who died four days after Alphonse) had attempted to dispose of some of her inherited lands in her will.
Joan was the only surviving child and heiress of Raymond VII, Count of Toulouse, Duke of Narbonne, and Marquis of Provence, so under Provençal and French law, the lands should have gone to her nearest male relative.
But, her will was invalidated by Parlement in 1274.
One specific bequest in Alphonse's will, giving his wife's lands in the Comtat Venaissin to the Holy See, was allowed, and it became a Papal territory, a status that it retained until 1791.
Alfonso Jordan, also spelled Alfons Jordan or Alphonse Jourdain (1103 – 1148), was the Count of Tripoli (1105 – 09), Count of Rouergue (1109 – 48) and Count of Toulouse, Margrave of Provence and Duke of Narbonne (1112 – 48).
He was the son of Raymond IV of Toulouse by his third wife, Elvira of Castile.
He was born in the castle of Mont Pèlerin in Tripoli while his father was on the First Crusade.
He was given the name "Jourdain" after being baptised in the Jordan River.
Alfonso's father died when he was two years old and he remained under the guardianship of his cousin, William Jordan, Count of Cerdagne, until he was five.
He was then taken to Europe, where his half-brother Bertrand had given him the county of Rouergue.
Upon Bertrand's death in 1112, Alfonso succeeded to the county of Toulouse and marquisate of Provence.
In 1114, Duke William IX of Aquitaine, who claimed Toulouse by right of his wife Philippa, daughter of Count William IV, invaded the county and conquered it.
Alfonso recovered a part in 1119, but he was not in full control until 1123.
When at last successful, he was excommunicated by Pope Callixtus II for having expelled the monks of Saint-Gilles, who had aided his enemies.
Alfonso next had to fight for his rights in Provence against Count Raymond Berengar III of Barcelona.
Not until September 1125 did their war end in "peace and concord" ("pax et concordia").
At this stage, Alfonso was master of the regions lying between the Pyrenees and the Alps, the Auvergne and the sea.
His ascendancy was, according to one commentator, an unmixed good to the country, for during a period of fourteen years art and industry flourished.
In March 1126, Alfonso was at the court of Alfonso VII of León when he acceded to the throne.
According to the "Chronica Adefonsi imperatoris", Alfonso and Suero Vermúdez took the city of León from opposition magnates and handed it over to Alfonso VII.
Among those who may have accompanied Alfonso on one of his many extended stays in Spain was the troubadour Marcabru.
About 1134 Alfonso seized the viscounty of Narbonne and ruled it during the minority of the Viscountess Ermengarde, only restoring it to her in 1143.
In 1141 King Louis VII pressed the claim of Philippa on behalf of his wife, Eleanor of Aquitaine, even besieging Toulouse, but without result.
That same year Alfonso Jordan was again in Spain, making a pilgrimage to Saint James of Compostela, when he proposed a peace between the king of León and García VI of Navarre, which became the basis for subsequent negotiations.
In 1144, Alfonso again incurred the displeasure of the church by siding with the citizens of Montpellier against their lord.
In 1145, Bernard of Clairvaux addressed a letter to him full of concern about a heretic named Henry in the diocese of Toulouse.
Bernard even went there to preach against the heresy, an early expression of Catharism.
A second time he was excommunicated; but in 1146 he took the cross (i.e., vowed to go on crusade) at a meeting in Vézelay called by Louis VII.
In August 1147, he embarked for the near east on the Second Crusade.
He lingered on the way in Italy and probably in Constantinople, where he may have met the Emperor Manuel I. Alfonso finally arrived at Acre in 1148.
Among his companions he had made enemies and he was destined to take no share in the crusade he had joined.
He died at Caesarea, and there were accusations of poisoning, usually levelled either against Eleanor of Aquitaine, wife of Louis, or Melisende, the mother of King Baldwin III of Jerusalem, who may have wanted to eliminate him as a rival to her brother-in-law Raymond II.
By his wife since 1125, Faydiva d'Uzès, he left two legitimate sons: Raymond, who succeeded him, and Alfonso.
His daughter Faydiva (died 1154) married Count Humbert III of Savoy.
He left two other daughters: the legitimate Agnes (died 1187) and the illegitimate Laurentia, who married Count Bernard III of Comminges.
The poem is known to us only through one Vatican manuscript, and long escaped the notice of historians.
Ambroise followed Richard I as a noncombatant, and not improbably as a court-minstrel.
He speaks as an eyewitness of the king's doings at Messina, in Cyprus, at the siege of Acre, and in the abortive campaign which followed the capture of that city.
Ambroise is surprisingly accurate in his chronology; though he did not complete his work before 1195, it is evidently founded upon notes which he had taken in the course of his pilgrimage.
He shows no greater political insight than we should expect from his position; but relates what he had seen and heard with a naïve vivacity which compels attention.
He is by no means an impartial source: he is prejudiced against the Saracens, against the French, and against all the rivals or enemies of his master, including the "Polein" party which supported Conrad of Montferrat against Guy of Lusignan.
He is rather to be treated as a biographer than as a historian of the Crusade in its broader aspects.
Nonetheless he is an interesting primary source for the events of the years 1190 – 1192 in the Kingdom of Jerusalem.
Books 2 – 6 of the "Itinerarium Regis Ricardi", a Latin prose narrative of the same events apparently compiled by Richard, a canon of Holy Trinity, London, are closely related to Ambroise's poem.
They were formerly sometimes regarded as the first-hand narrative on which Ambroise based his work, but that can no longer be maintained.
Art Deco, sometimes referred to as Deco, is a style of visual arts, architecture and design that first appeared in France just before World War I. Art Deco influenced the design of buildings, furniture, jewelry, fashion, cars, movie theatres, trains, ocean liners, and everyday objects such as radios and vacuum cleaners.
It took its name, short for "Arts Décoratifs", from the Exposition internationale des arts décoratifs et industriels modernes (International Exhibition of Modern Decorative and Industrial Arts) held in Paris in 1925.
It combined modern styles with fine craftsmanship and rich materials.
During its heyday, Art Deco represented luxury, glamour, exuberance, and faith in social and technological progress.
Art Deco was a pastiche of many different styles, sometimes contradictory, united by a desire to be modern.
From its outset, Art Deco was influenced by the bold geometric forms of Cubism and the Vienna Secession; the bright colors of Fauvism and of the Ballets Russes; the updated craftsmanship of the furniture of the eras of Louis Philippe I and Louis XVI; and the exotic styles of China and Japan, India, Persia, ancient Egypt and Maya art.
It featured rare and expensive materials, such as ebony and ivory, and exquisite craftsmanship.
The Chrysler Building and other skyscrapers of New York built during the 1920 s and 1930 s are monuments of the Art Deco style.
In the 1930 s, during the Great Depression, Art Deco became more subdued.
New materials arrived, including chrome plating, stainless steel, and plastic.
A sleeker form of the style, called Streamline Moderne, appeared in the 1930 s; it featured curving forms and smooth, polished surfaces.
Art Deco is one of the first truly international styles, but its dominance ended with the beginning of World War II and the rise of the strictly functional and unadorned styles of modern architecture and the International Style of architecture that followed.
Art Deco took its name, short for "arts décoratifs", from the Exposition Internationale des Arts Décoratifs et Industriels Modernes held in Paris in 1925, though the diverse styles that characterize Art Deco had already appeared in Paris and Brussels before World War I. The term "arts décoratifs" was first used in France in 1858; published in the "Bulletin de la Société française de photographie".
In 1868, "Le Figaro" newspaper used the term "objets d'art décoratifs" with respect to objects for stage scenery created for the Théâtre de l'Opéra.
In 1875, furniture designers, textile, jewelry and glass designers, and other craftsmen were officially given the status of artists by the French government.
In response to this, the "École royale gratuite de dessin" (Royal Free School of Design), founded in 1766 under King Louis XVI to train artists and artisans in crafts relating to the fine arts, was renamed the "École nationale des arts décoratifs (" National School of Decorative Arts).
It took its present name of ENSAD ("École nationale supérieure des arts décoratifs") in 1927.
ARTS.
, which were combined into a book, "L'art décoratif d'aujourd ' hui" (Decorative Art Today).
The book was a spirited attack on the excesses of the colorful and lavish objects at the Exposition; and on the idea that practical objects such as furniture should not have any decoration at all; his conclusion was that "Modern decoration has no decoration".
The actual phrase "art déco" did not appear in print until 1966, when it featured in the title of the first modern exhibition on the subject, held by the Museum of Decorative Arts in Paris, "Les Années 25: Art déco, Bauhaus, Stijl, Esprit nouveau", which covered the variety of major styles in the 1920 s and 1930 s.
The term "art déco" was then used in a 1966 newspaper article by Hillary Gelson in "The Times" (London, 12 November), describing the different styles at the exhibit.
Art Deco gained currency as a broadly applied stylistic label in 1968 when historian Bevis Hillier published the first major academic book on the style: "Art Deco of the 20 s and 30 s".
Hillier noted that the term was already being used by art dealers and cites "The Times" (2 November 1966) and an essay named "Les Arts Déco" in "Elle" magazine (November 1967) as examples of prior usage.
In 1971, Hillier organized an exhibition at the Minneapolis Institute of Arts, which he details in his book about it, "The World of Art Deco".
The emergence of Art Deco was closely connected with the rise in status of decorative artists, who until late in the 19th century had been considered simply as artisans.
The term "arts décoratifs" had been invented in 1875, giving the designers of furniture, textiles, and other decoration official status.
The "Société des artistes décorateurs" (Society of Decorative Artists), or SAD, was founded in 1901, and decorative artists were given the same rights of authorship as painters and sculptors.
A similar movement developed in Italy.
The first international exhibition devoted entirely to the decorative arts, the "Esposizione international d'Arte decorative moderna", was held in Turin in 1902.
Several new magazines devoted to decorative arts were founded in Paris, including "Arts et décoration" and "L'Art décoratif moderne".
Decorative arts sections were introduced into the annual salons of the "Sociéte des artistes français", and later in the "Salon d'Automne".
French nationalism also played a part in the resurgence of decorative arts; French designers felt challenged by the increasing exports of less expensive German furnishings.
In 1911, the SAD proposed the holding of a major new international exposition of decorative arts in 1912.
No copies of old styles were to be permitted; only modern works.
The exhibit was postponed until 1914, then, because of the war, postponed until 1925, when it gave its name to the whole family of styles known as "Déco".
Parisian department stores and fashion designers also played an important part in the rise of Art Deco.
Established firms including the luggage maker Louis Vuitton, silverware firm Christofle, glass designer René Lalique, and the jewelers Louis Cartier and Boucheron, who all began designing products in more modern styles.
Beginning in 1900, department stores had recruited decorative artists to work in their design studios.
The decoration of the 1912 "Salon d'Automne" had been entrusted to the department store "Printemps".
During the same year "Printemps" created its own workshop called "Primavera".
By 1920 "Primavera" employed more than three hundred artists.
The styles ranged from the updated versions of Louis XIV, Louis XVI, and especially Louis Philippe furniture made by Louis Süe and the "Primavera" workshop, to more modern forms from the workshop of the "Au Louvre" department store.
Other designers, including Émile-Jacques Ruhlmann and Paul Foliot refused to use mass production, and insisted that each piece be made individually by hand.
The early Art Deco style featured luxurious and exotic materials such as ebony, ivory and silk, very bright colors and stylized motifs, particularly baskets and bouquets of flowers of all colors, giving a modernist look.
The architects of the Vienna Secession (formed 1897), especially Josef Hoffmann, had a notable influence on Art Deco.
His Stoclet Palace in Brussels (1905 – 1911), was a prototype of the Art Deco style, featuring geometric volumes, symmetry, straight lines, concrete covered with marble plaques, finely-sculpted ornament, and lavish interiors, including mosaic friezes by Gustav Klimt.
Hoffmann was also a founder of the Wiener Werkstätte (1903 – 1932), an association of craftsmen and interior designers working in the new style.
This became the model for the "Compagnie des arts français", created in 1919, which brought together André Mare, and Louis Süe, the first leading French Art Deco designers and decorators.
New materials and technologies, especially reinforced concrete, were key to the development and appearance of Art Deco.
The first concrete house was built 1853 Paris suburbs by Francois Coignet.
In 1877 Joseph Monier introduced the idea of strengthening the concrete with a mesh of iron rods in a grill pattern.
In 1893 August Perret built the first concrete garage in Paris, then an apartment building, house, then, in 1913, the Théâtre des Champs-Élysées.
The theater was denounced by one critic as the "Zeppelin of Avenue Montaigne", an alleged Germanic influence, copied from the Vienna Secession.
Thereafter, the majority of Art Deco buildings were made of reinforced concrete, which gave greater freedom of form and less need for reinforcing pillars and columns.
Perret was also a pioneer in covering the concrete with ceramic tiles, both for protection and decoration.
The architect Le Corbusier first learned the uses of reinforced concrete working as a draftsman in Perret's studio.
Other new technologies that were important to Art Deco were new methods in producing plate glass, which were less expensive and allowed much larger and stronger windows, and for mass-producing aluminum, which was used for building and window frames and later, by Corbusier and others, for lightweight furniture.
The Théâtre des Champs-Élysées (1910 – 1913), by Auguste Perret, was the first landmark Art Deco building completed in Paris.
Previously, reinforced concrete had been used only for industrial and apartment buildings, Perret had built the first modern reinforced concrete apartment building in Paris on rue Benjamin Franklin in 1903 – 04.
Henri Sauvage, another important future Art Deco architect, built another in 1904 at 7, rue Trétaigne (1904).
From 1908 to 1910, the 21-year old Le Corbusier worked as a draftsman in Perret's office, learning the techniques of concrete construction.
Perret's building had clean rectangular form, geometric decoration and straight lines, the future trademarks of Art Deco.
The decor of the theater was also revolutionary; the facade was decorated with high reliefs by Antoine Bourdelle, a dome by Maurice Denis, paintings by Édouard Vuillard, and an Art Deco curtain by Ker-Xavier Roussel.
The theater became famous as the venue for many of the first performances of the Ballets Russes.
Perret and Sauvage became the leading Art Deco architects in Paris in the 1920 s.
At its birth between 1910 and 1914, Art Deco was an explosion of colors, featuring bright and often clashing hues, frequently in floral designs, presented in furniture upholstery, carpets, screens, wallpaper and fabrics.
Many colorful works, including chairs and a table by Maurice Dufrene and a bright Gobelin carpet by Paul Follot were presented at the 1912 Salon des artistes décorateurs.
In 1912 – 1913 designer Adrien Karbowsky made a floral chair with a parrot design for the hunting lodge of art collector Jacques Doucet.
The furniture designers Louis Süe and André Mare made their first appearance at the 1912 exhibit, under the name of the "Atelier français", combining colorful fabrics with exotic and expensive materials, including ebony and ivory.
After World War I, they became one of the most prominent French interior design firms, producing the furniture for the first-class salons and cabins of the French transatlantic ocean liners.
The vivid colors of Art Deco came from many sources, including the exotic set designs by Leon Bakst for the Ballets Russes, which caused a sensation in Paris just before World War I. Some of the colors were inspired by the earlier Fauvism movement led by Henri Matisse; others by the Orphism of painters such as Sonia Delaunay; others by the movement known as the Nabis, and in the work of symbolist painter Odilon Redon, who designed fireplace screens and other decorative objects.
Bright colors were a feature of the work of fashion designer Paul Poiret, whose work influenced both Art Deco fashion and interior design.
The art style known as Cubism appeared in France between 1907 and 1912, influencing the development of Art Deco.
The Cubists, themselves under the influence of Paul Cézanne, were interested in the simplification of forms to their geometric essentials: the cylinder, the sphere, the cone.
In 1912, the artists of the Section d'Or exhibited works considerably more accessible to the general public than the analytical Cubism of Picasso and Braque.
The Cubist vocabulary was poised to attract fashion, furniture and interior designers.
In the 1912 writings of André Vera.
"Le Nouveau style", published in the journal "L'Art décoratif", he expressed the rejection of Art Nouveau forms (asymmetric, polychrome and picturesque) and called for "simplicité volontaire, symétrie manifeste, l'ordre et l'harmonie", themes that would eventually become common within Art Deco; though the Deco style was often extremely colorful and anything but simple.
In the "Art Décoratif" section of the 1912 Salon d'Automne, an architectural installation was exhibited known as the "La Maison Cubiste".
The facade was designed by Raymond Duchamp-Villon.
The decor of the house was by André Mare.
"La Maison Cubiste" was a furnished installation with a facade, a staircase, wrought iron banisters, a bedroom, a living room—the "Salon Bourgeois", where paintings by Albert Gleizes, Jean Metzinger, Marie Laurencin, Marcel Duchamp, Fernand Léger and Roger de La Fresnaye were hung.
Thousands of spectators at the salon passed through the full-scale model.
The facade of the house, designed by Duchamp-Villon, was not very radical by modern standards; the lintels and pediments had prismatic shapes, but otherwise the facade resembled an ordinary house of the period.
For the two rooms, Mare designed the wallpaper, which featured stylized roses and floral patterns, along with upholstery, furniture and carpets, all with flamboyant and colorful motifs.
It was a distinct break from traditional decor.
The effect he seeks is obviously one of picturesqueness and gaiety.
The Cubist element was provided by the paintings.
The installation was attacked by some critics as extremely radical, which helped make for its success.
This architectural installation was subsequently exhibited at the 1913 Armory Show, New York, Chicago and Boston.
Thanks largely to the exhibition, the term "Cubist" began to be applied to anything modern, from women's haircuts to clothing to theater performances.
The Cubist influence continued within Art Deco, even as Deco branched out in many other directions.
In 1927, Cubists Joseph Csaky, Jacques Lipchitz, Louis Marcoussis, Henri Laurens, the sculptor Gustave Miklos, and others collaborated in the decoration of a Studio House, rue Saint-James, Neuilly-sur-Seine, designed by the architect Paul Ruaud and owned by the French fashion designer Jacques Doucet, also a collector of Post-Impressionist art by Henri Matisse and Cubist paintings (including "Les Demoiselles d'Avignon", which he bought directly from Picasso's studio).
Laurens designed the fountain, Csaky designed Doucet's staircase, Lipchitz made the fireplace mantel, and Marcoussis made a Cubist rug.
Besides the Cubist artists, Doucet brought in other Deco interior designers to help in decorating the house, including Pierre Legrain, who was in charge of organizing the decoration, and Paul Iribe, Marcel Coard, André Groult, Eileen Gray and Rose Adler to provide furniture.
The decor included massive pieces made of macassar ebony, inspired by African art, and furniture covered with Morocco leather, crocodile skin and snakeskin, and patterns taken from African designs.
Art Deco was not a single style, but a collection of different and sometimes contradictory styles.
In architecture, Art Deco was the successor to and reaction against Art Nouveau, a style which flourished in Europe between 1895 and 1900, and also gradually replaced the Beaux-Arts and neoclassical that were predominant in European and American architecture.
In 1905 Eugène Grasset wrote and published "Méthode de Composition Ornementale, Éléments Rectilignes," in which he systematically explored the decorative (ornamental) aspects of geometric elements, forms, motifs and their variations, in contrast with (and as a departure from) the undulating Art Nouveau style of Hector Guimard, so popular in Paris a few years earlier.
Grasset stressed the principle that various simple geometric shapes like triangles and squares are the basis of all compositional arrangements.
The reinforced concrete buildings of Auguste Perret and Henri Sauvage, and particularly the Theatre des Champs-Elysees, offered a new form of construction and decoration which was copied worldwide.
In decoration, many different styles were borrowed and used by Art Deco.
They included pre-modern art from around the world and observable at the Musée du Louvre, Musée de l'Homme and the Musée national des Arts d'Afrique et d'Océanie.
There was also popular interest in archeology due to excavations at Pompeii, Troy, and the tomb of the 18th dynasty Pharaoh Tutankhamun.
Artists and designers integrated motifs from ancient Egypt, Mesopotamia, Greece, Rome, Asia, Mesoamerica and Oceania with Machine Age elements.
Other styles borrowed included Russian Constructivism and Italian Futurism, as well as Orphism, Functionalism, and Modernism in general.
Art Deco also used the clashing colors and designs of Fauvism, notably in the work of Henri Matisse and André Derain, inspired the designs of art deco textiles, wallpaper, and painted ceramics.
It took ideas from the high fashion vocabulary of the period, which featured geometric designs, chevrons, zigzags, and stylized bouquets of flowers.
It was influenced by discoveries in Egyptology, and growing interest in the Orient and in African art.
From 1925 onwards, it was often inspired by a passion for new machines, such as airships, automobiles and ocean liners, and by 1930 this influence resulted in the style called Streamline Moderne.
Art Deco was associated with both luxury and modernity; it combined very expensive materials and exquisite craftsmanship put into modernistic forms.
Nothing was cheap about Art Deco: pieces of furniture included ivory and silver inlays, and pieces of Art Deco jewelry combined diamonds with platinum, jade, and other precious materials.
The style was used to decorate the first-class salons of ocean liners, deluxe trains, and skyscrapers.
It was used around the world to decorate the great movie palaces of the late 1920 s and 1930 s.
Later, after the Great Depression, the style changed and became more sober.
A good example of the luxury style of Art Deco is the boudoir of the fashion designer Jeanne Lanvin, designed by Armand-Albert Rateau (1882 – 1938) made between 1922 – 25.
It was located in her house at 16 rue Barbet de Jouy, in Paris, which was demolished in 1965.
The room was reconstructed in the Museum of Decorative Arts in Paris.
The walls are covered with molded "lambris" below sculpted bas-reliefs in stucco.
The alcove is framed with columns of marble on with bases and a plinth of sculpted wood.
The floor is of white and black marble, and in the cabinets decorative objects are displayed against a background of blue silk.
Her bathroom had a tub and washstand made of sienna marble, with a wall of carved stucco and bronze fittings.
By 1928 the style had become more comfortable, with deep leather club chairs.
The study designed by the Paris firm of Alavoine for an American businessman in 1928 – 30, now in the Brooklyn Museum.
By the 1930 s, the style had been somewhat simplified, but it was still extravagant.
In 1932 the decorator Paul Ruoud made the Glass Salon for Suzanne Talbot.
It featured a serpentine armchair and two tubular armchairs by Eileen Gray, a floor of mat silvered glass slabs, a panel of abstract patterns in silver and black lacquer, and an assortment of animal skins.
The event that marked the zenith of the style and gave it its name was the International Exhibition of Modern Decorative and Industrial Arts which took place in Paris from April to October in 1925.
This was officially sponsored by the French government, and covered a site in Paris of 55 acres, running from the Grand Palais on the right bank to Les Invalides on the left bank, and along the banks of the Seine.
The Grand Palais, the largest hall in the city, was filled with exhibits of decorative arts from the participating countries.
There were 15,000 exhibitors from twenty different countries, including England, Italy, Spain, Poland, Czechoslovakia, Belgium, Japan, and the new Soviet Union, though Germany was not invited because of tensions after the war and the United States, misunderstanding the purpose of the exhibit, declined to participate.
It was visited by sixteen million people during its seven-month run.
The rules of the exhibition required that all work be modern; no historical styles were allowed.
The main purpose of the Exhibit was to promote the French manufacturers of luxury furniture, porcelain, glass, metal work, textiles and other decorative products.
To further promote the products, all the major Paris department stores and major designers had their own pavilions.
The Exposition had a secondary purpose in promoting products from French colonies in Africa and Asia, including ivory and exotic woods.
The Hôtel du Collectionneur was a popular attraction at the Exposition; it displayed the new furniture designs of Emile-Jacques Ruhlmann, as well as Art Deco fabrics, carpets, and a painting by Jean Dupas.
The interior design followed the same principles of symmetry and geometric forms which set it apart from Art Nouveau, and bright colors, fine craftsmanship rare and expensive materials which set it apart from the strict functionality of the Modernist style.
While most of the pavilions were lavishly decorated and filled with hand-made luxury furniture, two pavilions, those of the Soviet Union and Pavilion du Nouveau Esprit, built by the magazine of that name run by Le Corbusier, were built in an austere style with plain white walls and no decoration; they were among the earliest examples of modernist architecture.
American skyscrapers marked the summit of the Art Deco style; they became the tallest and most recognizable modern buildings in the world.
They were designed to show the prestige of their builders through their height, their shape, their color, and their dramatic illumination at night.
The American Radiator Building by Raymond Hood (1924) combined Gothic and Deco modern elements in the design of the building.
Black brick on the frontage of the building (symbolizing coal) was selected to give an idea of solidity and to give the building a solid mass.
Other parts of the facade were covered in gold bricks (symbolizing fire), and the entry was decorated with marble and black mirrors.
Another early Art Deco skyscraper was Detroit's Guardian Building, which opened in 1929.
Designed by modernist Wirt C. Rowland, the building was the first to employ stainless steel as a decorative element, and the extensive use of colored designs in place of traditional ornaments.
The New York skyline was radically changed by the Chrysler Building in Manhattan (completed in 1930), designed by William Van Alen.
It was a giant seventy-seven floor tall advertisement for Chrysler automobiles.
The top was crowned by a stainless steel spire, and was ornamented by deco "gargoyles" in the form of stainless steel radiator cap decorations.
The base of the tower, thirty-three stories above the street, was decorated with colorful art deco friezes, and the lobby was decorated with art deco symbols and images expressing modernity.
The Chrysler Building was followed by the Empire State Building by William F. Lamb (1931) and the RCA Building (now the Comcast Building) in Rockefeller Center, by Raymond Hood (1933) which together completely changed the skyline of New York.
The tops of the buildings were decorated with Art Deco crowns and spires covered with stainless steel, and, in the case of the Chrysler building, with Art Deco gargoyles modeled after radiator ornaments, while the entrances and lobbies were lavishly decorated with Art Deco sculpture, ceramics, and design.
Similar buildings, though not quite as tall, soon appeared in Chicago and other large American cities.
The Chrysler Building was soon surpassed in height by the Empire State Building, in a slightly less lavish Deco style.
Rockefeller Center added a new design element: several tall building grouped around an open plaza, with a fountain in the center.
In 1925 two different competing schools coexisted within Art Deco: the traditionalists, who had founded the Society of Decorative Artists; included the furniture designer Emile-Jacques Ruhlmann, Jean Dunard, the sculptor Antoine Bourdelle, and designer Paul Poiret; they combined modern forms with traditional craftsmanship and expensive materials.
On the other side were the modernists, who increasingly rejected the past and wanted a style based upon advances in new technologies, simplicity, a lack of decoration, inexpensive materials, and mass production.
The modernists founded their own organization, The French Union of Modern Artists, in 1929.
Its members included architects Pierre Chareau, Francis Jourdain, Robert Mallet-Stevens, Corbusier, and, in the Soviet Union, Konstantin Melnikov; the Irish designer Eileen Gray, and French designer Sonia Delaunay, the jewelers Jean Fouquet and Jean Puiforcat.
They fiercely attacked the traditional art deco style, which they said was created only for the wealthy, and insisted that well-constructed buildings should be available to everyone, and that form should follow function.
The beauty of an object or building resided in whether it was perfectly fit to fulfill its function.
Modern industrial methods meant that furniture and buildings could be mass-produced, not made by hand.
If not, we would have to get rid of music, flowers, and perfumes ..
However, Le Corbusier was a brilliant publicist for modernist architecture; he stated that a house was simply "a machine to live in", and tirelessly promoted the idea that Art Deco was the past and modernism was the future.
Le Corbusier's ideas were gradually adopted by architecture schools, and the aesthetics of Art Deco were abandoned.
The same features that made Art Deco popular in the beginning, its craftsmanship, rich materials and ornament, led to its decline.
The Great Depression that began in the United States in 1929, and reached Europe shortly afterwards, greatly reduced the number of wealthy clients who could pay for the furnishings and art objects.
In the Depression economic climate, few companies were ready to build new skyscrapers.
Even the Ruhlmann firm resorted to producing pieces of furniture in series, rather than individual hand-made items.
The last buildings built in Paris in the new style were the Museum of Public Works by Auguste Perret (now the French Economic, Social and Environmental Council) and the Palais de Chaillot by Louis-Hippolyte Boileau, Jacques Carlu and Léon Azéma, and the Palais de Tokyo of the 1937 Paris International Exposition; they looked out at the grandiose pavilion of Nazi Germany, designed by Albert Speer, which faced the equally grandiose socialist-realist pavilion of Stalin's Soviet Union.
After World War II the dominant architectural style became the International Style pioneered by Le Corbusier, and Mies Van der Rohe.
A handful of Art Deco hotels were built in Miami Beach after World War II, but elsewhere the style largely vanished, except in industrial design, where it continued to be used in automobile styling and products such as jukeboxes.
In the 1960 s, it experienced a modest academic revival, thanks in part to the writings of architectural historians such as Bevis Hillier.
In the 1970 s efforts were made in the United States and Europe to preserve the best examples of Art Deco architecture, and many buildings were restored and repurposed.
Postmodern architecture, which first appeared in the 1980 s, like Art Deco, often includes purely decorative features.
Deco continues to inspire designers, and is often used in contemporary fashion, jewelry, and toiletries.
There was no section set aside for painting at the 1925 Exposition.
Art deco painting was by definition decorative, designed to decorate a room or work of architecture, so few painters worked exclusively in the style, but two painters are closely associated with Art Deco.
Jean Dupas painted Art Deco murals for the Bordeaux Pavilion at the 1925 Decorative Arts Exposition in Paris, and also painted the picture over the fireplace in the Maison de la Collectioneur exhibit at the 1925 Exposition, which featured furniture by Ruhlmann and other prominent Art Deco designers.
His murals were also prominent in the decor of the French ocean liner SS "Normandie".
His work was purely decorative, designed as a background or accompaniment to other elements of the decor.
The other painter closely associated with the style is Tamara de Lempicka.
Born in Poland, she emigrated to Paris after the Russian Revolution.
She studied under Maurice Denis and André Lhote, and borrowed many elements from their styles.
She painted portraits in a realistic, dynamic and colorful Art Deco style.
In the 1930 s a dramatic new form of Art Deco painting appeared in the United States.
During the Great Depression, the Federal Art Project of the Works Progress Administration was created to give work to unemployed artists.
Many were given the task of decorating government buildings, hospitals and schools.
There was no specific art deco style used in the murals; artists engaged to paint murals in government buildings came from many different schools, from American regionalism to social realism; they included Reginald Marsh, Rockwell Kent and the Mexican painter Diego Rivera.
The murals were Art Deco because they were all decorative and related to the activities in the building or city where they were painted: Reginald Marsh and Rockwell Kent both decorated U.S. postal buildings, and showed postal employees at work while Diego Rivera depicted automobile factory workers for the Detroit Institute of Arts.
Diego Rivera's mural "Man at the Crossroads" (1933) for Rockefeller Center featured an unauthorized portrait of Lenin.
When Rivera refused to remove Lenin, the painting was destroyed and a new mural was painted by the Spanish artist Josep Maria Sert.
Sculpture was a very common and integral feature of Art Deco architecture.
In France, allegorical bas-reliefs representing dance and music by Antoine Bourdelle decorated the earliest Art Deco landmark in Paris, the Théâtre des Champs-Élysées in Paris, in 1912.
The 1925 had major sculptural works placed around the site, pavilions were decorated with sculptural friezes, and several pavilions devoted to smaller studio sculpture.
In the 1930 s, a large group of prominent sculptors made works for the 1937 Exposition Internationale des Arts et Techniques dans la Vie Moderne at Chaillot.
Alfred Janniot made the relief sculptures on the facade of the Palais de Tokyo.
The Musée d'Art Moderne de la Ville de Paris, and the esplanade in front of the Palais de Chaillot, facing the Eiffel Tower, was crowded with new statuary by Charles Malfray, Henry Arnold, and many others.
Public art deco sculpture was almost always representational, usually of heroic or allegorical figures related to the purpose of the building or room.
The themes were usually selected by the patrons, not the artist.
Abstract sculpture for decoration was extremely rare.
In the United States, the most prominent Art Deco sculptor for public art was Paul Manship, who updated classical and mythological subjects and themes in an Art Deco style.
His most famous work was the statue of Prometheus at Rockefeller Center in New York, a 20th - century adaptation of a classical subject.
Other important works for Rockefeller Center were made by Lee Lawrie, including the sculptural facade and the Atlas statue.
During the Great Depression in the United States, many sculptors were commissioned to make works for the decoration of federal government buildings, with funds provided by the WPA, or Works Progress Administration.
They included sculptor Sidney Biehler Waugh, who created stylized and idealized images of workers and their tasks for federal government office buildings.
In San Francisco, Ralph Stackpole provided sculpture for the facade of the new San Francisco Stock Exchange building.
In Washington DC, Michael Lantz made works for the Federal Trade Commission building.
In Britain, Deco public statuary was made by Eric Gill for the BBC Broadcasting House, while Ronald Atkinson decorated the lobby of the former Daily Express Building in London (1932).
One of the best known and certainly the largest public Art Deco sculpture is the "Christ the Redeemer" by the French sculptor Paul Landowski, completed between 1922 and 1931, located on a mountain top overlooking Rio de Janeiro, Brazil.
Many early Art Deco sculptures were small, designed to decorate salons.
One genre of this sculpture was called the Chryselephantine statuette, named for a style of ancient Greek temple statues made of gold and ivory.
They were sometimes made of bronze, or sometimes with much more lavish materials, such as ivory.
onyx alabaster, and gold leaf.
One of the best-known Art Deco salon sculptors was the Romanian-born Demétre Chiparus, who produced colorful small sculptures of dancers.
Other notable salon sculptors included Ferdinand Preiss, Josef Lorenzl, Alexander Kelety, Dorothea Charol and Gustav Schmidtcassel.
Another important American sculptor in the studio format was Harriet Whitney Frishmuth, who had studied with Auguste Rodin in Paris.
Pierre Le Paguays was a prominent Art Deco studio sculptor, whose work was shown at the 1925 Exposition.
He worked with bronze, marble, ivory, onyx, gold, alabaster and other precious materials.
François Pompon was a pioneer of modern stylized animalier sculpture.
He was not fully recognized for his artistic accomplishments until the age of 67 at the Salon d'Automne of 1922 with the work "Ours blanc", also known as "The White Bear", now in the Musée d'Orsay in Paris.
Parallel with these Art Deco sculptors, more avant-garde and abstract modernist sculptors were at work in Paris and New York.
The most prominent were Constantin Brâncuși, Joseph Csaky, Alexander Archipenko, Henri Laurens, Jacques Lipchitz, Gustave Miklos, Jean Lambert-Rucki, Jan et Joël Martel, Chana Orloff and Pablo Gargallo.
The Art Deco style appeared early in the graphic arts, in the years just before World War I. It appeared in Paris in the posters and the costume designs of Leon Bakst for the Ballets Russes, and in the catalogs of the fashion designers Paul Poiret.
The illustrations of Georges Barbier, and Georges Lepape and the images in the fashion magazine "La Gazette du bon ton" perfectly captured the elegance and sensuality of the style.
In the 1920 s, the look changed; the fashions stressed were more casual, sportive and daring, with the woman models usually smoking cigarettes.
American fashion magazines such as "Vogue", "Vanity Fair" and "Harper's Bazaar" quickly picked up the new style and popularized it in the United States.
It also influenced the work of American book illustrators such as Rockwell Kent. In Germany, the most famous poster artist of the period was Ludwig Hohlwein, who created colorful and dramatic posters for music festivals, beers, and, late in his career, for the Nazi Party.
During the Art Nouveau period, posters usually advertised theatrical products or cabarets.
In the 1920 s, travel posters, made for steamship lines and airlines, became extremely popular.
The style changed notably in the 1920 s, to focus attention on the product being advertised.
The images became simpler, precise, more linear, more dynamic, and were often placed against a single color background.
In France popular Art Deco designers included, Charles Loupot and Paul Colin, who became famous for his posters of American singer and dancer Josephine Baker.
Jean Carlu designed posters for Charlie Chaplin movies, soaps, and theaters; in the late 1930 s he emigrated to the United States, where, during the World War, he designed posters to encourage war production.
The designer Charles Gesmar became famous making posters for the singer Mistinguett and for Air France.
Among the best known French Art Deco poster designers was Cassandre, who made the celebrated poster of the ocean liner SS "Normandie" in 1935.
In the 1930 s a new genre of posters appeared in the United States during the Great Depression.
The Federal Art Project hired American artists to create posters to promote tourism and cultural events.
The architectural style of art deco made its debut in Paris in 1903 – 04, with the construction of two apartment buildings in Paris, one by Auguste Perret on rue Trétaigne and the other on rue Benjamin Franklin by Henri Sauvage.
The two young architects used reinforced concrete for the first time in Paris residential buildings; the new buildings had clean lines, rectangular forms, and no decoration on the facades; they marked a clean break with the art nouveau style.
Between 1910 and 1913, Perret used his experience in concrete apartment buildings to construct the Théâtre des Champs-Élysées, 15 avenue Montaigne.
Between 1925 and 1928 he constructed the new art deco facade of the La Samaritaine department store in Paris.
After the First World War, art deco buildings of steel and reinforced concrete began to appear in large cities across Europe and the United States.
In the United States the style was most commonly used for office buildings, government buildings, movie theaters, and railroad stations.
It sometimes was combined with other styles; Los Angeles City Hall combined Art Deco with a roof based on the ancient Greek Mausoleum at Halicarnassus, while the Los Angeles railroad station combined Deco with Spanish mission architecture.
Art Deco elements also appeared in engineering projects, including the towers of the Golden Gate Bridge and the intake towers of Hoover Dam.
In the 1920 s and 1930 s it became a truly international style, with examples including the Palacio de Bellas Artes (Palace of Fine Arts) in Mexico City by, the Mayakovskaya Metro Station in Moscow and the National Diet Building in Tokyo by Watanabe Fukuzo.
The Art Deco style was not limited to buildings on land; the ocean liner SS "Normandie", whose first voyage was in 1935, featured Art Deco design, including a dining room whose ceiling and decoration were made of glass by Lalique.
The grand showcases of Art deco interior design were the lobbies of government buildings, theaters, and particularly office buildings.
Interiors were extremely colorful and dynamic, combining sculpture, murals, and ornate geometric design in marble, glass, ceramics and stainless steel.
An early example was the Fisher Building in Detroit, by Joseph Nathaniel French; the lobby was highly decorated with sculpture and ceramics.
The Guardian Building (originally the Union Trust Building) in Detroit, by Wirt Rowland (1929), decorated with red and black marble and brightly colored ceramics, highlighted by highly polished steel elevator doors and counters.
The sculptural decoration installed in the walls illustrated the virtues of industry and saving; the building was immediately termed the "Cathedral of Commerce".
The Medical and Dental Building called 450 Sutter Street in San Francisco by Timothy Pflueger was inspired by Mayan architecture, in a highly stylized form; it used pyramid shapes, and the interior walls were covered highly stylized rows of hieroglyphs.
In France, the best example of an Art Deco interior during period was the Palais de la Porte Dorée (1931) by Albert Laprade, Léon Jaussely and Léon Bazin.
The building (now the National Museum of Immigration, with an aquarium in the basement) was built for the Paris Colonial Exposition of 1931, to celebrate the people and products of French colonies.
The exterior facade was entirely covered with sculpture, and the lobby created an Art Deco harmony with a wood parquet floor in a geometric pattern, a mural depicting the people of French colonies; and a harmonious composition of vertical doors and horizontal balconies.
Many of the best surviving examples of Art Deco are movie theaters built in the 1920 s and 1930 s.
The Art Deco period coincided with the conversion of silent films to sound, and movie companies built enormous theaters in major cities to capture the huge audience that came to see movies.
Movie palaces in the 1920 s often combined exotic themes with art deco style; Grauman's Egyptian Theater in Hollywood (1922) was inspired by ancient Egyptian tombs and pyramids, while the Fox Theater in Bakersfield, California attached a tower in California Mission style to an Art Deco hall.
The largest of all is Radio City Music Hall in New York City, which opened in 1932.
Originally designed as a stage theater, it quickly transformed into a movie theater, which could seat 6,015 persons The interior design by Donald Deskey used glass, aluminum, chrome, and leather to create a colorful escape from reality The Paramount Theater in Oakland, California, by Timothy Pflueger, had a colorful ceramic facade a lobby four stories high, and separate Art Deco smoking rooms for gentlemen and ladies.
Similar grand palaces appeared in Europe.
The Grand Rex in Paris (1932), with its imposing tower, was the largest movie theater in Europe.
The Gaumont State Cinema in London (1937) had a tower modeled after the Empire State building, covered with cream-colored ceramic tiles and an interior in an Art Deco-Italian Renaissance style.
The Paramount Theater in Shanghai, China (1933) was originally built as a dance hall called "The gate of 100 pleasures"; it was converted to a movie theater after the Communist Revolution in 1949, and now is a ballroom and disco.
In the 1930 s Italian architects built a small movie palace, the Cinema Impero, in Asmara in what is now Eritrea.
Today, many of the movie theaters have been subdivided into multiplexes, but others have been restored and are used as cultural centers in their communities.
In the late 1930 s, a new variety of Art Deco architecture became common; it was called Streamline Moderne or simply Streamline, or, in France, the Style Paqueboat, or Ocean Liner style.
Buildings in the style were had rounded corners, long horizontal lines; they were built of reinforced concrete, and were almost always white; and sometimes had nautical features, such as railings that resembled those on a ship.
The rounded corner was not entirely new; it had appeared in Berlin in 1923 in the Mossehaus by Erich Mendelsohn, and later in the Hoover Building, an industrial complex in the London suburb of Perivale.
In the United States, it became most closely associated with transport; Streamline moderne was rare in office buildings, but was often used for bus stations and airport terminals, such as terminal at La Guardia airport in New York City that handled the first transatlantic flights, via the PanAm clipper flying boats; and in roadside architecture, such as gas stations and diners.
In the late 1930 s a series of diners, modeled after streamlined railroad cars, were produced and installed in towns in New England; at least two examples still remain and are now registered historic buildings.
Decoration in the Art Deco period went through several distinct phases.
Between 1910 and 1920, as Art Nouveau was exhausted, design styles saw a return to tradition, particularly in the work of Paul Iribe.
In 1912 André Vera published an essay in the magazine "L'Art Décoratif" calling for a return to the craftsmanship and materials of earlier centuries, and using a new repertoire of forms taken from nature, particularly baskets and garlands of fruit and flowers.
A second tendency of Art Deco, also from 1910 to 1920, was inspired by the bright colors of the artistic movement known as the Fauves and by the colorful costumes and sets of the Ballets Russes.
This style was often expressed with exotic materials such as sharkskin, mother of pearl, ivory, tinted leather, lacquered and painted wood, and decorative inlays on furniture that emphasized its geometry.
This period of the style reached its high point in the 1925 Paris Exposition of Decorative Arts.
In the late 1920 s and the 1930 s, the decorative style changed, inspired by new materials and technologies.
It became sleeker and less ornamental.
Furniture, like architecture, began to have rounded edges and to take on a polished, streamlined look, taken from the streamline modern style.
New materials, such as chrome-plated steel, aluminum and bakelite, an early form of plastic, began to appear in furniture and decoration.
Throughout the Art Deco period, and particularly in the 1930 s, the motifs of the decor expressed the function of the building.
Theaters were decorated with sculpture which illustrated music, dance, and excitement; power companies showed sunrises, the Chrysler building showed stylized hood ornaments; The friezes of Palais de la Porte Dorée at the 1931 Paris Colonial Exposition showed the faces of the different nationalities of French colonies.
The Streamline style made it appear that the building itself was in motion.
The WPA murals of the 1930 s featured ordinary people; factory workers, postal workers, families and farmers, in place of classical heroes.
French furniture from 1910 until the early 1920 s was largely an updating of French traditional furniture styles, and the art nouveau designs of Louis Majorelle, Charles Plumet and other manufacturers.
French furniture manufacturers felt threatened by the growing popularity of German manufacturers and styles, particularly the Biedermeier style, which was simple and clean-lined.
The French designer Frantz Jourdain, the President of the Paris Salon d'Automne, invited designers from Munich to participate in the 1910 Salon.
French designers saw the new German style, and decided to meet the German challenge.
The French designers decided to present new French styles in the Salon of 1912.
The rules of the Salon indicated that only modern styles would be permitted.
All of the major French furniture designers took part in Salon: Paul Follot, Paul Iribe, Maurice Dufrene, André Groult, André Mare and Louis Suë took part, presenting new works that updated the traditional French styles of Louis XVI and Louis Philippe with more angular corners inspired by Cubism and brighter colors inspired by Fauvism and the Nabis.
The painter André Mare and furniture designer Louis Süe both participated the 1912 Salon.
After the war the two men joined together to form their own company, formally called the "Compagnie des Arts Française", but usually known simply as Suë and Mare.
Unlike the prominent art nouveau designers like Louis Majorelle, who personally designed every piece, they assembled a team of skilled craftsmen and produced complete interior designs, including furniture, glassware, carpets, ceramics, wallpaper and lighting.
Their work featured bright colors and furniture and fine woods, such ebony encrusted with mother of pearl, abalone and silvered metal to create bouquets of flowers.
They designed everything from the interiors of ocean liners to perfume bottles for the label of Jean Patou.
The firm prospered in the early 1920 s, but the two men were better craftsmen than businessmen.
The firm was sold in 1928, and both men left.
The most prominent furniture designer at the 1925 Decorative Arts Exposition was Émile-Jacques Ruhlmann, from Alsace.
He first exhibited his works at the 1913 Autumn Salon, then had his own pavilion, the "House of the Rich Collector", at the 1925 Exposition.
He used only most rare and expensive materials, including ebony, mahogany, rosewood, ambon and other exotic woods, decorated with inlays of ivory, tortoise shell, mother of pearl, Little pompoms of silk decorated the handles of drawers of the cabinets.
His furniture was based upon 18th - century models, but simplified and reshaped.
In all of his work, the interior structure of the furniture was completely concealed.
The framework usually of oak, was completely covered with an overlay of thin strips of wood, then covered by a second layer of strips of rare and expensive woods.
This was then covered with a veneer and polished, so that the piece looked as if it had been cut out of a single block of wood.
Contrast to the dark wood was provided by inlays of ivory, and ivory key plates and handles.
According to Ruhlmann, armchairs had to be designed differently according to the functions of the rooms where they appeared; living room armchairs were designed to be welcoming, office chairs comfortable, and salon chairs voluptuous.
Only a small number of pieces of each design of furniture was made, and the average price of one of his beds or cabinets was greater than the price of an average house.
Jules Leleu was a traditional furniture designer who moved smoothly into Art Deco in the 1920 s; he designed the furniture for the dining room of the Élysée Palace, and for the first-class cabins of the steamship "Normandie".
his style was characterized by the use of ebony, Macassar wood, walnut, with decoration of plaques of ivory and mother of pearl.
He introduced the style of lacquered art deco furniture at the end of in the late 1920 s, and in the late 1930 s introduced furniture made of metal with panels of smoked glass.
In Italy, the designer Gio Ponti was famous for his streamlined designs.
The costly and exotic furniture of Ruhlmann and other traditionalists infuriated modernists, including the architect Le Corbusier, causing him to write a famous series of articles denouncing the "arts décoratif" style.
He attacked furniture made only for the rich, and called upon designers to create furniture made with inexpensive materials and modern style, which ordinary people could afford.
He designed his own chairs, created to be inexpensive and mass-produced.
In the 1930 s, furniture designs adapted to the form, with smoother surfaces and curved forms.
The masters of the late style included Donald Deskey was one of the most influential designers; he created the interior of the Radio City Music Hall.
He used a mixture of traditional and very modern materials, including aluminum, chrome, and bakelite, an early form of plastic.
The Waterfall style was popular the 1930 s and 1940 s, the most prevalent Art Deco form of furniture at the time.
Pieces were typically of plywood finished with blond veneer and with rounded edges, resembling a waterfall.
Streamline was a variety of Art Deco which emerged during the mid-1930 s.
It was influenced by modern aerodynamic principles developed for aviation and ballistics to reduce aerodynamic drag at high velocities.
The bullet shapes were applied by designers to cars, trains, ships, and even objects not intended to move, such as refrigerators, gas pumps, and buildings.
One of the first production vehicles in this style was the Chrysler Airflow of 1933.
It was unsuccessful commercially, but the beauty and functionality of its design set a precedent; meant modernity.
It continued to be used in car design well after World War II.
New industrial materials began to influence design of cars and household objects.
These included aluminum, chrome, and bakelite, an early form of plastic.
Bakelite could be easily molded into different forms, and soon was used in telephones, radios and other appliances.
Ocean liners also adopted a style of Art Deco, known in French as the "Style Paquebot", or "Ocean Liner Style".
The most famous example was the SS "Normandie", which made its first transatlantic trip in 1935.
It was designed particularly to bring wealthy Americans to Paris to shop.
The cabins and salons featured the latest Art Deco furnishings and decoration.
The Grand Salon of the ship, which was the restaurant for first-class passengers, was bigger than the Hall of Mirrors of the Palace of Versailles.
It was illuminated by electric lights within twelve pillars of Lalique crystal; thirty-six matching pillars lined the walls.
This was one of the earliest examples of illumination being directly integrated into architecture.
The style of ships was soon adapted to buildings.
A notable example is found on the San Francisco waterfront, where the Maritime Museum building, built as a public bath in 1937, resembles a ferryboat, with ship railings and rounded corners.
The Star Ferry Terminal in Hong Kong also used a variation of the style.
Textiles were an important part of the Art Deco style, in the form of colorful wallpaper, upholstery and carpets, In the 1920 s, designers were inspired by the stage sets of the Ballets Russes, fabric designs and costumes from Léon Bakst and creations by the Wiener Werkstätte.
The early interior designs of André Mare featured brightly colored and highly stylized garlands of roses and flowers, which decorated the walls, floors, and furniture.
Stylized Floral motifs also dominated the work of Raoul Dufy and Paul Poiret, and in the furniture designs of J.E. Ruhlmann.
The floral carpet was reinvented in Deco style by Paul Poiret.
The use of the style was greatly enhanced by the introduction of the "pochoir" stencil-based printing system, which allowed designers to achieve crispness of lines and very vivid colors.
Art Deco forms appeared in the clothing of Paul Poiret, Charles Worth and Jean Patou.
After World War I, exports of clothing and fabrics became one of the most important currency earners of France.
Late Art Deco wallpaper and textiles sometimes featured stylized industrial scenes, cityscapes, locomotives and other modern themes, as well as stylized female figures, metallic colors and geometric designs.
Fashion changed dramatically during the Art Deco period, thanks in particular to designers Paul Poiret and later Coco Chanel.
Poiret introduced an important innovation to fashion design, the concept of draping, a departure from the tailoring and pattern-making of the past.
He designed clothing cut along straight lines and constructed of rectangular motifs.
His styles offered structural simplicity The corseted look and formal styles of the previous period were abandoned, and fashion became more practical, and streamlined.
with the use of new materials, brighter colors and printed designs.
The designer Coco Chanel continued the transition, popularizing the style of sporty, casual chic.
In the 1920 s and 1930 s, designers including René Lalique and Cartier tried to reduce the traditional dominance of diamonds by introducing more colorful gemstones, such as small emeralds, rubies and sapphires.
They also placed greater emphasis on very elaborate and elegant settings, featuring less-expensive materials such as enamel, glass, horn and ivory.
Diamonds themselves were cut in less traditional forms; the 1925 Exposition saw a large number of diamonds cut in the form of tiny rods or matchsticks.
The settings for diamonds also changed; More and more often jewelers used platinum instead of gold, since it was strong and flexible, and could set clusters of stones.
Jewelers also began to use more dark materials, such as enamels and black onyx, which provided a higher contrast with diamonds.
Jewelry became much more colorful and varied in style.
Cartier and the firm of Boucheron combined diamonds with colorful other gemstones cut into the form of leaves, fruit or flowers, to make brooches, rings, earrings, clips and pendants.
Far Eastern themes also became popular; plaques of jade and coral were combined with platinum and diamonds, and vanity cases, cigarette cases and powder boxes were decorated with Japanese and Chinese landscapes made with mother of pearl, enamel and lacquer.
Rapidly changing fashions in clothing brought new styles of jewelry.
Sleeveless dresses of the 1920 s meant that arms needed decoration, and designers quickly created bracelets of gold, silver and platinum encrusted with lapis-lazuli, onyx, coral, and other colorful stones; Other bracelets were intended for the upper arms, and several bracelets were often worn at the same time.
The short haircuts of women in the twenties called for elaborate deco earring designs.
As women began to smoke in public, designers created very ornate cigarette cases and ivory cigarette holders.
The invention of the wrist-watch before World War I inspired jewelers to create extraordinary decorated watches, encrusted with diamonds and plated with enamel, gold and silver.
Pendant watches, hanging from a ribbon, also became fashionable.
The established jewelry houses of Paris in the period, Cartier, Chaumet, Georges Fouquet, Mauboussin, and Van Cleef & Arpels all created jewelry and objects in the new fashion.
The firm of Chaumet made highly geometric cigarette boxes, cigarette lighters, pillboxes and notebooks, made of hard stones decorated with jade, lapis lazuli, diamonds and sapphires.
They were joined by many young new designers, each with his own idea of deco.
Raymond Templier designed pieces with highly intricate geometric patterns, including silver earrings that looked like skyscrapers.
Gerard Sandoz was only 18 when he started to design jewelry in 1921; he designed many celebrated pieces based on the smooth and polished look of modern machinery.
The glass designer René Lalique also entered the field, creating pendants of fruit, flowers, frogs, fairies or mermaids made of sculpted glass in bright colors, hanging on cords of silk with tassels.
The jeweler Paul Brandt contrasted rectangular and triangular patterns, and embedded pearls in lines on onyx plaques.
Jean Despres made necklaces of contrasting colors by bringing together silver and black lacquer, or gold with lapis lazuli.
Many of his designs looked like highly polished pieces of machines.
Jean Dunand was also inspired by modern machinery, combined with bright reds and blacks contrasting with polished metal.
Like the Art Nouveau period before it, Art Deco was an exceptional period for fine glass and other decorative objects, designed to fit their architectural surroundings.
The most famous producer of glass objects was René Lalique, whose works, from vases to hood ornaments for automobiles, became symbols of the period.
He had made ventures into glass before World War I, designing bottles for the perfumes of François Coty, but he did not begin serious production of art glass until after World War I. In 1918, at the age of 58, he bought a large glass works in Combs-la-Ville and began to manufacture both artistic and practical glass objects.
He treated glass as a form of sculpture, and created statuettes, vases, bowls, lamps and ornaments.
He used demi-crystal rather than lead crystal, which was softer and easier to form, though not as lustrous.
He sometimes used colored glass, but more often used opalescent glass, where part or the whole of the outer surface was stained with a wash.
Lalique provided the decorative glass panels, lights and illuminated glass ceilings for the ocean liners SS "Ile de France" in 1927 and the SS "Normandie" in 1935, and for some of the first-class sleeping cars of the French railroads.
At the 1925 Exposition of Decorative Arts, he had his own pavilion, designed a dining room with a table settling and matching glass ceiling for the Sèvres Pavilion, and designed a glass fountain for the courtyard of the Cours des Métier, a slender glass column which spouted water from the sides and was illuminated at night.
Other notable Art Deco glass manufacturers included Marius-Ernest Sabino, who specialized in figurines, vases, bowls, and glass sculptures of fish, nudes, and animals.
For these he often used an opalescent glass which could change from white to blue to amber, depending upon the light.
His vases and bowls featured molded friezes of animals, nudes or busts of women with fruit or flowers.
His work was less subtle but more colorful than that of Lalique.
Other notable Deco glass designers included Edmond Etling, who also used bright opalescent colors, often with geometric patterns and sculpted nudes; Albert Simonet, and Aristide Colotte and Maurice Marinot, who was known for his deeply etched sculptural bottles and vases.
The firm of Daum from the city of Nancy, which had been famous for its Art Nouveau glass, produced a line of Deco vases and glass sculpture, solid, geometric and chunky in form.
More delicate multicolored works were made by Gabriel Argy-Rousseau, who produced delicately colored vases with sculpted butterflies and nymphs, and Francois Decorchemont, whose vases were streaked and marbled.
The Great Depression ruined a large part of the decorative glass industry, which depended upon wealthy clients.
Some artists turned to designing stained glass windows for churches.
In 1937, the Steuben glass company began the practice of commissioning famous artists to produce glassware.
Louis Majorelle, famous for his Art Nouveau furniture, designed a remarkable Art Deco stained glass window portraying steel workers for the offices of the Aciéries de Longwy, a steel mill in Longwy, France.
Art Deco artists produced a wide variety of practical objects in the Art Deco style, made of industrial materials from traditional wrought iron to chrome-plated steel.
The American artist Norman Bel Geddes designed a cocktail set resembling a skyscraper made of chrome-plated steel.
Raymond Subes designed an elegant metal grille for the entrance of the Palais de la Porte Dorée, the centerpiece of the 1931 Paris Colonial Exposition.
The French sculptor Jean Dunand produced magnificent doors on the theme "The Hunt", covered with gold leaf and paint on plaster (1935).
Art Deco visuals and imagery was used in animated films including "", "Night Hood", "All's Fair at the Fair", "Merry Mannequins", "Page Miss Glory", "Fantasia" and "Sleeping Beauty".
Art Deco architecture began in Europe, but by 1939 there were examples in large cities on every continent and in almost every country.
This is a selection of prominent buildings on each continent.
(For a comprehensive of existing buildings by country, see List of Art Deco architecture.)
Most Art Deco buildings in Africa were built during European colonial rule, and often designed by Italian and French architects.
A large number of the Art Deco buildings in Asia were designed by European architects.
But in the Philippines, local architects such as Juan Nakpil, Juan Arellano and others were preeminent.
Many Art Deco landmarks in Asia were demolished during the great economic expansion of Asia the late 20th century, but some notable enclaves of the architecture still remain, particularly in Shanghai and Mumbai.
Melbourne and Sydney Australia have several notable Art Deco buildings, including the Manchester Unity Building and the former Russell Street Police Headquarters in Melbourne, the Castlemaine Art Museum in Castlemaine, central Victoria and the Grace Building, AWA Tower and ANZAC War Memorial in Sydney.
Several towns in New Zealand, including Napier and Hastings were rebuilt in Art Deco style after the 1931 Hawke's Bay earthquake, and many of the buildings have been protected and restored.
Napier has been nominated for UNESCO World Heritage Site status, the first cultural site in New Zealand to be nominated.
Wellington has retained a sizeable number of Art Deco buildings.
In Canada, surviving Art Deco structures are mainly in the major cities; Montreal, Toronto, Hamilton, Ontario, and Vancouver.
They range from public buildings like Vancouver City Hall to commercial buildings (College Park) to public works (R. C. Harris Water Treatment Plant).
In Mexico, the most imposing Art Deco example is interior of the Palacio de Bellas Artes (Palace of Fine Arts), finished in 1934 with its elaborate decor and murals.
Examples of Art Deco residential architecture can be found in the Condesa neighborhood, many designed by Francisco J. Serrano.
In the United States, Art Deco buildings are found from coast to coast, in all the major cities.
It was most widely used for office buildings, train stations, airport terminals, and movie theaters; residential buildings are rare.
In the 1930 s, the more austere streamline style became popular.
Many buildings were demolished between 1945 and the late 1960 s, but then efforts began to protect the best examples.
The City of Miami Beach established the Miami Beach Architectural District to preserve the colorful collection of Art Deco buildings found there.
Art Deco buildings can be found throughout Central America.
A particularly rich collection is found in Cuba, built largely for the large number of tourists who came to the island from the United States.
One such building is the López Serrano built between 1929 and 1932 in the Vedado section of Havana.
The architectural style first appeared in Paris with the Théâtre des Champs-Élysées (1910 – 13) by Auguste Perret but then spread rapidly around Europe, until examples could be found in nearly every large city, from London to Moscow.
In Germany two variations of Art Deco flourished in the 1920 s and 30 s: The Neue Sachlichkeit style and Expressionist architecture.
Notable examples include Erich Mendelsohn's Mossehaus and Schaubühne theater in Berlin, Fritz Höger's Chilehaus in Hamburg and his Kirche am Hohenzollernplatz in Berlin, the Anzeiger Tower in Hannover and the Borsig Tower in Berlin.
One of the largest Art Deco buildings in Western Europe is the Basilica of the Sacred Heart in Koekelberg, Brussels.
In 1925, architect Albert van Huffel won the Grand Prize for Architecture with his scale model of the basilica at the Exposition Internationale des Arts Décoratifs et Industriels Modernes in Paris.
Spain and Portugal have some striking examples of Art Deco buildings, particularly movie theaters.
Examples in Portugal are the Capitólio Theater (1931) and the Éden Cine-Theater (1937) in Lisbon, the Rivoli Theater (1937) and the Coliseu (1941) in Porto and the Rosa Damasceno Theater (1937) in Santarém.
An example in Spain is the Cine Rialto in Valencia (1939).
During the 1930 s, Art Deco had a noticeable effect on house design in the United Kingdom, as well as the design of various public buildings.
Straight, white-rendered house frontages rising to flat roofs, sharply geometric door surrounds and tall windows, as well as convex-curved metal corner windows, were all characteristic of that period.
The London Underground is famous for many examples of Art Deco architecture, and there are a number of buildings in the style situated along the Golden Mile in Brentford.
Also in West London is the Hoover Building, which was originally built for The Hoover Company and was converted into a superstore in the early 1990 s.
The Indian Institute of Architects, founded in Mumbai in 1929, played a prominent role in propagating the Art Deco movement.
In November 1937, this institute organized the ‘ Ideal Home Exhibition ’ held in the Town Hall in Mumbai which spanned over 12 days and attracted about one hundred thousand visitors.
As a result, it was declared a success by the ' Journal of the Indian Institute of Architects'.
The exhibits displayed the ‘ ideal ’, or better described as the most ‘ modern ’ arrangements for various parts of the house, paying close detail to avoid architectural blunders and present the most efficient and well-thought-out models.
The exhibition focused on various elements of a home ranging from furniture, elements of interior decoration as well as radios and refrigerators using new and scientifically relevant materials and methods.
Guided by their desire to emulate the west, the Indian architects were fascinated by the industrial modernity that Art Deco offered.
The western elites were the first to experiment with the technologically advanced facets of Art Deco, and architects began the process of transformation by the early 1930 s.
Mumbai's expanding port commerce in the 1930 s resulted in the growth of educated middle class population.
It also saw an increase of people migrating to Mumbai in search of job opportunities.
This led to the pressing need for new developments through Land Reclamation Schemes and construction of new public and residential buildings.
Parallelly, the changing political climate in the country and the aspirational quality of the Art Deco aesthetics led to a whole-hearted acceptance of the building style in the city's development.
Most of the buildings from this period can be seen spread throughout the city neighbourhoods in areas such as Churchgate, Colaba, Fort, Mohammed Ali Road, Cumbala Hill, Dadar, Matunga, Bandra and Chembur.
The Art Deco in South America is present especially at the countries that received a great wave of immigration on the first half of the 20th century, with notable works at their richest cities, like São Paulo and Rio de Janeiro in Brazil and Buenos Aires in Argentina.
The Kavanagh building in Buenos Aires (1934), by Sánchez, Lagos and de la Torre, was the tallest reinforced concrete structure when it was completed, and a notable example of late Art Deco style.
In many cities, efforts have been made to protect the remaining Art Deco buildings.
In many U.S. cities, historic art deco movie theaters have been preserved and turned into cultural centers.
Even more modest art deco buildings have been preserved as part of America's architectural heritage; an art deco cafe and gas station along Route 66 in Shamrock, Texas is an historic monument.
The Miami Beach Architectural District protects several hundred old buildings, and requires that new buildings comply with the style.
In Havana, Cuba, a large number of Art Deco buildings have badly deteriorated.
Efforts are underway to bring the buildings back to their original color and appearance.
In the 21st century, modern variants of Art Deco, called Neo Art Deco (or Neo-Art Deco), have appeared in some American cities, inspired by the classic Art Deco buildings of the 1920 s and 1930 s.
Examples include the NBC Tower in Chicago, inspired by 30 Rockefeller Plaza in New York City; and Smith Center for the Performing Arts in Las Vegas, Nevada, which includes art deco features from Hoover Dam, fifty miles away.
ASCII art is a graphic design technique that uses computers for presentation and consists of pictures pieced together from the 95 printable (from a total of 128) characters defined by the ASCII Standard from 1963 and ASCII compliant character sets with proprietary extended characters (beyond the 128 characters of standard 7-bit ASCII).
The term is also loosely used to refer to text based visual art in general.
ASCII art can be created with any text editor, and is often used with free-form languages.
Most examples of ASCII art require a fixed-width font (non-proportional fonts, as on a traditional typewriter) such as Courier for presentation.
Among the oldest known examples of ASCII art are the creations by computer-art pioneer Kenneth Knowlton from around 1966, who was working for Bell Labs at the time.
"Studies in Perception I" by Ken Knowlton and Leon Harmon from 1966 shows some examples of their early ASCII art.
ASCII art was invented, in large part, because early printers often lacked graphics ability and thus characters were used in place of graphic marks.
Also, to mark divisions between different print jobs from different users, bulk printers often used ASCII art to print large banner pages, making the division easier to spot so that the results could be more easily separated by a computer operator or clerk.
ASCII art was also used in early e-mail when images could not be embedded.
Since 1867, typewriters have been used for creating visual art.
TTY stands for "TeleTYpe" or "TeleTYpewriter", and is also known as Teleprinter or Teletype.
RTTY stands for Radioteletype; character sets such as Baudot code, which predated ASCII, were used.
According to a chapter in the "RTTY Handbook", text images have been sent via teletypewriter as early as 1923.
However, none of the "old" RTTY art has been discovered yet.
What is known is that text images appeared frequently on radioteletype in the 1960 s and the 1970 s.
In the 1960 s, Andries van Dam published a representation of an electronic circuit produced on an IBM 1403 line printer.
At the same time, Kenneth Knowlton was producing realistic images, also on line printers, by overprinting several characters on top of one another.
Note that it was not ASCII art in a sense that the 1403 was driven by an EBCDIC-coded platform and the character sets and trains available on the 1403 were derived from EBCDIC rather than ASCII, despite some glyphs commonalities.
The widespread usage of ASCII art can be traced to the computer bulletin board systems of the late 1970 s and early 1980 s.
The limitations of computers of that time period necessitated the use of text characters to represent images.
Along with ASCII's use in communication, however, it also began to appear in the underground online art groups of the period.
An ASCII comic is a form of webcomic which uses ASCII text to create images.
In place of images in a regular comic, ASCII art is used, with the text or dialog usually placed underneath.
During the 1990 s, graphical browsing and variable-width fonts became increasingly popular, leading to a decline in ASCII art.
Despite this, ASCII art continued to survive through online MUDs, an acronym for "Multi-User Dungeon", (which are textual multiplayer role-playing video games), Internet Relay Chat, E-mail, message boards and other forms of online communication which commonly employ the needed fixed-width.
ASCII and more importantly, ANSI were staples of the early technological era; terminal systems relied on coherent presentation using color and control signals standard in the terminal protocols.
Over the years, warez groups began to enter the ASCII art scene.
Warez groups usually release.
nfo files with their software, cracks or other general software reverse-engineering releases.
The ASCII art will usually include the warez group's name and maybe some ASCII borders on the outsides of the release notes, etc.
BBS systems were based on ASCII and ANSI art, as were most DOS and similar console applications, and the precursor to AOL.
ASCII art is used wherever text can be more readily printed or transmitted than graphics, or in some cases, where the transmission of pictures is not possible.
This includes typewriters, teleprinters, non-graphic computer terminals, printer separators, in early computer networking (e.g., BBSes), e-mail, and Usenet news messages.
ASCII art is also used within the source code of computer programs for representation of company or product logos, and flow control or other diagrams.
In some cases, the entire source code of a program is a piece of ASCII art – for instance, an entry to one of the earlier International Obfuscated C Code Contest is a program that adds numbers, but visually looks like a binary adder drawn in logic ports.
Some electronic schematic archives represent the circuits using ASCII art.
Examples of ASCII-style art predating the modern computer era can be found in the June 1939, July 1948 and October 1948 editions of Popular Mechanics.
"0verkill" is a 2D platform multiplayer shooter game designed entirely in color ASCII art.
MPlayer and VLC media player can display videos as ASCII art through the AAlib library.
ASCII art is used in the making of DOS-based ZZT games.
Many game walkthrough guides come as part of a basic.
txt file; this file often contains the name of the game in ASCII art.
Such as below, word art is created using backslashes and other ASCII values in order to create the illusion of 3D.
Different techniques could be used in ASCII art to obtain different artistic effects.
Electronic circuits and diagrams were implemented by typewriter or teletype and provided the pretense for ASCII.
"Typewriter-style" lettering, made from individual letter characters: Line art, for creating shapes: Solid art, for creating filled objects: Shading, using symbols with various intensities for creating gradients or contrasts: Combinations of the above, often used as signatures, for example, at the end of an email: As-pixel characters use combinations of ░, █, ▄ and ▀ to make pictures :< br > The simplest forms of ASCII art are combinations of two or three characters for expressing emotion in text.
They are commonly referred to as' emoticon ', ' smilie ', or ' smiley '.
There is another type of one-line ASCII art that does not require the mental rotation of pictures, which is widely known in Japan as kaomoji (literally "face characters".)
Traditionally, they are referred to as "ASCII face".
More complex examples use several lines of text to draw large symbols or more complex figures.
Hundreds of different text smileys have developed over time, but only a few are generally accepted, used and understood.
An ASCII comic is a form of webcomic.
The Adventures of Nerd Boy, or just Nerd Boy, was an ASCII comic, published by Joaquim Gândara between 5 August 2001 and 17 July 2007, and consisting of 600 strips.
They were posted to ASCII art newsgroup alt.
ascii-art and on the website.
Some strips have been translated to Polish and French.
The Atari 400/800 which were released in 1979 did not follow the ASCII standard and had its own character set, called ATASCII.
The emergence of ATASCII art coincided with the growing popularity of BBS Systems caused by availability of the acoustic couplers that were compatible with the 8-bit home computers.
ATASCII text animations are also referred to as "break animations" by the Atari sceners.
The Commodore 64, which was released in 1982, also did not follow the ASCII standard.
The C-64 character set is called PETSCII, an extended form of ASCII-1963.
As with the Atari's ATASCII art, C-64 fans developed a similar scene that used PETSCII for their creations.
So-called "block ASCII" or "high ASCII" uses the extended characters of the 8-bit code page 437, which is a proprietary standard introduced by IBM in 1979 (ANSI Standard x3.
16) for the IBM PC DOS and MS-DOS operating systems.
"Block ASCIIs" were widely used on the PC during the 1990 s until the Internet replaced BBSes as the main communication platform.
Until then, "block ASCIIs" dominated the PC Text Art Scene.
The first art scene group that focused on the extended character set of the PC in their art work was called "Aces of ANSI Art" (< A.A. A >).
Some members left in 1990, and formed a group called "ANSI Creators in Demand" (ACiD).
In that same year the second major underground art scene group was founded, ICE, "Insane Creators Enterprise".
There is some debate between ASCII and block ASCII artist, with "Hardcore" ASCII artists maintaining that block ASCII art is in fact not ANSI art, because it does not use the 128 characters of the original ASCII standard.
On the other hand, block ASCII artists argue that if their art uses only characters of the computers character set, then it is to be called ASCII, regardless if the character set is proprietary or not.
Microsoft Windows does not support the ANSI Standard x3.
16.
One can view block ASCIIs with a text editor using the font "Terminal", but it will not look exactly as it was intended by the artist.
With a special ASCII/ANSI viewer, such as ACiDView for Windows (see ASCII and ANSI art viewers), one can see block ASCII and ANSI files properly.
An example that illustrates the difference in appearance is part of this article.
Alternatively, one could look at the file using the TYPE command in the command prompt.
In the art scene one popular ASCII style that used the 7-bit standard ASCII character set was the so-called "Oldskool" style.
It is also called "Amiga style", due to its origin and widespread use on the Commodore Amiga computers.
The style uses primarily the characters: codice_1.
The "oldskool" art looks more like the outlined drawings of shapes than real pictures.
This is an example of "Amiga style" (also referred to as "old school" or "oldskool" style) scene ASCII art.
The Amiga ASCII scene surfaced in 1992, seven years after the introduction of the Commodore Amiga 1000.
The Commodore 64 PETSCII scene did not make the transition to the Commodore Amiga as the C64 demo and warez scenes did.
Among the first Amiga ASCII art groups were ART, Epsilon Design, Upper Class, Unreal (later known as "DeZign").
This means that the text art scene on the Amiga was actually younger than the text art scene on the PC.
The Amiga artists also did not call their ASCII art style "Oldskool".
That term was introduced on the PC.
When and by whom is unknown and lost in history.
The Amiga style ASCII artwork was most often released in the form of a single text file, which included all the artwork (usually requested), with some design parts in between, as opposed to the PC art scene where the art work was released as a ZIP archive with separate text files for each piece.
Furthermore, the releases were usually called "ASCII collections" and not "art packs" like on the IBM PC.
This kind of ASCII art is handmade in a text editor.
Popular editors used to make this kind of ASCII art include Microsoft Notepad, CygnusEditor aka.
CED (Amiga), and EditPlus2 (PC).
Oldskool font example from the PC, which was taken from the ASCII editor FIGlet.
"Newskool" is a popular form of ASCII art which capitalizes on character strings like "$ # Xxo".
In spite of its name, the style is not "new"; on the contrary, it was very old but fell out of favor and was replaced by "Oldskool" and "Block" style ASCII art.
It was dubbed "Newskool" upon its comeback and renewed popularity at the end of the 1990 s.
Newskool changed significantly as the result of the introduction of extended proprietary characters.
The classic 7-bit standard ASCII characters remain predominant, but the extended characters are often used for "fine tuning" and "tweaking".
The style developed further after the introduction and adaptation of Unicode.
While some prefer to use a simple text editor to produce ASCII art, specialized programs, such as JavE have been developed that often simulate the features and tools in bitmap image editors.
For Block ASCII art and ANSI art the artist almost always uses a special text editor, because to generate the required characters on a standard keyboard, one needs to know the Alt code for each character.
For example, + will produce ▓, + will produce ▒, and + will produce ◘.
The special text editors have sets of special characters assigned to existing keys on the keyboard.
Popular DOS-based editors, such as TheDraw and ACiDDraw had multiple sets of different special characters mapped to the function keys to make the use of those characters easier for the artist who can switch between individual sets of characters via basic keyboard shortcuts.
PabloDraw is one of the very few special ASCII/ANSI art editors that were developed for Windows.
Other programs allow one to automatically convert an image to text characters, which is a special case of vector quantization.
A method is to sample the image down to grayscale with less than 8-bit precision, and then assign a character for each value.
Such ASCII art generators often allow users to choose the intensity and contrast of the generated image.
Three factors limit the "fidelity" of the conversion, especially of photographs: Examples of converted images are given below.
This is one of the earliest forms of ASCII art, dating back to the early days of the 1960 s minicomputers and teletypes.
During the 1970 s, it was popular in US malls to get a t-shirt with a photograph printed in ASCII art on it from an automated kiosk manned by a computer, and London's Science Museum had a similar service to produce printed portraits.
With the advent of the web, HTML and CSS, many ASCII conversion programs will now quantize to a full RGB colorspace, enabling colorized ASCII images.
Still images or movies can also be converted to ASCII on various UNIX and UNIX-like systems using the aalib (black and white) or libcaca (colour) graphics device driver, or the VLC media player or mpv under Windows, Linux or macOS; all of which render the screen using ASCII symbols instead of pixels.
There are also a number of smartphone applications, such as ASCII cam for Android, that generate ASCII art in real-time using input from the phone's camera.
These applications typically allow the ASCII art to be saved as either a text file or as an image made up of ASCII text.
Most ASCII art is created using a monospaced font, where all characters are identical in width (Courier is a popular monospaced font).
Early computers in use when ASCII art came into vogue had monospaced fonts for screen and printer displays.
Today, most of the more commonly used fonts in word processors, web browsers and other programs are proportional fonts, such as Helvetica or Times Roman, where different widths are used for different characters.
ASCII art drawn for a fixed width font will usually appear distorted, or even unrecognizable when displayed in a proportional font.
Some ASCII artists have produced art for display in proportional fonts.
These ASCIIs, rather than using a purely shade-based correspondence, use characters for slopes and borders and use block shading.
These ASCIIs generally offer greater precision and attention to detail than fixed-width ASCIIs for a lower character count, although they are not as universally accessible since they are usually relatively font-specific.
Animated ASCII art started in 1970 from so-called VT100 animations produced on VT100 terminals.
These animations were simply text with cursor movement instructions, deleting and erasing the characters necessary to appear animated.
Usually, they represented a long hand-crafted process undertaken by a single person to tell a story.
Contemporary web browser revitalized animated ASCII art again.
It became possible to display animated ASCII art via JavaScript or Java applets.
Static ASCII art pictures are loaded and displayed one after another, creating the animation, very similar to how movie projectors unreel film reel and project the individual pictures on the big screen at movie theaters.
A new term was born: "" ASCIImation "" – another name of "animated ASCII art".
A seminal work in this arena is the Star Wars ASCIImation.
More complicated routines in JavaScript generate more elaborate ASCIImations showing effects like Morphing effects, star field emulations, fading effects and calculated images, such as mandelbrot fractal animations.
There are now many tools and programs that can transform raster images into text symbols; some of these tools can operate on streaming video.
For example, the music video for American singer Beck's song "Black Tambourine" is made up entirely of ASCII characters that approximate the original footage.
VLC, a media player software, can render any video in colored ASCII through the libcaca module.
There are a variety of other types of art using text symbols from character sets other than ASCII and/or some form of color coding.
Despite not being pure ASCII, these are still often referred to as "ASCII art".
The character set portion designed specifically for drawing is known as the line drawing characters or pseudo-graphics.
The IBM PC graphics hardware in text mode uses 16 bits per character.
It supports a variety of configurations, but in its default mode under DOS they are used to give 256 glyphs from one of the IBM PC code pages (Code page 437 by default), 16 foreground colors, eight background colors, and a flash option.
Such art can be loaded into screen memory directly.
ANSI.
SYS, if loaded, also allows such art to be placed on screen by outputting escape sequences that indicate movements of the screen cursor and color/flash changes.
If this method is used then the art becomes known as ANSI art.
The IBM PC code pages also include characters intended for simple drawing which often made this art appear much cleaner than that made with more traditional character sets.
Plain text files are also seen with these characters, though they have become far less common since Windows GUI text editors (using the Windows ANSI code page) have largely replaced DOS-based ones.
In Japan, ASCII art (AA) is mainly known as Shift_JIS art.
Shift JIS offers a larger selection of characters than plain ASCII (including characters from Japanese scripts and fullwidth forms of ASCII characters), and may be used for text-based art on Japanese websites.
Often, such artwork is designed to be viewed with the default Japanese font on a platform, such as the proportional MS P Gothic.
Users on ASCII-NET, in which the word "ASCII" refers to the ASCII Corporation rather than the American Standard Code for Information Interchange, popularised a style of in which the face appears upright rather than rotated.
Unicode would seem to offer the ultimate flexibility in producing text based art with its huge variety of characters.
However, finding a suitable fixed-width font is likely to be difficult if a significant subset of Unicode is desired.
(Modern UNIX-style operating systems do provide complete fixed-width Unicode fonts, e.g. for xterm.
Windows has the Courier New font, which includes characters like ┌ ╥ ─ ╨ ┐ ♥ ☺ Ƹ̵̡Ӝ̵̨̄Ʒ).
Also, the common practice of rendering Unicode with a mixture of variable width fonts is likely to make predictable display hard, if more than a tiny subset of Unicode is used.
≽ ⱷ҅ⱷ ≼ is an adequate representation of a cat's face in a font with varying character widths.
The combining characters mechanism of Unicode provides considerable ways of customizing the style, even obfuscating the text (e.g. via an online generator like Obfuscator, which focuses on the filters).
It ’s a kind of art.
The corresponding creations are favored in web browsers (thanks to their always better support Overprinting had previously been used on typewriters, but the low-resolution pixelation of characters on video terminals meant that overprinting here produced seamless pixel graphics, rather than visibly overstruck combinations of letters on paper.
Beyond pixel graphics, this was also used for printing photographs, as the overall darkness of a particular character space dependent on how many characters, as well as the choice of character, were printed in a particular place.
Thanks to the increased granularity of tone, photographs were often converted to this type of printout.
Even manual typewriters or daisy wheel printers could be used.
The technique has fallen from popularity since all cheap printers can easily print photographs, and a normal text file (or an e-mail message or Usenet posting) cannot represent overprinted text.
However, something similar has emerged to replace it: shaded or colored ASCII art, using ANSI video terminal markup or color codes (such as those found in HTML, IRC, and many internet message boards) to add a bit more tone variation.
In this way, it is possible to create ASCII art where the characters only differ in color.
ASCII art text editors are used to create ASCII art from scratch, or to edit existing ASCII art files.
ASCII art may be created from an existing digital image using an ASCII art converter, an online tool or a software application, that automatically converts an image into ASCII art, using vector quantization.
Typically, this is done by sampling the image down to grayscale with less than 8-bit precision, so that each value corresponds to different ASCII character.
Alexius is the Latinized form of the given name Alexios (, polytonic, "defender", cf. Alexander), especially common in the later Byzantine Empire.
Variants include Alexis with the Russian Aleksey and its Ukrainian counterpart Oleksa/Oleksiy deriving from this form.
American English (AmE, AE, AmEng, USEng, en-US), sometimes called United States English or U.S. English, is the set of varieties of the English language native to the United States.
American English is considered to be the world's most influential form of English.
English is the most widely spoken language in the United States and is the "de facto" common language used by the federal and state governments, to the extent that all laws and compulsory education presume English as the primary language.
English is explicitly given official status by 32 of the 50 state governments.
While the local courts in some divisions of the United States grant equivalent status to both English and another language—for example, English and Spanish in Puerto Rico—under federal law, English is still the official language for any matters being referred to the United States district court for the territory.
The use of English in the United States is a result of British colonization of the Americas.
The first wave of English-speaking settlers arrived in North America during the 17th century, followed by further migrations in the 18th and 19th centuries.
During the 17th century, dialects from many different regions of England existed in every American colony, allowing a process of extensive dialect mixture and levelling in which English varieties across the colonies became more homogeneous compared with varieties in England.
English thus predominated in the colonies even by the end of the 17th century's first massive immigrations of non-English speakers from Europe and Africa, and firsthand descriptions of a fairly uniform American English became common after the mid-18 th century.
Since then, American English has developed into some new varieties, including regional dialects that, in some cases, show minor influences in the last two centuries from successive waves of immigrant speakers of diverse languages, primarily European languages.
American English varieties include many patterns of pronunciation, vocabulary, grammar, and particularly spelling that are unified nationwide but distinct from other English dialects around the world.
Any American or Canadian accent perceived as free of noticeably local, ethnic, or cultural markers is popularly called "General" or "Standard" American, a fairly uniform accent continuum native to certain regions of the U.S. and associated nationally with broadcast mass media and highly educated speech.
However, historical and present linguistic evidence does not support the notion of there being one single "mainstream" American accent.
The sound of American English continues to evolve, with some local accents disappearing, but several larger regional accents having emerged in the 20th century.
Compared with English as spoken in the United Kingdom North American English is more homogeneous, and any phonologically unremarkable North American accent is known as "General American".
This section mostly refers to such General American features.
Studies on historical usage of English in both the United States and the United Kingdom suggest that spoken American English did not simply deviate away from period British English, but is conservative in some ways, preserving certain features contemporary British English has since lost.
Full rhoticity (or R-fulness) is typical of American accents, pronouncing the phoneme (corresponding to the letter) in all environments, including after vowels, such as in "pearl", "car", and "court".
Non-rhotic American accents, those that do not pronounce except before a consonant, such as some Eastern New England, New York, a specific few (often older) Southern, and African American vernacular accents, are often quickly noticed by General American listeners and perceived to sound especially ethnic, regional, or "old-fashioned".
Rhoticity is common in most American accents (yet nowadays rare in England), because, during the 17th - century British colonization, nearly all dialects of English were rhotic, and most North American English simply remained that way.
This preservation of rhoticity in North America was also supported by continuing waves of rhotic-accented Scots-Irish immigrants, most intensely during the 18th century (and moderately during the following two centuries), when the Scots-Irish eventually made up one-seventh of the colonial population.
Scots-Irish settlers spread from Delaware and Pennsylvania throughout the larger Mid-Atlantic region, the inland regions of both the South and North, and throughout the West, all American dialect areas that consistently resisted upper-class non-rhotic influences and that consequently remain rhotic today.
The pronunciation of is a postalveolar approximant or retroflex approximant, though a unique "bunched tongue" variant of the approximant "r" sound is also associated with the United States, and perhaps mostly in the Midwest and the South.
For those American accents that have not undergone the "cot–caught" merger (the lexical sets and), they have instead retained a – split: a 17th - century split in which certain words (labeled as the lexical set) separated away from the set.
This split, which has now reversed in most British English, simultaneously shifts this relatively recent set into a merger with the ("caught") set.
Having taken place prior to the unrounding of the "cot" vowel, this results in lengthening and perhaps raising, merging the more recently separated vowel into the vowel in the following environments: before many instances of,, and particularly (as in "Austria, cloth, cost, loss, off, often," etc.)
, a few instances before (as in "strong, long, wrong"), and variably by region or speaker in "gone", "on", and certain other words.
The standard accent of southern England, Received Pronunciation (RP), has evolved in other ways too, compared to which General American English has remained relatively more conservative, for example, regarding today's RP features of a "trap–bath" split and the fronting of, neither of which is typical of General American accents.
Moreover, American dialects also do not participate in widespread H-dropping, an innovative feature characterizing perhaps a majority of regional dialects of England.
On the other hand, General American is more innovative than the dialects of England, or English elsewhere in the world, in a number of its own ways: Some mergers found in most varieties of both American and British English include: The process of coining new lexical items started as soon as English-speaking British-American colonists began borrowing names for unfamiliar flora, fauna, and topography from the Native American languages.
Examples of such names are "opossum, raccoon, squash", "moose" (from Algonquian), "wigwam", and "moccasin".
The languages of the other colonizing nations also added to the American vocabulary; for instance, "cookie", from Dutch; "kindergarten" from German, "levee" from French; and "rodeo" from Spanish.
Landscape features are often loanwords from French or Spanish, and the word "corn", used in England to refer to wheat (or any cereal), came to denote the maize plant, the most important crop in the U.S. Most Mexican Spanish contributions came after the War of 1812, with the opening of the West, like "ranch" (now a common house style).
Due to the Mexican culinary influence, many Spanish words are incorporated in general use when talking about certain popular dishes: cilantro (instead of coriander), queso, tacos, quesadillas, enchiladas, tostadas, fajitas, burritos, and guacamole.
These words don't really have an English equivalent and are found in popular restaurants.
New forms of dwelling created new terms "(lot, waterfront)" and types of homes like "log cabin, adobe" in the 18th century; "apartment," in the 19th century; "project, condominium, townhouse, mobile home" in the 20th century; and parts thereof "(driveway, breezeway, backyard)".
Industry and material innovations from the 19th century onwards provide distinctive new words, phrases, and idioms through railroading (see further at rail terminology) and transportation terminology, ranging from types of roads ("dirt roads", "freeways") to infrastructure "(parking lot, overpass, rest area)," to automotive terminology often now standard in English internationally.
Already existing English words—such as "store, shop, lumber" — underwent shifts in meaning; others remained in the U.S. while changing in Britain.
Science, urbanization, and democracy have been important factors in bringing about changes in the written and spoken language of the United States.
From the world of business and finance came new terms ("merger, downsize, bottom line"), from sports and gambling terminology came, specific jargon aside, common everyday American idioms, including many idioms related to baseball.
The names of some American inventions remained largely confined to North America ("elevator, gasoline") as did certain automotive terms ("truck", "trunk").
New foreign loanwords came with 19th and early 20th century European immigration to the U.S.; notably, from Yiddish "(chutzpah, schmooze") and German ("hamburger, wiener").
A large number of English colloquialisms from various periods are American in origin; some have lost their American flavor (from "OK" and "cool" to "nerd" and "24/7)," while others have not "(have a nice day, for sure);" many are now distinctly old-fashioned "(swell, groovy)."
Some English words now in general use, such as "hijacking, disc jockey, boost, bulldoze" and "jazz," originated as American slang.
American English has always shown a marked tendency to use words in different parts of speech and nouns are often used as verbs.
Examples of nouns that are now also verbs are "interview, advocate, vacuum, lobby, pressure, rear-end, transition, feature, profile, hashtag, head, divorce, loan, estimate, X-ray, spearhead, skyrocket, showcase, bad-mouth, vacation, major," and many others.
Compounds coined in the U.S. are for instance "foothill, landslide" (in all senses), ", teenager," brainstorm,, hitchhike, smalltime, and a huge number of others.
Other compound words have been founded based on industrialization and the wave of the automobile: five-passenger car, four-door sedan, two-door sedan, and station-wagon (called an estate car in England).
Some are euphemistic "(human resources, affirmative action, correctional facility)."
Many compound nouns have the verb-and-preposition combination: "stopover, lineup, tryout, spin-off, shootout, holdup, hideout, comeback, makeover," and many more.
Some prepositional and phrasal verbs are in fact of American origin ("win out, hold up, back up/off/down/out, face up to" and many others).
Noun endings such as "- ee (retiree), - ery (bakery), - ster (gangster)" and "- cian (beautician)" are also particularly productive in the U.S. Several verbs ending in "- ize" are of U.S. origin; for example, "fetishize, prioritize, burglarize, accessorize, weatherize," etc.
; and so are some back-formations "(locate, fine-tune, curate, donate, emote, upholster" and "enthuse)."
Among syntactical constructions that arose are "outside of, headed for, meet up with, back of," etc.
Americanisms formed by alteration of some existing words include notably "pesky, phony, rambunctious, buddy, sundae, skeeter, sashay" and "kitty-corner."
Adjectives that arose in the U.S. are, for example, "lengthy, bossy, cute" and "cutesy, punk" (in all senses), "sticky" (of the weather), "through" (as in "finished"), and many colloquial forms such as "peppy" or "wacky".
A number of words and meanings that originated in Middle English or Early Modern English and that have been in everyday use in the United States have since disappeared in most varieties of British English; some of these have cognates in Lowland Scots.
Terms such as "fall" ("autumn"), "faucet" ("tap"), "diaper" ("nappy"; itself unused in the U.S.), "candy" ("sweets"), "skillet", "eyeglasses", and "obligate" are often regarded as Americanisms.
"Fall" for example came to denote the season in 16th century England, a contraction of Middle English expressions like "fall of the leaf" and "fall of the year."
"Gotten" (past participle of "get") is often considered to be largely an Americanism.
Other words and meanings were brought back to Britain from the U.S., especially in the second half of the 20th century; these include "hire" ("to employ"), "I guess" (famously criticized by H. W. Fowler), "baggage", "hit" (a place), and the adverbs "overly" and "presently" ("currently").
Some of these, for example, "monkey wrench" and "wastebasket", originated in 19th century Britain.
The adjectives "mad" meaning "angry," "smart" meaning "intelligent," and "sick" meaning "ill" are also more frequent in American (and Irish) English than British English.
Linguist Bert Vaux created a survey, completed in 2003, polling English speakers across the United States about their specific everyday word choices, hoping to identify regionalisms.
The study found that most Americans prefer the term "sub" for a long sandwich, "soda" (but "pop" in the Great Lakes region and generic "coke" in the South) for a sweet and bubbly soft drink, "you" or "you guys" for the plural of "you" (but "y'all" in the South), "sneakers" for athletic shoes (but often "tennis shoes" outside the Northeast), and "shopping cart" for a cart used for carrying supermarket goods.
American English and British English (BrE) often differ at the levels of phonology, phonetics, vocabulary, and, to a much lesser extent, grammar and orthography.
The first large American dictionary, "An American Dictionary of the English Language", known as Webster's Dictionary, was written by Noah Webster in 1828, codifying several of these spellings.
Differences in grammar are relatively minor, and do not normally affect mutual intelligibility; these include: different use of some auxiliary verbs; formal (rather than notional) agreement with collective nouns; different preferences for the past forms of a few verbs (for example, AmE/BrE: "learned"/"learnt", "burned"/"burnt", "snuck/sneaked", "dove/dived") although the purportedly "British" forms can occasionally be seen in American English writing as well; different prepositions and adverbs in certain contexts (for example, AmE "in school," BrE "at school"); and whether or not a definite article is used, in very few cases (AmE "to the hospital", BrE "to hospital"; contrast, however, AmE "actress Elizabeth Taylor", BrE "the actress Elizabeth Taylor").
Often, these differences are a matter of relative preferences rather than absolute rules; and most are not stable, since the two varieties are constantly influencing each other, and American English is not a standardized set of dialects.
Differences in orthography are also minor.
The main differences are that American English usually uses spellings such as "flavor" for British "flavour", "fiber" for "fibre", "defense" for "defence", "analyze" for "analyse", "license" for "licence", "catalog" for "catalogue" and "traveling" for "travelling".
Noah Webster popularized such spellings in America, but he did not invent most of them.
Other differences are due to the francophile tastes of the 19th century Victorian era Britain (for example they preferred "programme" for "program", "manoeuvre" for "maneuver", "cheque" for "check", etc.).
AmE almost always uses "- ize" in words like "realize".
BrE prefers "- ise", but also uses "- ize" on occasion (see Oxford spelling).
There are a few differences in punctuation rules.
British English is more tolerant of run-on sentences, called "comma splices" in American English, and American English requires that periods and commas be placed inside closing quotation marks even in cases in which British rules would place them outside.
American English also favors the double quotation mark ("like this") over single (' as here ').
Vocabulary differences vary by regions.
For example, autumn is used more commonly in the United Kingdom, whereas fall is more common in American English.
Some other differences include: aerial (United Kingdom) vs. antenna, biscuit (United Kingdom) vs. cookie/cracker, car park (United Kingdom) vs. parking lot, caravan (United Kingdom) vs. trailer, city centre (United Kingdom) vs. downtown, flat (United Kingdom) vs. apartment, fringe (United Kingdom) vs. bangs, and holiday (United Kingdom) vs. vacation.
AmE sometimes favors words that are morphologically more complex, whereas BrE uses clipped forms, such as AmE "transportation" and BrE "transport" or where the British form is a back-formation, such as AmE "burglarize" and BrE "burgle" (from "burglar").
However, while individuals usually use one or the other, both forms will be widely understood and mostly used alongside each other within the two systems.
British English also differs from American English in that "schedule" can be pronounced with either or.
While written American English is largely standardized across the country and spoken American English dialects are highly mutually intelligible, there are still several recognizable regional and ethnic accents and lexical distinctions.
The regional sounds of present-day American English are reportedly engaged in a complex phenomenon of "both convergence and divergence": some accents are homogenizing and levelling, while others are diversifying and deviating further away from one another.
Having been settled longer than the American West Coast, the East Coast has had more time to develop unique accents, and it currently comprises three or four linguistically significant regions, each of which possesses English varieties both different from each other as well as quite internally diverse: New England, the Mid-Atlantic States (including a New York accent as well as a unique Philadelphia–Baltimore accent), and the South.
As of the twentieth century, the middle and eastern Great Lakes area, Chicago being the largest city with these speakers, also ushered in certain unique features, including the fronting of the vowel in the mouth toward and tensing of the vowel wholesale to.
These sound changes have triggered a series of other vowel shifts in the same region, known by linguists as the "Inland North".
The Inland North shares with the Eastern New England dialect (including Boston accents) a backer tongue positioning of the vowel (to) and the vowel (to) in comparison to the rest of the country.
Ranging from northern New England across the Great Lakes to Minnesota, another Northern regional marker is the variable fronting of before, for example appearing four times in the stereotypical Boston shibboleth "Park the car in Harvard Yard".
Several other phenomena serve to distinguish regional U.S. accents.
Boston, Pittsburgh, Upper Midwestern, and Western U.S. accents have fully completed a merger of the vowel with the vowel (and, respectively): a "cot–caught" merger, which is rapidly spreading throughout the whole country.
However, the South, Inland North, and a Northeastern coastal corridor passing through Rhode Island, New York City, Philadelphia, and Baltimore typically preserve an older "cot–caught" distinction.
For that Northeastern corridor, the realization of the vowel is particularly marked, as depicted in humorous spellings, like in "tawk" and "cawfee" ("talk" and "coffee"), which intend to represent it being tense and diphthongal:.
A split of into two separate phonemes, using different "a" pronunciations for example in "gap" versus "gas", further defines New York City as well as Philadelphia–Baltimore accents.
Most Americans preserve all historical sounds, using what is known as a rhotic accent.
The only traditionally "r" - dropping (or non-rhotic) regional U.S. accents are spoken in eastern New England, New York City variably, and some of the former plantation South primarily among older speakers (and consequently African-American Vernacular English variably across the country), though the vowel-consonant cluster found in "bird," "work," "hurt," "learn," etc.
usually retains its "r" pronunciation, even in these non-rhotic American accents.
Non-rhoticity among such speakers is presumed to have arisen from their upper classes' close historical contact with England, imitating London's "r" - dropping, a feature that has continued to gain prestige throughout England from the late 18th century onwards, but which has conversely lost prestige in the U.S. since at least the early 20th century.
Non-rhoticity makes a word like "car" sound like "cah" or "source" like "sauce".
The most prominent and stigmatized regional accents of the country are New York City and Southern accents.
Southern speech, strongest in southern Appalachia and certain areas of Texas, is commonly identified among Americans as a "country" accent, and is defined by the vowel losing its gliding quality:, the initiation event for a complicated Southern vowel shift, including a "Southern drawl" that makes short front vowels into distinct-sounding gliding vowels.
The fronting of the vowels of,,, and tends to also define Southern accents as well as the accents spoken in the "Midland": a vast band of the country that constitutes an intermediate dialect region between the traditional North and South.
Western U.S. accents mostly fall under the General American spectrum.
Below, ten major American English accents are defined by their particular combinations of certain vowel sounds: In 2010, William Labov noted that Great Lakes, Philadelphia, Pittsburgh, and West Coast accents have undergone "vigorous new sound changes" since the mid-nineteenth century onwards, so they "are now more different from each other than they were 50 or 100 years ago", while other accents, like of New York City and Boston, have remained stable in that same time-frame.
However, a General American sound system also has some debated degree of influence nationwide, for example, gradually beginning to oust the regional accent in urban areas of the South and at least some in the Inland North.
Rather than one particular accent, General American is best defined as an umbrella covering any American accent that does not incorporate features associated with some particular region, ethnicity, or socioeconomic group.
Typical General American features include rhoticity, the "father–bother" merger, "Mary–marry–merry" merger, pre-nasal "short" a "" tensing, and other particular vowel sounds.
General American features are embraced most by Americans who are highly educated or in the most formal contexts, and regional accents with the most General American native features include North Midland, Western New England, and Western accents.
Although no longer region-specific, African-American Vernacular English, which remains the native variety of most working - and middle-class African Americans, has a close relationship to Southern dialects and has greatly influenced everyday speech of many Americans, including hip hop culture.
Hispanic and Latino Americans have also developed native-speaker varieties of English.
The best-studied Latino Englishes are Chicano English, spoken in the West and Midwest, and New York Latino English, spoken in the New York metropolitan area.
Additionally, ethnic varieties such as Yeshiva English and "Yinglish" are spoken by some American Orthodox Jews, Cajun Vernacular English by some Cajuns in southern Louisiana, and Pennsylvania Dutch English by some Pennsylvania Dutch in Pennsylvania and the Midwest.
American Indian Englishes have been documented among diverse Indian tribes.
The island state of Hawaii, though primarily English-speaking, is also home to a creole language known commonly as Hawaiian Pidgin, and some Hawaii residents speak English with a Pidgin-influenced accent.
Albert Goodwill Spalding (September 2, 1850 – September 9, 1915) was an American pitcher, manager, and executive in the early years of professional baseball, and the co-founder of A.G. Spalding sporting goods company.
He was born and raised in Byron, Illinois yet graduated from Rockford Central High School in Rockford, Illinois.
He played major league baseball between 1871 and 1878.
Spalding set a trend when he started wearing a baseball glove.
After his retirement as a player, Spalding remained active with the Chicago White Stockings as president and part-owner.
In the 1880 s, he took players on the first world tour of baseball.
With William Hulbert, Spalding organized the National League.
He later called for the commission that investigated the origins of baseball and credited Abner Doubleday with creating the game.
He also wrote the first set of official baseball rules.
Having played baseball throughout his youth, Spalding first played competitively with the Rockford Pioneers, a youth team, which he joined in 1865.
After pitching his team to a 26 – 2 victory over a local men's amateur team (the Mercantiles), he was approached at the age of 15 by another squad, the Cleveland Forest Citys, for whom he played for two years.
In the autumn of 1867 he accepted a $ 40 per week contract ($ in today's dollars), nominally as a clerk, but really to play professionally for the Chicago Excelsiors, not an uncommon arrangement used to circumvent the rules of the time, which forbade the hiring of professional players.
Following the formation of baseball's first professional organization, the National Association of Professional Base Ball Players (which became known as the National Association, the Association, or NA) in 1871, Spalding joined the Boston Red Stockings (precursor club to the modern Atlanta Braves) and was highly successful; winning 206 games (and losing only 53) as a pitcher and batting.
323 as a hitter.
William Hulbert, principal owner of the Chicago White Stockings, did not like the loose organization of the National Association and the gambling element that influenced it, so he decided to create a new organization, which he dubbed the National League of Baseball Clubs.
To aid him in this venture, Hulbert enlisted the help of Spalding.
Playing to the pitcher's desire to return to his Midwestern roots and challenging Spalding's integrity, Hulbert convinced Spalding to sign a contract to play for the White Stockings (now known as the Chicago Cubs) in 1876.
Spalding then coaxed teammates Deacon White, Ross Barnes and Cal McVey, as well as Philadelphia Athletics players Cap Anson and Bob Addy, to sign with Chicago.
This was all done under complete secrecy during the playing season because players were all free agents in those days and they did not want their current club and especially the fans to know they were leaving to play elsewhere the next year.
News of the signings by the Boston and Philadelphia players leaked to the press before the season ended and all of them faced verbal abuse and physical threats from the fans of those cities.
He was "the premier pitcher of the 1870 s", leading the league in victories for each of his six full seasons as a professional.
During each of those years he was his team's only pitcher.
In 1876, Spalding won 47 games as the prime pitcher for the White Stockings and led them to win the first-ever National League pennant by a wide margin.
In 1877, Spalding began to use a glove to protect his catching hand.
People had used gloves previously, but they were not popular, and Spalding himself was skeptical of wearing one at first.
However, once he began donning gloves, he influenced other players to do so.
Spalding retired from playing baseball in 1878 at the age of 27, although he continued as president and part owner of the White Stockings and a major influence on the National League.
Spalding's.
796 career winning percentage (from an era when teams played about once or twice a week) is the highest ever by a baseball pitcher, far exceeding the second-best.
690.
In the months after signing for Chicago, Hulbert and Spalding organized the National League by enlisting the two major teams in the East and the four other top teams in what was then considered to be the West, also known as the jungle.
Joining Chicago initially were the leading teams from Cincinnati, Louisville, and St. Louis.
The owners of these western clubs accompanied Hulbert and Spalding to New York where they secretly met with owners from New York City, Philadelphia, Hartford, and Boston.
Each signed the league's constitution, and the National League was officially born.
"Spalding was thus involved in the transformation of baseball from a game of gentlemen athletes into a business and a professional sport."
Although the National Association held on for a few more seasons, it was no longer recognized as the premier organization for professional baseball.
Gradually, it faded out of existence and was replaced by myriad minor leagues and associations around the country.
In 1886, with Spalding as President of the franchise, the Chicago White Stockings (today's Chicago Cubs), began holding spring training in Hot Springs, Arkansas, which subsequently has been called the "birthplace" of spring training baseball.
The location and the training concept was the brainchild of Spalding and his player/manager Cap Anson, who saw that the city and the natural springs created positives for their players.
They first played in an area called the Hot Springs Baseball Grounds.
Many other teams followed the concept and began training in Hot Springs and other locations.
In 1905, after Henry Chadwick wrote an article saying that baseball grew from the British sports of cricket and rounders, Spalding called for a commission to find out the real source of baseball.
The commission called for citizens who knew anything about the founding of baseball to send in letters.
After three years of searching, on December 30, 1907, Spalding received a letter that (erroneously) declared baseball to be the invention of Abner Doubleday.
The commission, was biased, as Spalding would not appoint anyone to the commission if they believed the sport was somewhat related to rounders or cricket.
Just before the commission issued its findings, in a letter to sportswriter Tim Murnane, Spalding noted, "Our good old American game of baseball must have an American Dad."
The project, later called the Mills Commission, concluded that "Base Ball had its origins in the United States" and "the first scheme for playing baseball, according to the best evidence available to date, was devised by Abner Doubleday at Cooperstown, N.Y., in 1839."
Receiving the archives of Henry Chadwick in 1908, Spalding combined these records with his own memories (and biases) to write "America's National Game" (published 1911) which, despite its flaws, was probably the first scholarly account of the history of baseball.
In 1874 while Spalding was playing and organizing the league, Spalding and his brother Walter began a sporting goods store in Chicago, which grew rapidly (14 stores by 1901) and expanded into a manufacturer and distributor of all kinds of sporting equipment.
The company became "synonymous with sporting goods" and is still a going concern.
Spalding published the first official rules guide for baseball.
In it he stated that only Spalding balls could be used (previously, the quality of the balls used had been subpar).
Spalding also founded the "Baseball Guide", which at the time was the most widely read baseball publication.
In 1888 – 1889, Spalding took a group of major league players around the world to promote baseball and Spalding sporting goods.
This was the first-ever world baseball tour.
Playing across the western U.S., the tour made stops in Hawaii (although no game was played), New Zealand, Australia, Ceylon, Egypt, Italy, France, and England.
The tour returned to grand receptions in New York, Philadelphia, and Chicago.
The tour included future Hall of Famers Cap Anson and John Montgomery Ward.
While the players were on the tour, the National League instituted new rules regarding player pay that led to a revolt of players, led by Ward, who started the Players' League the following season (1890).
The league lasted one year, partially due to the anti-competitive tactics of Spalding to limit its success.
The tour and formation of the Player's League is depicted in the 2015 movie "Deadball."
In 1900 Spalding was appointed by President McKinley as the USA's Commissioner at that year's Summer Olympic Games.
Spalding had been a prominent member of the Theosophical Society under William Quan Judge.
In 1900, Spalding moved to San Diego with his newly acquired second wife, Elizabeth and became a prominent member and supporter of the Theosophical community Lomaland, which was being developed on Point Loma by Katherine Tingley.
He built an estate in the Sunset Cliffs area of Point Loma where he lived with Elizabeth for the rest of his life.
The Spaldings raised race horses and collected Chinese fine furniture and art.
The Spaldings had an extensive library which included many volumes on Theosophy, art, and literature.
In 1907 – 09 he was the driving force behind the development of a paved road, known as the "Point Loma boulevard", from downtown San Diego to Point Loma and Ocean Beach; the road also provided good access to Lomaland.
It later provided the basis for California State Route 209.
He proposed the project, supervised it on behalf of the city, and paid a portion of the cost out of his own pocket.
He joined with George Marston and other civic-minded businessmen to purchase the site of the original Presidio of San Diego, which they developed as a historic park and eventually donated to the city of San Diego.
He ran unsuccessfully for the United States Senate in 1910 as a Republican, but lost to eventual winner John D. Works by a vote of 92 to 21 in the California legislature.
He helped to organize the 1915 Panama-California Exposition, serving as second vice-president.
He died of a stroke on September 9, 1915, in San Diego, one week after his 66th birthday.
His ashes were scattered at his request.
He was elected to the Baseball Hall of Fame by the Veterans Committee in 1939, as one of the first inductees from the 19th century at that summer's opening ceremonies.
Organizational genius of baseball's pioneer days.
Star pitcher of Forest City Club in late 1860 s, 4-year champion Bostons 1871 – 75 and manager-pitcher of champion Chicagos in National League's first year.
Chicago president for 10 years.
His nephew, also named Albert Spalding, was a renowned violinist.
The Africa Alphabet (also International African Alphabet or IAI alphabet) was developed by the International Institute of African Languages and Cultures in 1928, with the help of some Africans led by Diedrich Hermann Westermann, who served as director of the organization from 1926 until 1939.
Meanwhile, the aim of the International Institute of African Languages and Cultures, later known as International African Institute (IAI), was to enable people to write all the African languages for practical and scientific purposes without the need of diacritics.
It is based on the International Phonetic Alphabet with a few differences, such as "j" and "y", which instead have the same (consonant) sound values as in English.
This alphabet has influenced development of orthographies of many African languages (serving "as the basis for the transcription" of about 60, by one count), but not all, and discussions of harmonization of systems of transcription that led to, among other things, adoption of the African reference alphabet.
The African Alphabet was used, with the International Phonetic Alphabet, as a basis for the World Orthography.
+ Africa Alphabet
Acquire is a multi-player mergers and acquisitions themed board game.
It is played with tiles representing hotels that are arranged on the board, play money and stock certificates.
The object of the game is to earn the most money by developing and merging hotel chains.
When a chain in which a player owns stock is acquired by a larger chain, players earn money based on the size of the acquired chain.
At the end of the game, all players liquidate their stock in order to determine which player has the most money.
It was one of the most popular games in the 1960 s 3 M bookshelf game series, and the only one still published in the United States.
The following components are included in all versions: Acquire started life as the Milton Bradley gambling-themed board game Lotto played in childhood by Sid Sackson, who went on to become a game designer.
He reworked the game into a wargame he called "Lotto War".
Sackson (along with Alex Randolph) was commissioned by 3 M to start a new games division in 1962.
When he submitted the game to 3 M in 1963, he called the game "Vacation".
3 M suggested the name change to Acquire, and Sackson agreed.
The game was test marketed in several U.S. cities in 1963, and production began in 1964 as a part of the bookshelf games series.
The 3 M game division was sold to Avalon Hill in 1976 and became part of their bookcase game series.
Avalon Hill made "Computer Acquire" for the PET, Apple II and TRS-80 in 1980.
The Avalon brand became part of Hasbro in 1998.
Hasbro slightly reworked and reissued the game in 2000, but thereafter discontinued it.
In the mid-2000 s, the game was transferred to a Hasbro subsidiary Wizards of the Coast.
Wizards celebrated "" 50 years of Avalon Hill Games "" with the release of the 2008 edition (though the game was not yet 50 years old).
In 2016, the game was transferred back to the Hasbro games division and republished in Nov. 2016 under the Avalon label.
In most versions, the theme of the game is investing in hotel chains.
In the 1990 s Hasbro edition, the hotel chains were replaced by fictitious corporations, though the actual gameplay was unchanged.
In the current Avalon edition, the companies are once again hotel chains.
The components of the game have varied over the years.
In particular, the tiles have been made from wood, plastic, and cardboard in various editions of the game.
In the 2008 version, the tiles were cardboard.
In the 2016 version, the tiles are plastic, but the board size was reduced, from 9x12 to 10x10.
A short setup precedes play, wherein each player receives play cash and a small random set of playing tiles and becomes the founder of a nascent hotel chain by drawing and placing a tile representing a hotel on the board.
Tiles are ordered, and correspond to spaces on the board.
Position of the starting tiles determines order of play.
Play consists of placing a tile on the board and optionally buying stock.
The placed tile may found a new hotel chain, grow an existing one or merge two or more chains.
Chains are sets of edge-wise adjacent tiles.
Founders receive a share of stock in new chains.
A chain can become "safe", immune to acquisition, by attaining a specified size.
Following placement of a tile, the player may then buy a limited number of shares of stock in existing chains.
Shares have a market value determined by the size and stature of the hotel chain.
At the end of his or her turn, the player receives a new tile to replace the one played.
When mergers occur, the smaller chain becomes defunct, and its tiles are then part of the acquiring chain.
The two largest shareholders in the acquired chain receive cash bonuses; players may sell their shares in the defunct chain, trade them in for shares of the acquiring chain, or keep them.
Mergers between 3 or more chains are handled in order from larger to smaller.
A player during his turn may declare the game at an end if the largest chain exceeds a specified size (about 40 % of the board), or all chains on the board are too large to be acquired.
When the game ends, shareholder bonuses are paid to the two largest shareholders of each chain, and players cash out their shares at market price (shares in any defunct chains are worthless).
The player with the most money wins.
An interesting and optional aspect of gameplay is whether numbers of players' shares is public or private information.
This is negotiated before the game starts.
Keeping this information private can greatly extend the game: when players are less certain of their status, they are less willing to end the game.
Acquire is for 2 – 6 players, and takes about an hour and a half to play.
In the December 1993 edition of "Dragon" (Issue 200), Allen Varney advised readers to ignore the hotel theme: "Supposedly a game of hotel acquisitions and mergers, this is actually a superb abstract game of strategy and capital."
Varney called the game "An early masterpiece from [Sid] Sackson, game historian and one of the great designers of our time."
The game was short-listed for the first Spiel des Jahres board game awards in 1979.
"GAMES" magazine has inducted "Acquire" into their buyers' guide Hall of Fame.
The magazine's stated criteria for the Hall of Fame encompasses "games that have met or exceeded the highest standards of quality and play value and have been continuously in production for at least 10 years; i.e., classics."
It was inducted into the Academy of Adventure Gaming Arts & Design's Hall of Fame, along with Sackson, in 2011.
Acquire is one of the Mind Sports Olympiad games.
Australian English (AuE; en-AU) is the set of varieties of the English language native to Australia.
Although English has no official status in the Constitution, Australian English is the country's national and "de facto" official language as it is the first language of the majority of the population.
Australian English began to diverge from British English after the First Settlers, who set up the Colony of New South Wales, arrived in 1788.
By 1820, their speech was recognised as being different from British English.
Australian English arose from the intermingling of early settlers, who were from a great variety of mutually intelligible dialectal regions of Great Britain and Ireland, and quickly developed into a distinct variety of English which differs considerably from most other varieties of English in vocabulary, accent, pronunciation, register, grammar and spelling.
The earliest form of Australian English was spoken by the children of the colonists in early New South Wales.
This first generation of native-born children created a new dialect that was to become the language of the nation.
The Australian-born children in the new colony were exposed to a wide range of dialects from all over the British Isles, in particular from Ireland and South East England.
The native-born children in the colony created the new dialect from the speech they heard around them, and with it expressed peer solidarity.
Even when new settlers arrived, this new dialect was strong enough to blunt other patterns of speech.
A quarter of the convicts were Irish.
Many had been arrested in Ireland, and some in Great Britain.
Many, if not most, of the Irish spoke Irish and either no English at all, or spoke it poorly and rarely.
There were other significant populations of convicts from non-English speaking parts of Britain, such as the Scottish Highlands, Wales and parts of Cornwall.
Records from the early 19th century show this distinct dialect in the colonies after the first settlement in 1788.
Peter Miller Cunningham's 1827 book "Two Years in New South Wales", described the distinctive accent and vocabulary of the native-born colonists, that differed from that of their parents and with a strong London influence.
Anthony Burgess writes that "Australian English may be thought of as a kind of fossilised Cockney of the Dickensian era."
The first of the Australian gold rushes, in the 1850 s, began a large wave of immigration, during which about two per cent of the population of the United Kingdom emigrated to the colonies of New South Wales and Victoria.
According to linguist Bruce Moore, "the major input of the various sounds that went into constructing the Australian accent was from south-east England".
Some elements of Aboriginal languages have been adopted by Australian English—mainly as names for places, flora and fauna (for example dingo) and local culture.
Many such are localised, and do not form part of general Australian use, while others, such as "kangaroo", "boomerang", "budgerigar", "wallaby" and so on have become international.
Other examples are "cooee" and "hard yakka".
The former is used as a high-pitched call, for attracting attention, (pronounced) which travels long distances.
"Cooee" is also a notional distance: "if he's within cooee, we'll spot him".
"Hard yakka" means "hard work" and is derived from "yakka", from the Jagera/Yagara language once spoken in the Brisbane region.
Also of Aboriginal origin is the word "bung", from the Sydney pidgin English (and ultimately from the Sydney Aboriginal language), meaning "dead", with some extension to "broken" or "useless".
Many towns or suburbs of Australia have also been influenced or named after Aboriginal words.
The best-known example is the capital, Canberra, named after a local language word meaning "meeting place".
Among the changes starting in the 19th century were the introduction of words, spellings, terms and usages from North American English.
The words imported included some later considered to be typically Australian, such as "bushwhacker" and "squatter".
This American influence continued with the popularity of American films and the influx of American military personnel in World War II; seen in the enduring persistence of such terms as "okay", "you guys" and "gee".
The primary way in which Australian English is distinctive from other varieties of English is through its unique pronunciation.
It shares most similarity with other Southern Hemisphere accents, in particular New Zealand English.
Like most dialects of English it is distinguished primarily by its vowel phonology.
The vowels of Australian English can be divided according to length.
The long vowels, which include monophthongs and diphthongs, mostly correspond to the tense vowels used in analyses of Received Pronunciation (RP) as well as its centring diphthongs.
The short vowels, consisting only of monophthongs, correspond to the RP lax vowels.
There exist pairs of long and short vowels with overlapping vowel quality giving Australian English phonemic length distinction, which is unusual amongst the various dialects of English, though not unknown elsewhere, such as in regional south-eastern dialects of the UK and eastern seaboard dialects in the US.
As with New Zealand English, the weak-vowel merger is complete in Australian English: unstressed is merged into (schwa), unless it is followed by a velar consonant.
"foot", "hood", "chook" "goose", "boo", "who ’d" "near," beard "," hear "kit", "bid", "hid", "fleece", "bead", "heat" "mouth", "bowed", "how ’d" ɛ "dress", "led", "head" "square", "bared", "haired" "goat", "bode", "hoed" "comma, about", "winter" "nurse", "bird", "heard" "face", "bait", "made" "trap", "lad", "had" æː bad, sad, mad "price", "bite", "hide" "strut", "bud", "hud" ɐː "start", "palm", "bath" "choice", "boy, oil" "lot", "cloth", "hot" oː "thought", "north", "force" There is little variation in the sets of consonants used in different English dialects but there are variations in how these consonants are used.
Australian English is no exception.
+ Consonant phonemes of Australian English Australian English is non-rhotic; that is, the sound does not appear at the end of a syllable or immediately before a consonant.
However, a linking can occur when a word that has a final < r > in the spelling comes before another word that starts with a vowel.
An intrusive may similarly be inserted before a vowel in words that do not have < r > in the spelling in certain environments, namely after the long vowel and after word final.
This can be heard in "law-r-and order," where an intrusive R is voiced after the W and before the A. There is some degree of allophonic variation in the alveolar stops.
As with North American English, Intervocalic alveolar flapping is a feature of Australian English: prevocalic and surface as the alveolar tap after sonorants other than as well as at the end of a word or morpheme before any vowel in the same breath group.
The wine–whine merger is complete in Australian English.
"Yod" - dropping occurs after, and,.
Other cases of and, along with and, have coalesced to,, and respectively for many speakers.
is generally retained in other consonant clusters.
Differences in stress, weak forms and standard pronunciation of isolated words occur between Australian English and other forms of English, which while noticeable do not impair intelligibility.
The affixes "- ary", "- ery", "- ory", "- bury", "- berry" and "- mony" (seen in words such as "necessary, mulberry" and "matrimony") can be pronounced either with a full vowel or a schwa.
Although some words like "necessary" are almost universally pronounced with the full vowel, older generations of Australians are relatively likely to pronounce these affixes with a schwa while younger generations are relatively likely to use a full vowel.
In addition, miscellaneous pronunciation differences exist when compared with other varieties of English in relation to seemingly random words.
For example, as with American English, the vowel in "yoghurt" is pronounced as ("long o") rather than ("short o"); "vitamin", "migraine" and "privacy" are pronounced with (as in "mine") rather than, and respectively; "paedophile" is pronounced with/ɛ/(as in "red") rather than; the prefix "homo -" (as in "homosexual" or "homophobic") is pronounced with a ("long o") rather than ("short o"); "urinal" is pronounced with schwa rather than ("long i"); and "harass" and "harassment" are pronounced with the stress on the second, rather than the first syllable.
As with British English, "advertisement" is pronounced with; "tomato" and "vase" are pronounced with (as in "father") instead of; "zebra" is pronounced with/ɛ/(as in "red") rather than; "basil" is pronounced with ("short a") rather than ("long a"); and "buoy" is pronounced as (as in "boy") rather than.
Examples of miscellaneous pronunciations which contrast with both standard American and British usages are "data", which is pronounced with ("dah") instead of ("day"); "garage", pronounced instead of British or American (although the American pronunciation is also used); and "maroon" (colour), pronounced with ("own") as opposed to ("oon").
+ Variation in Australian closing diphthongs Academic research has shown that the most notable variation within Australian English is largely sociocultural.
This is mostly evident in phonology, which is divided into three sociocultural varieties: "broad", "general" and "cultivated".
A limited range of word choices is strongly regional in nature.
Consequently, the geographical background of individuals can be inferred, if they use words that are peculiar to particular Australian states or territories and, in some cases, even smaller regions.
In addition, some Australians speak creole languages derived from Australian English, such as Australian Kriol, Torres Strait Creole and Norfuk.
The "broad", "general" and "cultivated" accents form a continuum that reflects minute variations in the Australian accent.
They can reflect the social class, education and urban or rural background of speakers, though such indicators are not always reliable.
According to linguists, the general Australian variant emerged some time before 1900.
Recent generations have seen a comparatively smaller proportion of the population speaking with the broad variant, along with the near extinction of the cultivated Australian accent.
The growth and dominance of general Australian accents perhaps reflects its prominence on radio and television during the late 20th century.
Australian Aboriginal English is made up of a range of forms which developed differently in different parts of Australia, and are said to vary along a continuum, from forms close to Standard Australian English to more non-standard forms.
There are distinctive features of accent, grammar, words and meanings, as well as language use.
The ethnocultural dialects are diverse accents in Australian English that are spoken by the minority groups, which are of non-English speaking background.
A massive immigration from Asia has made a large increase in diversity and the will for people to show their cultural identity within the Australian context.
These ethnocultural varieties contain features of General Australian English as adopted by the children of immigrants blended with some non-English language features, such as Afro-Asiatic languages and languages of Asia.
Although Australian English is relatively homogeneous, there are some regional variations.
The dialects of English spoken in South Australia, Western Australia, New South Wales, Victoria, Tasmania, Queensland and the Torres Strait Islands differ slightly in vocabulary and phonology.
Most regional differences are in word usage.
Swimming clothes are known as "cossies" or "swimmers" in New South Wales, "togs" in Queensland, and "bathers" in Victoria, Tasmania, Western Australia and South Australia.
What Queensland and New South Wales call a "stroller" is usually called a "pram" in Victoria, Western Australia, South Australia and Tasmania.
Preference for some synonymous words also differ between states.
"Garbage" (i.e., garbage bin, garbage truck) dominates over "rubbish" in New South Wales and Queensland, while "rubbish" is more popular in Victoria, Tasmania, Western Australia and South Australia.
The word "footy" generally refers to the most popular football code in an area; that is, rugby league or rugby union depending on the local area, in most of New South Wales and Queensland, and Australian rules football elsewhere.
Beer glasses are also named differently in different states.
Distinctive grammatical patterns exist such as the use of the interrogative "eh" (also spelled "ay" or "aye"), which is particularly associated with Queensland.
Tasmanian English has a unique stress on the English syllable ' schwa ', denoted in IPA as [ə] (the e sound in ' herd '), in Tasmanian English it is typically stressed to [əː] or [ˈə].
There are some notable regional variations in the pronunciations of certain words.
The trap‑bath split is more complete in South Australia, which had later direct settlement from the British Isles than other parts of the country, which were settled while the trap-bath split was more substantially incomplete.
Words such as "dance", "advance", "plant", "graph", "example" and "answer" are pronounced with (as in "father") far more frequently in South Australia while elsewhere in Australia the older (as in "mad") is more common.
"L" - vocalisation is also more common in South Australia than other states.
In Western Australian and Queensland English, the vowels in "near" and "square" are typically realised as centring diphthongs ("nee-ya"), whereas in the other states they may also be realised as monophthongs.
A feature common in Victorian English is salary–celery merger, whereby a Victorian pronunciation of "Ellen" may sound like "Alan" and Victoria's capital city "Melbourne" may sound like "Malbourne" to speakers from other states.
There is also regional variation in before (as in "school" and "pool").
Australian English has many words and idioms which are unique to the dialect and have been written on extensively, with the "Macquarie Dictionary 4th Edition" incorporating numerous Australian terms.
Internationally well-known examples of Australian terminology include "outback", meaning a remote, sparsely populated area, "the bush", meaning either a native forest or a country area in general, and "g'day", a greeting.
"Dinkum", or "fair dinkum" means "true" or "is that true?"
, among other things, depending on context and inflection.
The derivative "dinky-di" means "true" or devoted: a "dinky-di Aussie" is a "true Australian".
Australian poetry, such as "The Man from Snowy River", as well as folk songs such as "Waltzing Matilda", contain many historical Australian words and phrases that are understood by Australians even though some are not in common usage today.
Australian English, in common with several British English dialects (for example, Cockney, Scouse, Glaswegian and Geordie), uses the word "mate".
Several words used by Australians were at one time used in the United Kingdom but have since fallen out of usage or changed in meaning there.
For example, "creek" in Australia, as in North America, means a stream or small river, whereas in the UK it means a small watercourse flowing into the sea; "paddock" in Australia means field, whereas in the UK it means a small enclosure for livestock; "bush" or "scrub" in Australia, as in North America, means a wooded area, whereas in England they are commonly used only in proper names (such as Shepherd's Bush and Wormwood Scrubs).
Litotes, such as "not bad", "not much" and "you're not wrong", are also used, as are diminutives, which are commonly used and are often used to indicate familiarity.
Some common examples are "arvo" (afternoon), "barbie" (barbecue), "smoko" (cigarette break), "Aussie" (Australian), "Straya" (Australia) and "pressie" (present/gift).
This may also be done with people's names to create nicknames (other English speaking countries create similar diminutives).
For example, "Gazza" from Gary, or "Smitty" from John Smith.
The use of the suffix "- o" originates in Irish Gaelic (Irish "ó"), which is both a postclitic and a suffix with much the same meaning as in Australian English.
In informal speech, incomplete comparisons are sometimes used, such as "sweet as" (as in "That car is sweet as."
).
"Full", "fully" or "heaps" may precede a word to act as an intensifier (as in "The waves at the beach were heaps good."
).
This was more common in regional Australia and South Australia but has been in common usage in urban Australia for decades.
The suffix "- ly" is sometimes omitted in broader Australian English.
For instance, "really good" can become "real good".
Australia's switch to the metric system in the 1970 s changed most of the country's vocabulary of measurement from imperial to metric measures.
Since the switch to metric, heights of individuals are listed in centimetres on official documents such as a driver's licence but older people understand and may speak of feet and inches.
Where British and American English vocabulary differs, in different circumstances Australian English favours: There are also terms shared by British and American English but not commonly found in Australian English, which include: In addition to the large number of uniquely Australian idioms in common use, there are instances of idioms taking different forms in Australian English than in other varieties, for instance: There also exist words in Australian English which are ascribed different meanings from those ascribed in other varieties of English, for instance: A non-exhaustive selection of British English terms not commonly used in Australian English include: A non-exhaustive list of American English terms not commonly found in Australian English include: As with American English, but unlike British English, collective nouns are almost always singular in construction, e.g., "the government was unable to decide" as opposed to "the government were unable to decide".
"Shan't", the negation of "should" as in "I shan't be happy if ..."
, the use of "haven't any" instead of "haven't got any" and the use of "don't let's" in place of "let's not", common in upper-register British English, are almost never encountered in Australian (or North American) English.
"River" generally follows the name of the river in question as in North America, i.e., "Darling River", rather than the British convention of coming before the name, e.g., "River Thames".
In South Australia however, the British convention applies—for example, the "River Murray" or the "River Torrens".
As with American English, "on the weekend" and "studied medicine" are used rather than the British "at the weekend" and "read medicine".
Similarly, "around" is more commonly used in constructions such as "running around", "stomping around" or "messing around" in contrast with the British convention of using "about".
In common with British English, the past tense and past participles of the verbs "learn", "spell" and "smell" are often irregular ("learnt", "spelt", "smelt").
Similarly, in Australian usage, the "to" in "I'll write to you" is retained, as opposed to US usage where it may be dropped.
While prepositions before days may be omitted in American English, i.e., "She resigned Thursday", they are retained in Australian English, as in British English: "She resigned on Thursday".
Ranges of dates use "to", i.e., "Monday to Friday", as with British English, rather than "Monday through Friday" in American English.
When saying or writing out numbers, "and" is inserted before the tens and units, i.e., "one hundred and sixty-two", as with British practice.
However Australians, like Americans, are more likely to pronounce numbers such as 1,200 as "twelve hundred", rather than "one thousand two hundred".
When referring to time, Australians will refer to 10:30 as "half past ten" and do not use the British "half ten".
Similarly, "a quarter to ten" is used for 9:45 in favour of the American "(a) quarter of ten".
As in most English-speaking countries, there is no official governmental regulator or overseer of normative spelling and grammar.
The "Macquarie Dictionary" is used by some universities and some other organisations as a standard for Australian English spelling.
The "Style Manual: For Authors, Editors and Printers", the "Cambridge Guide to Australian English Usage" and the "Australian Guide to Legal Citation" are prominent style guides.
Australian spelling is closer to British than American spelling.
As with British spelling, the "u" is retained in words such as "colour", "honour", "labour" and "favour".
While the "Macquarie Dictionary" lists the "- our" ending and follows it with the "- or" ending as an acceptable variant, the latter is rarely found in actual use today.
Australian print media, including digital media, today strongly favour "- our" endings.
A notable exception to this rule is the Australian Labor Party, which officially adopted the "- or" spelling in its name in 1912, after a period where both spellings seem to have been used indiscriminately.
Consistent with British spellings, "- re", rather than "- er", is the only listed variant in Australian dictionaries in words such as "theatre", "centre" and "manoeuvre".
Unlike British English, which is split between "- ise" and "- ize" in words such as "organise" and "realise", with "- ize" favoured by the Oxford English Dictionary and "- ise" listed as a variant, "- ize" is rare in Australian English and designated as a variant by the "Macquarie Dictionary".
"Ae" and "oe" are often maintained in words such as "manoeuvre" and "paedophilia" (excepting those listed below); however, the "Macquarie Dictionary" lists forms with "e" (e.g., pedophilia) as acceptable variants and notes a tendency within Australian English towards using only "e".
Individual words where the preferred spelling is listed by the "Macquarie Dictionary" as being different from the British spellings include "program" (in all contexts) as opposed to "programme", "inquire" and derivatives "inquired", "inquiry", etc.
as opposed to "enquire" and derivatives, "analog" (as opposed to digital) as opposed to "analogue", "livable" as opposed to "liveable", "guerilla" as opposed to "guerrilla", "yoghurt" as opposed to "yogurt", "verandah" as opposed to "veranda", "burqa" as opposed to "burka", "pastie" (food) as opposed to "pasty".
Unspaced prepositions such as "onto", "anytime", "alright" and "anymore" are also listed as being as acceptable as their spaced counterparts.
Different spellings have existed throughout Australia's history.
A pamphlet entitled "The So-Called" American Spelling "", published in Sydney some time in the 19th century, argued that "there is no valid etymological reason for the preservation of the" u "in such words as" honor "," labor ", etc."
The pamphlet also claimed that "the tendency of people in Australasia is to excise the u, and one of the Sydney morning papers habitually does this, while the other generally follows the older form."
What are today regarded as American spellings were popular in Australia throughout the late 19th and early 20th centuries, with the Victorian Department of Education endorsing them into the 1970 s and "The Age" newspaper until the 1990 s.
This influence can be seen in the spelling of the Australian Labor Party and also in some place names such as Victor Harbor.
The "Concise Oxford English Dictionary" has been attributed with re-establishing the dominance of the British spellings in the 1920 s and 1930 s.
For a short time during the late 20th century, Harry Lindgren's 1969 spelling reform proposal ("Spelling Reform 1" or "SR1") gained some support in Australia: in 1975, the Australian Teachers' Federation adopted SR1 as a policy.
SR1 calls for the short sound (as in "bet") to be spelt with E (for example "friend → frend, head → hed").
Both single and double quotation marks are in use (with double quotation marks being far more common in print media), with logical (as opposed to typesetter's) punctuation.
Spaced and unspaced em-dashes remain in mainstream use, as with American and Canadian English.
The DD/MM/YYYY date format is followed and the 12-hour clock is generally used in everyday life (as opposed to service, police, and airline applications).
There are two major English language keyboard layouts, the United States layout and the United Kingdom layout.
Keyboards and keyboard software for the Australian market universally use the United States keyboard layout, which lacks pound sterling, Euro currency and negation symbols.
Punctuation symbols are also placed differently from British keyboards.
American Airlines Flight 77 was a scheduled American Airlines domestic transcontinental passenger flight from Washington Dulles International Airport in Dulles, Virginia, to Los Angeles International Airport in Los Angeles, California.
The Boeing 757 - 223 aircraft serving the flight was hijacked by five Saudi men affiliated with al-Qaeda on September 11, 2001, as part of the September 11 attacks.
They deliberately crashed the plane into the Pentagon in Arlington County, Virginia, near Washington, D.C., killing all 64 people on board, including the five hijackers and six crew, as well as 125 people in the building.
Less than 35 minutes into the flight, the hijackers stormed the cockpit and forced the passengers, crew, and pilots to the rear of the aircraft.
Hani Hanjour, one of the hijackers who was trained as a pilot, assumed control of the flight.
Unknown to the hijackers, passengers aboard made telephone calls to friends and family and relayed information on the hijacking.
The hijackers crashed the aircraft into the western side of the Pentagon at 09:37 EDT.
Many people witnessed the crash, and news sources began reporting on the incident within minutes.
The impact severely damaged an area of the Pentagon and caused a large fire.
A portion of the building collapsed; firefighters spent days working to fully extinguish the blaze.
The damaged sections of the Pentagon were rebuilt in 2002, with occupants moving back into the completed areas that August.
The 184 victims of the attack are memorialized in the Pentagon Memorial adjacent to the crash site.
The park contains a bench for each of the victims, arranged according to their year of birth, ranging from 1930 to 1998.
The hijackers on American Airlines Flight 77 were led by Hani Hanjour, who piloted the aircraft into the Pentagon.
Hanjour first came to the United States in 1990.
Hanjour trained at the CRM Airline Training Center in Scottsdale, Arizona, earning his FAA commercial pilot's certificate in April 1999.
He had wanted to be a commercial pilot for the Saudi national airline but was rejected when he applied to the civil aviation school in Jeddah in 1999.
Hanjour's brother later explained that, frustrated at not finding a job, Hanjour "increasingly turned his attention toward religious texts and cassette tapes of militant Islamic preachers".
Hanjour returned to Saudi Arabia after being certified as a pilot, but left again in late 1999, telling his family that he was going to the United Arab Emirates to work for an airline.
Hanjour likely went to Afghanistan, where Al-Qaeda recruits were screened for special skills they might have.
Already having selected the Hamburg cell members, Al Qaeda leaders selected Hanjour to lead the fourth team of hijackers.
Alec Station, the CIA's unit dedicated to tracking Osama bin Laden, had discovered that two of the other hijackers, al-Hazmi and al-Mihdhar, had multiple-entry visas to the United States well before 9/11.
Two FBI agents inside the unit tried to alert FBI headquarters, but CIA officers rebuffed them.
In December 2000, Hanjour arrived in San Diego, joining "muscle" hijackers Nawaf al-Hazmi and Khalid al-Mihdhar, who had been there since January 2000.
Soon after arriving, Hanjour and Hazmi left for Mesa, Arizona, where Hanjour began refresher training at Arizona Aviation.
In April 2001, they relocated to Falls Church, Virginia, where they awaited the arrival of the remaining "muscle" hijackers.
One of these men, Majed Moqed, arrived on May 2, 2001, with Flight 175 hijacker Ahmed al-Ghamdi from Dubai at Dulles International Airport.
They moved into an apartment with Hazmi and Hanjour.
On May 21, 2001, Hanjour rented a room in Paterson, New Jersey, where he stayed with other hijackers through the end of August.
The last Flight 77 "muscle" hijacker, Salem al-Hazmi, arrived on June 29, 2001, with Abdulaziz al-Omari (a hijacker of Flight 11) at John F. Kennedy International Airport from the United Arab Emirates.
They stayed with Hanjour.
Hanjour received ground instruction and did practice flights at Air Fleet Training Systems in Teterboro, New Jersey, and at Caldwell Flight Academy in Fairfield, New Jersey.
Hanjour moved out of the room in Paterson and arrived at the Valencia Motel in Laurel, Maryland, on September 2, 2001.
While in Maryland, Hanjour and fellow hijackers trained at Gold's Gym in Greenbelt.
On September 10, he completed a certification flight, using a terrain recognition system for navigation, at Congressional Air Charters in Gaithersburg, Maryland.
On September 10, Nawaf al-Hazmi—accompanied by other hijackers—checked into the Marriott in Herndon, Virginia, near Dulles Airport.
According to a U.S. State Department cable leaked in the WikiLeaks dump in February 2010, the FBI has investigated another suspect, Mohammed al-Mansoori.
He had associated with three Qatari citizens who flew from Los Angeles to London (via Washington) and Qatar on the eve of the attacks, after allegedly surveying the World Trade Center and the White House.
U.S. law enforcement officials said that the data about the four men was "just one of many leads that were thoroughly investigated at the time and never led to terrorism charges".
An official added that the three Qatari citizens have never been questioned by the FBI.
Eleanor Hill, the former staff director for the congressional joint inquiry on the September 11 attacks, said the cable reinforces questions about the thoroughness of the FBI's investigation.
She also said that the inquiry concluded that the hijackers had a support network that helped them in different ways.
The three Qatari men were booked to fly from Los Angeles to Washington on September 10, 2001, on the same plane that was hijacked and piloted into the Pentagon on the following day.
Instead, they flew from Los Angeles to Qatar, via Washington and London.
While the cable said that Mansoori was currently under investigation, U.S. law enforcement officials said that there was no active investigation of him or of the Qatari citizens mentioned in the cable.
The American Airlines Flight 77 aircraft was a Boeing 757 - 223 (registration The aircraft was built and had its first flight in 1991.
The flight crew included pilot Charles Burlingame (a Naval Academy graduate and former fighter pilot), First Officer David Charlebois, and flight attendants Michele Heidenberger, Jennifer Lewis, Kenneth Lewis, and Renee May.
The capacity of the aircraft was 188 passengers, but with 58 passengers on September 11, the load factor was 33 percent.
American Airlines said that Tuesdays were the least-traveled day of the week, with the same load factor seen on Tuesdays in the previous three months for Flight 77.
On the morning of September 11, 2001, the five hijackers arrived at Washington Dulles International Airport.
At 07:15, Khalid al-Mihdhar and Majed Moqed checked in at the American Airlines ticket counter for Flight 77, arriving at the passenger security checkpoint a few minutes later at 07:18.
Both men set off the metal detector and were put through secondary screening.
Moqed continued to set off the alarm, so he was searched with a hand wand.
The Hazmi brothers checked in together at the ticket counter at 07:29.
Hani Hanjour checked in separately and arrived at the passenger security checkpoint at 07:35.
Hanjour was followed minutes later at the checkpoint by Salem and Nawaf al-Hazmi, who also set off the metal detector's alarm.
The screener at the checkpoint never resolved what set off the alarm.
As seen in security footage later released, Nawaf Hazmi appeared to have an unidentified item in his back pocket.
Utility knives up to four inches were permitted at the time by the Federal Aviation Administration (FAA) as carry-on items.
The passenger security checkpoint at Dulles International Airport was operated by Argenbright Security, under contract with United Airlines.
The hijackers were all selected for extra screening of their checked bags.
Hanjour, al-Mihdhar, and Moqed were chosen by the Computer Assisted Passenger Prescreening System criteria, while the brothers Nawaf and Salem al-Hazmi were selected because they did not provide adequate identification and were deemed suspicious by the airline check-in agent.
Hanjour, Mihdhar, and Nawaf al-Hazmi did not check any bags for the flight.
Checked bags belonging to Moqed and Salem al-Hazmi were held until they boarded the aircraft.
Flight 77 was scheduled to depart for Los Angeles at 08:10; 58 passengers boarded through Gate D26, including the five hijackers.
The 53 other passengers on board excluding the hijackers were 26 men, 22 women, and five children ranging in age from three to eleven.
On the flight, Hani Hanjour was seated up front in 1B, while Salem and Nawaf al-Hazmi were seated in first class in seats 5E and 5 F. Majed Moqed and Khalid al-Mihdhar were seated further back in 12A and 12B, in economy class.
Flight 77 left the gate on time and took off from Runway 30 at Dulles at 08:20.
The 9/11 Commission estimated that the flight was hijacked between 08:51 and 08:54, shortly after American Airlines Flight 11 struck the World Trade Center and not too long after United Airlines Flight 175 had been hijacked.
The last normal radio communications from the aircraft to air traffic control occurred at 08:50:51.
Unlike the other three flights, there were no reports of anyone being stabbed or a bomb threat and the pilots were not immediately killed but shoved to the back of the plane with the rest of the passengers.
At 08:54, the plane began to deviate from its normal, assigned flight path and turned south.
Two minutes later at 08:56, the plane's transponder was switched off.
The hijackers set the flight's autopilot on a course heading east towards Washington, D.C. The FAA was aware at this point that there was an emergency on board the airplane.
By this time, Flight 11 had already crashed into the North Tower of the World Trade Center and Flight 175 was known to have been hijacked and was within minutes of striking the South Tower.
After learning of this second hijacking involving an American Airlines aircraft and the hijacking involving United Airlines, American Airlines' executive vice president Gerard Arpey ordered a nationwide ground stop for the airline.
The Indianapolis Air Traffic Control Center, as well as American Airlines dispatchers, made several failed attempts to contact the aircraft.
At the time the airplane was hijacked, it was flying over an area of limited radar coverage.
With air controllers unable to contact the flight by radio, an Indianapolis official declared that the Boeing 757 had possibly crashed at 09:09.
Two people on the aircraft made phone calls to contacts on the ground.
At 09:12, flight attendant Renee May called her mother, Nancy May, in Las Vegas.
During the call, which lasted nearly two minutes, May said her flight was being hijacked by six persons, and staff and passengers had been moved to the rear of the airplane.
May asked her mother to contact American Airlines, which she and her husband promptly did; American Airlines was already aware of the hijacking.
Between 09:16 and 09:26, passenger Barbara Olson called her husband, United States Solicitor General Theodore Olson, and reported that the airplane had been hijacked and that the assailants had box cutters and knives.
She reported that the passengers, including the pilots, had been moved to the back of the cabin and that the hijackers were unaware of her call.
A minute into the conversation, the call was cut off.
Theodore Olson contacted the command center at the Department of Justice, and tried unsuccessfully to contact Attorney General John Ashcroft.
About five minutes later, Barbara Olson called again, told her husband that the "pilot" (possibly Hanjour on the cabin intercom) had announced the flight was hijacked, and asked, "What do I tell the pilot to do?"
Ted Olson asked her location and she reported the plane was flying low over a residential area.
He told her of the attacks on the World Trade Center.
Soon afterward, the call cut off again.
An airplane was detected again by Dulles controllers on radar screens as it approached Washington, turning and descending rapidly.
Controllers initially thought this was a military fighter, due to its high speed and maneuvering.
Reagan Airport controllers asked a passing Air National Guard Lockheed C-130 Hercules to identify and follow the aircraft.
The pilot, Lt. Col. Steven O'Brien, told them it was a Boeing 757 or 767, and its silver fuselage meant that it was probably an American Airlines jet.
He had difficulty picking out the airplane in the "East Coast haze", but then saw a "huge" fireball, and initially assumed it had hit the ground.
Approaching the Pentagon, he saw the impact site on the building's west side and reported to Reagan control, "Looks like that aircraft crashed into the Pentagon, sir."
According to the 9/11 Commission Report, as Flight 77 was west-southwest of the Pentagon, it made a 330-degree spiral turn clockwise.
At the end of the turn, it was descending through, pointed toward the Pentagon and downtown Washington.
Hani Hanjour advanced the throttles to maximum power and dived toward the Pentagon.
While level above the ground and seconds from impact, the wings clipped five street lampposts and the right wing struck a portable generator, creating a smoke trail seconds before smashing into the Pentagon.
Flight 77, flying at 530 mph (853 km/h, 237 m/s, or 460 knots) over the Navy Annex Building adjacent to Arlington National Cemetery, impacted the western side of the Pentagon in Arlington County, Virginia, just south of Washington, D.C., at 09:37:46.
The plane hit the Pentagon at the first-floor level, and at the moment of impact, the airplane was rolled slightly to the left, with the right wing elevated.
The front part of the fuselage disintegrated on impact, while the mid and tail sections moved for another fraction of a second, with tail section debris penetrating furthest into the building.
In all, the airplane took eight-tenths of a second to fully penetrate into the three outermost of the building's five rings and unleashed a fireball that rose above the building.
At the time of the attacks, approximately 18,000 people worked in the Pentagon, which was 4,000 fewer than before renovations began in 1998.
The section of the Pentagon that was struck, which had recently been renovated at a cost of $ 250 million, housed the Naval Command Center.
In all, there were 189 deaths at the Pentagon site, including the 125 in the Pentagon building in addition to the 64 on board the aircraft.
Passenger Barbara Olson was en route to a recording of the TV show "Politically Incorrect".
A group of children, their chaperones, and two National Geographic Society staff members were also on board, embarking on an educational trip west to the Channel Islands National Marine Sanctuary near Santa Barbara, California.
The fatalities at the Pentagon included 55 military personnel and 70 civilians.
Of those 125 killed, 92 were on the first floor, 31 were on the second floor, and two were on the third.
Seven Defense Intelligence Agency civilian employees were killed while the Office of the Secretary of Defense lost one contractor.
The U.S. Army suffered 75 fatalities—53 civilians (47 employees and six contractors) and 22 soldiers—while the U.S. Navy suffered 42 fatalities—nine civilians (six employees and three contractors) and 33 sailors.
Lieutenant General Timothy Maude, an Army Deputy Chief of Staff, was the highest-ranking military officer killed at the Pentagon; also killed was retired Rear Admiral Wilson Flagg, a passenger on the plane.
LT Mari-Rae Sopper, JAGC, USNR, was also on board the flight, and was the first Navy Judge Advocate ever to be killed in action.
Another 106 were injured on the ground and were treated at area hospitals.
On the side where the plane hit, the Pentagon is bordered by Interstate 395 and Washington Boulevard.
Motorist Mary Lyman, who was on I-395, saw the airplane pass over at a "steep angle toward the ground and going fast" and then saw the cloud of smoke from the Pentagon.
Omar Campo, another witness, was cutting the grass on the other side of the road when the airplane flew over his head, and later recalled: Afework Hagos, a computer programmer, was on his way to work and stuck in a traffic jam near the Pentagon when the airplane flew over.
Everybody was running away in different directions.
It was tilting its wings up and down like it was trying to balance.
Daryl Donley witnessed the crash and took some of the first photographs of the site.
"USA Today" reporter Mike Walter was driving on Washington Boulevard when he witnessed the crash, which he recounted, Terrance Kean, who lived in a nearby apartment building, heard the noise of loud jet engines, glanced out his window, and saw a "very, very large passenger jet".
The nose penetrated into the portico.
Tim Timmerman, who is a pilot himself, noticed American Airlines markings on the aircraft as he saw it hit the Pentagon.
Other drivers on Washington Boulevard, Interstate 395, and Columbia Pike witnessed the crash, as did people in Pentagon City, Crystal City, and other nearby locations.
Former Georgetown University basketball coach John Thompson had originally booked a ticket on Flight 77.
As he would tell the story many times in the following years, including a September 12, 2011 interview on Jim Rome's radio show, he had been scheduled to appear on that show on September 12, 2001.
Thompson was planning to be in Las Vegas for a friend's birthday on September 13, and initially insisted on traveling to Rome's Los Angeles studio on the 11th.
However, this did not work for the show, which wanted him to travel on the day of the show.
After a Rome staffer personally assured Thompson that he would be able to travel from Los Angeles to Las Vegas immediately after the show, Thompson changed his travel plans.
He felt the impact from the crash at his home near the Pentagon.
Rescue efforts began immediately after the crash.
Almost all the successful rescues of survivors occurred within half an hour of the impact.
Initially, rescue efforts were led by the military and civilian employees within the building.
Within minutes, the first fire companies arrived and found these volunteers searching near the impact site.
The firemen ordered them to leave as they were not properly equipped or trained to deal with the hazards.
The Arlington County Fire Department (ACFD) assumed command of the immediate rescue operation within 10 minutes of the crash.
ACFD Assistant Chief James Schwartz implemented an incident command system (ICS) to coordinate response efforts among multiple agencies.
It took about an hour for the ICS structure to become fully operational.
Firefighters from Fort Myer and Reagan National Airport arrived within minutes.
Rescue and firefighting efforts were impeded by rumors of additional incoming planes.
Chief Schwartz ordered two evacuations during the day in response to these rumors.
As firefighters attempted to extinguish the fires, they watched the building in fear of a structural collapse.
One firefighter remarked that they "pretty much knew the building was going to collapse because it started making weird sounds and creaking".
Officials saw a cornice of the building move and ordered an evacuation.
Minutes later, at 10:10, the upper floors of the damaged area of the Pentagon collapsed.
The collapsed area was about at its widest point and at its deepest.
The amount of time between impact and collapse allowed everyone on the fourth and fifth levels to evacuate safely before the structure collapsed.
After the collapse, the interior fires intensified, spreading through all five floors.
After 11:00, firefighters mounted a two-pronged attack against the fires.
Officials estimated temperatures of up to.
While progress was made against the interior fires by late afternoon, firefighters realized a flammable layer of wood under the Pentagon's slate roof had caught fire and begun to spread.
Typical firefighting tactics were rendered useless by the reinforced structure as firefighters were unable to reach the fire to extinguish it.
Firefighters instead made firebreaks in the roof on September 12 to prevent further spreading.
At 18:00 on the 12th, Arlington County issued a press release stating the fire was "controlled" but not fully "extinguished".
Firefighters continued to put out smaller fires that ignited in the succeeding days.
Various pieces of aircraft debris were found within the wreckage at the Pentagon.
While on fire and escaping from the Navy Command Center, Lt. Kevin Shaeffer observed a chunk of the aircraft's nose cone and the nose landing gear in the service road between rings B and C. Early in the morning on Friday, September 14, Fairfax County Urban Search and Rescue Team members Carlton Burkhammer and Brian Moravitz came across an "intact seat from the plane's cockpit", while paramedics and firefighters located the two black boxes near the punch out hole in the A-E drive, nearly into the building.
The cockpit voice recorder was to retrieve any information, though the flight data recorder yielded useful information.
Investigators also found a part of Nawaf al-Hazmi's driver's license in the North Parking Lot rubble pile.
Personal effects belonging to victims were found and taken to Fort Myer.
Army engineers determined by 5:30 p.m. on the first day that no one remained alive in the damaged section of the building.
In the days after the crash, news reports emerged that up to 800 people had died.
Army soldiers from Fort Belvoir were the first teams to survey the interior of the crash site and noted the presence of human remains.
Federal Emergency Management Agency (FEMA) Urban Search and Rescue teams, including Fairfax County Urban Search and Rescue assisted the search for remains, working through the National Interagency Incident Management System (NIIMS).
Debris from the Pentagon was taken to the Pentagon's north parking lot for more detailed search for remains and evidence.
Remains that were recovered from the Pentagon were photographed, and turned over to the Armed Forces Medical Examiner office, located at Dover Air Force Base in Delaware.
The medical examiner's office was able to identify remains belonging to 179 of the victims.
Investigators eventually identified 184 of the 189 people who died in the attack.
The remains of the five hijackers were identified through a process of elimination, and were turned over as evidence to the Federal Bureau of Investigation (FBI).
On September 21, the ACFD relinquished control of the crime scene to the FBI.
The Washington Field Office, National Capital Response Squad (NCRS), and the Joint Terrorism Task Force (JTTF) led the crime scene investigation at the Pentagon.
By October 2, 2001, the search for evidence and remains was complete and the site was turned over to Pentagon officials.
In 2002, the remains of 25 victims were buried collectively at Arlington National Cemetery, with a five-sided granite marker inscribed with the names of all the victims in the Pentagon.
The ceremony also honored the five victims whose remains were never found.
At around 3:40 a.m. on September 14, a paramedic and a firefighter who were searching through the debris of the impact site found two dark boxes, about by long.
They called for an FBI agent, who in turn called for someone from the National Transportation Safety Board (NTSB).
The NTSB employee confirmed that these were the flight recorders ("black boxes") from American Airlines Flight 77.
Dick Bridges, deputy manager for Arlington County, Virginia, said the cockpit voice recorder was damaged on the outside and the flight data recorder was charred.
Bridges said the recorders were found "right where the plane came into the building."
The cockpit voice recorder was transported to the NTSB lab in Washington, D.C., to see what data was salvageable.
In its report, the NTSB identified the unit as an L-3 Communications, Fairchild Aviation Recorders model A-100 A cockpit voice recorder—a device which records on magnetic tape.
No usable segments of tape were found inside the recorder; according to the NTSB's report, "[t] he majority of the recording tape was fused into a solid block of charred plastic".
On the other hand, all the data from the flight data recorder, which used a solid-state drive, was recovered.
At the moment of impact, Secretary of Defense Donald Rumsfeld was in his office on the other side of the Pentagon, away from the crash site.
He ran to the site and assisted the injured.
Rumsfeld returned to his office, and went to a conference room in the Executive Support Center where he joined a secure videoteleconference with Vice President Dick Cheney and other officials.
On the day of the attacks, DoD officials considered moving their command operations to Site R, a backup facility in Pennsylvania.
Secretary of Defense Rumsfeld insisted he remain at the Pentagon, and sent Deputy Secretary Paul Wolfowitz to Site R. The National Military Command Center (NMCC) continued to operate at the Pentagon, even as smoke entered the facility.
Engineers and building managers manipulated the ventilation and other building systems that still functioned to draw smoke out of the NMCC and bring in fresh air.
Pentagon employees returned the next day to offices in mostly unaffected areas of the building.
By the end of September, more workers returned to the lightly damaged areas of the Pentagon.
Early estimates on rebuilding the damaged section of the Pentagon were that it would take three years to complete.
However, the project moved forward at an accelerated pace and was completed by the first anniversary of the attack.
The rebuilt section of the Pentagon includes a small indoor memorial and chapel at the point of impact.
An outdoor memorial, commissioned by the Pentagon and designed by Julie Beckman and Keith Kaseman, was completed on schedule for its dedication on September 11, 2008.
Since September 11, American Airlines continues to fly from Dulles International Airport to Los Angeles International Airport.
As of September 2018, flight number 77 has been renumbered to 252, now using a Boeing 737 - 800, departing at 7:27 in the morning.
The Department of Defense released filmed footage on May 16, 2006, that was recorded by a security camera of American Airlines Flight 77 crashing into the Pentagon, with a plane visible in one frame, as a "thin white blur" and an explosion following.
The images were made public in response to a December 2004 Freedom of Information Act request by Judicial Watch.
Some still images from the video had previously been released and publicly circulated, but this was the first official release of the edited video of the crash.
A nearby Citgo service station also had security cameras, but a video released on September 15, 2006 did not show the crash because the camera was pointed away from the crash site.
The Doubletree Hotel, located nearby in Crystal City, Virginia, also had a security camera video.
The FBI released the video on December 4, 2006, in response to a FOIA lawsuit filed by Scott Bingham.
The footage is "grainy and the focus is soft, but a rapidly growing tower of smoke is visible in the distance on the upper edge of the frame as the plane crashes into the building".
On September 12, 2002, Defense Secretary Donald Rumsfeld and General Richard Myers, Chairman of the Joint Chiefs of Staff, dedicated the Victims of Terrorist Attack on the Pentagon Memorial at Arlington National Cemetery.
The memorial specifically honors the five individuals for whom no identifiable remains were found.
This included Dana Falkenberg, age three, who was aboard American Airlines Flight 77 with her parents and older sister.
A portion of the remains of 25 other victims are also buried at the site.
The memorial is a pentagonal granite marker high.
On five sides of the memorial along the top are inscribed the words "Victims of Terrorist Attack on the Pentagon September 11, 2001".
Aluminum plaques, painted black, are inscribed with the names of the 184 victims of the terrorist attack.
The site is located in Section 64, on a slight rise, which gives it a view of the Pentagon.
At the National September 11 Memorial, the names of the Pentagon victims are inscribed on the South Pool, on Panels S-1 and S-72 – S-76.
The Pentagon Memorial, located just southwest of The Pentagon in Arlington County, Virginia, is a permanent outdoor memorial to the 184 people who died as victims in the building and on American Airlines Flight 77 during the September 11 attacks.
Designed by Julie Beckman and Keith Kaseman of the architectural firm of Kaseman Beckman Advanced Strategies with engineers Buro Happold, the memorial opened on September 11, 2008, seven years after the attack.
The nationalities of the 53 passengers and six crew members included six different countries: United States47653 China202 Australia101 Ethiopia101 South Korea101 United Kingdom101 Total53659
An ambush is a long-established military tactic in which combatants take advantage of concealment and the element of surprise to attack unsuspecting enemy combatants from concealed positions, such as among dense underbrush or behind hilltops.
Ambushes have been used consistently throughout history, from ancient to modern warfare.
In the 20th century, an ambush might involve thousands of soldiers on a large scale, such as over a choke point such as a mountain pass, or a small irregular band or insurgent group attacking a regular armed force patrol.
Theoretically, a single well-armed and concealed soldier could ambush other troops in a surprise attack.
The use by early humans of the ambush may date as far back as two million years when anthropologists have recently suggested that ambush techniques were used to hunt large game.
One example from ancient times is the Battle of the Trebia river.
Hannibal encamped within striking distance of the Romans with the Trebia River between them, and placed a strong force of cavalry and infantry in concealment, near the battle zone.
He had noticed, says Polybius, a "place between the two camps, flat indeed and treeless, but well adapted for an ambuscade, as it was traversed by a water-course with steep banks, densely overgrown with brambles and other thorny plants, and here he proposed to lay a stratagem to surprise the enemy".
When the Roman infantry became entangled in combat with his army, the hidden ambush force attacked the legionnaires in the rear.
The result was slaughter and defeat for the Romans.
Nevertheless, the battle also displays the effects of good tactical discipline on the part of the ambushed force.
Although most of the legions were lost, about 10,000 Romans cut their way through to safety, maintaining unit cohesion.
This ability to maintain discipline and break out or maneuver away from a kill zone is a hallmark of good troops and training in any ambush situation.
(See Ranger reference below).
Ambushes were widely utilized by the Lusitanians, in particular by their chieftain Viriathus.
Their usual tactic, called "concursare", involved repeatedly charging and retreating, forcing the enemy to eventually give them chase, in order to set up ambushes in difficult terrain where allied forces would be awaiting.
In his first victory, he eluded the siege of Roman praetor Gaius Vetilius and attracted him to a narrow pass next to the Barbesuda river, where he destroyed his army and killed the praetor.
Viriathus's ability to turn chases into ambushes would grant him victories over a number of Roman generals.
Another famous Lusitanian ambush was performed by Curius and Apuleius on Roman general Quintus Fabius Maximus Servilianus, who led a numerically superior army complete with war elephants and Numidian cavalry.
The ambush allowed Curius and Apuleius to steal Servilianus's loot train, although a tactic error in their retreat led to the Romans retaking the train and putting the Lusitanians to flight.
Viriathus later defeated Servilianus with a surprise attack.
Possibly the most famous ambush in ancient warfare was that sprung by Germanic warchief Arminius against the Romans at Battle of the Teutoburg Forest.
This particular ambush was to affect the course of Western history.
The Germanic forces demonstrated several principles needed for a successful ambush.
They took cover in difficult forested terrain, allowing the warriors time and space to mass without detection.
They had the element of surprise, and this was also aided by the defection of Arminius from Roman ranks prior to the battle.
They sprang the attack when the Romans were most vulnerable; when they had left their fortified camp, and were on the march in a pounding rainstorm.
The Germans did not dawdle at the hour of decision but attacked quickly, using a massive series of short, rapid, vicious charges against the length of the whole Roman line, with charging units sometimes withdrawing to the forest to regroup while others took their place.
The Germans also used blocking obstacles, erecting a trench and earthen wall to hinder Roman movement along the route of the killing zone.
The result was mass slaughter of the Romans, and the destruction of three legions.
The Germanic victory caused a limit on Roman expansion in the West. Ultimately, it established the Rhine as the boundary of the Roman Empire for the next four hundred years, until the decline of the Roman influence in the West. The Roman Empire made no further concerted attempts to conquer Germania beyond the Rhine.
According to Muslim tradition, Islamic Prophet Muhammad used ambush tactics in his military campaigns.
His first such use was during the Caravan raids, in the Kharrar caravan raid Sa `d ibn Abi Waqqas was ordered to lead a raid against the Quraysh.
His group consisted of about twenty Muhajirs.
This raid was done about a month after the previous.
Sa'd, with his soldiers, set up an ambush in the valley of Kharrar on the road to Mecca and waited to raid a returning Meccan caravan from Syria.
But the caravan had already passed and the Muslims returned to Medina without any loot.
Arab tribes during Muhammad's era also used ambush tactics.
One example retold in Muslim tradition is said to have taken place during the First Raid on Banu Thalabah.
The Banu Thalabah tribe were already aware of the impending attack; so they lay in wait for the Muslims, and when Muhammad ibn Maslama arrived at the site.
The Banu Thalabah, with 100 men ambushed them, while the Muslims were making preparation to sleep; and after a brief resistance killed all of Muhammad ibn Maslama's men.
Muhammad ibn Maslama pretended to be dead.
A Muslim who happened to pass that way found him and assisted him to return to Medina.
The raid was unsuccessful.
In modern warfare, an ambush is most often employed by ground troops up to platoon size against enemy targets, which may be other ground troops, or possibly vehicles.
However, in some situations, especially when deep behind enemy lines, the actual attack will be carried out by a platoon, a company-sized unit will be deployed to support the attack group, setting up and maintaining a forward patrol harbour from which the attacking force will deploy, and to which they will retire after the attack.
Ambushes are complex multi-phase operations and are therefore usually planned in some detail.
First, a suitable killing zone is identified.
This is the place where the ambush will be laid.
It is generally a place where enemy units are expected to pass, and which gives reasonable cover for the deployment, execution and extraction phases of the ambush patrol.
A path along a wooded valley floor would be a typical example.
Ambush can be described geometrically as: Ambush criteria: The terrain for the ambush had to meet strict criteria: One important feature of the ambush was that the target units should ' pile up ' after being attacked, thus preventing them any easy means of withdrawal from the kill zone and hindering their use of heavy weapons and supporting fire.
Terrain was usually selected which would facilitate this and slow down the enemy.
Any terrain around the ambush site which was not favorable to the ambushing force, or which offered some protection to the target, was heavily mined and booby trapped or pre-registered for mortars.
Ambush units: The NVA/VC ambush formations consisted of: Other elements might also be included if the situation demanded, such as a sniper screen along a nearby avenue of approach to delay enemy reinforcements.
Command posts: When deploying into an ambush site, the NVA first occupied several observation posts, placed to detect the enemy as early as possible and to report on the formation it was using, its strength and firepower, as well as to provide early warning to the unit commander.
Usually one main OP and several secondary OP's were established.
Runners and occasionally radios were used to communicate between the OP's and the main command post.
The OP's were located so that they could observe enemy movement into the ambush and often they would remain in position throughout the ambush in order to report routes of reinforcement and withdrawal by the enemy as well as his maneuver options.
Frequently the OP's were reinforced to squad size and served as flank security.
The command post was situated in a central location, often on terrain which afforded it a vantage point overlooking the ambush site.
Recon methods: Reconnaissance elements observing a potential ambush target on the move generally stayed 300 – 500 meters away.
Sometimes a "leapfrogging" recon technique was used.
Surveillance units were echeloned one behind the other.
As the enemy drew close to the first, it fell back behind the last recon team, leaving an advance group in its place.
This one in turn fell back as the enemy again closed the gap, and the cycle rotated.
This method helped keep the enemy under continuous observation from a variety of vantage points, and allowed the recon groups to cover one another.
An abzyme (from antibody and enzyme), also called "catmab" (from "catalytic monoclonal antibody"), and most often called "catalytic antibody", is a monoclonal antibody with catalytic activity.
Abzymes are usually raised in lab animals immunized against synthetic haptens, but some natural abzymes can be found in normal humans (anti-vasoactive intestinal peptide autoantibodies) and in patients with autoimmune diseases such as systemic lupus erythematosus, where they can bind to and hydrolyze DNA.
To date abzymes display only weak, modest catalytic activity and have not proved to be of any practical use.
They are, however, subjects of considerable academic interest.
Studying them has yielded important insights into reaction mechanisms, enzyme structure and function, catalysis, and the immune system itself.
Enzymes function by lowering the activation energy of the transition state of a chemical reaction, thereby enabling the formation of an otherwise less-favorable molecular intermediate between the reactant (s) and the product (s).
If an antibody is developed to bind to a molecule that is structurally and electronically similar to the transition state of a given chemical reaction, the developed antibody will bind to, and stabilize, the transition state, just like a natural enzyme, lowering the activation energy of the reaction, and thus catalyzing the reaction.
By raising an antibody to bind to a stable transition-state analog, a new and unique type of enzyme is produced.
So far, all catalytic antibodies produced have displayed only modest, weak catalytic activity.
The reasons for low catalytic activity for these molecules have been widely discussed.
Possibilities indicate that factors beyond the binding site may play an important, in particular through protein dynamics.
Some abzymes have been engineered to use metal ions and other cofactors to improve their catalytic activity.
The possibility of catalyzing a reaction by means of an antibody which binds the transition state was first suggested by William P. Jencks in 1969.
In 1994 Peter G. Schultz and Richard A. Lerner received the prestigious Wolf Prize in Chemistry for developing catalytic antibodies for many reactions and popularizing their study into a significant sub-field of enzymology.
In a June 2008 issue of the journal Autoimmunity Review, researchers S Planque, Sudhir Paul, Ph. D, and Yasuhiro Nishiyama, Ph. D of the University Of Texas Medical School at Houston announced that they have engineered an abzyme that degrades the superantigenic region of the gp120 CD4 binding site.
This is the one part of the HIV virus outer coating that does not change, because it is the attachment point to T lymphocytes, the key cell in cell-mediated immunity.
Once infected by HIV, patients produce antibodies to the more changeable parts of the viral coat.
The antibodies are ineffective because of the virus' ability to change their coats rapidly.
Because this protein gp120 is necessary for HIV to attach, it does not change across different strains and is a point of vulnerability across the entire range of the HIV variant population.
The abzyme does more than bind to the site: it catalytically destroys the site, rendering the virus inert, and then can attack other HIV viruses.
A single abzyme molecule can destroy thousands of HIV viruses.
In evolutionary biology, adaptive radiation is a process in which organisms diversify rapidly from an ancestral species into a multitude of new forms, particularly when a change in the environment makes new resources available, creates new challenges, or opens new environmental niches.
Starting with a recent single ancestor, this process results in the speciation and phenotypic adaptation of an array of species exhibiting different morphological and physiological traits.
The prototypical example of adaptive radiation is finch speciation on the Galapagos ("Darwin's finches"), but examples are known from around the world.
Four features can be used to identify an adaptive radiation: Adaptive radiation tends to take place under the following conditions: Darwin's finches are an often-used textbook example of adaptive radiation.
Today represented by approximately 15 species, Darwin's finches are Galapagos endemics famously adapted for a specialized feeding behavior (although one species, the Cocos finch ("Pinaroloxias inornata"), is not found in the Galapagos but on the island of Cocos south of Costa Rica).
Darwin's finches are not actually finches in the true sense, but are members of the tanager family Thraupidae, and are derived from a single ancestor that arrived in the Galapagos from mainland South America perhaps just 3 million years ago.
Excluding the Cocos finch, each species of Darwin's finch is generally widely distributed in the Galapagos and fills the same niche on each island.
For the ground finches, this niche is a diet of seeds, and they have thick bills to facilitate the consumption of these hard materials.
The ground finches are further specialized to eat seeds of a particular size: the large ground finch ("Geospiza magnirostris") is the largest species of Darwin's finch and has the thickest beak for breaking open the toughest seeds, the small ground finch ("Geospiza fuliginosa") has a smaller beak for eating smaller seeds, and the medium ground finch ("Geospiza fortis") has a beak of intermediate size for optimal consumption of intermediately sized seeds (relative to "G. magnirostris" and "G. fuliginosa").
There is some overlap: for example, the most robust medium ground finches could have beaks larger than those of the smallest large ground finches.
Because of this overlap, it can be difficult to tell the species apart by eye, though their songs differ.
These three species often occur sympatrically, and during the rainy season in the Galapagos when food is plentiful, they specialize little and eat the same, easily accessible foods.
It was not well-understood why their beaks were so adapted until Peter and Rosemary Grant studied their feeding behavior in the long dry season, and discovered that when food is scarce, the ground finches use their specialized beaks to eat the seeds that they are best suited to eat and thus avoid starvation.
The other finches in the Galapagos are similarly uniquely adapted for their particular niche.
The cactus finches ("Geospiza" sp.) have somewhat longer beaks than the ground finches that serve the dual purpose of allowing them to feed on Opuntia cactus nectar and pollen while these plants are flowering, but on seeds during the rest of the year.
The warbler-finches ("Certhidea" sp.) have short, pointed beaks for eating insects.
The woodpecker finch ("Camarhynchus pallidus") has a slender beak which it uses to pick at wood in search of insects; it also uses small sticks to reach insect prey inside the wood, making it one of the few animals that use tools.
The mechanism by which the finches initially diversified is still an area of active research.
One proposition is that the finches were able to have a non-adaptive, allopatric speciation event on separate islands in the archipelago, such that when they reconverged on some islands, they were able to maintain reproductive isolation.
Once they occurred in sympatry, niche specialization was favored so that the different species competed less directly for resources.
This second, sympatric event was adaptive radiation.
The haplochromine cichlid fishes in the Great Lakes of the East African Rift (particularly in Lake Tanganyika, Lake Malawi, and Lake Victoria) form the most speciose modern example of adaptive radiation.
These lakes are believed to be home to about 2,000 different species of cichlid, spanning a wide range of ecological roles and morphological characteristics.
Cichlids in these lakes fill nearly all of the roles typically filled by many fish families, including those of predators, scavengers, and herbivores, with varying dentitions and head shapes to match their dietary habits.
In each case, the radiation events are only a few million years old, making the high level of speciation particularly remarkable.
Several factors could be responsible for this diversity: the availability of a multitude of niches probably favored specialization, as few other fish taxa are present in the lakes (meaning that sympatric speciation was the most probable mechanism for initial specialization).
Also, continual changes in the water level of the lakes during the Pleistocene (which often turned the largest lakes into several smaller ones) could have created the conditions for secondary allopatric speciation.
Lake Tanganyika is the site from which nearly all the cichlid lineages of East Africa (including both riverine and lake species) originated.
Thus, the species in the lake constitute a single adaptive radiation event but do not form a single monophyletic clade.
Lake Tanganyika is also the least speciose of the three largest African Great Lakes, with only around 200 species of cichlid; however, these cichlids are more morphologically divergent and ecologically distinct than their counterparts in lakes Malawi and Victoria, an artifact of Lake Tanganyika's older cichlid fauna.
Lake Tanganyika itself is believed to have formed 9 – 12 million years ago, putting a recent cap on the age of the lake's cichlid fauna.
Many of Tanganyika's cichlids live very specialized lifestyles.
The giant or emperor cichlid ("Boulengerochromis microlepis") is a piscivore often ranked the largest of all cichlids (though it competes for this title with South America's "Cichla temensis", the speckled peacock bass).
It is thought that giant cichlids spawn only a single time, breeding in their third year and defending their young until they reach a large size, before dying of starvation some time thereafter.
The three species of "Altolamprologus" are also piscivores, but with laterally compressed bodies and thick scales enabling them to chase prey into thin cracks in rocks without damaging their skin.
"Plecodus straeleni" has evolved large, strangely curved teeth that are designed to scrape scales off of the sides of other fish, scales being its main source of food.
"Gnathochromis permaxillaris" possesses a large mouth with a protruding upper lip, and feeds by opening this mouth downward onto the sandy lake bottom, sucking in small invertebrates.
A number of Tanganyika's cichlids are shell-brooders, meaning that mating pairs lay and fertilize their eggs inside of empty shells on the lake bottom.
"Lamprologus callipterus" is the most unique egg-brooding species, with 15 cm-long males amassing collections of shells and guarding them in the hopes of attracting females (about 6 cm in length) to lay eggs in these shells.
These dominant males must defend their territories from three types of rival: (1) other dominant males looking to steal shells; (2) younger, "sneaker" males looking to fertilize eggs in a dominant male's territory; and (3) tiny, 2 – 4 cm "parasitic dwarf" males that also attempt to rush in and fertilize eggs in the dominant male's territory.
These parasitic dwarf males never grow to the size of dominant males, and the male offspring of dominant and parasitic dwarf males grow with 100 % fidelity into the form of their fathers.
A number of other highly specialized Tanganyika cichlids exist aside from these examples, including those adapted for life in open lake water up to 200 m deep.
The cichlids of Lake Malawi constitute a "species flock" of up to 1000 endemic species.
Only seven cichlid species in Lake Malawi are not a part of the species flock: the Eastern happy ("Astatotilapia calliptera"), the sungwa ("Serranochromis robustus"), and five tilapia species (genera "Oreochromis" and "Coptodon").
All of the other cichlid species in the lake are descendants of a single original colonist species, which itself was descended from Tanganyikan ancestors.
The common ancestor of Malawi's species flock is believed to have reached the lake 3.4 million years ago at the earliest, making Malawi cichlids' diversification into their present numbers particularly rapid.
Malawi's cichlids span a similarly range of feeding behaviors to those of Tanganyika, but also show signs of a much more recent origin.
For example, all members of the Malawi species flock are mouth-brooders, meaning the female keeps her eggs in her mouth until they hatch; in almost all species, the eggs are also fertilized in the female's mouth, and in a few species, the females continue to guard their fry in their mouth after they hatch.
Males of most species display predominantly blue coloration when mating.
However, a number of particularly divergent species are known from Malawi, including the piscivorous "Nimbochromis livingtonii", which lies on its side in the substrate until small cichlids, perhaps drawn to its broken white patterning, come to inspect the predator - at which point they are swiftly eaten.
Lake Victoria's cichlids are also a species flock, once composed of some 500 or more species.
The deliberate introduction of the Nile Perch ("Lates niloticus") in the 1950 s proved disastrous for Victoria cichlids, and the collective biomass of the Victoria cichlid species flock has decreased substantially and an unknown number of species have become extinct.
However, the original range of morphological and behavioral diversity seen in the lake's cichlid fauna is still mostly present today, if endangered.
These again include cichlids specialized for niches across the trophic spectrum, as in Tanganyika and Malawi, but again, there are standouts.
Victoria is famously home to many piscivorous cichlid species, some of which feed by sucking the contents out of mouthbrooding females' mouths.
Victoria's cichlids constitute a far younger radiation than even that of Lake Malawi, with estimates of the age of the flock ranging from 200,000 years to as little as 14,000.
Hawaii has served as the site of a number of adaptive radiation events, owing to its isolation, recent origin, and large land area.
The three most famous examples of these radiations are presented below, though insects like the Hawaiian drosophilid flies and "Hyposmocoma" moths have also undergone adaptive radiation.
The Hawaiian honeycreepers form a large, highly morphologically diverse species group that began radiating in the early days of the Hawaiian archipelago.
While today only 17 species are known to persist in Hawaii (3 more may or may not be extinct), there were more than 50 species prior to Polynesian colonization of the archipelago (between 18 and 21 species have gone extinct since the discovery of the islands by westerners).
The Hawaiian honeycreepers are known for their beaks, which are specialized to satisfy a wide range of dietary needs: for example, the beak of the ʻakiapōlāʻau ("Hemignathus wilsoni") is characterized by a short, sharp lower mandible for scraping bark off of trees, and the much longer, curved upper mandible is used to probe the wood underneath for insects.
Meanwhile, the ʻiʻiwi ("Drepanis coccinea") has a very long curved beak for reaching nectar deep in "Lobelia" flowers.
An entire clade of Hawaiian honeycreepers, the tribe Psittirostrini, is composed of thick-billed, mostly seed-eating birds, like the Laysan finch ("Telespiza cantans").
In at least some cases, similar morphologies and behaviors appear to have evolved convergently among the Hawaiian honeycreepers; for example, the short, pointed beaks of "Loxops" and "Oreomystis" evolved separately despite once forming the justification for lumping the two genera together.
The Hawaiian honeycreepers are believed to have descended from a single common ancestor some 15 to 20 million years ago, though estimates range as low as 3.5 million years.
Adaptive radiation is not a strictly vertebrate phenomenon, and examples are also known from among plants.
The most famous example of adaptive radiation in plants is quite possibly the Hawaiian silverswords, named for alpine desert-dwelling "Argyroxiphium" species with long, silvery leaves that live for up to 20 years before growing a single flowering stalk and then dying.
The Hawaiian silversword alliance consists of twenty-eight species of Hawaiian plants which, aside from the namesake silverswords, includes trees, shrubs, vines, cushion plants, and more.
The silversword alliance is believed to have originated in Hawaii no more than 6 million years ago, making this one of Hawaii's youngest adaptive radiation events.
This means that the silverswords evolved on Hawaii's modern high islands, and descended from a single common ancestor that arrived on Kauai from western North America.
The closest modern relatives of the silverswords today are California tarweeds of the family Asteraceae.
Hawaii is also the site of a separate major floral adaptive radiation event: the Hawaiian lobelioids.
The Hawaiian lobelioids are significantly more speciose than the silverswords, perhaps because they have been present in Hawaii for so much longer: they descended from a single common ancestor who arrived in the archipelago up to 15 million years ago.
Today the Hawaiian lobelioids form a clade of over 125 species, including succulents, trees, shrubs, epiphytes, etc.
Many species have been lost to extinction and many of the surviving species endangered.
Anole lizards are distributed broadly in the New World, from the Southeastern US to South America.
With over 400 species currently recognized, often placed in a single genus ("Anolis"), they constitute one of the largest radiation events among all lizards.
Anole radiation on the mainland has largely been a process of speciation, and is not adaptive to any great degree, but anoles on each of the Greater Antilles (Cuba, Hispaniola, Puerto Rico, and Jamaica) have adaptively radiated in separate, convergent ways.
On each of these islands, anoles have evolved with such a consistent set of morphological adaptations that each species can be assigned to one of six "ecomorphs": trunk–ground, trunk–crown, grass–bush, crown–giant, twig, and trunk.
Take, for example, crown–giants from each of these islands: the Cuban "Anolis luteogularis", Hispaniola's "Anolis ricordii", Puerto Rico's "Anolis cuvieri", and Jamaica's "Anolis garmani" (Cuba and Hispaniola are both home to more than one species of crown–giant).
These anoles are all large, canopy-dwelling species with large heads and large lamellae (scales on the undersides of the fingers and toes that are important for traction in climbing), and yet none of these species are particularly closely related and appear to have evolved these similar traits independently.
The same can be said of the other five ecomorphs across the Caribbean's four largest islands.
Much like in the case of the cichlids of the three largest African Great Lakes, each of these islands is home to its own convergent "Anolis" adaptive radiation event.
Presented above are the most well-documented examples of modern adaptive radiation, but other examples are known.
On Madagascar, birds of the family Vangidae are marked by very distinct beak shapes to suit their ecological roles.
Madagascan mantellid frogs have radiated into forms that mirror other tropical frog faunas, with the brightly colored mantellas ("Mantella") having evolved convergently with the Neotropical poison dart frogs of Dendrobatidae, while the arboreal "Boophis" species are the Madagascan equivalent of tree frogs and glass frogs.
The pseudoxyrhophiine snakes of Madagascar have evolved into fossorial, arboreal, terrestrial, and semi-aquatic forms that converge with the colubroid faunas in the rest of the world.
These Madagascan examples are significantly older than most of the other examples presented here: Madagascar's fauna has been evolving in isolation since the island split from India some 88 million years ago, and the Mantellidae originated around 50 mya.
Older examples are known: the K-Pg extinction event, which caused the disappearance of the dinosaurs and most other reptilian megafauna 65 million years ago, is seen as having triggered a global adaptive radiation event that created the mammal diversity that exists today.
Agarose gel electrophoresis is a method of gel electrophoresis used in biochemistry, molecular biology, genetics, and clinical chemistry to separate a mixed population of macromolecules such as DNA or proteins in a matrix of agarose, one of the two main components of agar.
The proteins may be separated by charge and/or size (isoelectric focusing agarose electrophoresis is essentially size independent), and the DNA and RNA fragments by length.
Biomolecules are separated by applying an electric field to move the charged molecules through an agarose matrix, and the biomolecules are separated by size in the agarose gel matrix.
Agarose gel is easy to cast, has relatively fewer charged groups, and is particularly suitable for separating DNA of size range most often encountered in laboratories, which accounts for the popularity of its use.
The separated DNA may be viewed with stain, most commonly under UV light, and the DNA fragments can be extracted from the gel with relative ease.
Most agarose gels used are between 0.7 – 2 % dissolved in a suitable electrophoresis buffer.
Agarose gel is a three-dimensional matrix formed of helical agarose molecules in supercoiled bundles that are aggregated into three-dimensional structures with channels and pores through which biomolecules can pass. The 3-D structure is held together with hydrogen bonds and can therefore be disrupted by heating back to a liquid state.
The melting temperature is different from the gelling temperature, depending on the sources, agarose gel has a gelling temperature of 35 – 42 °C and a melting temperature of 85 – 95 °C.
Low-melting and low-gelling agaroses made through chemical modifications are also available.
Agarose gel has large pore size and good gel strength, making it suitable as an anticonvection medium for the electrophoresis of DNA and large protein molecules.
The pore size of a 1 % gel has been estimated from 100 nm to 200 – 500 nm, and its gel strength allows gels as dilute as 0.15 % to form a slab for gel electrophoresis.
Low-concentration gels (0.1 – 0.2 %) however are fragile and therefore hard to handle.
Agarose gel has lower resolving power than polyacrylamide gel for DNA but has a greater range of separation, and is therefore used for DNA fragments of usually 50 – 20,000 bp in size.
The limit of resolution for standard agarose gel electrophoresis is around 750 kb, but resolution of over 6 Mb is possible with pulsed field gel electrophoresis (PFGE).
It can also be used to separate large proteins, and it is the preferred matrix for the gel electrophoresis of particles with effective radii larger than 5 – 10 nm.
A 0.9 % agarose gel has pores large enough for the entry of bacteriophage T4.
The agarose polymer contains charged groups, in particular pyruvate and sulphate.
These negatively charged groups create a flow of water in the opposite direction to the movement of DNA in a process called electroendosmosis (EEO), and can therefore retard the movement of DNA and cause blurring of bands.
Higher concentration gels would have higher electroosmotic flow.
Low EEO agarose is therefore generally preferred for use in agarose gel electrophoresis of nucleic acids, but high EEO agarose may be used for other purposes.
The lower sulphate content of low EEO agarose, particularly low-melting point (LMP) agarose, is also beneficial in cases where the DNA extracted from gel is to be used for further manipulation as the presence of contaminating sulphates may affect some subsequent procedures, such as ligation and PCR.
Zero EEO agaroses however are undesirable for some applications as they may be made by adding positively charged groups and such groups can affect subsequent enzyme reactions.
Electroendosmosis is a reason agarose is used in preference to agar as the agaropectin component in agar contains a significant amount of negatively charged sulphate and carboxyl groups.
The removal of agaropectin in agarose substantially reduces the EEO, as well as reducing the non-specific adsorption of biomolecules to the gel matrix.
However, for some applications such as the electrophoresis of serum proteins, a high EEO may be desirable, and agaropectin may be added in the gel used.
A number of factors can affect the migration of nucleic acids: the dimension of the gel pores (gel concentration), size of DNA being electrophoresed, the voltage used, the ionic strength of the buffer, and the concentration of intercalating dye such as ethidium bromide if used during electrophoresis.
Smaller molecules travel faster than larger molecules in gel, and double-stranded DNA moves at a rate that is inversely proportional to the logarithm of the number of base pairs.
This relationship however breaks down with very large DNA fragments, and separation of very large DNA fragments requires the use of pulsed field gel electrophoresis (PFGE), which applies alternating current from two different directions and the large DNA fragments are separated as they reorient themselves with the changing current.
For standard agarose gel electrophoresis, larger molecules are resolved better using a low concentration gel while smaller molecules separate better at high concentration gel.
High concentrations gel however requires longer run times (sometimes days).
The movement of the DNA may be affected by the conformation of the DNA molecule, for example, supercoiled DNA usually moves faster than relaxed DNA because it is tightly coiled and hence more compact.
In a normal plasmid DNA preparation, multiple forms of DNA may be present.
Gel electrophoresis of the plasmids would normally show the negatively supercoiled form as the main band, while nicked DNA (open circular form) and the relaxed closed circular form appears as minor bands.
The rate at which the various forms move however can change using different electrophoresis conditions, and the mobility of larger circular DNA may be more strongly affected than linear DNA by the pore size of the gel.
Ethidium bromide which intercalates into circular DNA can change the charge, length, as well as the superhelicity of the DNA molecule, therefore its presence in gel during electrophoresis can affect its movement.
For example, the positive charge of ethidium bromide can reduce the DNA movement by 15 %.
Agarose gel electrophoresis can be used to resolve circular DNA with different supercoiling topology.
DNA damage due to increased cross-linking will also reduce electrophoretic DNA migration in a dose-dependent way.
The rate of migration of the DNA is proportional to the voltage applied, i.e. the higher the voltage, the faster the DNA moves.
The resolution of large DNA fragments however is lower at high voltage.
The mobility of DNA may also change in an unsteady field – in a field that is periodically reversed, the mobility of DNA of a particular size may drop significantly at a particular cycling frequency.
This phenomenon can result in band inversion in field inversion gel electrophoresis (FIGE), whereby larger DNA fragments move faster than smaller ones.
The negative charge of its phosphate backbone moves the DNA towards the positively charged anode during electrophoresis.
However, the migration of DNA molecules in solution, in the absence of a gel matrix, is independent of molecular weight during electrophoresis.
The gel matrix is therefore responsible for the separation of DNA by size during electrophoresis, and a number of models exist to explain the mechanism of separation of biomolecules in gel matrix.
A widely accepted one is the Ogston model which treats the polymer matrix as a sieve.
A globular protein or a random coil DNA moves through the interconnected pores, and the movement of larger molecules is more likely to be impeded and slowed down by collisions with the gel matrix, and the molecules of different sizes can therefore be separated in this sieving process.
The Ogston model however breaks down for large molecules whereby the pores are significantly smaller than size of the molecule.
For DNA molecules of size greater than 1 kb, a reptation model (or its variants) is most commonly used.
This model assumes that the DNA can crawl in a "snake-like" fashion (hence "reptation") through the pores as an elongated molecule.
A biased reptation model applies at higher electric field strength, whereby the leading end of the molecule become strongly biased in the forward direction and pulls the rest of the molecule along.
Real-time fluorescence microscopy of stained molecules, however, showed more subtle dynamics during electrophoresis, with the DNA showing considerable elasticity as it alternately stretching in the direction of the applied field and then contracting into a ball, or becoming hooked into a U-shape when it gets caught on the polymer fibres.
The details of an agarose gel electrophoresis experiment may vary depending on methods, but most follow a general procedure.
The gel is prepared by dissolving the agarose powder in an appropriate buffer, such as TAE or TBE, to be used in electrophoresis.
The agarose is dispersed in the buffer before heating it to near-boiling point, but avoid boiling.
The melted agarose is allowed to cool sufficiently before pouring the solution into a cast as the cast may warp or crack if the agarose solution is too hot.
A comb is placed in the cast to create wells for loading sample, and the gel should be completely set before use.
The concentration of gel affects the resolution of DNA separation.
The agarose gel is composed of microscopic pores through which the molecules travel, and there is an inverse relationship between the pore size of the agarose gel and the concentration – pore size decreases as the density of agarose fibers increases.
High gel concentration improves separation of smaller DNA molecules, while lowering gel concentration permits large DNA molecules to be separated.
The process allows fragments ranging from 50 base pairs to several mega bases to be separated depending on the gel concentration used.
The concentration is measured in weight of agarose over volume of buffer used (g/ml).
For a standard agarose gel electrophoresis, a 0.8 % gel gives good separation or resolution of large 5 – 10 kb DNA fragments, while 2 % gel gives good resolution for small 0.2 – 1 kb fragments.
1 % gels is often used for a standard electrophoresis.
High percentage gels are often brittle and may not set evenly, while low percentage gels (0.1 - 0.2 %) are fragile and not easy to handle.
Low-melting-point (LMP) agarose gels are also more fragile than normal agarose gel.
Low-melting point agarose may be used on its own or simultaneously with standard agarose for the separation and isolation of DNA.
PFGE and FIGE are often done with high percentage agarose gels.
Once the gel has set, the comb is removed, leaving wells where DNA samples can be loaded.
Loading buffer is mixed with the DNA sample before the mixture is loaded into the wells.
The loading buffer contains a dense compound, which may be glycerol, sucrose, or Ficoll, that raises the density of the sample so that the DNA sample may sink to the bottom of the well.
If the DNA sample contains residual ethanol after its preparation, it may float out of the well.
The loading buffer also includes colored dyes such as xylene cyanol and bromophenol blue used to monitor the progress of the electrophoresis.
The DNA samples are loaded using a pipette.
Agarose gel electrophoresis is most commonly done horizontally in a submarine mode whereby the slab gel is completely submerged in buffer during electrophoresis.
It is also possible, but less common, to perform the electrophoresis vertically, as well as horizontally with the gel raised on agarose legs using an appropriate apparatus.
The buffer used in the gel is the same as the running buffer in the electrophoresis tank, which is why electrophoresis in the submarine mode is possible with agarose gel.
For optimal resolution of DNA greater than 2 kb in size in standard gel electrophoresis, 5 to 8 V/cm is recommended (the distance in cm refers to the distance between electrodes, therefore this recommended voltage would be 5 to 8 multiplied by the distance between the electrodes in cm).
Voltage may also be limited by the fact that it heats the gel and may cause the gel to melt if it is run at high voltage for a prolonged period, especially if the gel used is LMP agarose gel.
Too high a voltage may also reduce resolution, as well as causing band streaking for large DNA molecules.
Too low a voltage may lead to broadening of band for small DNA fragments due to dispersion and diffusion.
Since DNA is not visible in natural light, the progress of the electrophoresis is monitored using colored dyes.
Xylene cyanol (light blue color) comigrates large DNA fragments, while Bromophenol blue (dark blue) comigrates with the smaller fragments.
Less commonly used dyes include Cresol Red and Orange G which migrate ahead of bromophenol blue.
A DNA marker is also run together for the estimation of the molecular weight of the DNA fragments.
Note however that the size of a circular DNA like plasmids cannot be accurately gauged using standard markers unless it has been linearized by restriction digest, alternatively a supercoiled DNA marker may be used.
DNA as well as RNA are normally visualized by staining with ethidium bromide, which intercalates into the major grooves of the DNA and fluoresces under UV light.
The intercalation depends on the concentration of DNA and thus, a band with high intensity will indicate a higher amount of DNA compared to a band of less intensity.
The ethidium bromide may be added to the agarose solution before it gels, or the DNA gel may be stained later after electrophoresis.
Destaining of the gel is not necessary but may produce better images.
Other methods of staining are available; examples are SYBR Green, GelRed, methylene blue, brilliant cresyl blue, Nile blue sulphate, and crystal violet.
SYBR Green, GelRed and other similar commercial products are sold as safer alternatives to ethidium bromide as it has been shown to be mutagenic in Ames test, although the carcinogenicity of ethidium bromide has not actually been established.
SYBR Green requires the use of a blue-light transilluminator.
DNA stained with crystal violet can be viewed under natural light without the use of a UV transilluminator which is an advantage, however it may not produce a strong band.
When stained with ethidium bromide, the gel is viewed with an ultraviolet (UV) transilluminator.
The UV light excites the electrons within the aromatic ring of ethidium bromide, and once they return to the ground state, light is released, making the DNA and ethidium bromide complex fluoresce.
Standard transilluminators use wavelengths of 302/312-nm (UV-B), however exposure of DNA to UV radiation for as little as 45 seconds can produce damage to DNA and affect subsequent procedures, for example reducing the efficiency of transformation, "in vitro" transcription, and PCR.
Exposure of the DNA to UV radiation therefore should be limited.
Using a higher wavelength of 365 nm (UV-A range) causes less damage to the DNA but also produces much weaker fluorescence with ethidium bromide.
Where multiple wavelengths can be selected in the transillumintor, the shorter wavelength would be used to capture images, while the longer wavelength should be used if it is necessary to work on the gel for any extended period of time.
The transilluminator apparatus may also contain image capture devices, such as a digital or polaroid camera, that allow an image of the gel to be taken or printed.
For gel electrophoresis of protein, the bands may be visualised with Coomassie or silver stains.
The separated DNA bands are often used for further procedures, and a DNA band may be cut out of the gel as a slice, dissolved and purified.
Contaminants however may affect some downstream procedures such as PCR, and low melting point agarose may be preferred in some cases as it contains fewer of the sulphates that can affect some enzymatic reactions.
The gels may also be used for blotting techniques.
In general, the ideal buffer should have good conductivity, produce less heat and have a long life.
There are a number of buffers used for agarose electrophoresis; common ones for nucleic acids include Tris/Acetate/EDTA (TAE) and Tris/Borate/EDTA (TBE).
The buffers used contain EDTA to inactivate many nucleases which require divalent cation for their function.
The borate in TBE buffer can be problematic as borate can polymerize, and/or interact with cis diols such as those found in RNA.
TAE has the lowest buffering capacity, but it provides the best resolution for larger DNA.
This means a lower voltage and more time, but a better product.
Many other buffers have been proposed, e.g. lithium borate (LB), iso electric histidine, pK matched goods buffers, etc.
; in most cases the purported rationale is lower current (less heat) and or matched ion mobilities, which leads to longer buffer life.
Tris-phosphate buffer has high buffering capacity but cannot be used if DNA extracted is to be used in phosphate sensitive reaction.
LB is relatively new and is ineffective in resolving fragments larger than 5 kbp; However, with its low conductivity, a much higher voltage could be used (up to 35 V/cm), which means a shorter analysis time for routine electrophoresis.
As low as one base pair size difference could be resolved in 3 % agarose gel with an extremely low conductivity medium (1 mM lithium borate).
Other buffering system may be used in specific applications, for example, barbituric acid-sodium barbiturate or Tris-barbiturate buffers may be used for in agarose gel electrophoresis of proteins, for example in the detection of abnormal distribution of proteins.
Agarose gels are easily cast and handled compared to other matrices and nucleic acids are not chemically altered during electrophoresis.
Samples are also easily recovered.
After the experiment is finished, the resulting gel can be stored in a plastic bag in a refrigerator.
Electrophoresis is performed in buffer solutions to reduce pH changes due to the electric field, which is important because the charge of DNA and RNA depends on pH, but running for too long can exhaust the buffering capacity of the solution.
Further, different preparations of genetic material may not migrate consistently with each other, for morphological or other reasons.
An allele (, from German Allel and Greek ἄλλος "állos" “ other ”) is a variant form of a given gene, meaning it is one of two or more versions of a known mutation at the same place on a chromosome.
It can also refer to different sequence variations for a several-hundred base-pair or more region of the genome that codes for a protein.
Alleles can come in different extremes of size.
At the lowest possible end one can be the single base choice of an SNP.
At the higher end, it can be the sequence variations for the regions of the genome that code for the same protein which can be up to several thousand base-pairs long.
Sometimes, different alleles can result in different observable phenotypic traits, such as different pigmentation.
A notable example of this trait of color variation is Gregor Mendel's discovery that the white and purple flower colors in pea plants were the result of "pure line" traits which could be used as a control for future experiments.
However, most alleles result in little or no observable phenotypic variation.
Most multicellular organisms have two sets of chromosomes; that is, they are diploid.
In this case, the chromosomes can be paired: each pair is made up of two homologous chromosomes.
If both alleles of a gene at the locus on the homologous chromosomes are the same, they and the organism are homozygous with respect to that gene.
If the alleles are different, they and the organism are heterozygous with respect to that gene.
The word "allele" is a short form of allelomorph ("other form", a word coined by British geneticists William Bateson and Edith Rebecca Saunders), which was used in the early days of genetics to describe variant forms of a gene detected as different phenotypes.
It derives from the Greek prefix ἀλληλο -, "allelo -", meaning "mutual", "reciprocal", or "each other", which itself is related to the Greek adjective ἄλλος, "allos" (cognate with Latin "alius"), meaning "other".
In many cases, genotypic interactions between the two alleles at a locus can be described as dominant or recessive, according to which of the two homozygous phenotypes the heterozygote most resembles.
Where the heterozygote is indistinguishable from one of the homozygotes, the allele expressed is the one that leads to the "dominant" phenotype, and the other allele is said to be "recessive".
The degree and pattern of dominance varies among loci.
This type of interaction was first formally described by Gregor Mendel.
However, many traits defy this simple categorization and the phenotypes are modeled by co-dominance and polygenic inheritance.
The term "wild type" allele is sometimes used to describe an allele that is thought to contribute to the typical phenotypic character as seen in "wild" populations of organisms, such as fruit flies ("Drosophila melanogaster").
Such a "wild type" allele was historically regarded as leading to a dominant (overpowering - always expressed), common, and normal phenotype, in contrast to "mutant" alleles that lead to recessive, rare, and frequently deleterious phenotypes.
It was formerly thought that most individuals were homozygous for the "wild type" allele at most gene loci, and that any alternative "mutant" allele was found in homozygous form in a small minority of "affected" individuals, often as genetic diseases, and more frequently in heterozygous form in "carriers" for the mutant allele.
It is now appreciated that most or all gene loci are highly polymorphic, with multiple alleles, whose frequencies vary from population to population, and that a great deal of genetic variation is hidden in the form of alleles that do not produce obvious phenotypic differences.
A population or species of organisms typically includes multiple alleles at each locus among various individuals.
Allelic variation at a locus is measurable as the number of alleles (polymorphism) present, or the proportion of heterozygotes in the population.
A null allele is a gene variant that lacks the gene's normal function because it either is not expressed, or the expressed protein is inactive.
For example, at the gene locus for the ABO blood type carbohydrate antigens in humans, classical genetics recognizes three alleles, I, I, and i, which determine compatibility of blood transfusions.
Any individual has one of six possible genotypes (II, Ii, II, Ii, II, and ii) which produce one of four possible phenotypes: "Type A" (produced by II homozygous and Ii heterozygous genotypes), "Type B" (produced by II homozygous and Ii heterozygous genotypes), "Type AB" produced by II heterozygous genotype, and "Type O" produced by ii homozygous genotype.
(It is now known that each of the A, B, and O alleles is actually a class of multiple alleles with different DNA sequences that produce proteins with identical properties: more than 70 alleles are known at the ABO locus.
Hence an individual with "Type A" blood may be an AO heterozygote, an AA homozygote, or an AA heterozygote with two different "A" alleles.)
The frequency of alleles in a diploid population can be used to predict the frequencies of the corresponding genotypes (see Hardy-Weinberg principle).
For a simple model, with two alleles; where "p" is the frequency of one allele and "q" is the frequency of the alternative allele, which necessarily sum to unity.
Then, "p" is the fraction of the population homozygous for the first allele, 2 "pq" is the fraction of heterozygotes, and "q" is the fraction homozygous for the alternative allele.
If the first allele is dominant to the second then the fraction of the population that will show the dominant phenotype is "p" + 2 "pq", and the fraction with the recessive phenotype is "q".
With three alleles: In the case of multiple alleles at a diploid locus, the number of possible genotypes (G) with a number of alleles (a) is given by the expression: A number of genetic disorders are caused when an individual inherits two recessive alleles for a single-gene trait.
Recessive genetic disorders include albinism, cystic fibrosis, galactosemia, phenylketonuria (PKU), and Tay–Sachs disease.
Other disorders are also due to recessive alleles, but because the gene locus is located on the X chromosome, so that males have only one copy (that is, they are hemizygous), they are more frequent in males than in females.
Examples include red-green color blindness and fragile X syndrome.
Other disorders, such as Huntington's disease, occur when an individual inherits only one dominant allele.
While heritable traits are typically studied in terms of genetic alleles, epigenetic marks such as DNA methylation can be inherited at specific genomic regions in certain species, a process termed transgenerational epigenetic inheritance.
The term "epiallele" is used to distinguish these heritable marks from traditional alleles, which are defined by nucleotide sequence.
A specific class of epiallele, the metastable epialleles, has been discovered in mice and in humans which is characterized by stochastic (probabilistic) establishment of epigenetic state that can be mitotically inherited.
Ampicillin is an antibiotic used to prevent and treat a number of bacterial infections, such as respiratory tract infections, urinary tract infections, meningitis, salmonellosis, and endocarditis.
It may also be used to prevent group B streptococcal infection in newborns.
It is used by mouth, by injection into a muscle, or intravenously.
Like all antibiotics, it is not useful for the treatment of viral infections.
Common side effects include rash, nausea, and diarrhea.
It should not be used in people who are allergic to penicillin.
Serious side effects may include "Clostridium difficile" colitis or anaphylaxis.
While usable in those with kidney problems, the dose may need to be decreased.
Its use during pregnancy and breastfeeding appears to be generally safe.
Ampicillin was discovered in 1958 and came into commercial use in 1961.
It is on the World Health Organization's List of Essential Medicines, the most effective and safe medicines needed in a health system.
Its wholesale cost in the developing world is between US $ 0.13 and 1.20 for a vial of the intravenous solution as of 2014.
In the United States, it is available as a generic medication and 10 days of treatment cost about $ 13.
Ampicillin used to also be used to treat gonorrhea, but there are now too many strains resistant to penicillins.
Ampicillin is used to treat infections by many Gram-positive and Gram-negative bacteria.
It was the first "broad spectrum" penicillin with activity against Gram-positive bacteria, including "Streptococcus pneumoniae", "Streptococcus pyogenes", some isolates of "Staphylococcus aureus" (but not penicillin-resistant or methicillin-resistant strains), "Trueperella", and some "Enterococcus".
It is one of the few antibiotics that works against multidrug resistant "Enterococcus faecalis" and "E. faecium".
Activity against Gram-negative bacteria includes "Neisseria meningitidis", some "Haemophilus influenzae", and some of the Enterobacteriaceae (though most Enterobacteriaceae and "Pseudomonas" are resistant).
Its spectrum of activity is enhanced by co-administration of sulbactam, a drug that inhibits beta lactamase, an enzyme produced by bacteria to inactivate ampicillin and related antibiotics.
It is sometimes used in combination with other antibiotics that have different mechanisms of action, like vancomycin, linezolid, daptomycin, and tigecycline.
Ampicillin can be administered by mouth, an intramuscular injection (shot) or by intravenous infusion.
The oral form, available as capsules or oral suspensions, is not given as an initial treatment for severe infections, but rather as a follow-up to an IM or IV injection.
For IV and IM injections, ampicillin is kept as a powder that must be reconstituted.
IV injections must be given slowly, as rapid IV injections can lead to convulsive seizures.
Ampicillin is one of the most used drugs in pregnancy, and has been found to be generally harmless both by the Food and Drug Administration in the U.S. (which classified it as category B) and the Therapeutic Goods Administration in Australia (which classified it as category A).
It is the drug of choice for treating "Listeria monocytogenes" in pregnant women, either alone or combined with an aminoglycoside.
Pregnancy increases the clearance of ampicillin by up to 50 %, and a higher dose is thus needed to reach therapeutic levels.
Ampicillin crosses the placenta and remains in the amniotic fluid at 50 – 100 % of the concentration in maternal plasma; this can lead to high concentrations of ampicillin in the newborn.
While lactating mothers secrete some ampicillin into their breast milk, the amount is minimal.
In newborns, ampicillin has a longer half-life and lower plasma protein binding.
The clearance by the kidneys is lower, as kidney function has not fully developed.
Ampicillin is contraindicated in those with a hypersensitivity to penicillins, as they can cause fatal anaphylactic reactions.
Hypersensitivity reactions can include frequent skin rashes and hives, exfoliative dermatitis, erythema multiforme, and a temporary decrease in both red and white blood cells.
Ampicillin is not recommended in people with concurrent mononucleosis, as over 40 % of patients develop a skin rash.
Ampicillin is comparatively less toxic than other antibiotics, and side effects are more likely in those who are sensitive to penicillins and those with a history of asthma or allergies.
In very rare cases, it causes severe side effects such as angioedema, anaphylaxis, and "C. difficile" infection (that can range from mild diarrhea to serious pseudomembranous colitis).
Some develop black "furry" tongue.
Serious adverse effects also include seizures and serum sickness.
The most common side effects, experienced by about 10 % of users are diarrhea and rash.
Less common side effects can be nausea, vomiting, itching, and blood dyscrasias.
The gastrointestinal effects, such as hairy tongue, nausea, vomiting, diarrhea, and colitis, are more common with the oral form of penicillin.
Other conditions may develop up several weeks after treatment.
Ampicillin overdose can cause behavioral changes, confusion, blackouts, and convulsions, as well as neuromuscular hypersensitivity, electrolyte imbalance, and renal failure.
Ampicillin reacts with probenecid and methotrexate to decrease renal excretion.
Large doses of ampicillin can increase the risk of bleeding with concurrent use of warfarin and other oral anticoagulants, possibly by inhibiting platelet aggregation.
Ampicillin has been said to make oral contraceptives less effective, but this has been disputed.
It can be made less effective by other antibiotic, such as chloramphenicol, erythromycin, cephalosporins, and tetracyclines.
For example, tetracyclines inhibit protein synthesis in bacteria, reducing the target against which ampicillin acts.
If given at the same time as aminoglycosides, it can bind to it and inactivate it.
When administered separately, aminoglycosides and ampicillin can potentiate each other instead.
Ampicillin causes skin rashes more often when given with allopurinol.
Both the live cholera vaccine and live typhoid vaccine can be made ineffective if given with ampicillin.
Ampicillin is normally used to treat cholera and typhoid fever, lowering the immunological response that the body has to mount.
Ampicillin is in the penicillin group of beta-lactam antibiotics and is part of the aminopenicillin family.
It is roughly equivalent to amoxicillin in terms of activity.
Ampicillin is able to penetrate Gram-positive and some Gram-negative bacteria.
It differs from penicillin G, or benzylpenicillin, only by the presence of an amino group.
This amino group, present on both ampicillin and amoxicillin, helps these antibiotics pass through the pores of the outer membrane of Gram-negative bacteria, such as "E. coli", "Proteus mirabilis", "Salmonella enterica", and "Shigella".
Ampicillin acts as an irreversible inhibitor of the enzyme transpeptidase, which is needed by bacteria to make the cell wall.
It inhibits the third and final stage of bacterial cell wall synthesis in binary fission, which ultimately leads to cell lysis; therefore, ampicillin is usually bacteriolytic.
Ampicillin is well-absorbed from the GI tract (though food reduces its absorption), and reaches peak concentrations in one to two hours.
The bioavailability is around 62 % for parenteral routes.
Unlike other penicillins, which usually have bind 60 – 90 % to plasma proteins, ampicillin binds to only 15 – 20 %.
Ampicillin is distributed through most tissues, though it is concentrated in the liver and kidneys.
It can also be found in the cerebrospinal fluid when the meninges become inflamed (such as, for example, meningitis).
Some ampicillin is metabolized by hydrolyzing the beta-lactam ring to penicilloic acid, though most of it is excreted unchanged.
In the kidneys, it is filtered out mostly by tubular secretion; some also undergoes glomerular filtration, and the rest is excreted in the feces and bile.
Hetacillin and pivampicillin are ampicillin esters that have been developed to increase bioavailability.
Ampicillin has been used extensively to treat bacterial infections since 1961.
Until the introduction of ampicillin by the British company Beecham, penicillin therapies had only been effective against Gram-positive organisms such as staphylococci and streptococci.
Ampicillin (originally branded as "Penbritin") also demonstrated activity against Gram-negative organisms such as "H. influenzae", coliforms, and "Proteus" spp.
, ampicillin's wholesale cost is between US $ 0.13 and 1.20 for a vial of the intravenous solution.
In the United States, it is available as a generic medication: 10 days of treatment cost about $ 13.
In veterinary medicine, ampicillin is used in cats, dogs, and farm animals to treat: Horses are generally not treated with ampicillin, as they have low bioavailability of beta-lactams.
The half-life in animals is around that same of that in humans (just over an hour).
Oral absorption is less than 50 % in cats and dogs, and less than 4 % in horses.
Antimicrobial resistance (AMR or AR) is the ability of a microbe to resist the effects of medication that once could successfully treat the microbe.
The term antibiotic resistance (AR or ABR) is a subset of AMR, as it applies only to bacteria becoming resistant to antibiotics.
Resistant microbes are more difficult to treat, requiring alternative medications or higher doses of antimicrobials.
These approaches may be more expensive, more toxic or both.
Microbes resistant to multiple antimicrobials are called multidrug resistant (MDR).
Those considered extensively drug resistant (XDR) or totally drug-resistant (TDR) are sometimes called "superbugs".
Resistance arises through one of three mechanisms: natural resistance in certain types of bacteria, genetic mutation, or by one species acquiring resistance from another.
All classes of microbes can develop resistance.
Fungi develop antifungal resistance.
Viruses develop antiviral resistance.
Protozoa develop antiprotozoal resistance, and bacteria develop antibiotic resistance.
Resistance can appear spontaneously because of random mutations.
However, extended use of antimicrobials appears to encourage selection for mutations which can render antimicrobials ineffective.
Preventive measures include only using antibiotics when needed, thereby stopping misuse of antibiotics or antimicrobials.
Narrow-spectrum antibiotics are preferred over broad-spectrum antibiotics when possible, as effectively and accurately targeting specific organisms is less likely to cause resistance, as well as side effects.
For people who take these medications at home, education about proper use is essential.
Health care providers can minimize spread of resistant infections by use of proper sanitation and hygiene, including handwashing and disinfecting between patients, and should encourage the same of the patient, visitors, and family members.
Rising drug resistance is caused mainly by use of antimicrobials in humans and other animals, and spread of resistant strains between the two.
Growing resistance has also been linked to dumping of inadequately treated effluents from the pharmaceutical industry, especially in countries where bulk drugs are manufactured.
Antibiotics increase selective pressure in bacterial populations, causing vulnerable bacteria to die; this increases the percentage of resistant bacteria which continue growing.
Even at very low levels of antibiotic, resistant bacteria can have a growth advantage and grow faster than vulnerable bacteria.
With resistance to antibiotics becoming more common there is greater need for alternative treatments.
Calls for new antibiotic therapies have been issued, but new drug development is becoming rarer.
Antimicrobial resistance is increasing globally because of greater access to antibiotic drugs in developing countries.
Estimates are that 700,000 to several million deaths result per year.
Each year in the United States, at least 2.8 million people become infected with bacteria that are resistant to antibiotics and at least 35,000 people die as a result.
There are public calls for global collective action to address the threat that include proposals for international treaties on antimicrobial resistance.
Worldwide antibiotic resistance is not completely identified, but poorer countries with weaker healthcare systems are more affected.
The WHO defines antimicrobial resistance as a microorganism's resistance to an antimicrobial drug that was once able to treat an infection by that microorganism.
A person cannot become resistant to antibiotics.
Resistance is a property of the microbe, not a person or other organism infected by a microbe.
Antibiotic resistance is a subset of antimicrobial resistance.
This more specified resistance is linked to pathogenic bacteria and thus broken down into two further subsets, microbiological and clinical.
Resistance linked microbiologically is the most common and occurs from genes, mutated or inherited, that allow the bacteria to resist the mechanism associated with certain antibiotics.
Clinical resistance is shown through the failure of many therapeutic techniques where the bacteria that are normally susceptible to a treatment become resistant after surviving the outcome of the treatment.
In both cases of acquired resistance, the bacteria can pass the genetic catalyst for resistance through conjugation, transduction, or transformation.
This allows the resistance to spread across the same pathogen or even similar bacterial pathogens.
The European Centre for Disease Prevention and Control calculated that in 2015 there were 671,689 infections in the EU and European Economic Area caused by antibiotic-resistant bacteria, resulting in 33,110 deaths.
Most were acquired in healthcare settings.
Bacteria with resistance to antibiotics predate medical use of antibiotics by humans.
However, widespread antibiotic use has made more bacteria resistant through the process of evolutionary pressure.
Reasons for the widespread use of antibiotics in human medicine include: Other causes include: Antiseptics create AMR to antibiotics and other antiseptics: Antiseptics appear to activate tolerance mechanisms in bacteria, which offer them protection against a range of antiseptics as well as antibiotics.
Antiseptics are used for cleaning in hospitals and in many wound care dressings.
These findings may explain the increase in treatment-resistant hospital infections.
Exposure to low doses of the antiseptic octenidine allowed several different strains of "Pseudomonas aeruginosa" to develop cross-tolerance to other antiseptics and to several different antibiotics.
The level of tolerance was substantial, i.e. in several cases a 32-fold increase in concentrations of the antiseptic was required to obtain the same antimicrobial effect.
Also, this increased resistance was permanent.
The same group also reported that "Klebsiella pneumoniae" was able to develop tolerance to chlorhexidine and that 5 out of 6 strains showed cross-resistance to the last-resort antibiotic, colistin.
Increasing bacterial resistance is linked with the volume of antibiotic prescribed, as well as missing doses when taking antibiotics.
Inappropriate prescribing of antibiotics has been attributed to a number of causes, such as patients insisting on antibiotics and physicians prescribing them as they do not have time to explain why they are not necessary.
Another cause can be physicians not knowing when to prescribe antibiotics or being overly cautious for medical or legal reasons.
For example, 70 to 80 percent of diarrhea is caused by viral pathogens, for which antibiotics are not effective.
But nevertheless, around 40 percent of these cases are attempted to be treated with antibiotics.
In some areas even over 80 percent of such cases are attempted to be treated with antibiotics.
Lower antibiotic concentration contributes to the increase of AMR by introducing more mutations that support bacterial growth in higher antibiotic concentration.
For example, sub-inhibitory concentration have induced genetic mutation in bacteria such as "Pseudomonas aeruginosa" and "Bacteroides fragilis".
Up to half of antibiotics used in humans are unnecessary and inappropriate.
For example, a third of people believe that antibiotics are effective for the common cold, and the common cold is the most common reason antibiotics are prescribed even though antibiotics are useless against viruses.
A single regimen of antibiotics even in compliant individuals leads to a greater risk of resistant organisms to that antibiotic in the person for a month to possibly a year.
Antibiotic resistance increases with duration of treatment.
Therefore, as long as an effective minimum is kept, shorter courses of antibiotics are likely to decrease rates of resistance, reduce cost, and have better outcomes with fewer complications.
Short course regimens exist for community-acquired pneumonia spontaneous bacterial peritonitis, suspected lung infections in intense care wards, so-called acute abdomen, middle ear infections, sinusitis and throat infections, and penetrating gut injuries.
In some situations a short course may not cure the infection as well as a long course.
A BMJ editorial recommended that antibiotics can often be safely stopped 72 hours after symptoms resolve.
Because individuals may feel better before the infection is eradicated, doctors must provide instructions to them so they know when it is safe to stop taking a prescription.
Some researchers advocate doctors' using a very short course of antibiotics, reevaluating the patient after a few days, and stopping treatment if there are no clinical signs of infection.
Certain antibiotic classes result in resistance more than others.
Increased rates of MRSA infections are seen when using glycopeptides, cephalosporins, and quinolone antibiotics.
Cephalosporins, and particularly quinolones and clindamycin, are more likely to produce colonisation with "Clostridium difficile".
Factors within the intensive care unit setting such as mechanical ventilation and multiple underlying diseases also appear to contribute to bacterial resistance.
Poor hand hygiene by hospital staff has been associated with the spread of resistant organisms.
Counterfeit medications may contain sub-therapeutic concentrations of antibiotics, designed to reduce the chance of detection, and this by definition, increases antimicrobial resistance.
The World Health Organization concluded that inappropriate use of antibiotics in animal husbandry is an underlying contributor to the emergence and spread of antibiotic-resistant germs, and that the use of antibiotics as growth promoters in animal feeds should be restricted.
The World Organisation for Animal Health has added to the Terrestrial Animal Health Code a series of guidelines with recommendations to its members for the creation and harmonization of national antimicrobial resistance surveillance and monitoring programs, monitoring of the quantities of antibiotics used in animal husbandry, and recommendations to ensure the proper and prudent use of antibiotic substances.
Another guideline is to implement methodologies that help to establish associated risk factors and assess the risk of antibiotic resistance.
Naturally occurring antibiotic resistance is common.
Genes for resistance to antibiotics, like antibiotics themselves, are ancient.
The genes that confer resistance are known as the environmental resistome.
These genes may be transferred from non-disease-causing bacteria to those that do cause disease, leading to clinically significant antibiotic resistance.
In 1952 it was shown that penicillin-resistant bacteria existed before penicillin treatment; and also preexistent bacterial resistance to streptomycin.
In 1962, the presence of penicillinase was detected in dormant endospores of "Bacillus licheniformis", revived from dried soil on the roots of plants, preserved since 1689 in the British Museum.
Six strains of "Clostridium", found in the bowels of William Braine and John Hartnell (members of the Franklin Expedition) showed resistance to cefoxitin and clindamycin.
Penicillinase may have emerged as a defense mechanism for bacteria in their habitats, such as the case of penicillinase-rich "Staphylococcus aureus", living with penicillin-producing "Trichophyton"; however, this may be circumstantial.
Search for a penicillinase ancestor has focused on the class of proteins that must be "a priori" capable of specific combination with penicillin.
The resistance to cefoxitin and clindamycin in turn was attributed to Braine's and Hartnell's contact with microorganisms that naturally produce them or random mutation in the chromosomes of "Clostridium" strains.
There is evidence that heavy metals and other pollutants may select for antibiotic-resistant bacteria, generating a constant source of them in small numbers.
Antibiotic resistance is a growing problem among humans and wildlife in terrestrial or aquatic environments.
In this respect, the spread and contamination of the environment, especially through water pollution "hot spots" such as hospital wastewater and untreated urban wastewater, is a growing and serious public health problem.
Antibiotics have been polluting the environment since their introduction through human waste (medication, farming), animals, and the pharmaceutical industry.
The contribution of the pharmaceutical industry is so significant that parallels can be drawn between countries with highest rate of increasing antibiotic resistance and countries with largest footprint of pharmaceutical industry.
China, which contributes to nearly 40 percent of the world's active pharmaceutical ingredient (API) manufacturing, has seen a 22 per cent increase in rate of antimicrobial resistance in six years, compared to a 6 per cent increase in the United States.
Along with antibiotic waste, resistant bacteria follow, thus introducing antibiotic-resistant bacteria into the environment.
Already in 2011, mapping of sewage and water supply samples in New Delhi showed widespread and uncontrolled infection as indicated by the presence of NDM-1 - positive enteric bacteria (New Delhi metallo-beta-lactamase 1).
As bacteria replicate quickly, the resistant bacteria that enter water bodies through wastewater replicate their resistance genes as they continue to divide.
In addition, bacteria carrying resistance genes have the ability to spread those genes to other species via horizontal gene transfer.
Therefore, even if the specific antibiotic is no longer introduced into the environment, antibiotic-resistance genes will persist through the bacteria that have since replicated without continuous exposure.
Antibiotic resistance is widespread in marine vertebrates, and they may be important reservoirs of antibiotic-resistant bacteria in the marine environment.
There have been increasing public calls for global collective action to address the threat, including a proposal for international treaty on antimicrobial resistance.
Further detail and attention is still needed in order to recognize and measure trends in resistance on the international level; the idea of a global tracking system has been suggested but implementation has yet to occur.
A system of this nature would provide insight to areas of high resistance as well as information necessary for evaluation of programs and other changes made to fight or reverse antibiotic resistance.
Antibiotic treatment duration should be based on the infection and other health problems a person may have.
For many infections once a person has improved there is little evidence that stopping treatment causes more resistance.
Some therefore feel that stopping early may be reasonable in some cases.
Other infections, however, do require long courses regardless of whether a person feels better.
There are multiple national and international monitoring programs for drug-resistant threats, including methicillin-resistant "Staphylococcus aureus" (MRSA), vancomycin-resistant "S. aureus" (VRSA), extended spectrum beta-lactamase (ESBL), vancomycin-resistant "Enterococcus" (VRE), multidrug-resistant "A. baumannii" (MRAB).
ResistanceOpen is an online global map of antimicrobial resistance developed by HealthMap which displays aggregated data on antimicrobial resistance from publicly available and user submitted data.
The website can display data for a 25-mile radius from a location.
Users may submit data from antibiograms for individual hospitals or laboratories.
European data is from the EARS-Net (European Antimicrobial Resistance Surveillance Network), part of the ECDC.
ResistanceMap is a website by the Center for Disease Dynamics, Economics & Policy and provides data on antimicrobial resistance on a global level.
Antibiotic stewardship programmes appear useful in reducing rates of antibiotic resistance.
The antibiotic stewardship program will also provide pharmacists with the knowledge to educate patients that antibiotics will not work for a virus.
Excessive antibiotic use has become one of the top contributors to the development of antibiotic resistance.
Since the beginning of the antibiotic era, antibiotics have been used to treat a wide range of disease.
Overuse of antibiotics has become the primary cause of rising levels of antibiotic resistance.
The main problem is that doctors are willing to prescribe antibiotics to ill-informed individuals who believe that antibiotics can cure nearly all illnesses, including viral infections like the common cold.
In an analysis of drug prescriptions, 36 % of individuals with a cold or an upper respiratory infection (both viral in origin) were given prescriptions for antibiotics.
These prescriptions accomplished nothing other than increasing the risk of further evolution of antibiotic resistant bacteria.
Antimicrobial stewardship teams in hospitals are encouraging optimal use of antimicrobials.
The goals of antimicrobial stewardship are to help practitioners pick the right drug at the right dose and duration of therapy while preventing misuse and minimizing the development of resistance.
Stewardship may reduce the length of stay by an average of slightly over 1 day while not increasing the risk of death.
It is established that the use of antibiotics in animal husbandry can give rise to AMR resistances in bacteria found in food animals to the antibiotics being administered (through injections or medicated feeds).
For this reason antimicrobials that are deemed "not-clinically relevant" are used in these practices.
Recent studies have shown that the prophylactic use of "non-priority" or "non-clinically relevant" antimicrobials in feeds can potentially, under certain conditions, lead to co-selection of environmental AMR bacteria with resistance to medically important antibiotics.
The possibility for co-selection of AMR resistances in the food chain pipeline may have far-reaching implications for human health.
Given the volume of care provided in primary care (General Practice), recent strategies have focused on reducing unnecessary antibiotic prescribing in this setting.
Simple interventions, such as written information explaining the futility of antibiotics for common infections such as upper respiratory tract infections, have been shown to reduce antibiotic prescribing.
The prescriber should closely adhere to the five rights of drug administration: the right patient, the right drug, the right dose, the right route, and the right time.
Cultures should be taken before treatment when indicated and treatment potentially changed based on the susceptibility report.
About a third of antibiotic prescriptions written in outpatient settings in the United States were not appropriate in 2010 and 2011.
Doctors in the U.S. wrote 506 annual antibiotic scripts for every 1,000 people, with 353 being medically necessary.
Health workers and pharmacists can help tackle resistance by: enhancing infection prevention and control; only prescribing and dispensing antibiotics when they are truly needed; prescribing and dispensing the right antibiotic (s) to treat the illness.
People can help tackle resistance by using antibiotics only when prescribed by a doctor; completing the full prescription, even if they feel better; never sharing antibiotics with others or using leftover prescriptions.
Infectious disease control through improved water, sanitation and hygiene (WASH) infrastructure needs to be included in the antimicrobial resistance (AMR) agenda.
The "Interagency Coordination Group on Antimicrobial Resistance" stated in 2018 that "the spread of pathogens through unsafe water results in a high burden of gastrointestinal disease, increasing even further the need for antibiotic treatment."
This is particularly a problem in developing countries where the spread of infectious diseases caused by inadequate WASH standards is a major driver of antibiotic demand.
Growing usage of antibiotics together with persistent infectious disease levels have led to a dangerous cycle in which reliance on antimicrobials increases while the efficacy of drugs diminishes.
The proper use of infrastructure for water, sanitation and hygiene (WASH) can result in a 47 – 72 percent decrease of diarrhea cases treated with antibiotics depending on the type of intervention and its effectiveness.
A reduction of the diarrhea disease burden through improved infrastructure would result in large decreases in the number of diarrhea cases treated with antibiotics.
This was estimated as ranging from 5 million in Brazil to up to 590 million in India by the year 2030.
The strong link between increased consumption and resistance indicates that this will directly mitigate the accelerating spread of AMR.
Sanitation and water for all by 2030 is Goal Number 6 of the Sustainable Development Goals.
An increase in hand washing compliance by hospital staff results in decreased rates of resistant organisms.
Water supply and sanitation infrastructure in health facilities offer significant co-benefits for combatting AMR, and investment should be increased.
There is much room for improvement: WHO and UNICEF estimated in 2015 that globally 38 % of health facilities did not have a source of water, nearly 19 % had no toilets and 35 % had no water and soap or alcohol-based hand rub for handwashing.
Manufacturers of antimicrobials need to improve the treatment of their wastewater (by using industrial wastewater treatment processes) to reduce the release of residues into the environment.
In 1997, European Union health ministers voted to ban avoparcin and four additional antibiotics used to promote animal growth in 1999.
In 2006 a ban on the use of antibiotics in European feed, with the exception of two antibiotics in poultry feeds, became effective.
In Scandinavia, there is evidence that the ban has led to a lower prevalence of antibiotic resistance in (nonhazardous) animal bacterial populations.
As of 2004, several European countries established a decline of antimicrobial resistance in humans through limiting the usage antimicrobials in agriculture and food industries without jeopardizing animal health or economic cost.
The United States Department of Agriculture (USDA) and the Food and Drug Administration (FDA) collect data on antibiotic use in humans and in a more limited fashion in animals.
The FDA first determined in 1977 that there is evidence of emergence of antibiotic-resistant bacterial strains in livestock.
The long-established practice of permitting OTC sales of antibiotics (including penicillin and other drugs) to lay animal owners for administration to their own animals nonetheless continued in all states.
In 2000, the FDA announced their intention to revoke approval of fluoroquinolone use in poultry production because of substantial evidence linking it to the emergence of fluoroquinolone-resistant "Campylobacter" infections in humans.
Legal challenges from the food animal and pharmaceutical industries delayed the final decision to do so until 2006.
Fluroquinolones have been banned from extra-label use in food animals in the USA since 2007.
However, they remain widely used in companion and exotic animals.
The increasing interconnectedness of the world and the fact that new classes of antibiotics have not been developed and approved for more than 25 years highlight the extent to which antimicrobial resistance is a global health challenge.
A global action plan to tackle the growing problem of resistance to antibiotics and other antimicrobial medicines was endorsed at the Sixty-eighth World Health Assembly in May 2015.
One of the key objectives of the plan is to improve awareness and understanding of antimicrobial resistance through effective communication, education and training.
This global action plan developed by the World Health Organization was created to combat the issue of antimicrobial resistance and was guided by the advice of countries and key stakeholders.
The WHO's global action plan is composed of five key objectives that can be targeted through different means, and represents countries coming together to solve a major problem that can have future health consequences.
These objectives are as follows: Steps towards progress The World Health Organization has promoted the first World Antibiotic Awareness Week running from 16 – 22 November 2015.
The aim of the week is to increase global awareness of antibiotic resistance.
It also wants to promote the correct usage of antibiotics across all fields in order to prevent further instances of antibiotic resistance.
World Antibiotic Awareness Week has been held every November since 2015.
For 2017, the Food and Agriculture Organization of the United Nations (FAO), the World Health Organization (WHO) and the World Organisation for Animal Health (OIE) are together calling for responsible use of antibiotics in humans and animals to reduce the emergence of antibiotic resistance.
United Nations In 2016 the Secretary-General of the United Nations convened the Interagency Coordination Group (IACG) on Antimicrobial Resistance.
The IACG worked with international organizations and experts in human, animal, and plant health to create a plan to fight antimicrobial resistance.
Their report released in April 2019 highlights the seriousness of antimicrobial resistance and the threat is poses to world health.
It suggests five recommendations for member states to follow in order to tackle this increasing threat.
The IACG recommendations are as follows: The four main mechanisms by which bacteria exhibit resistance to antibiotics are: In gram-negative bacteria, plasmid-mediated resistance genes produce proteins that can bind to DNA gyrase, protecting it from the action of quinolones.
Finally, mutations at key sites in DNA gyrase or topoisomerase IV can decrease their binding affinity to quinolones, decreasing the drug's effectiveness.
Some bacteria are naturally resistant to certain antibiotics; for example, gram-negative bacteria are resistant to most β-lactam antibiotics due to the presence of β-lactamase.
Antibiotic resistance can also be acquired as a result of either genetic mutation or horizontal gene transfer.
Although mutations are rare, with spontaneous mutations in the pathogen genome occurring at a rate of about 1 in 10 to 1 in 10 per chromosomal replication, the fact that bacteria reproduce at a high rate allows for the effect to be significant.
Given that lifespans and production of new generations can be on a timescale of mere hours, a new (de novo) mutation in a parent cell can quickly become an inherited mutation of widespread prevalence, resulting in the microevolution of a fully resistant colony.
However, chromosomal mutations also confer a cost of fitness.
For example, a ribosomal mutation may protect a bacterial cell by changing the binding site of an antibiotic but will also slow protein synthesis.
manifesting, in slower growth rate.
Moreover, some adaptive mutations can propagate not only through inheritance but also through horizontal gene transfer.
The most common mechanism of horizontal gene transfer is the transferring of plasmids carrying antibiotic resistance genes between bacteria of the same or different species via conjugation.
However, bacteria can also acquire resistance through transformation, as in "Streptococcus pneumoniae" uptaking of naked fragments of extracellular DNA that contain antibiotic resistance genes to streptomycin, through transduction, as in the bacteriophage-mediated transfer of tetracycline resistance genes between strains of "S. pyogenes", or through gene transfer agents, which are particles produced by the host cell that resemble bacteriophage structures and are capable of transferring DNA.
Antibiotic resistance can be introduced artificially into a microorganism through laboratory protocols, sometimes used as a selectable marker to examine the mechanisms of gene transfer or to identify individuals that absorbed a piece of DNA that included the resistance gene and another gene of interest.
Recent findings show no necessity of large populations of bacteria for the appearance of antibiotic resistance.
Small populations of "E. coli" in an antibiotic gradient can become resistant.
Any heterogeneous environment with respect to nutrient and antibiotic gradients may facilitate antibiotic resistance in small bacterial populations.
Researchers hypothesize that the mechanism of resistance development is based on four SNP mutations in the genome of "E. coli" produced by the gradient of antibiotic.
In recent years, the emergence and spread of β-lactamases called carbapenemases has become a major health crisis.
One such carbapenemase is New Delhi metallo-beta-lactamase 1 (NDM-1), an enzyme that makes bacteria resistant to a broad range of beta-lactam antibiotics.
The most common bacteria that make this enzyme are gram-negative such as "Escherichia coli" and "Klebsiella pneumoniae", but the gene for NDM-1 can spread from one strain of bacteria to another by horizontal gene transfer.
Specific antiviral drugs are used to treat some viral infections.
These drugs prevent viruses from reproducing by inhibiting essential stages of the virus's replication cycle in infected cells.
Antivirals are used to treat HIV, hepatitis B, hepatitis C, influenza, herpes viruses including varicella zoster virus, cytomegalovirus and Epstein-Barr virus.
With each virus, some strains have become resistant to the administered drugs.
Antiviral drugs typically target key components of viral reproduction; for example, oseltamivir targets influenza neuraminidase, while guanosine analogs inhibit viral DNA polymerase.
Resistance to antivirals is thus acquired through mutations in the genes that encode the protein targets of the drugs.
Resistance to HIV antivirals is problematic, and even multi-drug resistant strains have evolved.
One source of resistance is that many current HIV drugs, including NRTIs and NNRTIs, target reverse transcriptase; however, HIV-1 reverse transcriptase is highly error prone and thus mutations conferring resistance arise rapidly.
Resistant strains of the HIV virus emerge rapidly if only one antiviral drug is used.
Using three or more drugs together, termed combination therapy, has helped to control this problem, but new drugs are needed because of the continuing emergence of drug-resistant HIV strains.
Infections by fungi are a cause of high morbidity and mortality in immunocompromised persons, such as those with HIV/AIDS, tuberculosis or receiving chemotherapy.
The fungi candida, "Cryptococcus neoformans" and "Aspergillus fumigatus" cause most of these infections and antifungal resistance occurs in all of them.
Multidrug resistance in fungi is increasing because of the widespread use of antifungal drugs to treat infections in immunocompromised individuals.
Of particular note, Fluconazole-resistant Candida species have been highlighted as a growing problem by the CDC.
More than 20 species of Candida can cause Candidiasis infection, the most common of which is "Candida albicans".
Candida yeasts normally inhabit the skin and mucous membranes without causing infection.
However, overgrowth of Candida can lead to Candidiasis.
Some Candida strains are becoming resistant to first-line and second-line antifungal agents such as azoles and echinocandins.
The protozoan parasites that cause the diseases malaria, trypanosomiasis, toxoplasmosis, cryptosporidiosis and leishmaniasis are important human pathogens.
Malarial parasites that are resistant to the drugs that are currently available to infections are common and this has led to increased efforts to develop new drugs.
Resistance to recently developed drugs such as artemisinin has also been reported.
The problem of drug resistance in malaria has driven efforts to develop vaccines.
Trypanosomes are parasitic protozoa that cause African trypanosomiasis and Chagas disease (American trypanosomiasis).
There are no vaccines to prevent these infections so drugs such as pentamidine and suramin, benznidazole and nifurtimox are used to treat infections.
These drugs are effective but infections caused by resistant parasites have been reported.
Leishmaniasis is caused by protozoa and is an important public health problem worldwide, especially in sub-tropical and tropical countries.
Drug resistance has "become a major concern".
The discovery of penicillin in 1928 and other antibiotics in the 20th century proved to be a significant medical achievement, saving millions of lives and significantly reducing the burden of infectious diseases.
